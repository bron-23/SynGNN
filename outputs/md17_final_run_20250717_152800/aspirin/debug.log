2025-07-17 15:28:03,136 - logger.py:50 - --- Starting training for aspirin ---
2025-07-17 15:28:03,136 - logger.py:50 - Namespace(amp=False, batch_size=80, clip_grad=1.0, contrastive_aug_mask_ratio=0.15, contrastive_loss_weight=0.1, contrastive_mask_token_idx=0, contrastive_prioritize_heteroatoms=False, contrastive_projection_dim=128, contrastive_temp=0.1, cooldown_epochs=10, data_path='data/md17', decay_rate=0.1, delta_frame=3000, device='cuda:0', drop_path=0.0, empp_atom_type_embed_irreps='16x0e', empp_loss_weight=0.5, empp_num_mask=1, empp_pos_pred_num_s2_channels=32, empp_pos_pred_res_s2grid=100, empp_pos_pred_temp_label=0.1, empp_pos_pred_temp_softmax=0.1, empp_prioritize_heteroatoms=True, empp_ssp_feature_dim='16x0e', enable_contrastive=False, epochs=500, exp_name='md17_final_run_20250717_152800', logger=<logger.FileLogger object at 0x7f2678399b20>, loss='l2', lr=0.0004, max_test_samples=2000, max_train_samples=500, max_val_samples=2000, min_lr=1e-06, model_name='graph_attention_transformer_nonlinear_l2', molecule_type='aspirin', momentum=0.9, num_basis=128, opt='adamw', opt_betas=None, opt_eps=1e-08, output_dir='outputs/md17_final_run_20250717_152800', patience_epochs=10, pin_mem=True, print_freq=50, radius=5.0, sched='cosine', seed=42, ssp=True, warmup_epochs=10, warmup_lr=1e-06, weight_decay=1e-06, workers=8)
2025-07-17 15:28:03,137 - logger.py:50 - Loading datasets...
2025-07-17 15:28:03,145 - logger.py:50 - Creating model...
2025-07-17 15:28:12,171 - logger.py:50 - Number of params: 3,205,881
2025-07-17 15:28:17,991 - logger.py:50 - Epoch: [0][0/6]	Total Loss: 1.53522	Main MSE (x10^-2): 153.5224	LR: 1.00e-06	EMPP_Raw: 2.57386
2025-07-17 15:28:43,363 - logger.py:50 - Epoch: [0][5/6]	Total Loss: 1.53259	Main MSE (x10^-2): 153.2595	LR: 1.00e-06	EMPP_Raw: 2.57613
2025-07-17 15:28:43,383 - logger.py:50 - Epoch 0 Training Summary: Avg Total Loss: 1.53259, Avg Main MSE: 1.53259, Time: 31.21s
2025-07-17 15:29:22,682 - logger.py:50 - *** New Best Val MSE (x10^-2): 24.3111, Corresponding Test MSE (x10^-2): 24.4981 at Epoch 0 ***
2025-07-17 15:29:22,727 - logger.py:50 - Epoch 0 Summary | Train MSE (x10^-2): 153.2595 | Val MSE (x10^-2): 24.3111 | Time: 70.55s
2025-07-17 15:29:26,743 - logger.py:50 - Epoch: [1][0/6]	Total Loss: 1.61183	Main MSE (x10^-2): 161.1834	LR: 1.00e-06	EMPP_Raw: 2.67878
2025-07-17 15:29:46,070 - logger.py:50 - Epoch: [1][5/6]	Total Loss: 1.51679	Main MSE (x10^-2): 151.6792	LR: 1.00e-06	EMPP_Raw: 2.54529
2025-07-17 15:29:46,111 - logger.py:50 - Epoch 1 Training Summary: Avg Total Loss: 1.51679, Avg Main MSE: 1.51679, Time: 23.38s
2025-07-17 15:30:25,290 - logger.py:50 - *** New Best Val MSE (x10^-2): 24.2993, Corresponding Test MSE (x10^-2): 24.4862 at Epoch 1 ***
2025-07-17 15:30:25,338 - logger.py:50 - Epoch 1 Summary | Train MSE (x10^-2): 151.6792 | Val MSE (x10^-2): 24.2993 | Time: 62.61s
2025-07-17 15:30:29,671 - logger.py:50 - Epoch: [2][0/6]	Total Loss: 1.54728	Main MSE (x10^-2): 154.7283	LR: 4.09e-05	EMPP_Raw: 2.59827
2025-07-17 15:30:48,820 - logger.py:50 - Epoch: [2][5/6]	Total Loss: 1.32862	Main MSE (x10^-2): 132.8617	LR: 4.09e-05	EMPP_Raw: 2.17301
2025-07-17 15:30:48,853 - logger.py:50 - Epoch 2 Training Summary: Avg Total Loss: 1.32862, Avg Main MSE: 1.32862, Time: 23.51s
2025-07-17 15:31:27,915 - logger.py:50 - *** New Best Val MSE (x10^-2): 23.8220, Corresponding Test MSE (x10^-2): 24.0078 at Epoch 2 ***
2025-07-17 15:31:27,961 - logger.py:50 - Epoch 2 Summary | Train MSE (x10^-2): 132.8617 | Val MSE (x10^-2): 23.8220 | Time: 62.62s
2025-07-17 15:31:31,983 - logger.py:50 - Epoch: [3][0/6]	Total Loss: 1.22230	Main MSE (x10^-2): 122.2302	LR: 8.08e-05	EMPP_Raw: 2.01226
2025-07-17 15:31:51,769 - logger.py:50 - Epoch: [3][5/6]	Total Loss: 1.18502	Main MSE (x10^-2): 118.5019	LR: 8.08e-05	EMPP_Raw: 1.90386
2025-07-17 15:31:51,808 - logger.py:50 - Epoch 3 Training Summary: Avg Total Loss: 1.18502, Avg Main MSE: 1.18502, Time: 23.84s
2025-07-17 15:32:31,266 - logger.py:50 - *** New Best Val MSE (x10^-2): 23.2508, Corresponding Test MSE (x10^-2): 23.4352 at Epoch 3 ***
2025-07-17 15:32:31,313 - logger.py:50 - Epoch 3 Summary | Train MSE (x10^-2): 118.5019 | Val MSE (x10^-2): 23.2508 | Time: 63.35s
2025-07-17 15:32:35,345 - logger.py:50 - Epoch: [4][0/6]	Total Loss: 1.15084	Main MSE (x10^-2): 115.0844	LR: 1.21e-04	EMPP_Raw: 1.83691
2025-07-17 15:32:54,617 - logger.py:50 - Epoch: [4][5/6]	Total Loss: 1.11244	Main MSE (x10^-2): 111.2444	LR: 1.21e-04	EMPP_Raw: 1.76168
2025-07-17 15:32:54,652 - logger.py:50 - Epoch 4 Training Summary: Avg Total Loss: 1.11244, Avg Main MSE: 1.11244, Time: 23.34s
2025-07-17 15:33:33,706 - logger.py:50 - *** New Best Val MSE (x10^-2): 22.8647, Corresponding Test MSE (x10^-2): 23.0352 at Epoch 4 ***
2025-07-17 15:33:33,874 - logger.py:50 - Epoch 4 Summary | Train MSE (x10^-2): 111.2444 | Val MSE (x10^-2): 22.8647 | Time: 62.56s
2025-07-17 15:33:37,916 - logger.py:50 - Epoch: [5][0/6]	Total Loss: 1.05726	Main MSE (x10^-2): 105.7264	LR: 1.61e-04	EMPP_Raw: 1.71487
2025-07-17 15:33:57,271 - logger.py:50 - Epoch: [5][5/6]	Total Loss: 1.06173	Main MSE (x10^-2): 106.1729	LR: 1.61e-04	EMPP_Raw: 1.67513
2025-07-17 15:33:57,305 - logger.py:50 - Epoch 5 Training Summary: Avg Total Loss: 1.06173, Avg Main MSE: 1.06173, Time: 23.43s
2025-07-17 15:34:39,545 - logger.py:50 - *** New Best Val MSE (x10^-2): 21.7718, Corresponding Test MSE (x10^-2): 21.8968 at Epoch 5 ***
2025-07-17 15:34:39,592 - logger.py:50 - Epoch 5 Summary | Train MSE (x10^-2): 106.1729 | Val MSE (x10^-2): 21.7718 | Time: 65.72s
2025-07-17 15:34:43,622 - logger.py:50 - Epoch: [6][0/6]	Total Loss: 1.00328	Main MSE (x10^-2): 100.3278	LR: 2.00e-04	EMPP_Raw: 1.62518
2025-07-17 15:35:02,765 - logger.py:50 - Epoch: [6][5/6]	Total Loss: 1.03902	Main MSE (x10^-2): 103.9020	LR: 2.00e-04	EMPP_Raw: 1.66073
2025-07-17 15:35:02,800 - logger.py:50 - Epoch 6 Training Summary: Avg Total Loss: 1.03902, Avg Main MSE: 1.03902, Time: 23.20s
2025-07-17 15:35:41,862 - logger.py:50 - *** New Best Val MSE (x10^-2): 20.1500, Corresponding Test MSE (x10^-2): 20.1707 at Epoch 6 ***
2025-07-17 15:35:41,909 - logger.py:50 - Epoch 6 Summary | Train MSE (x10^-2): 103.9020 | Val MSE (x10^-2): 20.1500 | Time: 62.32s
2025-07-17 15:35:45,941 - logger.py:50 - Epoch: [7][0/6]	Total Loss: 1.02355	Main MSE (x10^-2): 102.3546	LR: 2.40e-04	EMPP_Raw: 1.64435
2025-07-17 15:36:05,210 - logger.py:50 - Epoch: [7][5/6]	Total Loss: 1.02050	Main MSE (x10^-2): 102.0505	LR: 2.40e-04	EMPP_Raw: 1.65292
2025-07-17 15:36:05,248 - logger.py:50 - Epoch 7 Training Summary: Avg Total Loss: 1.02050, Avg Main MSE: 1.02050, Time: 23.34s
2025-07-17 15:36:44,419 - logger.py:50 - *** New Best Val MSE (x10^-2): 19.6717, Corresponding Test MSE (x10^-2): 19.5678 at Epoch 7 ***
2025-07-17 15:36:44,465 - logger.py:50 - Epoch 7 Summary | Train MSE (x10^-2): 102.0505 | Val MSE (x10^-2): 19.6717 | Time: 62.56s
2025-07-17 15:36:48,641 - logger.py:50 - Epoch: [8][0/6]	Total Loss: 0.99728	Main MSE (x10^-2): 99.7275	LR: 2.80e-04	EMPP_Raw: 1.61844
2025-07-17 15:37:07,897 - logger.py:50 - Epoch: [8][5/6]	Total Loss: 1.00204	Main MSE (x10^-2): 100.2037	LR: 2.80e-04	EMPP_Raw: 1.62312
2025-07-17 15:37:07,931 - logger.py:50 - Epoch 8 Training Summary: Avg Total Loss: 1.00204, Avg Main MSE: 1.00204, Time: 23.46s
2025-07-17 15:37:47,134 - logger.py:50 - *** New Best Val MSE (x10^-2): 19.0069, Corresponding Test MSE (x10^-2): 18.8866 at Epoch 8 ***
2025-07-17 15:37:47,181 - logger.py:50 - Epoch 8 Summary | Train MSE (x10^-2): 100.2037 | Val MSE (x10^-2): 19.0069 | Time: 62.71s
2025-07-17 15:37:51,209 - logger.py:50 - Epoch: [9][0/6]	Total Loss: 0.99586	Main MSE (x10^-2): 99.5863	LR: 3.20e-04	EMPP_Raw: 1.58878
2025-07-17 15:38:10,304 - logger.py:50 - Epoch: [9][5/6]	Total Loss: 0.99149	Main MSE (x10^-2): 99.1489	LR: 3.20e-04	EMPP_Raw: 1.61273
2025-07-17 15:38:10,337 - logger.py:50 - Epoch 9 Training Summary: Avg Total Loss: 0.99149, Avg Main MSE: 0.99149, Time: 23.15s
2025-07-17 15:38:49,428 - logger.py:50 - *** New Best Val MSE (x10^-2): 18.6340, Corresponding Test MSE (x10^-2): 18.5565 at Epoch 9 ***
2025-07-17 15:38:49,475 - logger.py:50 - Epoch 9 Summary | Train MSE (x10^-2): 99.1489 | Val MSE (x10^-2): 18.6340 | Time: 62.29s
2025-07-17 15:38:53,501 - logger.py:50 - Epoch: [10][0/6]	Total Loss: 0.97064	Main MSE (x10^-2): 97.0640	LR: 3.60e-04	EMPP_Raw: 1.59398
2025-07-17 15:39:12,772 - logger.py:50 - Epoch: [10][5/6]	Total Loss: 0.97570	Main MSE (x10^-2): 97.5696	LR: 3.60e-04	EMPP_Raw: 1.58487
2025-07-17 15:39:12,808 - logger.py:50 - Epoch 10 Training Summary: Avg Total Loss: 0.97570, Avg Main MSE: 0.97570, Time: 23.33s
2025-07-17 15:39:52,047 - logger.py:50 - *** New Best Val MSE (x10^-2): 18.5044, Corresponding Test MSE (x10^-2): 18.4196 at Epoch 10 ***
2025-07-17 15:39:52,094 - logger.py:50 - Epoch 10 Summary | Train MSE (x10^-2): 97.5696 | Val MSE (x10^-2): 18.5044 | Time: 62.62s
2025-07-17 15:39:56,135 - logger.py:50 - Epoch: [11][0/6]	Total Loss: 0.97497	Main MSE (x10^-2): 97.4969	LR: 4.00e-04	EMPP_Raw: 1.56288
2025-07-17 15:40:15,347 - logger.py:50 - Epoch: [11][5/6]	Total Loss: 0.96352	Main MSE (x10^-2): 96.3525	LR: 4.00e-04	EMPP_Raw: 1.56591
2025-07-17 15:40:15,384 - logger.py:50 - Epoch 11 Training Summary: Avg Total Loss: 0.96352, Avg Main MSE: 0.96352, Time: 23.29s
2025-07-17 15:40:54,426 - logger.py:50 - *** New Best Val MSE (x10^-2): 18.3677, Corresponding Test MSE (x10^-2): 18.2653 at Epoch 11 ***
2025-07-17 15:40:54,473 - logger.py:50 - Epoch 11 Summary | Train MSE (x10^-2): 96.3525 | Val MSE (x10^-2): 18.3677 | Time: 62.38s
2025-07-17 15:40:58,530 - logger.py:50 - Epoch: [12][0/6]	Total Loss: 0.97515	Main MSE (x10^-2): 97.5149	LR: 4.00e-04	EMPP_Raw: 1.56097
2025-07-17 15:41:17,769 - logger.py:50 - Epoch: [12][5/6]	Total Loss: 0.96762	Main MSE (x10^-2): 96.7623	LR: 4.00e-04	EMPP_Raw: 1.57656
2025-07-17 15:41:17,803 - logger.py:50 - Epoch 12 Training Summary: Avg Total Loss: 0.96762, Avg Main MSE: 0.96762, Time: 23.33s
2025-07-17 15:41:57,003 - logger.py:50 - *** New Best Val MSE (x10^-2): 18.1780, Corresponding Test MSE (x10^-2): 18.0933 at Epoch 12 ***
2025-07-17 15:41:57,050 - logger.py:50 - Epoch 12 Summary | Train MSE (x10^-2): 96.7623 | Val MSE (x10^-2): 18.1780 | Time: 62.58s
2025-07-17 15:42:01,261 - logger.py:50 - Epoch: [13][0/6]	Total Loss: 0.92699	Main MSE (x10^-2): 92.6985	LR: 3.99e-04	EMPP_Raw: 1.53857
2025-07-17 15:42:20,470 - logger.py:50 - Epoch: [13][5/6]	Total Loss: 0.96389	Main MSE (x10^-2): 96.3894	LR: 3.99e-04	EMPP_Raw: 1.56936
2025-07-17 15:42:20,504 - logger.py:50 - Epoch 13 Training Summary: Avg Total Loss: 0.96389, Avg Main MSE: 0.96389, Time: 23.45s
2025-07-17 15:42:40,089 - logger.py:50 - Epoch 13 Summary | Train MSE (x10^-2): 96.3894 | Val MSE (x10^-2): 18.1855 | Time: 43.04s
2025-07-17 15:42:44,642 - logger.py:50 - Epoch: [14][0/6]	Total Loss: 0.92312	Main MSE (x10^-2): 92.3122	LR: 3.99e-04	EMPP_Raw: 1.52248
2025-07-17 15:43:03,820 - logger.py:50 - Epoch: [14][5/6]	Total Loss: 0.95518	Main MSE (x10^-2): 95.5177	LR: 3.99e-04	EMPP_Raw: 1.55103
2025-07-17 15:43:03,860 - logger.py:50 - Epoch 14 Training Summary: Avg Total Loss: 0.95518, Avg Main MSE: 0.95518, Time: 23.76s
2025-07-17 15:43:23,419 - logger.py:50 - Epoch 14 Summary | Train MSE (x10^-2): 95.5177 | Val MSE (x10^-2): 18.3261 | Time: 43.32s
2025-07-17 15:43:27,686 - logger.py:50 - Epoch: [15][0/6]	Total Loss: 0.98321	Main MSE (x10^-2): 98.3207	LR: 3.99e-04	EMPP_Raw: 1.56218
2025-07-17 15:43:46,945 - logger.py:50 - Epoch: [15][5/6]	Total Loss: 0.94981	Main MSE (x10^-2): 94.9812	LR: 3.99e-04	EMPP_Raw: 1.53632
2025-07-17 15:43:46,991 - logger.py:50 - Epoch 15 Training Summary: Avg Total Loss: 0.94981, Avg Main MSE: 0.94981, Time: 23.56s
2025-07-17 15:44:25,966 - logger.py:50 - *** New Best Val MSE (x10^-2): 17.9586, Corresponding Test MSE (x10^-2): 17.8759 at Epoch 15 ***
2025-07-17 15:44:26,017 - logger.py:50 - Epoch 15 Summary | Train MSE (x10^-2): 94.9812 | Val MSE (x10^-2): 17.9586 | Time: 62.59s
2025-07-17 15:44:30,243 - logger.py:50 - Epoch: [16][0/6]	Total Loss: 0.95766	Main MSE (x10^-2): 95.7659	LR: 3.99e-04	EMPP_Raw: 1.56000
2025-07-17 15:44:49,444 - logger.py:50 - Epoch: [16][5/6]	Total Loss: 0.92871	Main MSE (x10^-2): 92.8715	LR: 3.99e-04	EMPP_Raw: 1.50352
2025-07-17 15:44:49,484 - logger.py:50 - Epoch 16 Training Summary: Avg Total Loss: 0.92871, Avg Main MSE: 0.92871, Time: 23.46s
2025-07-17 15:45:28,860 - logger.py:50 - *** New Best Val MSE (x10^-2): 17.8971, Corresponding Test MSE (x10^-2): 17.7719 at Epoch 16 ***
2025-07-17 15:45:28,907 - logger.py:50 - Epoch 16 Summary | Train MSE (x10^-2): 92.8715 | Val MSE (x10^-2): 17.8971 | Time: 62.89s
2025-07-17 15:45:32,936 - logger.py:50 - Epoch: [17][0/6]	Total Loss: 0.97899	Main MSE (x10^-2): 97.8986	LR: 3.99e-04	EMPP_Raw: 1.59000
2025-07-17 15:45:52,295 - logger.py:50 - Epoch: [17][5/6]	Total Loss: 0.95240	Main MSE (x10^-2): 95.2403	LR: 3.99e-04	EMPP_Raw: 1.54922
2025-07-17 15:45:52,328 - logger.py:50 - Epoch 17 Training Summary: Avg Total Loss: 0.95240, Avg Main MSE: 0.95240, Time: 23.42s
2025-07-17 15:46:11,761 - logger.py:50 - Epoch 17 Summary | Train MSE (x10^-2): 95.2403 | Val MSE (x10^-2): 18.0230 | Time: 42.85s
2025-07-17 15:46:15,828 - logger.py:50 - Epoch: [18][0/6]	Total Loss: 0.94696	Main MSE (x10^-2): 94.6963	LR: 3.99e-04	EMPP_Raw: 1.51792
2025-07-17 15:46:35,089 - logger.py:50 - Epoch: [18][5/6]	Total Loss: 0.94288	Main MSE (x10^-2): 94.2883	LR: 3.99e-04	EMPP_Raw: 1.53501
2025-07-17 15:46:35,129 - logger.py:50 - Epoch 18 Training Summary: Avg Total Loss: 0.94288, Avg Main MSE: 0.94288, Time: 23.36s
2025-07-17 15:47:14,192 - logger.py:50 - *** New Best Val MSE (x10^-2): 17.7742, Corresponding Test MSE (x10^-2): 17.6470 at Epoch 18 ***
2025-07-17 15:47:14,239 - logger.py:50 - Epoch 18 Summary | Train MSE (x10^-2): 94.2883 | Val MSE (x10^-2): 17.7742 | Time: 62.47s
2025-07-17 15:47:18,271 - logger.py:50 - Epoch: [19][0/6]	Total Loss: 0.97464	Main MSE (x10^-2): 97.4636	LR: 3.99e-04	EMPP_Raw: 1.59630
2025-07-17 15:47:37,784 - logger.py:50 - Epoch: [19][5/6]	Total Loss: 0.94518	Main MSE (x10^-2): 94.5180	LR: 3.99e-04	EMPP_Raw: 1.54260
2025-07-17 15:47:37,834 - logger.py:50 - Epoch 19 Training Summary: Avg Total Loss: 0.94518, Avg Main MSE: 0.94518, Time: 23.59s
2025-07-17 15:48:17,060 - logger.py:50 - *** New Best Val MSE (x10^-2): 17.7544, Corresponding Test MSE (x10^-2): 17.6322 at Epoch 19 ***
2025-07-17 15:48:17,110 - logger.py:50 - Epoch 19 Summary | Train MSE (x10^-2): 94.5180 | Val MSE (x10^-2): 17.7544 | Time: 62.87s
2025-07-17 15:48:21,167 - logger.py:50 - Epoch: [20][0/6]	Total Loss: 0.96039	Main MSE (x10^-2): 96.0392	LR: 3.99e-04	EMPP_Raw: 1.57514
2025-07-17 15:48:40,609 - logger.py:50 - Epoch: [20][5/6]	Total Loss: 0.94075	Main MSE (x10^-2): 94.0745	LR: 3.99e-04	EMPP_Raw: 1.53645
2025-07-17 15:48:40,645 - logger.py:50 - Epoch 20 Training Summary: Avg Total Loss: 0.94075, Avg Main MSE: 0.94075, Time: 23.53s
2025-07-17 15:49:19,730 - logger.py:50 - *** New Best Val MSE (x10^-2): 17.7163, Corresponding Test MSE (x10^-2): 17.5776 at Epoch 20 ***
2025-07-17 15:49:19,778 - logger.py:50 - Epoch 20 Summary | Train MSE (x10^-2): 94.0745 | Val MSE (x10^-2): 17.7163 | Time: 62.67s
2025-07-17 15:49:23,854 - logger.py:50 - Epoch: [21][0/6]	Total Loss: 0.96200	Main MSE (x10^-2): 96.2003	LR: 3.98e-04	EMPP_Raw: 1.54686
2025-07-17 15:49:43,418 - logger.py:50 - Epoch: [21][5/6]	Total Loss: 0.93754	Main MSE (x10^-2): 93.7540	LR: 3.98e-04	EMPP_Raw: 1.53079
2025-07-17 15:49:43,455 - logger.py:50 - Epoch 21 Training Summary: Avg Total Loss: 0.93754, Avg Main MSE: 0.93754, Time: 23.67s
2025-07-17 15:50:22,829 - logger.py:50 - *** New Best Val MSE (x10^-2): 17.5092, Corresponding Test MSE (x10^-2): 17.3837 at Epoch 21 ***
2025-07-17 15:50:22,877 - logger.py:50 - Epoch 21 Summary | Train MSE (x10^-2): 93.7540 | Val MSE (x10^-2): 17.5092 | Time: 63.10s
2025-07-17 15:50:27,112 - logger.py:50 - Epoch: [22][0/6]	Total Loss: 0.95256	Main MSE (x10^-2): 95.2558	LR: 3.98e-04	EMPP_Raw: 1.56729
2025-07-17 15:50:46,412 - logger.py:50 - Epoch: [22][5/6]	Total Loss: 0.93630	Main MSE (x10^-2): 93.6297	LR: 3.98e-04	EMPP_Raw: 1.52945
2025-07-17 15:50:46,447 - logger.py:50 - Epoch 22 Training Summary: Avg Total Loss: 0.93630, Avg Main MSE: 0.93630, Time: 23.57s
2025-07-17 15:51:26,107 - logger.py:50 - *** New Best Val MSE (x10^-2): 17.4761, Corresponding Test MSE (x10^-2): 17.3237 at Epoch 22 ***
2025-07-17 15:51:26,154 - logger.py:50 - Epoch 22 Summary | Train MSE (x10^-2): 93.6297 | Val MSE (x10^-2): 17.4761 | Time: 63.28s
2025-07-17 15:51:30,278 - logger.py:50 - Epoch: [23][0/6]	Total Loss: 0.93460	Main MSE (x10^-2): 93.4596	LR: 3.98e-04	EMPP_Raw: 1.50501
2025-07-17 15:51:49,729 - logger.py:50 - Epoch: [23][5/6]	Total Loss: 0.93720	Main MSE (x10^-2): 93.7201	LR: 3.98e-04	EMPP_Raw: 1.53274
2025-07-17 15:51:49,768 - logger.py:50 - Epoch 23 Training Summary: Avg Total Loss: 0.93720, Avg Main MSE: 0.93720, Time: 23.61s
2025-07-17 15:52:09,718 - logger.py:50 - Epoch 23 Summary | Train MSE (x10^-2): 93.7201 | Val MSE (x10^-2): 17.5046 | Time: 43.56s
2025-07-17 15:52:13,815 - logger.py:50 - Epoch: [24][0/6]	Total Loss: 0.92347	Main MSE (x10^-2): 92.3475	LR: 3.98e-04	EMPP_Raw: 1.53136
2025-07-17 15:52:33,110 - logger.py:50 - Epoch: [24][5/6]	Total Loss: 0.91925	Main MSE (x10^-2): 91.9248	LR: 3.98e-04	EMPP_Raw: 1.50253
2025-07-17 15:52:33,153 - logger.py:50 - Epoch 24 Training Summary: Avg Total Loss: 0.91925, Avg Main MSE: 0.91925, Time: 23.43s
2025-07-17 15:53:12,543 - logger.py:50 - *** New Best Val MSE (x10^-2): 17.2749, Corresponding Test MSE (x10^-2): 17.1149 at Epoch 24 ***
2025-07-17 15:53:12,594 - logger.py:50 - Epoch 24 Summary | Train MSE (x10^-2): 91.9248 | Val MSE (x10^-2): 17.2749 | Time: 62.87s
2025-07-17 15:53:16,674 - logger.py:50 - Epoch: [25][0/6]	Total Loss: 0.88864	Main MSE (x10^-2): 88.8642	LR: 3.98e-04	EMPP_Raw: 1.48154
2025-07-17 15:53:36,214 - logger.py:50 - Epoch: [25][5/6]	Total Loss: 0.91596	Main MSE (x10^-2): 91.5958	LR: 3.98e-04	EMPP_Raw: 1.49460
2025-07-17 15:53:36,248 - logger.py:50 - Epoch 25 Training Summary: Avg Total Loss: 0.91596, Avg Main MSE: 0.91596, Time: 23.65s
2025-07-17 15:54:15,309 - logger.py:50 - *** New Best Val MSE (x10^-2): 17.2597, Corresponding Test MSE (x10^-2): 17.0834 at Epoch 25 ***
2025-07-17 15:54:15,464 - logger.py:50 - Epoch 25 Summary | Train MSE (x10^-2): 91.5958 | Val MSE (x10^-2): 17.2597 | Time: 62.87s
2025-07-17 15:54:19,489 - logger.py:50 - Epoch: [26][0/6]	Total Loss: 0.93239	Main MSE (x10^-2): 93.2394	LR: 3.98e-04	EMPP_Raw: 1.52440
2025-07-17 15:54:38,827 - logger.py:50 - Epoch: [26][5/6]	Total Loss: 0.92827	Main MSE (x10^-2): 92.8267	LR: 3.98e-04	EMPP_Raw: 1.52235
2025-07-17 15:54:38,867 - logger.py:50 - Epoch 26 Training Summary: Avg Total Loss: 0.92827, Avg Main MSE: 0.92827, Time: 23.40s
2025-07-17 15:54:58,536 - logger.py:50 - Epoch 26 Summary | Train MSE (x10^-2): 92.8267 | Val MSE (x10^-2): 17.2943 | Time: 43.07s
2025-07-17 15:55:02,626 - logger.py:50 - Epoch: [27][0/6]	Total Loss: 0.94606	Main MSE (x10^-2): 94.6061	LR: 3.97e-04	EMPP_Raw: 1.51774
2025-07-17 15:55:21,976 - logger.py:50 - Epoch: [27][5/6]	Total Loss: 0.92388	Main MSE (x10^-2): 92.3877	LR: 3.97e-04	EMPP_Raw: 1.51552
2025-07-17 15:55:22,018 - logger.py:50 - Epoch 27 Training Summary: Avg Total Loss: 0.92388, Avg Main MSE: 0.92388, Time: 23.47s
2025-07-17 15:55:41,892 - logger.py:50 - Epoch 27 Summary | Train MSE (x10^-2): 92.3877 | Val MSE (x10^-2): 17.3737 | Time: 43.35s
2025-07-17 15:55:46,007 - logger.py:50 - Epoch: [28][0/6]	Total Loss: 0.90720	Main MSE (x10^-2): 90.7204	LR: 3.97e-04	EMPP_Raw: 1.49516
2025-07-17 15:56:05,447 - logger.py:50 - Epoch: [28][5/6]	Total Loss: 0.92363	Main MSE (x10^-2): 92.3631	LR: 3.97e-04	EMPP_Raw: 1.51319
2025-07-17 15:56:05,486 - logger.py:50 - Epoch 28 Training Summary: Avg Total Loss: 0.92363, Avg Main MSE: 0.92363, Time: 23.58s
2025-07-17 15:56:45,132 - logger.py:50 - *** New Best Val MSE (x10^-2): 17.0615, Corresponding Test MSE (x10^-2): 16.8796 at Epoch 28 ***
2025-07-17 15:56:45,182 - logger.py:50 - Epoch 28 Summary | Train MSE (x10^-2): 92.3631 | Val MSE (x10^-2): 17.0615 | Time: 63.28s
2025-07-17 15:56:49,236 - logger.py:50 - Epoch: [29][0/6]	Total Loss: 0.90636	Main MSE (x10^-2): 90.6364	LR: 3.97e-04	EMPP_Raw: 1.50181
2025-07-17 15:57:08,685 - logger.py:50 - Epoch: [29][5/6]	Total Loss: 0.92098	Main MSE (x10^-2): 92.0975	LR: 3.97e-04	EMPP_Raw: 1.50899
2025-07-17 15:57:08,721 - logger.py:50 - Epoch 29 Training Summary: Avg Total Loss: 0.92098, Avg Main MSE: 0.92098, Time: 23.54s
2025-07-17 15:57:28,403 - logger.py:50 - Epoch 29 Summary | Train MSE (x10^-2): 92.0975 | Val MSE (x10^-2): 18.1510 | Time: 43.22s
2025-07-17 15:57:32,459 - logger.py:50 - Epoch: [30][0/6]	Total Loss: 0.93466	Main MSE (x10^-2): 93.4657	LR: 3.97e-04	EMPP_Raw: 1.52720
2025-07-17 15:57:51,745 - logger.py:50 - Epoch: [30][5/6]	Total Loss: 0.92732	Main MSE (x10^-2): 92.7315	LR: 3.97e-04	EMPP_Raw: 1.51902
2025-07-17 15:57:51,788 - logger.py:50 - Epoch 30 Training Summary: Avg Total Loss: 0.92732, Avg Main MSE: 0.92732, Time: 23.38s
2025-07-17 15:58:31,118 - logger.py:50 - *** New Best Val MSE (x10^-2): 17.0352, Corresponding Test MSE (x10^-2): 16.8650 at Epoch 30 ***
2025-07-17 15:58:31,165 - logger.py:50 - Epoch 30 Summary | Train MSE (x10^-2): 92.7315 | Val MSE (x10^-2): 17.0352 | Time: 62.76s
2025-07-17 15:58:35,232 - logger.py:50 - Epoch: [31][0/6]	Total Loss: 0.92473	Main MSE (x10^-2): 92.4727	LR: 3.96e-04	EMPP_Raw: 1.55459
2025-07-17 15:58:54,582 - logger.py:50 - Epoch: [31][5/6]	Total Loss: 0.91652	Main MSE (x10^-2): 91.6523	LR: 3.96e-04	EMPP_Raw: 1.51039
2025-07-17 15:58:54,615 - logger.py:50 - Epoch 31 Training Summary: Avg Total Loss: 0.91652, Avg Main MSE: 0.91652, Time: 23.45s
2025-07-17 15:59:33,622 - logger.py:50 - *** New Best Val MSE (x10^-2): 16.9579, Corresponding Test MSE (x10^-2): 16.7615 at Epoch 31 ***
2025-07-17 15:59:33,668 - logger.py:50 - Epoch 31 Summary | Train MSE (x10^-2): 91.6523 | Val MSE (x10^-2): 16.9579 | Time: 62.50s
2025-07-17 15:59:37,752 - logger.py:50 - Epoch: [32][0/6]	Total Loss: 0.90641	Main MSE (x10^-2): 90.6407	LR: 3.96e-04	EMPP_Raw: 1.50795
2025-07-17 15:59:57,118 - logger.py:50 - Epoch: [32][5/6]	Total Loss: 0.90961	Main MSE (x10^-2): 90.9608	LR: 3.96e-04	EMPP_Raw: 1.49959
2025-07-17 15:59:57,152 - logger.py:50 - Epoch 32 Training Summary: Avg Total Loss: 0.90961, Avg Main MSE: 0.90961, Time: 23.48s
2025-07-17 16:00:36,255 - logger.py:50 - *** New Best Val MSE (x10^-2): 16.7509, Corresponding Test MSE (x10^-2): 16.5855 at Epoch 32 ***
2025-07-17 16:00:36,302 - logger.py:50 - Epoch 32 Summary | Train MSE (x10^-2): 90.9608 | Val MSE (x10^-2): 16.7509 | Time: 62.63s
2025-07-17 16:00:40,355 - logger.py:50 - Epoch: [33][0/6]	Total Loss: 0.89661	Main MSE (x10^-2): 89.6606	LR: 3.96e-04	EMPP_Raw: 1.48964
2025-07-17 16:00:59,764 - logger.py:50 - Epoch: [33][5/6]	Total Loss: 0.90993	Main MSE (x10^-2): 90.9931	LR: 3.96e-04	EMPP_Raw: 1.50053
2025-07-17 16:00:59,798 - logger.py:50 - Epoch 33 Training Summary: Avg Total Loss: 0.90993, Avg Main MSE: 0.90993, Time: 23.49s
2025-07-17 16:01:19,391 - logger.py:50 - Epoch 33 Summary | Train MSE (x10^-2): 90.9931 | Val MSE (x10^-2): 16.7543 | Time: 43.09s
2025-07-17 16:01:23,473 - logger.py:50 - Epoch: [34][0/6]	Total Loss: 0.92804	Main MSE (x10^-2): 92.8038	LR: 3.96e-04	EMPP_Raw: 1.50616
2025-07-17 16:01:42,887 - logger.py:50 - Epoch: [34][5/6]	Total Loss: 0.91088	Main MSE (x10^-2): 91.0882	LR: 3.96e-04	EMPP_Raw: 1.50550
2025-07-17 16:01:42,928 - logger.py:50 - Epoch 34 Training Summary: Avg Total Loss: 0.91088, Avg Main MSE: 0.91088, Time: 23.53s
2025-07-17 16:02:02,398 - logger.py:50 - Epoch 34 Summary | Train MSE (x10^-2): 91.0882 | Val MSE (x10^-2): 16.7585 | Time: 43.00s
2025-07-17 16:02:06,482 - logger.py:50 - Epoch: [35][0/6]	Total Loss: 0.89276	Main MSE (x10^-2): 89.2765	LR: 3.95e-04	EMPP_Raw: 1.48530
2025-07-17 16:02:26,032 - logger.py:50 - Epoch: [35][5/6]	Total Loss: 0.90232	Main MSE (x10^-2): 90.2323	LR: 3.95e-04	EMPP_Raw: 1.48677
2025-07-17 16:02:26,094 - logger.py:50 - Epoch 35 Training Summary: Avg Total Loss: 0.90232, Avg Main MSE: 0.90232, Time: 23.69s
2025-07-17 16:03:06,367 - logger.py:50 - *** New Best Val MSE (x10^-2): 16.7395, Corresponding Test MSE (x10^-2): 16.5239 at Epoch 35 ***
2025-07-17 16:03:06,414 - logger.py:50 - Epoch 35 Summary | Train MSE (x10^-2): 90.2323 | Val MSE (x10^-2): 16.7395 | Time: 64.01s
2025-07-17 16:03:10,491 - logger.py:50 - Epoch: [36][0/6]	Total Loss: 0.91045	Main MSE (x10^-2): 91.0452	LR: 3.95e-04	EMPP_Raw: 1.51228
2025-07-17 16:03:29,883 - logger.py:50 - Epoch: [36][5/6]	Total Loss: 0.90832	Main MSE (x10^-2): 90.8318	LR: 3.95e-04	EMPP_Raw: 1.50149
2025-07-17 16:03:29,917 - logger.py:50 - Epoch 36 Training Summary: Avg Total Loss: 0.90832, Avg Main MSE: 0.90832, Time: 23.50s
2025-07-17 16:04:08,903 - logger.py:50 - *** New Best Val MSE (x10^-2): 16.6496, Corresponding Test MSE (x10^-2): 16.4631 at Epoch 36 ***
2025-07-17 16:04:08,951 - logger.py:50 - Epoch 36 Summary | Train MSE (x10^-2): 90.8318 | Val MSE (x10^-2): 16.6496 | Time: 62.54s
2025-07-17 16:04:13,155 - logger.py:50 - Epoch: [37][0/6]	Total Loss: 0.86476	Main MSE (x10^-2): 86.4761	LR: 3.95e-04	EMPP_Raw: 1.44328
2025-07-17 16:04:32,415 - logger.py:50 - Epoch: [37][5/6]	Total Loss: 0.90445	Main MSE (x10^-2): 90.4454	LR: 3.95e-04	EMPP_Raw: 1.49902
2025-07-17 16:04:32,476 - logger.py:50 - Epoch 37 Training Summary: Avg Total Loss: 0.90445, Avg Main MSE: 0.90445, Time: 23.52s
2025-07-17 16:04:52,164 - logger.py:50 - Epoch 37 Summary | Train MSE (x10^-2): 90.4454 | Val MSE (x10^-2): 16.7565 | Time: 43.21s
2025-07-17 16:04:56,413 - logger.py:50 - Epoch: [38][0/6]	Total Loss: 0.92454	Main MSE (x10^-2): 92.4540	LR: 3.95e-04	EMPP_Raw: 1.50747
2025-07-17 16:05:15,664 - logger.py:50 - Epoch: [38][5/6]	Total Loss: 0.91010	Main MSE (x10^-2): 91.0096	LR: 3.95e-04	EMPP_Raw: 1.50842
2025-07-17 16:05:15,708 - logger.py:50 - Epoch 38 Training Summary: Avg Total Loss: 0.91010, Avg Main MSE: 0.91010, Time: 23.53s
2025-07-17 16:05:36,600 - logger.py:50 - Epoch 38 Summary | Train MSE (x10^-2): 91.0096 | Val MSE (x10^-2): 16.6752 | Time: 44.43s
2025-07-17 16:05:41,118 - logger.py:50 - Epoch: [39][0/6]	Total Loss: 0.85415	Main MSE (x10^-2): 85.4148	LR: 3.94e-04	EMPP_Raw: 1.41867
2025-07-17 16:06:00,809 - logger.py:50 - Epoch: [39][5/6]	Total Loss: 0.89132	Main MSE (x10^-2): 89.1323	LR: 3.94e-04	EMPP_Raw: 1.47412
2025-07-17 16:06:00,861 - logger.py:50 - Epoch 39 Training Summary: Avg Total Loss: 0.89132, Avg Main MSE: 0.89132, Time: 24.25s
2025-07-17 16:06:20,400 - logger.py:50 - Epoch 39 Summary | Train MSE (x10^-2): 89.1323 | Val MSE (x10^-2): 16.8877 | Time: 43.79s
2025-07-17 16:06:24,637 - logger.py:50 - Epoch: [40][0/6]	Total Loss: 0.89244	Main MSE (x10^-2): 89.2438	LR: 3.94e-04	EMPP_Raw: 1.49537
2025-07-17 16:06:43,902 - logger.py:50 - Epoch: [40][5/6]	Total Loss: 0.90020	Main MSE (x10^-2): 90.0200	LR: 3.94e-04	EMPP_Raw: 1.49120
2025-07-17 16:06:43,942 - logger.py:50 - Epoch 40 Training Summary: Avg Total Loss: 0.90020, Avg Main MSE: 0.90020, Time: 23.53s
2025-07-17 16:07:03,567 - logger.py:50 - Epoch 40 Summary | Train MSE (x10^-2): 90.0200 | Val MSE (x10^-2): 16.6733 | Time: 43.16s
2025-07-17 16:07:07,788 - logger.py:50 - Epoch: [41][0/6]	Total Loss: 0.89647	Main MSE (x10^-2): 89.6467	LR: 3.94e-04	EMPP_Raw: 1.48653
2025-07-17 16:07:27,067 - logger.py:50 - Epoch: [41][5/6]	Total Loss: 0.91019	Main MSE (x10^-2): 91.0194	LR: 3.94e-04	EMPP_Raw: 1.51556
2025-07-17 16:07:27,108 - logger.py:50 - Epoch 41 Training Summary: Avg Total Loss: 0.91019, Avg Main MSE: 0.91019, Time: 23.53s
2025-07-17 16:07:46,523 - logger.py:50 - Epoch 41 Summary | Train MSE (x10^-2): 91.0194 | Val MSE (x10^-2): 16.7455 | Time: 42.95s
2025-07-17 16:07:50,742 - logger.py:50 - Epoch: [42][0/6]	Total Loss: 0.89061	Main MSE (x10^-2): 89.0611	LR: 3.93e-04	EMPP_Raw: 1.48522
2025-07-17 16:08:09,905 - logger.py:50 - Epoch: [42][5/6]	Total Loss: 0.89225	Main MSE (x10^-2): 89.2248	LR: 3.93e-04	EMPP_Raw: 1.47885
2025-07-17 16:08:09,947 - logger.py:50 - Epoch 42 Training Summary: Avg Total Loss: 0.89225, Avg Main MSE: 0.89225, Time: 23.41s
2025-07-17 16:08:29,438 - logger.py:50 - Epoch 42 Summary | Train MSE (x10^-2): 89.2248 | Val MSE (x10^-2): 16.6678 | Time: 42.91s
2025-07-17 16:08:33,654 - logger.py:50 - Epoch: [43][0/6]	Total Loss: 0.90292	Main MSE (x10^-2): 90.2919	LR: 3.93e-04	EMPP_Raw: 1.50250
2025-07-17 16:08:52,916 - logger.py:50 - Epoch: [43][5/6]	Total Loss: 0.89275	Main MSE (x10^-2): 89.2751	LR: 3.93e-04	EMPP_Raw: 1.48389
2025-07-17 16:08:52,961 - logger.py:50 - Epoch 43 Training Summary: Avg Total Loss: 0.89275, Avg Main MSE: 0.89275, Time: 23.51s
2025-07-17 16:09:31,870 - logger.py:50 - *** New Best Val MSE (x10^-2): 16.5279, Corresponding Test MSE (x10^-2): 16.3175 at Epoch 43 ***
2025-07-17 16:09:31,917 - logger.py:50 - Epoch 43 Summary | Train MSE (x10^-2): 89.2751 | Val MSE (x10^-2): 16.5279 | Time: 62.47s
2025-07-17 16:09:36,118 - logger.py:50 - Epoch: [44][0/6]	Total Loss: 0.89702	Main MSE (x10^-2): 89.7022	LR: 3.93e-04	EMPP_Raw: 1.49896
2025-07-17 16:09:55,341 - logger.py:50 - Epoch: [44][5/6]	Total Loss: 0.89448	Main MSE (x10^-2): 89.4482	LR: 3.93e-04	EMPP_Raw: 1.49347
2025-07-17 16:09:55,375 - logger.py:50 - Epoch 44 Training Summary: Avg Total Loss: 0.89448, Avg Main MSE: 0.89448, Time: 23.45s
2025-07-17 16:10:34,468 - logger.py:50 - *** New Best Val MSE (x10^-2): 16.4067, Corresponding Test MSE (x10^-2): 16.1888 at Epoch 44 ***
2025-07-17 16:10:34,516 - logger.py:50 - Epoch 44 Summary | Train MSE (x10^-2): 89.4482 | Val MSE (x10^-2): 16.4067 | Time: 62.60s
2025-07-17 16:10:38,634 - logger.py:50 - Epoch: [45][0/6]	Total Loss: 0.88858	Main MSE (x10^-2): 88.8584	LR: 3.92e-04	EMPP_Raw: 1.46996
2025-07-17 16:10:58,178 - logger.py:50 - Epoch: [45][5/6]	Total Loss: 0.88889	Main MSE (x10^-2): 88.8894	LR: 3.92e-04	EMPP_Raw: 1.48475
2025-07-17 16:10:58,217 - logger.py:50 - Epoch 45 Training Summary: Avg Total Loss: 0.88889, Avg Main MSE: 0.88889, Time: 23.70s
2025-07-17 16:11:17,802 - logger.py:50 - Epoch 45 Summary | Train MSE (x10^-2): 88.8894 | Val MSE (x10^-2): 16.7297 | Time: 43.29s
2025-07-17 16:11:21,882 - logger.py:50 - Epoch: [46][0/6]	Total Loss: 0.86907	Main MSE (x10^-2): 86.9069	LR: 3.92e-04	EMPP_Raw: 1.44910
2025-07-17 16:11:41,294 - logger.py:50 - Epoch: [46][5/6]	Total Loss: 0.88535	Main MSE (x10^-2): 88.5348	LR: 3.92e-04	EMPP_Raw: 1.47759
2025-07-17 16:11:41,333 - logger.py:50 - Epoch 46 Training Summary: Avg Total Loss: 0.88535, Avg Main MSE: 0.88535, Time: 23.52s
2025-07-17 16:12:01,209 - logger.py:50 - Epoch 46 Summary | Train MSE (x10^-2): 88.5348 | Val MSE (x10^-2): 16.7976 | Time: 43.40s
2025-07-17 16:12:05,299 - logger.py:50 - Epoch: [47][0/6]	Total Loss: 0.89507	Main MSE (x10^-2): 89.5073	LR: 3.92e-04	EMPP_Raw: 1.48885
2025-07-17 16:12:24,635 - logger.py:50 - Epoch: [47][5/6]	Total Loss: 0.89478	Main MSE (x10^-2): 89.4782	LR: 3.92e-04	EMPP_Raw: 1.49625
2025-07-17 16:12:24,679 - logger.py:50 - Epoch 47 Training Summary: Avg Total Loss: 0.89478, Avg Main MSE: 0.89478, Time: 23.46s
2025-07-17 16:12:44,271 - logger.py:50 - Epoch 47 Summary | Train MSE (x10^-2): 89.4782 | Val MSE (x10^-2): 16.5720 | Time: 43.06s
2025-07-17 16:12:48,370 - logger.py:50 - Epoch: [48][0/6]	Total Loss: 0.88815	Main MSE (x10^-2): 88.8154	LR: 3.91e-04	EMPP_Raw: 1.50185
2025-07-17 16:13:07,661 - logger.py:50 - Epoch: [48][5/6]	Total Loss: 0.88201	Main MSE (x10^-2): 88.2014	LR: 3.91e-04	EMPP_Raw: 1.47725
2025-07-17 16:13:07,701 - logger.py:50 - Epoch 48 Training Summary: Avg Total Loss: 0.88201, Avg Main MSE: 0.88201, Time: 23.42s
2025-07-17 16:13:27,351 - logger.py:50 - Epoch 48 Summary | Train MSE (x10^-2): 88.2014 | Val MSE (x10^-2): 16.4982 | Time: 43.08s
2025-07-17 16:13:31,404 - logger.py:50 - Epoch: [49][0/6]	Total Loss: 0.88327	Main MSE (x10^-2): 88.3267	LR: 3.91e-04	EMPP_Raw: 1.51200
2025-07-17 16:13:50,675 - logger.py:50 - Epoch: [49][5/6]	Total Loss: 0.88829	Main MSE (x10^-2): 88.8292	LR: 3.91e-04	EMPP_Raw: 1.49322
2025-07-17 16:13:50,715 - logger.py:50 - Epoch 49 Training Summary: Avg Total Loss: 0.88829, Avg Main MSE: 0.88829, Time: 23.35s
2025-07-17 16:14:10,428 - logger.py:50 - Epoch 49 Summary | Train MSE (x10^-2): 88.8292 | Val MSE (x10^-2): 16.6411 | Time: 43.07s
2025-07-17 16:14:14,519 - logger.py:50 - Epoch: [50][0/6]	Total Loss: 0.85763	Main MSE (x10^-2): 85.7628	LR: 3.91e-04	EMPP_Raw: 1.42988
2025-07-17 16:14:33,757 - logger.py:50 - Epoch: [50][5/6]	Total Loss: 0.88073	Main MSE (x10^-2): 88.0728	LR: 3.91e-04	EMPP_Raw: 1.47930
2025-07-17 16:14:33,797 - logger.py:50 - Epoch 50 Training Summary: Avg Total Loss: 0.88073, Avg Main MSE: 0.88073, Time: 23.36s
2025-07-17 16:14:54,464 - logger.py:50 - Epoch 50 Summary | Train MSE (x10^-2): 88.0728 | Val MSE (x10^-2): 16.4768 | Time: 44.03s
2025-07-17 16:14:58,578 - logger.py:50 - Epoch: [51][0/6]	Total Loss: 0.89420	Main MSE (x10^-2): 89.4199	LR: 3.90e-04	EMPP_Raw: 1.52638
2025-07-17 16:15:17,851 - logger.py:50 - Epoch: [51][5/6]	Total Loss: 0.89792	Main MSE (x10^-2): 89.7924	LR: 3.90e-04	EMPP_Raw: 1.51665
2025-07-17 16:15:17,892 - logger.py:50 - Epoch 51 Training Summary: Avg Total Loss: 0.89792, Avg Main MSE: 0.89792, Time: 23.42s
2025-07-17 16:15:37,558 - logger.py:50 - Epoch 51 Summary | Train MSE (x10^-2): 89.7924 | Val MSE (x10^-2): 16.6818 | Time: 43.09s
2025-07-17 16:15:41,656 - logger.py:50 - Epoch: [52][0/6]	Total Loss: 0.84748	Main MSE (x10^-2): 84.7476	LR: 3.90e-04	EMPP_Raw: 1.46336
2025-07-17 16:16:00,968 - logger.py:50 - Epoch: [52][5/6]	Total Loss: 0.88141	Main MSE (x10^-2): 88.1408	LR: 3.90e-04	EMPP_Raw: 1.48301
2025-07-17 16:16:01,011 - logger.py:50 - Epoch 52 Training Summary: Avg Total Loss: 0.88141, Avg Main MSE: 0.88141, Time: 23.44s
2025-07-17 16:16:20,732 - logger.py:50 - Epoch 52 Summary | Train MSE (x10^-2): 88.1408 | Val MSE (x10^-2): 16.9167 | Time: 43.17s
2025-07-17 16:16:24,843 - logger.py:50 - Epoch: [53][0/6]	Total Loss: 0.89101	Main MSE (x10^-2): 89.1005	LR: 3.89e-04	EMPP_Raw: 1.50930
2025-07-17 16:16:44,160 - logger.py:50 - Epoch: [53][5/6]	Total Loss: 0.87874	Main MSE (x10^-2): 87.8737	LR: 3.89e-04	EMPP_Raw: 1.48404
2025-07-17 16:16:44,203 - logger.py:50 - Epoch 53 Training Summary: Avg Total Loss: 0.87874, Avg Main MSE: 0.87874, Time: 23.46s
2025-07-17 16:17:03,793 - logger.py:50 - Epoch 53 Summary | Train MSE (x10^-2): 87.8737 | Val MSE (x10^-2): 16.7187 | Time: 43.05s
2025-07-17 16:17:07,889 - logger.py:50 - Epoch: [54][0/6]	Total Loss: 0.86756	Main MSE (x10^-2): 86.7565	LR: 3.89e-04	EMPP_Raw: 1.49067
2025-07-17 16:17:27,214 - logger.py:50 - Epoch: [54][5/6]	Total Loss: 0.87455	Main MSE (x10^-2): 87.4552	LR: 3.89e-04	EMPP_Raw: 1.47721
2025-07-17 16:17:27,254 - logger.py:50 - Epoch 54 Training Summary: Avg Total Loss: 0.87455, Avg Main MSE: 0.87455, Time: 23.45s
2025-07-17 16:17:46,996 - logger.py:50 - Epoch 54 Summary | Train MSE (x10^-2): 87.4552 | Val MSE (x10^-2): 17.0962 | Time: 43.20s
2025-07-17 16:17:51,178 - logger.py:50 - Epoch: [55][0/6]	Total Loss: 0.88988	Main MSE (x10^-2): 88.9876	LR: 3.89e-04	EMPP_Raw: 1.52750
2025-07-17 16:18:10,410 - logger.py:50 - Epoch: [55][5/6]	Total Loss: 0.87799	Main MSE (x10^-2): 87.7991	LR: 3.89e-04	EMPP_Raw: 1.48503
2025-07-17 16:18:10,462 - logger.py:50 - Epoch 55 Training Summary: Avg Total Loss: 0.87799, Avg Main MSE: 0.87799, Time: 23.45s
2025-07-17 16:18:30,054 - logger.py:50 - Epoch 55 Summary | Train MSE (x10^-2): 87.7991 | Val MSE (x10^-2): 16.9583 | Time: 43.05s
2025-07-17 16:18:34,143 - logger.py:50 - Epoch: [56][0/6]	Total Loss: 0.84130	Main MSE (x10^-2): 84.1295	LR: 3.88e-04	EMPP_Raw: 1.40964
2025-07-17 16:18:53,410 - logger.py:50 - Epoch: [56][5/6]	Total Loss: 0.86402	Main MSE (x10^-2): 86.4019	LR: 3.88e-04	EMPP_Raw: 1.46205
2025-07-17 16:18:53,456 - logger.py:50 - Epoch 56 Training Summary: Avg Total Loss: 0.86402, Avg Main MSE: 0.86402, Time: 23.39s
2025-07-17 16:19:12,996 - logger.py:50 - Epoch 56 Summary | Train MSE (x10^-2): 86.4019 | Val MSE (x10^-2): 16.8179 | Time: 42.94s
2025-07-17 16:19:17,088 - logger.py:50 - Epoch: [57][0/6]	Total Loss: 0.88605	Main MSE (x10^-2): 88.6054	LR: 3.88e-04	EMPP_Raw: 1.48748
2025-07-17 16:19:36,467 - logger.py:50 - Epoch: [57][5/6]	Total Loss: 0.87120	Main MSE (x10^-2): 87.1199	LR: 3.88e-04	EMPP_Raw: 1.48248
2025-07-17 16:19:36,506 - logger.py:50 - Epoch 57 Training Summary: Avg Total Loss: 0.87120, Avg Main MSE: 0.87120, Time: 23.50s
2025-07-17 16:19:56,422 - logger.py:50 - Epoch 57 Summary | Train MSE (x10^-2): 87.1199 | Val MSE (x10^-2): 16.9733 | Time: 43.42s
2025-07-17 16:20:00,519 - logger.py:50 - Epoch: [58][0/6]	Total Loss: 0.84889	Main MSE (x10^-2): 84.8888	LR: 3.87e-04	EMPP_Raw: 1.43984
2025-07-17 16:20:19,832 - logger.py:50 - Epoch: [58][5/6]	Total Loss: 0.85898	Main MSE (x10^-2): 85.8980	LR: 3.87e-04	EMPP_Raw: 1.46008
2025-07-17 16:20:19,874 - logger.py:50 - Epoch 58 Training Summary: Avg Total Loss: 0.85898, Avg Main MSE: 0.85898, Time: 23.44s
2025-07-17 16:20:39,508 - logger.py:50 - Epoch 58 Summary | Train MSE (x10^-2): 85.8980 | Val MSE (x10^-2): 17.2295 | Time: 43.08s
2025-07-17 16:20:43,729 - logger.py:50 - Epoch: [59][0/6]	Total Loss: 0.85422	Main MSE (x10^-2): 85.4222	LR: 3.87e-04	EMPP_Raw: 1.46512
2025-07-17 16:21:02,982 - logger.py:50 - Epoch: [59][5/6]	Total Loss: 0.86299	Main MSE (x10^-2): 86.2990	LR: 3.87e-04	EMPP_Raw: 1.47131
2025-07-17 16:21:03,021 - logger.py:50 - Epoch 59 Training Summary: Avg Total Loss: 0.86299, Avg Main MSE: 0.86299, Time: 23.50s
2025-07-17 16:21:23,145 - logger.py:50 - Epoch 59 Summary | Train MSE (x10^-2): 86.2990 | Val MSE (x10^-2): 17.1329 | Time: 43.63s
2025-07-17 16:21:27,489 - logger.py:50 - Epoch: [60][0/6]	Total Loss: 0.89056	Main MSE (x10^-2): 89.0556	LR: 3.86e-04	EMPP_Raw: 1.53631
2025-07-17 16:21:47,138 - logger.py:50 - Epoch: [60][5/6]	Total Loss: 0.87033	Main MSE (x10^-2): 87.0330	LR: 3.86e-04	EMPP_Raw: 1.49198
2025-07-17 16:21:47,185 - logger.py:50 - Epoch 60 Training Summary: Avg Total Loss: 0.87033, Avg Main MSE: 0.87033, Time: 24.03s
2025-07-17 16:22:07,023 - logger.py:50 - Epoch 60 Summary | Train MSE (x10^-2): 87.0330 | Val MSE (x10^-2): 17.6981 | Time: 43.87s
2025-07-17 16:22:11,303 - logger.py:50 - Epoch: [61][0/6]	Total Loss: 0.85651	Main MSE (x10^-2): 85.6505	LR: 3.86e-04	EMPP_Raw: 1.49224
2025-07-17 16:22:30,783 - logger.py:50 - Epoch: [61][5/6]	Total Loss: 0.86867	Main MSE (x10^-2): 86.8672	LR: 3.86e-04	EMPP_Raw: 1.48829
2025-07-17 16:22:30,826 - logger.py:50 - Epoch 61 Training Summary: Avg Total Loss: 0.86867, Avg Main MSE: 0.86867, Time: 23.79s
2025-07-17 16:22:50,364 - logger.py:50 - Epoch 61 Summary | Train MSE (x10^-2): 86.8672 | Val MSE (x10^-2): 16.7690 | Time: 43.33s
2025-07-17 16:22:54,681 - logger.py:50 - Epoch: [62][0/6]	Total Loss: 0.84119	Main MSE (x10^-2): 84.1191	LR: 3.86e-04	EMPP_Raw: 1.42607
2025-07-17 16:23:15,009 - logger.py:50 - Epoch: [62][5/6]	Total Loss: 0.85946	Main MSE (x10^-2): 85.9455	LR: 3.86e-04	EMPP_Raw: 1.48240
2025-07-17 16:23:15,051 - logger.py:50 - Epoch 62 Training Summary: Avg Total Loss: 0.85946, Avg Main MSE: 0.85946, Time: 24.68s
2025-07-17 16:23:35,170 - logger.py:50 - Epoch 62 Summary | Train MSE (x10^-2): 85.9455 | Val MSE (x10^-2): 18.2147 | Time: 44.80s
2025-07-17 16:23:39,506 - logger.py:50 - Epoch: [63][0/6]	Total Loss: 0.84212	Main MSE (x10^-2): 84.2121	LR: 3.85e-04	EMPP_Raw: 1.45464
2025-07-17 16:23:59,448 - logger.py:50 - Epoch: [63][5/6]	Total Loss: 0.85419	Main MSE (x10^-2): 85.4190	LR: 3.85e-04	EMPP_Raw: 1.47634
2025-07-17 16:23:59,493 - logger.py:50 - Epoch 63 Training Summary: Avg Total Loss: 0.85419, Avg Main MSE: 0.85419, Time: 24.31s
2025-07-17 16:24:19,375 - logger.py:50 - Epoch 63 Summary | Train MSE (x10^-2): 85.4190 | Val MSE (x10^-2): 17.3954 | Time: 44.20s
2025-07-17 16:24:23,660 - logger.py:50 - Epoch: [64][0/6]	Total Loss: 0.85220	Main MSE (x10^-2): 85.2196	LR: 3.85e-04	EMPP_Raw: 1.49362
2025-07-17 16:24:43,244 - logger.py:50 - Epoch: [64][5/6]	Total Loss: 0.85873	Main MSE (x10^-2): 85.8726	LR: 3.85e-04	EMPP_Raw: 1.48996
2025-07-17 16:24:43,291 - logger.py:50 - Epoch 64 Training Summary: Avg Total Loss: 0.85873, Avg Main MSE: 0.85873, Time: 23.91s
2025-07-17 16:25:03,069 - logger.py:50 - Epoch 64 Summary | Train MSE (x10^-2): 85.8726 | Val MSE (x10^-2): 18.4203 | Time: 43.69s
2025-07-17 16:25:07,385 - logger.py:50 - Epoch: [65][0/6]	Total Loss: 0.88945	Main MSE (x10^-2): 88.9450	LR: 3.84e-04	EMPP_Raw: 1.55177
2025-07-17 16:25:26,914 - logger.py:50 - Epoch: [65][5/6]	Total Loss: 0.86403	Main MSE (x10^-2): 86.4029	LR: 3.84e-04	EMPP_Raw: 1.49800
2025-07-17 16:25:26,953 - logger.py:50 - Epoch 65 Training Summary: Avg Total Loss: 0.86403, Avg Main MSE: 0.86403, Time: 23.87s
2025-07-17 16:25:46,716 - logger.py:50 - Epoch 65 Summary | Train MSE (x10^-2): 86.4029 | Val MSE (x10^-2): 18.2819 | Time: 43.64s
2025-07-17 16:25:51,044 - logger.py:50 - Epoch: [66][0/6]	Total Loss: 0.85449	Main MSE (x10^-2): 85.4490	LR: 3.84e-04	EMPP_Raw: 1.47486
2025-07-17 16:26:10,560 - logger.py:50 - Epoch: [66][5/6]	Total Loss: 0.85385	Main MSE (x10^-2): 85.3855	LR: 3.84e-04	EMPP_Raw: 1.48080
2025-07-17 16:26:10,602 - logger.py:50 - Epoch 66 Training Summary: Avg Total Loss: 0.85385, Avg Main MSE: 0.85385, Time: 23.88s
2025-07-17 16:26:31,458 - logger.py:50 - Epoch 66 Summary | Train MSE (x10^-2): 85.3855 | Val MSE (x10^-2): 17.8056 | Time: 44.74s
2025-07-17 16:26:37,366 - logger.py:50 - Epoch: [67][0/6]	Total Loss: 0.89037	Main MSE (x10^-2): 89.0375	LR: 3.83e-04	EMPP_Raw: 1.53834
2025-07-17 16:27:00,488 - logger.py:50 - Epoch: [67][5/6]	Total Loss: 0.84959	Main MSE (x10^-2): 84.9591	LR: 3.83e-04	EMPP_Raw: 1.48033
2025-07-17 16:27:00,535 - logger.py:50 - Epoch 67 Training Summary: Avg Total Loss: 0.84959, Avg Main MSE: 0.84959, Time: 29.06s
2025-07-17 16:27:20,388 - logger.py:50 - Epoch 67 Summary | Train MSE (x10^-2): 84.9591 | Val MSE (x10^-2): 17.7156 | Time: 48.92s
2025-07-17 16:27:24,670 - logger.py:50 - Epoch: [68][0/6]	Total Loss: 0.84660	Main MSE (x10^-2): 84.6600	LR: 3.83e-04	EMPP_Raw: 1.47776
2025-07-17 16:27:44,324 - logger.py:50 - Epoch: [68][5/6]	Total Loss: 0.84790	Main MSE (x10^-2): 84.7897	LR: 3.83e-04	EMPP_Raw: 1.48314
2025-07-17 16:27:44,369 - logger.py:50 - Epoch 68 Training Summary: Avg Total Loss: 0.84790, Avg Main MSE: 0.84790, Time: 23.97s
2025-07-17 16:28:03,967 - logger.py:50 - Epoch 68 Summary | Train MSE (x10^-2): 84.7897 | Val MSE (x10^-2): 17.5295 | Time: 43.57s
2025-07-17 16:28:08,253 - logger.py:50 - Epoch: [69][0/6]	Total Loss: 0.85979	Main MSE (x10^-2): 85.9787	LR: 3.82e-04	EMPP_Raw: 1.49936
2025-07-17 16:28:27,586 - logger.py:50 - Epoch: [69][5/6]	Total Loss: 0.84285	Main MSE (x10^-2): 84.2855	LR: 3.82e-04	EMPP_Raw: 1.47911
2025-07-17 16:28:27,628 - logger.py:50 - Epoch 69 Training Summary: Avg Total Loss: 0.84285, Avg Main MSE: 0.84285, Time: 23.66s
2025-07-17 16:28:47,302 - logger.py:50 - Epoch 69 Summary | Train MSE (x10^-2): 84.2855 | Val MSE (x10^-2): 18.5099 | Time: 43.33s
2025-07-17 16:28:51,546 - logger.py:50 - Epoch: [70][0/6]	Total Loss: 0.84941	Main MSE (x10^-2): 84.9412	LR: 3.82e-04	EMPP_Raw: 1.50816
2025-07-17 16:29:11,943 - logger.py:50 - Epoch: [70][5/6]	Total Loss: 0.83280	Main MSE (x10^-2): 83.2799	LR: 3.82e-04	EMPP_Raw: 1.46028
2025-07-17 16:29:11,990 - logger.py:50 - Epoch 70 Training Summary: Avg Total Loss: 0.83280, Avg Main MSE: 0.83280, Time: 24.68s
2025-07-17 16:29:31,796 - logger.py:50 - Epoch 70 Summary | Train MSE (x10^-2): 83.2799 | Val MSE (x10^-2): 18.0743 | Time: 44.49s
2025-07-17 16:29:36,094 - logger.py:50 - Epoch: [71][0/6]	Total Loss: 0.86509	Main MSE (x10^-2): 86.5089	LR: 3.81e-04	EMPP_Raw: 1.52414
2025-07-17 16:29:55,603 - logger.py:50 - Epoch: [71][5/6]	Total Loss: 0.83749	Main MSE (x10^-2): 83.7486	LR: 3.81e-04	EMPP_Raw: 1.47894
2025-07-17 16:29:55,650 - logger.py:50 - Epoch 71 Training Summary: Avg Total Loss: 0.83749, Avg Main MSE: 0.83749, Time: 23.84s
2025-07-17 16:30:17,250 - logger.py:50 - Epoch 71 Summary | Train MSE (x10^-2): 83.7486 | Val MSE (x10^-2): 18.1666 | Time: 45.45s
2025-07-17 16:30:21,612 - logger.py:50 - Epoch: [72][0/6]	Total Loss: 0.83541	Main MSE (x10^-2): 83.5408	LR: 3.80e-04	EMPP_Raw: 1.47946
2025-07-17 16:30:41,340 - logger.py:50 - Epoch: [72][5/6]	Total Loss: 0.83656	Main MSE (x10^-2): 83.6558	LR: 3.80e-04	EMPP_Raw: 1.47376
2025-07-17 16:30:41,401 - logger.py:50 - Epoch 72 Training Summary: Avg Total Loss: 0.83656, Avg Main MSE: 0.83656, Time: 24.14s
2025-07-17 16:31:01,222 - logger.py:50 - Epoch 72 Summary | Train MSE (x10^-2): 83.6558 | Val MSE (x10^-2): 18.4119 | Time: 43.97s
2025-07-17 16:31:05,545 - logger.py:50 - Epoch: [73][0/6]	Total Loss: 0.85031	Main MSE (x10^-2): 85.0305	LR: 3.80e-04	EMPP_Raw: 1.51481
2025-07-17 16:31:25,429 - logger.py:50 - Epoch: [73][5/6]	Total Loss: 0.83762	Main MSE (x10^-2): 83.7617	LR: 3.80e-04	EMPP_Raw: 1.47708
2025-07-17 16:31:25,473 - logger.py:50 - Epoch 73 Training Summary: Avg Total Loss: 0.83762, Avg Main MSE: 0.83762, Time: 24.24s
2025-07-17 16:31:45,464 - logger.py:50 - Epoch 73 Summary | Train MSE (x10^-2): 83.7617 | Val MSE (x10^-2): 18.5333 | Time: 44.24s
2025-07-17 16:31:49,761 - logger.py:50 - Epoch: [74][0/6]	Total Loss: 0.86170	Main MSE (x10^-2): 86.1698	LR: 3.79e-04	EMPP_Raw: 1.54359
2025-07-17 16:32:09,511 - logger.py:50 - Epoch: [74][5/6]	Total Loss: 0.83884	Main MSE (x10^-2): 83.8843	LR: 3.79e-04	EMPP_Raw: 1.49126
2025-07-17 16:32:09,558 - logger.py:50 - Epoch 74 Training Summary: Avg Total Loss: 0.83884, Avg Main MSE: 0.83884, Time: 24.08s
2025-07-17 16:32:29,500 - logger.py:50 - Epoch 74 Summary | Train MSE (x10^-2): 83.8843 | Val MSE (x10^-2): 18.9545 | Time: 44.03s
2025-07-17 16:32:33,796 - logger.py:50 - Epoch: [75][0/6]	Total Loss: 0.83530	Main MSE (x10^-2): 83.5302	LR: 3.79e-04	EMPP_Raw: 1.48972
2025-07-17 16:32:53,277 - logger.py:50 - Epoch: [75][5/6]	Total Loss: 0.84519	Main MSE (x10^-2): 84.5190	LR: 3.79e-04	EMPP_Raw: 1.50907
2025-07-17 16:32:53,323 - logger.py:50 - Epoch 75 Training Summary: Avg Total Loss: 0.84519, Avg Main MSE: 0.84519, Time: 23.81s
2025-07-17 16:33:13,108 - logger.py:50 - Epoch 75 Summary | Train MSE (x10^-2): 84.5190 | Val MSE (x10^-2): 19.6687 | Time: 43.60s
2025-07-17 16:33:17,415 - logger.py:50 - Epoch: [76][0/6]	Total Loss: 0.81621	Main MSE (x10^-2): 81.6214	LR: 3.78e-04	EMPP_Raw: 1.46733
2025-07-17 16:33:36,821 - logger.py:50 - Epoch: [76][5/6]	Total Loss: 0.81976	Main MSE (x10^-2): 81.9756	LR: 3.78e-04	EMPP_Raw: 1.46436
2025-07-17 16:33:36,875 - logger.py:50 - Epoch 76 Training Summary: Avg Total Loss: 0.81976, Avg Main MSE: 0.81976, Time: 23.76s
2025-07-17 16:33:56,485 - logger.py:50 - Epoch 76 Summary | Train MSE (x10^-2): 81.9756 | Val MSE (x10^-2): 19.7464 | Time: 43.37s
2025-07-17 16:34:00,831 - logger.py:50 - Epoch: [77][0/6]	Total Loss: 0.82390	Main MSE (x10^-2): 82.3901	LR: 3.78e-04	EMPP_Raw: 1.48340
2025-07-17 16:34:20,260 - logger.py:50 - Epoch: [77][5/6]	Total Loss: 0.81856	Main MSE (x10^-2): 81.8556	LR: 3.78e-04	EMPP_Raw: 1.46241
2025-07-17 16:34:20,302 - logger.py:50 - Epoch 77 Training Summary: Avg Total Loss: 0.81856, Avg Main MSE: 0.81856, Time: 23.81s
2025-07-17 16:34:39,901 - logger.py:50 - Epoch 77 Summary | Train MSE (x10^-2): 81.8556 | Val MSE (x10^-2): 18.3225 | Time: 43.41s
2025-07-17 16:34:44,043 - logger.py:50 - Epoch: [78][0/6]	Total Loss: 0.80201	Main MSE (x10^-2): 80.2013	LR: 3.77e-04	EMPP_Raw: 1.44520
2025-07-17 16:35:03,572 - logger.py:50 - Epoch: [78][5/6]	Total Loss: 0.81294	Main MSE (x10^-2): 81.2940	LR: 3.77e-04	EMPP_Raw: 1.46120
2025-07-17 16:35:03,634 - logger.py:50 - Epoch 78 Training Summary: Avg Total Loss: 0.81294, Avg Main MSE: 0.81294, Time: 23.73s
2025-07-17 16:35:23,127 - logger.py:50 - Epoch 78 Summary | Train MSE (x10^-2): 81.2940 | Val MSE (x10^-2): 18.4517 | Time: 43.23s
2025-07-17 16:35:27,221 - logger.py:50 - Epoch: [79][0/6]	Total Loss: 0.84184	Main MSE (x10^-2): 84.1844	LR: 3.77e-04	EMPP_Raw: 1.51928
2025-07-17 16:35:46,726 - logger.py:50 - Epoch: [79][5/6]	Total Loss: 0.82147	Main MSE (x10^-2): 82.1472	LR: 3.77e-04	EMPP_Raw: 1.48356
2025-07-17 16:35:46,792 - logger.py:50 - Epoch 79 Training Summary: Avg Total Loss: 0.82147, Avg Main MSE: 0.82147, Time: 23.66s
2025-07-17 16:36:06,306 - logger.py:50 - Epoch 79 Summary | Train MSE (x10^-2): 82.1472 | Val MSE (x10^-2): 18.9469 | Time: 43.18s
2025-07-17 16:36:10,407 - logger.py:50 - Epoch: [80][0/6]	Total Loss: 0.81186	Main MSE (x10^-2): 81.1864	LR: 3.76e-04	EMPP_Raw: 1.49058
2025-07-17 16:36:30,330 - logger.py:50 - Epoch: [80][5/6]	Total Loss: 0.81165	Main MSE (x10^-2): 81.1651	LR: 3.76e-04	EMPP_Raw: 1.46936
2025-07-17 16:36:30,379 - logger.py:50 - Epoch 80 Training Summary: Avg Total Loss: 0.81165, Avg Main MSE: 0.81165, Time: 24.07s
2025-07-17 16:36:53,080 - logger.py:50 - Epoch 80 Summary | Train MSE (x10^-2): 81.1651 | Val MSE (x10^-2): 19.1262 | Time: 46.77s
2025-07-17 16:36:57,271 - logger.py:50 - Epoch: [81][0/6]	Total Loss: 0.82500	Main MSE (x10^-2): 82.5001	LR: 3.75e-04	EMPP_Raw: 1.51184
2025-07-17 16:37:17,424 - logger.py:50 - Epoch: [81][5/6]	Total Loss: 0.81909	Main MSE (x10^-2): 81.9088	LR: 3.75e-04	EMPP_Raw: 1.48547
2025-07-17 16:37:17,467 - logger.py:50 - Epoch 81 Training Summary: Avg Total Loss: 0.81909, Avg Main MSE: 0.81909, Time: 24.38s
2025-07-17 16:37:36,960 - logger.py:50 - Epoch 81 Summary | Train MSE (x10^-2): 81.9088 | Val MSE (x10^-2): 19.2525 | Time: 43.87s
2025-07-17 16:37:41,077 - logger.py:50 - Epoch: [82][0/6]	Total Loss: 0.80547	Main MSE (x10^-2): 80.5472	LR: 3.75e-04	EMPP_Raw: 1.46432
2025-07-17 16:38:00,550 - logger.py:50 - Epoch: [82][5/6]	Total Loss: 0.81112	Main MSE (x10^-2): 81.1119	LR: 3.75e-04	EMPP_Raw: 1.47217
2025-07-17 16:38:00,593 - logger.py:50 - Epoch 82 Training Summary: Avg Total Loss: 0.81112, Avg Main MSE: 0.81112, Time: 23.62s
2025-07-17 16:38:20,539 - logger.py:50 - Epoch 82 Summary | Train MSE (x10^-2): 81.1119 | Val MSE (x10^-2): 19.3561 | Time: 43.57s
2025-07-17 16:38:24,619 - logger.py:50 - Epoch: [83][0/6]	Total Loss: 0.78586	Main MSE (x10^-2): 78.5865	LR: 3.74e-04	EMPP_Raw: 1.43067
2025-07-17 16:38:43,959 - logger.py:50 - Epoch: [83][5/6]	Total Loss: 0.81213	Main MSE (x10^-2): 81.2129	LR: 3.74e-04	EMPP_Raw: 1.47943
2025-07-17 16:38:44,004 - logger.py:50 - Epoch 83 Training Summary: Avg Total Loss: 0.81213, Avg Main MSE: 0.81213, Time: 23.46s
2025-07-17 16:39:03,694 - logger.py:50 - Epoch 83 Summary | Train MSE (x10^-2): 81.2129 | Val MSE (x10^-2): 18.9814 | Time: 43.15s
2025-07-17 16:39:07,823 - logger.py:50 - Epoch: [84][0/6]	Total Loss: 0.80518	Main MSE (x10^-2): 80.5179	LR: 3.73e-04	EMPP_Raw: 1.47593
2025-07-17 16:39:27,200 - logger.py:50 - Epoch: [84][5/6]	Total Loss: 0.80436	Main MSE (x10^-2): 80.4363	LR: 3.73e-04	EMPP_Raw: 1.46989
2025-07-17 16:39:27,245 - logger.py:50 - Epoch 84 Training Summary: Avg Total Loss: 0.80436, Avg Main MSE: 0.80436, Time: 23.54s
2025-07-17 16:39:46,902 - logger.py:50 - Epoch 84 Summary | Train MSE (x10^-2): 80.4363 | Val MSE (x10^-2): 18.9831 | Time: 43.20s
2025-07-17 16:39:51,013 - logger.py:50 - Epoch: [85][0/6]	Total Loss: 0.82161	Main MSE (x10^-2): 82.1608	LR: 3.73e-04	EMPP_Raw: 1.51307
2025-07-17 16:40:10,448 - logger.py:50 - Epoch: [85][5/6]	Total Loss: 0.80840	Main MSE (x10^-2): 80.8397	LR: 3.73e-04	EMPP_Raw: 1.48515
2025-07-17 16:40:10,484 - logger.py:50 - Epoch 85 Training Summary: Avg Total Loss: 0.80840, Avg Main MSE: 0.80840, Time: 23.57s
2025-07-17 16:40:30,584 - logger.py:50 - Epoch 85 Summary | Train MSE (x10^-2): 80.8397 | Val MSE (x10^-2): 19.4160 | Time: 43.68s
2025-07-17 16:40:34,792 - logger.py:50 - Epoch: [86][0/6]	Total Loss: 0.79261	Main MSE (x10^-2): 79.2611	LR: 3.72e-04	EMPP_Raw: 1.46182
2025-07-17 16:40:54,149 - logger.py:50 - Epoch: [86][5/6]	Total Loss: 0.80796	Main MSE (x10^-2): 80.7961	LR: 3.72e-04	EMPP_Raw: 1.48546
2025-07-17 16:40:54,188 - logger.py:50 - Epoch 86 Training Summary: Avg Total Loss: 0.80796, Avg Main MSE: 0.80796, Time: 23.60s
2025-07-17 16:41:13,895 - logger.py:50 - Epoch 86 Summary | Train MSE (x10^-2): 80.7961 | Val MSE (x10^-2): 19.6814 | Time: 43.31s
2025-07-17 16:41:18,008 - logger.py:50 - Epoch: [87][0/6]	Total Loss: 0.82192	Main MSE (x10^-2): 82.1916	LR: 3.72e-04	EMPP_Raw: 1.51097
2025-07-17 16:41:37,360 - logger.py:50 - Epoch: [87][5/6]	Total Loss: 0.80380	Main MSE (x10^-2): 80.3798	LR: 3.72e-04	EMPP_Raw: 1.47768
2025-07-17 16:41:37,406 - logger.py:50 - Epoch 87 Training Summary: Avg Total Loss: 0.80380, Avg Main MSE: 0.80380, Time: 23.50s
2025-07-17 16:41:57,187 - logger.py:50 - Epoch 87 Summary | Train MSE (x10^-2): 80.3798 | Val MSE (x10^-2): 19.5942 | Time: 43.29s
2025-07-17 16:42:01,362 - logger.py:50 - Epoch: [88][0/6]	Total Loss: 0.81448	Main MSE (x10^-2): 81.4477	LR: 3.71e-04	EMPP_Raw: 1.49691
2025-07-17 16:42:20,844 - logger.py:50 - Epoch: [88][5/6]	Total Loss: 0.80197	Main MSE (x10^-2): 80.1970	LR: 3.71e-04	EMPP_Raw: 1.47694
2025-07-17 16:42:20,886 - logger.py:50 - Epoch 88 Training Summary: Avg Total Loss: 0.80197, Avg Main MSE: 0.80197, Time: 23.69s
2025-07-17 16:42:40,566 - logger.py:50 - Epoch 88 Summary | Train MSE (x10^-2): 80.1970 | Val MSE (x10^-2): 19.1142 | Time: 43.37s
2025-07-17 16:42:44,667 - logger.py:50 - Epoch: [89][0/6]	Total Loss: 0.79493	Main MSE (x10^-2): 79.4930	LR: 3.70e-04	EMPP_Raw: 1.46946
2025-07-17 16:43:04,041 - logger.py:50 - Epoch: [89][5/6]	Total Loss: 0.79041	Main MSE (x10^-2): 79.0410	LR: 3.70e-04	EMPP_Raw: 1.46351
2025-07-17 16:43:04,083 - logger.py:50 - Epoch 89 Training Summary: Avg Total Loss: 0.79041, Avg Main MSE: 0.79041, Time: 23.51s
2025-07-17 16:43:23,656 - logger.py:50 - Epoch 89 Summary | Train MSE (x10^-2): 79.0410 | Val MSE (x10^-2): 18.6627 | Time: 43.08s
2025-07-17 16:43:27,785 - logger.py:50 - Epoch: [90][0/6]	Total Loss: 0.81110	Main MSE (x10^-2): 81.1101	LR: 3.70e-04	EMPP_Raw: 1.51109
2025-07-17 16:43:47,185 - logger.py:50 - Epoch: [90][5/6]	Total Loss: 0.78888	Main MSE (x10^-2): 78.8884	LR: 3.70e-04	EMPP_Raw: 1.46320
2025-07-17 16:43:47,225 - logger.py:50 - Epoch 90 Training Summary: Avg Total Loss: 0.78888, Avg Main MSE: 0.78888, Time: 23.56s
2025-07-17 16:44:06,914 - logger.py:50 - Epoch 90 Summary | Train MSE (x10^-2): 78.8884 | Val MSE (x10^-2): 19.6979 | Time: 43.25s
2025-07-17 16:44:10,998 - logger.py:50 - Epoch: [91][0/6]	Total Loss: 0.77848	Main MSE (x10^-2): 77.8476	LR: 3.69e-04	EMPP_Raw: 1.43721
2025-07-17 16:44:30,800 - logger.py:50 - Epoch: [91][5/6]	Total Loss: 0.79355	Main MSE (x10^-2): 79.3548	LR: 3.69e-04	EMPP_Raw: 1.47198
2025-07-17 16:44:30,839 - logger.py:50 - Epoch 91 Training Summary: Avg Total Loss: 0.79355, Avg Main MSE: 0.79355, Time: 23.92s
2025-07-17 16:44:50,405 - logger.py:50 - Epoch 91 Summary | Train MSE (x10^-2): 79.3548 | Val MSE (x10^-2): 19.2557 | Time: 43.49s
2025-07-17 16:44:54,522 - logger.py:50 - Epoch: [92][0/6]	Total Loss: 0.79836	Main MSE (x10^-2): 79.8356	LR: 3.68e-04	EMPP_Raw: 1.47646
2025-07-17 16:45:13,913 - logger.py:50 - Epoch: [92][5/6]	Total Loss: 0.78359	Main MSE (x10^-2): 78.3591	LR: 3.68e-04	EMPP_Raw: 1.45571
2025-07-17 16:45:13,958 - logger.py:50 - Epoch 92 Training Summary: Avg Total Loss: 0.78359, Avg Main MSE: 0.78359, Time: 23.54s
2025-07-17 16:45:33,629 - logger.py:50 - Epoch 92 Summary | Train MSE (x10^-2): 78.3591 | Val MSE (x10^-2): 19.5759 | Time: 43.22s
2025-07-17 16:45:37,727 - logger.py:50 - Epoch: [93][0/6]	Total Loss: 0.76481	Main MSE (x10^-2): 76.4812	LR: 3.68e-04	EMPP_Raw: 1.41665
2025-07-17 16:45:57,172 - logger.py:50 - Epoch: [93][5/6]	Total Loss: 0.78739	Main MSE (x10^-2): 78.7388	LR: 3.68e-04	EMPP_Raw: 1.46574
2025-07-17 16:45:57,225 - logger.py:50 - Epoch 93 Training Summary: Avg Total Loss: 0.78739, Avg Main MSE: 0.78739, Time: 23.59s
2025-07-17 16:46:17,041 - logger.py:50 - Epoch 93 Summary | Train MSE (x10^-2): 78.7388 | Val MSE (x10^-2): 19.2578 | Time: 43.41s
2025-07-17 16:46:21,136 - logger.py:50 - Epoch: [94][0/6]	Total Loss: 0.78997	Main MSE (x10^-2): 78.9974	LR: 3.67e-04	EMPP_Raw: 1.47669
2025-07-17 16:46:40,364 - logger.py:50 - Epoch: [94][5/6]	Total Loss: 0.78518	Main MSE (x10^-2): 78.5178	LR: 3.67e-04	EMPP_Raw: 1.46456
2025-07-17 16:46:40,408 - logger.py:50 - Epoch 94 Training Summary: Avg Total Loss: 0.78518, Avg Main MSE: 0.78518, Time: 23.36s
2025-07-17 16:47:00,122 - logger.py:50 - Epoch 94 Summary | Train MSE (x10^-2): 78.5178 | Val MSE (x10^-2): 19.0926 | Time: 43.08s
2025-07-17 16:47:04,226 - logger.py:50 - Epoch: [95][0/6]	Total Loss: 0.77964	Main MSE (x10^-2): 77.9644	LR: 3.66e-04	EMPP_Raw: 1.45894
2025-07-17 16:47:23,728 - logger.py:50 - Epoch: [95][5/6]	Total Loss: 0.78588	Main MSE (x10^-2): 78.5882	LR: 3.66e-04	EMPP_Raw: 1.46664
2025-07-17 16:47:23,773 - logger.py:50 - Epoch 95 Training Summary: Avg Total Loss: 0.78588, Avg Main MSE: 0.78588, Time: 23.64s
2025-07-17 16:47:43,587 - logger.py:50 - Epoch 95 Summary | Train MSE (x10^-2): 78.5882 | Val MSE (x10^-2): 19.1736 | Time: 43.46s
2025-07-17 16:47:47,717 - logger.py:50 - Epoch: [96][0/6]	Total Loss: 0.76867	Main MSE (x10^-2): 76.8672	LR: 3.66e-04	EMPP_Raw: 1.44462
2025-07-17 16:48:07,283 - logger.py:50 - Epoch: [96][5/6]	Total Loss: 0.78172	Main MSE (x10^-2): 78.1725	LR: 3.66e-04	EMPP_Raw: 1.46677
2025-07-17 16:48:07,324 - logger.py:50 - Epoch 96 Training Summary: Avg Total Loss: 0.78172, Avg Main MSE: 0.78172, Time: 23.73s
2025-07-17 16:48:27,095 - logger.py:50 - Epoch 96 Summary | Train MSE (x10^-2): 78.1725 | Val MSE (x10^-2): 18.6987 | Time: 43.51s
2025-07-17 16:48:31,198 - logger.py:50 - Epoch: [97][0/6]	Total Loss: 0.78419	Main MSE (x10^-2): 78.4193	LR: 3.65e-04	EMPP_Raw: 1.47084
2025-07-17 16:48:50,546 - logger.py:50 - Epoch: [97][5/6]	Total Loss: 0.79059	Main MSE (x10^-2): 79.0592	LR: 3.65e-04	EMPP_Raw: 1.48044
2025-07-17 16:48:50,586 - logger.py:50 - Epoch 97 Training Summary: Avg Total Loss: 0.79059, Avg Main MSE: 0.79059, Time: 23.48s
2025-07-17 16:49:10,521 - logger.py:50 - Epoch 97 Summary | Train MSE (x10^-2): 79.0592 | Val MSE (x10^-2): 19.2568 | Time: 43.42s
2025-07-17 16:49:14,590 - logger.py:50 - Epoch: [98][0/6]	Total Loss: 0.78844	Main MSE (x10^-2): 78.8444	LR: 3.64e-04	EMPP_Raw: 1.47840
2025-07-17 16:49:33,943 - logger.py:50 - Epoch: [98][5/6]	Total Loss: 0.78645	Main MSE (x10^-2): 78.6446	LR: 3.64e-04	EMPP_Raw: 1.47729
2025-07-17 16:49:33,984 - logger.py:50 - Epoch 98 Training Summary: Avg Total Loss: 0.78645, Avg Main MSE: 0.78645, Time: 23.45s
2025-07-17 16:49:53,565 - logger.py:50 - Epoch 98 Summary | Train MSE (x10^-2): 78.6446 | Val MSE (x10^-2): 18.8527 | Time: 43.04s
2025-07-17 16:49:57,674 - logger.py:50 - Epoch: [99][0/6]	Total Loss: 0.78755	Main MSE (x10^-2): 78.7553	LR: 3.63e-04	EMPP_Raw: 1.48391
2025-07-17 16:50:16,928 - logger.py:50 - Epoch: [99][5/6]	Total Loss: 0.77648	Main MSE (x10^-2): 77.6482	LR: 3.63e-04	EMPP_Raw: 1.46022
2025-07-17 16:50:16,967 - logger.py:50 - Epoch 99 Training Summary: Avg Total Loss: 0.77648, Avg Main MSE: 0.77648, Time: 23.40s
2025-07-17 16:50:36,585 - logger.py:50 - Epoch 99 Summary | Train MSE (x10^-2): 77.6482 | Val MSE (x10^-2): 18.7858 | Time: 43.02s
2025-07-17 16:50:40,731 - logger.py:50 - Epoch: [100][0/6]	Total Loss: 0.78183	Main MSE (x10^-2): 78.1827	LR: 3.63e-04	EMPP_Raw: 1.47732
2025-07-17 16:51:00,064 - logger.py:50 - Epoch: [100][5/6]	Total Loss: 0.77994	Main MSE (x10^-2): 77.9942	LR: 3.63e-04	EMPP_Raw: 1.46851
2025-07-17 16:51:00,120 - logger.py:50 - Epoch 100 Training Summary: Avg Total Loss: 0.77994, Avg Main MSE: 0.77994, Time: 23.53s
2025-07-17 16:51:20,034 - logger.py:50 - Epoch 100 Summary | Train MSE (x10^-2): 77.9942 | Val MSE (x10^-2): 19.3244 | Time: 43.44s
2025-07-17 16:51:24,149 - logger.py:50 - Epoch: [101][0/6]	Total Loss: 0.78556	Main MSE (x10^-2): 78.5557	LR: 3.62e-04	EMPP_Raw: 1.48049
2025-07-17 16:51:43,464 - logger.py:50 - Epoch: [101][5/6]	Total Loss: 0.78116	Main MSE (x10^-2): 78.1157	LR: 3.62e-04	EMPP_Raw: 1.47277
2025-07-17 16:51:43,515 - logger.py:50 - Epoch 101 Training Summary: Avg Total Loss: 0.78116, Avg Main MSE: 0.78116, Time: 23.48s
2025-07-17 16:52:03,272 - logger.py:50 - Epoch 101 Summary | Train MSE (x10^-2): 78.1157 | Val MSE (x10^-2): 18.5871 | Time: 43.24s
2025-07-17 16:52:07,378 - logger.py:50 - Epoch: [102][0/6]	Total Loss: 0.80370	Main MSE (x10^-2): 80.3702	LR: 3.61e-04	EMPP_Raw: 1.51579
2025-07-17 16:52:26,670 - logger.py:50 - Epoch: [102][5/6]	Total Loss: 0.77361	Main MSE (x10^-2): 77.3607	LR: 3.61e-04	EMPP_Raw: 1.45778
2025-07-17 16:52:26,708 - logger.py:50 - Epoch 102 Training Summary: Avg Total Loss: 0.77361, Avg Main MSE: 0.77361, Time: 23.43s
2025-07-17 16:52:46,388 - logger.py:50 - Epoch 102 Summary | Train MSE (x10^-2): 77.3607 | Val MSE (x10^-2): 19.5974 | Time: 43.11s
2025-07-17 16:52:50,585 - logger.py:50 - Epoch: [103][0/6]	Total Loss: 0.75299	Main MSE (x10^-2): 75.2985	LR: 3.60e-04	EMPP_Raw: 1.42447
2025-07-17 16:53:10,636 - logger.py:50 - Epoch: [103][5/6]	Total Loss: 0.77805	Main MSE (x10^-2): 77.8055	LR: 3.60e-04	EMPP_Raw: 1.47132
2025-07-17 16:53:10,677 - logger.py:50 - Epoch 103 Training Summary: Avg Total Loss: 0.77805, Avg Main MSE: 0.77805, Time: 24.28s
2025-07-17 16:53:30,768 - logger.py:50 - Epoch 103 Summary | Train MSE (x10^-2): 77.8055 | Val MSE (x10^-2): 19.3870 | Time: 44.38s
2025-07-17 16:53:34,878 - logger.py:50 - Epoch: [104][0/6]	Total Loss: 0.78583	Main MSE (x10^-2): 78.5826	LR: 3.60e-04	EMPP_Raw: 1.47946
2025-07-17 16:53:54,282 - logger.py:50 - Epoch: [104][5/6]	Total Loss: 0.78449	Main MSE (x10^-2): 78.4491	LR: 3.60e-04	EMPP_Raw: 1.48486
2025-07-17 16:53:54,325 - logger.py:50 - Epoch 104 Training Summary: Avg Total Loss: 0.78449, Avg Main MSE: 0.78449, Time: 23.55s
2025-07-17 16:54:14,231 - logger.py:50 - Epoch 104 Summary | Train MSE (x10^-2): 78.4491 | Val MSE (x10^-2): 19.8359 | Time: 43.46s
2025-07-17 16:54:18,331 - logger.py:50 - Epoch: [105][0/6]	Total Loss: 0.77503	Main MSE (x10^-2): 77.5028	LR: 3.59e-04	EMPP_Raw: 1.47173
2025-07-17 16:54:38,116 - logger.py:50 - Epoch: [105][5/6]	Total Loss: 0.77372	Main MSE (x10^-2): 77.3723	LR: 3.59e-04	EMPP_Raw: 1.46719
2025-07-17 16:54:38,162 - logger.py:50 - Epoch 105 Training Summary: Avg Total Loss: 0.77372, Avg Main MSE: 0.77372, Time: 23.92s
2025-07-17 16:54:59,081 - logger.py:50 - Epoch 105 Summary | Train MSE (x10^-2): 77.3723 | Val MSE (x10^-2): 18.9296 | Time: 44.84s
2025-07-17 16:55:03,430 - logger.py:50 - Epoch: [106][0/6]	Total Loss: 0.77272	Main MSE (x10^-2): 77.2724	LR: 3.58e-04	EMPP_Raw: 1.46910
2025-07-17 16:55:23,596 - logger.py:50 - Epoch: [106][5/6]	Total Loss: 0.78637	Main MSE (x10^-2): 78.6369	LR: 3.58e-04	EMPP_Raw: 1.49374
2025-07-17 16:55:23,662 - logger.py:50 - Epoch 106 Training Summary: Avg Total Loss: 0.78637, Avg Main MSE: 0.78637, Time: 24.57s
2025-07-17 16:55:44,518 - logger.py:50 - Epoch 106 Summary | Train MSE (x10^-2): 78.6369 | Val MSE (x10^-2): 18.9728 | Time: 45.43s
2025-07-17 16:55:48,727 - logger.py:50 - Epoch: [107][0/6]	Total Loss: 0.75570	Main MSE (x10^-2): 75.5700	LR: 3.57e-04	EMPP_Raw: 1.43030
2025-07-17 16:56:08,531 - logger.py:50 - Epoch: [107][5/6]	Total Loss: 0.76396	Main MSE (x10^-2): 76.3956	LR: 3.57e-04	EMPP_Raw: 1.44657
2025-07-17 16:56:08,575 - logger.py:50 - Epoch 107 Training Summary: Avg Total Loss: 0.76396, Avg Main MSE: 0.76396, Time: 24.05s
2025-07-17 16:56:28,714 - logger.py:50 - Epoch 107 Summary | Train MSE (x10^-2): 76.3956 | Val MSE (x10^-2): 19.1211 | Time: 44.19s
2025-07-17 16:56:32,895 - logger.py:50 - Epoch: [108][0/6]	Total Loss: 0.79393	Main MSE (x10^-2): 79.3926	LR: 3.57e-04	EMPP_Raw: 1.50826
2025-07-17 16:56:52,509 - logger.py:50 - Epoch: [108][5/6]	Total Loss: 0.78038	Main MSE (x10^-2): 78.0377	LR: 3.57e-04	EMPP_Raw: 1.48325
2025-07-17 16:56:52,553 - logger.py:50 - Epoch 108 Training Summary: Avg Total Loss: 0.78038, Avg Main MSE: 0.78038, Time: 23.83s
2025-07-17 16:57:12,829 - logger.py:50 - Epoch 108 Summary | Train MSE (x10^-2): 78.0377 | Val MSE (x10^-2): 18.5862 | Time: 44.11s
2025-07-17 16:57:17,011 - logger.py:50 - Epoch: [109][0/6]	Total Loss: 0.75777	Main MSE (x10^-2): 75.7767	LR: 3.56e-04	EMPP_Raw: 1.43932
2025-07-17 16:57:36,853 - logger.py:50 - Epoch: [109][5/6]	Total Loss: 0.76241	Main MSE (x10^-2): 76.2412	LR: 3.56e-04	EMPP_Raw: 1.45137
2025-07-17 16:57:36,895 - logger.py:50 - Epoch 109 Training Summary: Avg Total Loss: 0.76241, Avg Main MSE: 0.76241, Time: 24.06s
2025-07-17 16:57:57,777 - logger.py:50 - Epoch 109 Summary | Train MSE (x10^-2): 76.2412 | Val MSE (x10^-2): 19.1170 | Time: 44.94s
2025-07-17 16:58:01,952 - logger.py:50 - Epoch: [110][0/6]	Total Loss: 0.77447	Main MSE (x10^-2): 77.4471	LR: 3.55e-04	EMPP_Raw: 1.48168
2025-07-17 16:58:22,121 - logger.py:50 - Epoch: [110][5/6]	Total Loss: 0.76475	Main MSE (x10^-2): 76.4747	LR: 3.55e-04	EMPP_Raw: 1.45684
2025-07-17 16:58:22,161 - logger.py:50 - Epoch 110 Training Summary: Avg Total Loss: 0.76475, Avg Main MSE: 0.76475, Time: 24.37s
2025-07-17 16:58:42,999 - logger.py:50 - Epoch 110 Summary | Train MSE (x10^-2): 76.4747 | Val MSE (x10^-2): 18.5380 | Time: 45.22s
2025-07-17 16:58:47,225 - logger.py:50 - Epoch: [111][0/6]	Total Loss: 0.75722	Main MSE (x10^-2): 75.7223	LR: 3.54e-04	EMPP_Raw: 1.44724
2025-07-17 16:59:07,261 - logger.py:50 - Epoch: [111][5/6]	Total Loss: 0.76653	Main MSE (x10^-2): 76.6534	LR: 3.54e-04	EMPP_Raw: 1.46274
2025-07-17 16:59:07,315 - logger.py:50 - Epoch 111 Training Summary: Avg Total Loss: 0.76653, Avg Main MSE: 0.76653, Time: 24.31s
2025-07-17 16:59:28,225 - logger.py:50 - Epoch 111 Summary | Train MSE (x10^-2): 76.6534 | Val MSE (x10^-2): 18.9836 | Time: 45.22s
2025-07-17 16:59:32,471 - logger.py:50 - Epoch: [112][0/6]	Total Loss: 0.77648	Main MSE (x10^-2): 77.6482	LR: 3.53e-04	EMPP_Raw: 1.48330
2025-07-17 16:59:52,436 - logger.py:50 - Epoch: [112][5/6]	Total Loss: 0.77819	Main MSE (x10^-2): 77.8189	LR: 3.53e-04	EMPP_Raw: 1.48497
2025-07-17 16:59:52,486 - logger.py:50 - Epoch 112 Training Summary: Avg Total Loss: 0.77819, Avg Main MSE: 0.77819, Time: 24.25s
2025-07-17 17:00:13,319 - logger.py:50 - Epoch 112 Summary | Train MSE (x10^-2): 77.8189 | Val MSE (x10^-2): 19.3985 | Time: 45.09s
2025-07-17 17:00:17,657 - logger.py:50 - Epoch: [113][0/6]	Total Loss: 0.78232	Main MSE (x10^-2): 78.2319	LR: 3.53e-04	EMPP_Raw: 1.49692
2025-07-17 17:00:37,719 - logger.py:50 - Epoch: [113][5/6]	Total Loss: 0.77092	Main MSE (x10^-2): 77.0916	LR: 3.53e-04	EMPP_Raw: 1.47113
2025-07-17 17:00:37,764 - logger.py:50 - Epoch 113 Training Summary: Avg Total Loss: 0.77092, Avg Main MSE: 0.77092, Time: 24.44s
2025-07-17 17:00:58,489 - logger.py:50 - Epoch 113 Summary | Train MSE (x10^-2): 77.0916 | Val MSE (x10^-2): 18.7161 | Time: 45.16s
2025-07-17 17:01:02,826 - logger.py:50 - Epoch: [114][0/6]	Total Loss: 0.76191	Main MSE (x10^-2): 76.1908	LR: 3.52e-04	EMPP_Raw: 1.45739
2025-07-17 17:01:22,690 - logger.py:50 - Epoch: [114][5/6]	Total Loss: 0.76324	Main MSE (x10^-2): 76.3236	LR: 3.52e-04	EMPP_Raw: 1.45655
2025-07-17 17:01:22,731 - logger.py:50 - Epoch 114 Training Summary: Avg Total Loss: 0.76324, Avg Main MSE: 0.76324, Time: 24.23s
2025-07-17 17:01:43,743 - logger.py:50 - Epoch 114 Summary | Train MSE (x10^-2): 76.3236 | Val MSE (x10^-2): 18.9114 | Time: 45.25s
2025-07-17 17:01:47,998 - logger.py:50 - Epoch: [115][0/6]	Total Loss: 0.77653	Main MSE (x10^-2): 77.6525	LR: 3.51e-04	EMPP_Raw: 1.47081
2025-07-17 17:02:08,055 - logger.py:50 - Epoch: [115][5/6]	Total Loss: 0.76792	Main MSE (x10^-2): 76.7919	LR: 3.51e-04	EMPP_Raw: 1.46461
2025-07-17 17:02:08,117 - logger.py:50 - Epoch 115 Training Summary: Avg Total Loss: 0.76792, Avg Main MSE: 0.76792, Time: 24.36s
2025-07-17 17:02:28,645 - logger.py:50 - Epoch 115 Summary | Train MSE (x10^-2): 76.7919 | Val MSE (x10^-2): 18.6097 | Time: 44.90s
2025-07-17 17:02:32,892 - logger.py:50 - Epoch: [116][0/6]	Total Loss: 0.77355	Main MSE (x10^-2): 77.3553	LR: 3.50e-04	EMPP_Raw: 1.47576
2025-07-17 17:02:52,824 - logger.py:50 - Epoch: [116][5/6]	Total Loss: 0.78072	Main MSE (x10^-2): 78.0717	LR: 3.50e-04	EMPP_Raw: 1.49345
2025-07-17 17:02:52,871 - logger.py:50 - Epoch 116 Training Summary: Avg Total Loss: 0.78072, Avg Main MSE: 0.78072, Time: 24.21s
2025-07-17 17:03:13,927 - logger.py:50 - Epoch 116 Summary | Train MSE (x10^-2): 78.0717 | Val MSE (x10^-2): 18.8602 | Time: 45.28s
2025-07-17 17:03:18,194 - logger.py:50 - Epoch: [117][0/6]	Total Loss: 0.77901	Main MSE (x10^-2): 77.9014	LR: 3.49e-04	EMPP_Raw: 1.49415
2025-07-17 17:03:38,096 - logger.py:50 - Epoch: [117][5/6]	Total Loss: 0.76309	Main MSE (x10^-2): 76.3088	LR: 3.49e-04	EMPP_Raw: 1.46026
2025-07-17 17:03:38,161 - logger.py:50 - Epoch 117 Training Summary: Avg Total Loss: 0.76309, Avg Main MSE: 0.76309, Time: 24.22s
2025-07-17 17:03:58,708 - logger.py:50 - Epoch 117 Summary | Train MSE (x10^-2): 76.3088 | Val MSE (x10^-2): 19.2905 | Time: 44.77s
2025-07-17 17:04:02,992 - logger.py:50 - Epoch: [118][0/6]	Total Loss: 0.75848	Main MSE (x10^-2): 75.8483	LR: 3.48e-04	EMPP_Raw: 1.45025
2025-07-17 17:04:22,967 - logger.py:50 - Epoch: [118][5/6]	Total Loss: 0.76128	Main MSE (x10^-2): 76.1280	LR: 3.48e-04	EMPP_Raw: 1.45737
2025-07-17 17:04:23,004 - logger.py:50 - Epoch 118 Training Summary: Avg Total Loss: 0.76128, Avg Main MSE: 0.76128, Time: 24.29s
2025-07-17 17:04:43,810 - logger.py:50 - Epoch 118 Summary | Train MSE (x10^-2): 76.1280 | Val MSE (x10^-2): 18.9099 | Time: 45.09s
2025-07-17 17:04:48,003 - logger.py:50 - Epoch: [119][0/6]	Total Loss: 0.78822	Main MSE (x10^-2): 78.8220	LR: 3.48e-04	EMPP_Raw: 1.51560
2025-07-17 17:05:08,175 - logger.py:50 - Epoch: [119][5/6]	Total Loss: 0.77197	Main MSE (x10^-2): 77.1967	LR: 3.48e-04	EMPP_Raw: 1.47887
2025-07-17 17:05:08,215 - logger.py:50 - Epoch 119 Training Summary: Avg Total Loss: 0.77197, Avg Main MSE: 0.77197, Time: 24.40s
2025-07-17 17:05:31,342 - logger.py:50 - Epoch 119 Summary | Train MSE (x10^-2): 77.1967 | Val MSE (x10^-2): 19.1953 | Time: 47.53s
2025-07-17 17:05:35,712 - logger.py:50 - Epoch: [120][0/6]	Total Loss: 0.76378	Main MSE (x10^-2): 76.3776	LR: 3.47e-04	EMPP_Raw: 1.46564
2025-07-17 17:05:56,182 - logger.py:50 - Epoch: [120][5/6]	Total Loss: 0.76157	Main MSE (x10^-2): 76.1565	LR: 3.47e-04	EMPP_Raw: 1.45973
2025-07-17 17:05:56,248 - logger.py:50 - Epoch 120 Training Summary: Avg Total Loss: 0.76157, Avg Main MSE: 0.76157, Time: 24.90s
2025-07-17 17:06:16,946 - logger.py:50 - Epoch 120 Summary | Train MSE (x10^-2): 76.1565 | Val MSE (x10^-2): 19.1491 | Time: 45.60s
2025-07-17 17:06:21,117 - logger.py:50 - Epoch: [121][0/6]	Total Loss: 0.77288	Main MSE (x10^-2): 77.2879	LR: 3.46e-04	EMPP_Raw: 1.48222
2025-07-17 17:06:41,156 - logger.py:50 - Epoch: [121][5/6]	Total Loss: 0.76127	Main MSE (x10^-2): 76.1269	LR: 3.46e-04	EMPP_Raw: 1.46229
2025-07-17 17:06:41,202 - logger.py:50 - Epoch 121 Training Summary: Avg Total Loss: 0.76127, Avg Main MSE: 0.76127, Time: 24.25s
2025-07-17 17:07:02,159 - logger.py:50 - Epoch 121 Summary | Train MSE (x10^-2): 76.1269 | Val MSE (x10^-2): 19.1951 | Time: 45.21s
2025-07-17 17:07:06,602 - logger.py:50 - Epoch: [122][0/6]	Total Loss: 0.76023	Main MSE (x10^-2): 76.0229	LR: 3.45e-04	EMPP_Raw: 1.45626
2025-07-17 17:07:26,984 - logger.py:50 - Epoch: [122][5/6]	Total Loss: 0.76147	Main MSE (x10^-2): 76.1473	LR: 3.45e-04	EMPP_Raw: 1.46132
2025-07-17 17:07:27,033 - logger.py:50 - Epoch 122 Training Summary: Avg Total Loss: 0.76147, Avg Main MSE: 0.76147, Time: 24.87s
2025-07-17 17:07:47,689 - logger.py:50 - Epoch 122 Summary | Train MSE (x10^-2): 76.1473 | Val MSE (x10^-2): 19.1326 | Time: 45.53s
2025-07-17 17:07:51,985 - logger.py:50 - Epoch: [123][0/6]	Total Loss: 0.74841	Main MSE (x10^-2): 74.8409	LR: 3.44e-04	EMPP_Raw: 1.43788
2025-07-17 17:08:12,135 - logger.py:50 - Epoch: [123][5/6]	Total Loss: 0.75437	Main MSE (x10^-2): 75.4366	LR: 3.44e-04	EMPP_Raw: 1.44955
2025-07-17 17:08:12,188 - logger.py:50 - Epoch 123 Training Summary: Avg Total Loss: 0.75437, Avg Main MSE: 0.75437, Time: 24.49s
2025-07-17 17:08:32,846 - logger.py:50 - Epoch 123 Summary | Train MSE (x10^-2): 75.4366 | Val MSE (x10^-2): 19.0265 | Time: 45.15s
2025-07-17 17:08:37,040 - logger.py:50 - Epoch: [124][0/6]	Total Loss: 0.75944	Main MSE (x10^-2): 75.9439	LR: 3.43e-04	EMPP_Raw: 1.46047
2025-07-17 17:08:57,064 - logger.py:50 - Epoch: [124][5/6]	Total Loss: 0.75680	Main MSE (x10^-2): 75.6804	LR: 3.43e-04	EMPP_Raw: 1.45365
2025-07-17 17:08:57,108 - logger.py:50 - Epoch 124 Training Summary: Avg Total Loss: 0.75680, Avg Main MSE: 0.75680, Time: 24.26s
2025-07-17 17:09:17,792 - logger.py:50 - Epoch 124 Summary | Train MSE (x10^-2): 75.6804 | Val MSE (x10^-2): 19.0296 | Time: 44.94s
2025-07-17 17:09:21,990 - logger.py:50 - Epoch: [125][0/6]	Total Loss: 0.77141	Main MSE (x10^-2): 77.1408	LR: 3.42e-04	EMPP_Raw: 1.48348
2025-07-17 17:09:42,128 - logger.py:50 - Epoch: [125][5/6]	Total Loss: 0.77079	Main MSE (x10^-2): 77.0792	LR: 3.42e-04	EMPP_Raw: 1.47786
2025-07-17 17:09:42,176 - logger.py:50 - Epoch 125 Training Summary: Avg Total Loss: 0.77079, Avg Main MSE: 0.77079, Time: 24.37s
2025-07-17 17:10:02,808 - logger.py:50 - Epoch 125 Summary | Train MSE (x10^-2): 77.0792 | Val MSE (x10^-2): 19.0118 | Time: 45.01s
2025-07-17 17:10:07,138 - logger.py:50 - Epoch: [126][0/6]	Total Loss: 0.74654	Main MSE (x10^-2): 74.6536	LR: 3.42e-04	EMPP_Raw: 1.43645
2025-07-17 17:10:27,112 - logger.py:50 - Epoch: [126][5/6]	Total Loss: 0.76307	Main MSE (x10^-2): 76.3068	LR: 3.42e-04	EMPP_Raw: 1.46411
2025-07-17 17:10:27,148 - logger.py:50 - Epoch 126 Training Summary: Avg Total Loss: 0.76307, Avg Main MSE: 0.76307, Time: 24.33s
2025-07-17 17:10:47,837 - logger.py:50 - Epoch 126 Summary | Train MSE (x10^-2): 76.3068 | Val MSE (x10^-2): 18.6133 | Time: 45.02s
2025-07-17 17:10:52,114 - logger.py:50 - Epoch: [127][0/6]	Total Loss: 0.73224	Main MSE (x10^-2): 73.2244	LR: 3.41e-04	EMPP_Raw: 1.40403
2025-07-17 17:11:12,243 - logger.py:50 - Epoch: [127][5/6]	Total Loss: 0.75743	Main MSE (x10^-2): 75.7430	LR: 3.41e-04	EMPP_Raw: 1.45784
2025-07-17 17:11:12,287 - logger.py:50 - Epoch 127 Training Summary: Avg Total Loss: 0.75743, Avg Main MSE: 0.75743, Time: 24.44s
2025-07-17 17:11:33,199 - logger.py:50 - Epoch 127 Summary | Train MSE (x10^-2): 75.7430 | Val MSE (x10^-2): 18.8188 | Time: 45.36s
2025-07-17 17:11:37,441 - logger.py:50 - Epoch: [128][0/6]	Total Loss: 0.78377	Main MSE (x10^-2): 78.3765	LR: 3.40e-04	EMPP_Raw: 1.51088
2025-07-17 17:11:57,332 - logger.py:50 - Epoch: [128][5/6]	Total Loss: 0.76439	Main MSE (x10^-2): 76.4391	LR: 3.40e-04	EMPP_Raw: 1.47378
2025-07-17 17:11:57,378 - logger.py:50 - Epoch 128 Training Summary: Avg Total Loss: 0.76439, Avg Main MSE: 0.76439, Time: 24.17s
2025-07-17 17:12:18,005 - logger.py:50 - Epoch 128 Summary | Train MSE (x10^-2): 76.4391 | Val MSE (x10^-2): 18.7125 | Time: 44.80s
2025-07-17 17:12:22,291 - logger.py:50 - Epoch: [129][0/6]	Total Loss: 0.75915	Main MSE (x10^-2): 75.9145	LR: 3.39e-04	EMPP_Raw: 1.46118
2025-07-17 17:12:42,567 - logger.py:50 - Epoch: [129][5/6]	Total Loss: 0.75501	Main MSE (x10^-2): 75.5015	LR: 3.39e-04	EMPP_Raw: 1.45476
2025-07-17 17:12:42,613 - logger.py:50 - Epoch 129 Training Summary: Avg Total Loss: 0.75501, Avg Main MSE: 0.75501, Time: 24.60s
2025-07-17 17:13:03,170 - logger.py:50 - Epoch 129 Summary | Train MSE (x10^-2): 75.5015 | Val MSE (x10^-2): 18.5065 | Time: 45.16s
2025-07-17 17:13:07,387 - logger.py:50 - Epoch: [130][0/6]	Total Loss: 0.77370	Main MSE (x10^-2): 77.3700	LR: 3.38e-04	EMPP_Raw: 1.49593
2025-07-17 17:13:27,522 - logger.py:50 - Epoch: [130][5/6]	Total Loss: 0.77073	Main MSE (x10^-2): 77.0727	LR: 3.38e-04	EMPP_Raw: 1.48847
2025-07-17 17:13:27,571 - logger.py:50 - Epoch 130 Training Summary: Avg Total Loss: 0.77073, Avg Main MSE: 0.77073, Time: 24.39s
2025-07-17 17:13:48,513 - logger.py:50 - Epoch 130 Summary | Train MSE (x10^-2): 77.0727 | Val MSE (x10^-2): 18.5650 | Time: 45.34s
2025-07-17 17:13:52,731 - logger.py:50 - Epoch: [131][0/6]	Total Loss: 0.75426	Main MSE (x10^-2): 75.4262	LR: 3.37e-04	EMPP_Raw: 1.45570
2025-07-17 17:14:12,793 - logger.py:50 - Epoch: [131][5/6]	Total Loss: 0.75738	Main MSE (x10^-2): 75.7376	LR: 3.37e-04	EMPP_Raw: 1.45898
2025-07-17 17:14:12,838 - logger.py:50 - Epoch 131 Training Summary: Avg Total Loss: 0.75738, Avg Main MSE: 0.75738, Time: 24.31s
2025-07-17 17:14:33,388 - logger.py:50 - Epoch 131 Summary | Train MSE (x10^-2): 75.7376 | Val MSE (x10^-2): 19.0295 | Time: 44.87s
2025-07-17 17:14:37,648 - logger.py:50 - Epoch: [132][0/6]	Total Loss: 0.74329	Main MSE (x10^-2): 74.3294	LR: 3.36e-04	EMPP_Raw: 1.43074
2025-07-17 17:14:57,703 - logger.py:50 - Epoch: [132][5/6]	Total Loss: 0.75960	Main MSE (x10^-2): 75.9601	LR: 3.36e-04	EMPP_Raw: 1.46502
2025-07-17 17:14:57,746 - logger.py:50 - Epoch 132 Training Summary: Avg Total Loss: 0.75960, Avg Main MSE: 0.75960, Time: 24.35s
2025-07-17 17:15:18,472 - logger.py:50 - Epoch 132 Summary | Train MSE (x10^-2): 75.9601 | Val MSE (x10^-2): 18.6482 | Time: 45.08s
2025-07-17 17:15:22,651 - logger.py:50 - Epoch: [133][0/6]	Total Loss: 0.74027	Main MSE (x10^-2): 74.0271	LR: 3.35e-04	EMPP_Raw: 1.43132
2025-07-17 17:15:42,618 - logger.py:50 - Epoch: [133][5/6]	Total Loss: 0.75263	Main MSE (x10^-2): 75.2627	LR: 3.35e-04	EMPP_Raw: 1.45185
2025-07-17 17:15:42,659 - logger.py:50 - Epoch 133 Training Summary: Avg Total Loss: 0.75263, Avg Main MSE: 0.75263, Time: 24.18s
2025-07-17 17:16:03,514 - logger.py:50 - Epoch 133 Summary | Train MSE (x10^-2): 75.2627 | Val MSE (x10^-2): 18.6638 | Time: 45.04s
2025-07-17 17:16:07,798 - logger.py:50 - Epoch: [134][0/6]	Total Loss: 0.74942	Main MSE (x10^-2): 74.9417	LR: 3.34e-04	EMPP_Raw: 1.45101
2025-07-17 17:16:27,955 - logger.py:50 - Epoch: [134][5/6]	Total Loss: 0.75517	Main MSE (x10^-2): 75.5172	LR: 3.34e-04	EMPP_Raw: 1.45756
2025-07-17 17:16:28,017 - logger.py:50 - Epoch 134 Training Summary: Avg Total Loss: 0.75517, Avg Main MSE: 0.75517, Time: 24.50s
2025-07-17 17:16:49,016 - logger.py:50 - Epoch 134 Summary | Train MSE (x10^-2): 75.5172 | Val MSE (x10^-2): 18.7749 | Time: 45.50s
2025-07-17 17:16:53,367 - logger.py:50 - Epoch: [135][0/6]	Total Loss: 0.73734	Main MSE (x10^-2): 73.7336	LR: 3.33e-04	EMPP_Raw: 1.42033
2025-07-17 17:17:13,535 - logger.py:50 - Epoch: [135][5/6]	Total Loss: 0.75341	Main MSE (x10^-2): 75.3411	LR: 3.33e-04	EMPP_Raw: 1.45357
2025-07-17 17:17:13,576 - logger.py:50 - Epoch 135 Training Summary: Avg Total Loss: 0.75341, Avg Main MSE: 0.75341, Time: 24.55s
2025-07-17 17:17:34,685 - logger.py:50 - Epoch 135 Summary | Train MSE (x10^-2): 75.3411 | Val MSE (x10^-2): 18.4791 | Time: 45.66s
2025-07-17 17:17:38,949 - logger.py:50 - Epoch: [136][0/6]	Total Loss: 0.75500	Main MSE (x10^-2): 75.4999	LR: 3.32e-04	EMPP_Raw: 1.45706
2025-07-17 17:17:59,071 - logger.py:50 - Epoch: [136][5/6]	Total Loss: 0.75933	Main MSE (x10^-2): 75.9325	LR: 3.32e-04	EMPP_Raw: 1.46551
2025-07-17 17:17:59,119 - logger.py:50 - Epoch 136 Training Summary: Avg Total Loss: 0.75933, Avg Main MSE: 0.75933, Time: 24.43s
2025-07-17 17:18:20,071 - logger.py:50 - Epoch 136 Summary | Train MSE (x10^-2): 75.9325 | Val MSE (x10^-2): 18.6159 | Time: 45.38s
2025-07-17 17:18:24,346 - logger.py:50 - Epoch: [137][0/6]	Total Loss: 0.73319	Main MSE (x10^-2): 73.3192	LR: 3.31e-04	EMPP_Raw: 1.41517
2025-07-17 17:18:44,398 - logger.py:50 - Epoch: [137][5/6]	Total Loss: 0.74434	Main MSE (x10^-2): 74.4338	LR: 3.31e-04	EMPP_Raw: 1.43560
2025-07-17 17:18:44,448 - logger.py:50 - Epoch 137 Training Summary: Avg Total Loss: 0.74434, Avg Main MSE: 0.74434, Time: 24.36s
2025-07-17 17:19:05,071 - logger.py:50 - Epoch 137 Summary | Train MSE (x10^-2): 74.4338 | Val MSE (x10^-2): 18.9561 | Time: 44.99s
2025-07-17 17:19:09,393 - logger.py:50 - Epoch: [138][0/6]	Total Loss: 0.76257	Main MSE (x10^-2): 76.2574	LR: 3.31e-04	EMPP_Raw: 1.47307
2025-07-17 17:19:29,457 - logger.py:50 - Epoch: [138][5/6]	Total Loss: 0.76474	Main MSE (x10^-2): 76.4738	LR: 3.31e-04	EMPP_Raw: 1.47710
2025-07-17 17:19:29,503 - logger.py:50 - Epoch 138 Training Summary: Avg Total Loss: 0.76474, Avg Main MSE: 0.76474, Time: 24.42s
2025-07-17 17:19:50,244 - logger.py:50 - Epoch 138 Summary | Train MSE (x10^-2): 76.4738 | Val MSE (x10^-2): 18.9612 | Time: 45.17s
2025-07-17 17:19:54,487 - logger.py:50 - Epoch: [139][0/6]	Total Loss: 0.75885	Main MSE (x10^-2): 75.8852	LR: 3.30e-04	EMPP_Raw: 1.46656
2025-07-17 17:20:14,617 - logger.py:50 - Epoch: [139][5/6]	Total Loss: 0.75925	Main MSE (x10^-2): 75.9245	LR: 3.30e-04	EMPP_Raw: 1.46759
2025-07-17 17:20:14,665 - logger.py:50 - Epoch 139 Training Summary: Avg Total Loss: 0.75925, Avg Main MSE: 0.75925, Time: 24.41s
2025-07-17 17:20:36,039 - logger.py:50 - Epoch 139 Summary | Train MSE (x10^-2): 75.9245 | Val MSE (x10^-2): 19.1667 | Time: 45.79s
2025-07-17 17:20:41,229 - logger.py:50 - Epoch: [140][0/6]	Total Loss: 0.77829	Main MSE (x10^-2): 77.8292	LR: 3.29e-04	EMPP_Raw: 1.50697
2025-07-17 17:21:02,905 - logger.py:50 - Epoch: [140][5/6]	Total Loss: 0.76620	Main MSE (x10^-2): 76.6199	LR: 3.29e-04	EMPP_Raw: 1.48219
2025-07-17 17:21:02,952 - logger.py:50 - Epoch 140 Training Summary: Avg Total Loss: 0.76620, Avg Main MSE: 0.76620, Time: 26.91s
2025-07-17 17:21:24,152 - logger.py:50 - Epoch 140 Summary | Train MSE (x10^-2): 76.6199 | Val MSE (x10^-2): 19.2543 | Time: 48.11s
2025-07-17 17:21:28,384 - logger.py:50 - Epoch: [141][0/6]	Total Loss: 0.75304	Main MSE (x10^-2): 75.3044	LR: 3.28e-04	EMPP_Raw: 1.45478
2025-07-17 17:21:48,729 - logger.py:50 - Epoch: [141][5/6]	Total Loss: 0.75734	Main MSE (x10^-2): 75.7340	LR: 3.28e-04	EMPP_Raw: 1.46435
2025-07-17 17:21:48,790 - logger.py:50 - Epoch 141 Training Summary: Avg Total Loss: 0.75734, Avg Main MSE: 0.75734, Time: 24.63s
2025-07-17 17:22:12,349 - logger.py:50 - Epoch 141 Summary | Train MSE (x10^-2): 75.7340 | Val MSE (x10^-2): 18.7356 | Time: 48.19s
2025-07-17 17:22:16,807 - logger.py:50 - Epoch: [142][0/6]	Total Loss: 0.73793	Main MSE (x10^-2): 73.7926	LR: 3.27e-04	EMPP_Raw: 1.42763
2025-07-17 17:22:37,105 - logger.py:50 - Epoch: [142][5/6]	Total Loss: 0.75315	Main MSE (x10^-2): 75.3149	LR: 3.27e-04	EMPP_Raw: 1.45608
2025-07-17 17:22:37,170 - logger.py:50 - Epoch 142 Training Summary: Avg Total Loss: 0.75315, Avg Main MSE: 0.75315, Time: 24.81s
2025-07-17 17:22:57,856 - logger.py:50 - Epoch 142 Summary | Train MSE (x10^-2): 75.3149 | Val MSE (x10^-2): 18.4471 | Time: 45.50s
2025-07-17 17:23:02,037 - logger.py:50 - Epoch: [143][0/6]	Total Loss: 0.78227	Main MSE (x10^-2): 78.2271	LR: 3.26e-04	EMPP_Raw: 1.51409
2025-07-17 17:23:21,853 - logger.py:50 - Epoch: [143][5/6]	Total Loss: 0.75552	Main MSE (x10^-2): 75.5519	LR: 3.26e-04	EMPP_Raw: 1.46070
2025-07-17 17:23:21,907 - logger.py:50 - Epoch 143 Training Summary: Avg Total Loss: 0.75552, Avg Main MSE: 0.75552, Time: 24.04s
2025-07-17 17:23:43,377 - logger.py:50 - Epoch 143 Summary | Train MSE (x10^-2): 75.5519 | Val MSE (x10^-2): 19.0131 | Time: 45.51s
2025-07-17 17:23:47,680 - logger.py:50 - Epoch: [144][0/6]	Total Loss: 0.74626	Main MSE (x10^-2): 74.6259	LR: 3.25e-04	EMPP_Raw: 1.44305
2025-07-17 17:24:07,619 - logger.py:50 - Epoch: [144][5/6]	Total Loss: 0.76193	Main MSE (x10^-2): 76.1932	LR: 3.25e-04	EMPP_Raw: 1.47456
2025-07-17 17:24:07,664 - logger.py:50 - Epoch 144 Training Summary: Avg Total Loss: 0.76193, Avg Main MSE: 0.76193, Time: 24.28s
2025-07-17 17:24:28,244 - logger.py:50 - Epoch 144 Summary | Train MSE (x10^-2): 76.1932 | Val MSE (x10^-2): 18.4221 | Time: 44.86s
2025-07-17 17:24:32,585 - logger.py:50 - Epoch: [145][0/6]	Total Loss: 0.75877	Main MSE (x10^-2): 75.8774	LR: 3.24e-04	EMPP_Raw: 1.47156
2025-07-17 17:24:52,445 - logger.py:50 - Epoch: [145][5/6]	Total Loss: 0.75641	Main MSE (x10^-2): 75.6407	LR: 3.24e-04	EMPP_Raw: 1.46419
2025-07-17 17:24:52,493 - logger.py:50 - Epoch 145 Training Summary: Avg Total Loss: 0.75641, Avg Main MSE: 0.75641, Time: 24.24s
2025-07-17 17:25:13,204 - logger.py:50 - Epoch 145 Summary | Train MSE (x10^-2): 75.6407 | Val MSE (x10^-2): 18.6001 | Time: 44.95s
2025-07-17 17:25:17,397 - logger.py:50 - Epoch: [146][0/6]	Total Loss: 0.73735	Main MSE (x10^-2): 73.7351	LR: 3.23e-04	EMPP_Raw: 1.42763
2025-07-17 17:25:36,728 - logger.py:50 - Epoch: [146][5/6]	Total Loss: 0.75402	Main MSE (x10^-2): 75.4023	LR: 3.23e-04	EMPP_Raw: 1.45975
2025-07-17 17:25:36,776 - logger.py:50 - Epoch 146 Training Summary: Avg Total Loss: 0.75402, Avg Main MSE: 0.75402, Time: 23.56s
2025-07-17 17:25:56,404 - logger.py:50 - Epoch 146 Summary | Train MSE (x10^-2): 75.4023 | Val MSE (x10^-2): 18.9279 | Time: 43.19s
2025-07-17 17:26:00,491 - logger.py:50 - Epoch: [147][0/6]	Total Loss: 0.76257	Main MSE (x10^-2): 76.2573	LR: 3.22e-04	EMPP_Raw: 1.48308
2025-07-17 17:26:19,783 - logger.py:50 - Epoch: [147][5/6]	Total Loss: 0.76068	Main MSE (x10^-2): 76.0677	LR: 3.22e-04	EMPP_Raw: 1.47375
2025-07-17 17:26:19,827 - logger.py:50 - Epoch 147 Training Summary: Avg Total Loss: 0.76068, Avg Main MSE: 0.76068, Time: 23.42s
2025-07-17 17:26:39,656 - logger.py:50 - Epoch 147 Summary | Train MSE (x10^-2): 76.0677 | Val MSE (x10^-2): 18.7561 | Time: 43.25s
2025-07-17 17:26:43,814 - logger.py:50 - Epoch: [148][0/6]	Total Loss: 0.75769	Main MSE (x10^-2): 75.7685	LR: 3.21e-04	EMPP_Raw: 1.46866
2025-07-17 17:27:03,107 - logger.py:50 - Epoch: [148][5/6]	Total Loss: 0.76559	Main MSE (x10^-2): 76.5588	LR: 3.21e-04	EMPP_Raw: 1.48293
2025-07-17 17:27:03,146 - logger.py:50 - Epoch 148 Training Summary: Avg Total Loss: 0.76559, Avg Main MSE: 0.76559, Time: 23.48s
2025-07-17 17:27:22,772 - logger.py:50 - Epoch 148 Summary | Train MSE (x10^-2): 76.5588 | Val MSE (x10^-2): 19.3594 | Time: 43.11s
2025-07-17 17:27:26,866 - logger.py:50 - Epoch: [149][0/6]	Total Loss: 0.76660	Main MSE (x10^-2): 76.6600	LR: 3.20e-04	EMPP_Raw: 1.48352
2025-07-17 17:27:46,177 - logger.py:50 - Epoch: [149][5/6]	Total Loss: 0.75193	Main MSE (x10^-2): 75.1930	LR: 3.20e-04	EMPP_Raw: 1.45660
2025-07-17 17:27:46,221 - logger.py:50 - Epoch 149 Training Summary: Avg Total Loss: 0.75193, Avg Main MSE: 0.75193, Time: 23.44s
2025-07-17 17:28:05,863 - logger.py:50 - Epoch 149 Summary | Train MSE (x10^-2): 75.1930 | Val MSE (x10^-2): 18.4296 | Time: 43.09s
2025-07-17 17:28:09,963 - logger.py:50 - Epoch: [150][0/6]	Total Loss: 0.76476	Main MSE (x10^-2): 76.4756	LR: 3.19e-04	EMPP_Raw: 1.47993
2025-07-17 17:28:29,243 - logger.py:50 - Epoch: [150][5/6]	Total Loss: 0.75746	Main MSE (x10^-2): 75.7460	LR: 3.19e-04	EMPP_Raw: 1.46685
2025-07-17 17:28:29,284 - logger.py:50 - Epoch 150 Training Summary: Avg Total Loss: 0.75746, Avg Main MSE: 0.75746, Time: 23.41s
2025-07-17 17:28:49,095 - logger.py:50 - Epoch 150 Summary | Train MSE (x10^-2): 75.7460 | Val MSE (x10^-2): 18.6948 | Time: 43.23s
2025-07-17 17:28:53,200 - logger.py:50 - Epoch: [151][0/6]	Total Loss: 0.76226	Main MSE (x10^-2): 76.2261	LR: 3.18e-04	EMPP_Raw: 1.47913
2025-07-17 17:29:12,709 - logger.py:50 - Epoch: [151][5/6]	Total Loss: 0.75755	Main MSE (x10^-2): 75.7547	LR: 3.18e-04	EMPP_Raw: 1.46932
2025-07-17 17:29:12,747 - logger.py:50 - Epoch 151 Training Summary: Avg Total Loss: 0.75755, Avg Main MSE: 0.75755, Time: 23.64s
2025-07-17 17:29:32,317 - logger.py:50 - Epoch 151 Summary | Train MSE (x10^-2): 75.7547 | Val MSE (x10^-2): 18.6320 | Time: 43.22s
2025-07-17 17:29:36,414 - logger.py:50 - Epoch: [152][0/6]	Total Loss: 0.76614	Main MSE (x10^-2): 76.6145	LR: 3.17e-04	EMPP_Raw: 1.48758
2025-07-17 17:29:55,838 - logger.py:50 - Epoch: [152][5/6]	Total Loss: 0.75737	Main MSE (x10^-2): 75.7369	LR: 3.17e-04	EMPP_Raw: 1.47041
2025-07-17 17:29:55,883 - logger.py:50 - Epoch 152 Training Summary: Avg Total Loss: 0.75737, Avg Main MSE: 0.75737, Time: 23.56s
2025-07-17 17:30:16,372 - logger.py:50 - Epoch 152 Summary | Train MSE (x10^-2): 75.7369 | Val MSE (x10^-2): 19.0287 | Time: 44.05s
2025-07-17 17:30:20,532 - logger.py:50 - Epoch: [153][0/6]	Total Loss: 0.75957	Main MSE (x10^-2): 75.9567	LR: 3.16e-04	EMPP_Raw: 1.47809
2025-07-17 17:30:40,174 - logger.py:50 - Epoch: [153][5/6]	Total Loss: 0.75704	Main MSE (x10^-2): 75.7041	LR: 3.16e-04	EMPP_Raw: 1.47027
2025-07-17 17:30:40,215 - logger.py:50 - Epoch 153 Training Summary: Avg Total Loss: 0.75704, Avg Main MSE: 0.75704, Time: 23.83s
2025-07-17 17:31:00,420 - logger.py:50 - Epoch 153 Summary | Train MSE (x10^-2): 75.7041 | Val MSE (x10^-2): 19.1716 | Time: 44.04s
2025-07-17 17:31:04,534 - logger.py:50 - Epoch: [154][0/6]	Total Loss: 0.74455	Main MSE (x10^-2): 74.4554	LR: 3.15e-04	EMPP_Raw: 1.44139
2025-07-17 17:31:24,087 - logger.py:50 - Epoch: [154][5/6]	Total Loss: 0.76160	Main MSE (x10^-2): 76.1603	LR: 3.15e-04	EMPP_Raw: 1.47713
2025-07-17 17:31:24,154 - logger.py:50 - Epoch 154 Training Summary: Avg Total Loss: 0.76160, Avg Main MSE: 0.76160, Time: 23.72s
2025-07-17 17:31:43,987 - logger.py:50 - Epoch 154 Summary | Train MSE (x10^-2): 76.1603 | Val MSE (x10^-2): 18.7418 | Time: 43.56s
2025-07-17 17:31:48,156 - logger.py:50 - Epoch: [155][0/6]	Total Loss: 0.76246	Main MSE (x10^-2): 76.2461	LR: 3.14e-04	EMPP_Raw: 1.48181
2025-07-17 17:32:07,772 - logger.py:50 - Epoch: [155][5/6]	Total Loss: 0.76335	Main MSE (x10^-2): 76.3346	LR: 3.14e-04	EMPP_Raw: 1.48329
2025-07-17 17:32:07,835 - logger.py:50 - Epoch 155 Training Summary: Avg Total Loss: 0.76335, Avg Main MSE: 0.76335, Time: 23.84s
2025-07-17 17:32:28,101 - logger.py:50 - Epoch 155 Summary | Train MSE (x10^-2): 76.3346 | Val MSE (x10^-2): 18.5382 | Time: 44.11s
2025-07-17 17:32:32,371 - logger.py:50 - Epoch: [156][0/6]	Total Loss: 0.75073	Main MSE (x10^-2): 75.0727	LR: 3.13e-04	EMPP_Raw: 1.45972
2025-07-17 17:32:52,150 - logger.py:50 - Epoch: [156][5/6]	Total Loss: 0.75963	Main MSE (x10^-2): 75.9628	LR: 3.13e-04	EMPP_Raw: 1.47568
2025-07-17 17:32:52,201 - logger.py:50 - Epoch 156 Training Summary: Avg Total Loss: 0.75963, Avg Main MSE: 0.75963, Time: 24.09s
2025-07-17 17:33:11,830 - logger.py:50 - Epoch 156 Summary | Train MSE (x10^-2): 75.9628 | Val MSE (x10^-2): 19.0904 | Time: 43.72s
2025-07-17 17:33:15,908 - logger.py:50 - Epoch: [157][0/6]	Total Loss: 0.75199	Main MSE (x10^-2): 75.1986	LR: 3.12e-04	EMPP_Raw: 1.46162
2025-07-17 17:33:35,268 - logger.py:50 - Epoch: [157][5/6]	Total Loss: 0.75136	Main MSE (x10^-2): 75.1358	LR: 3.12e-04	EMPP_Raw: 1.46005
2025-07-17 17:33:35,310 - logger.py:50 - Epoch 157 Training Summary: Avg Total Loss: 0.75136, Avg Main MSE: 0.75136, Time: 23.47s
2025-07-17 17:33:55,055 - logger.py:50 - Epoch 157 Summary | Train MSE (x10^-2): 75.1358 | Val MSE (x10^-2): 18.4833 | Time: 43.22s
2025-07-17 17:33:59,143 - logger.py:50 - Epoch: [158][0/6]	Total Loss: 0.74760	Main MSE (x10^-2): 74.7605	LR: 3.11e-04	EMPP_Raw: 1.44799
2025-07-17 17:34:18,533 - logger.py:50 - Epoch: [158][5/6]	Total Loss: 0.74938	Main MSE (x10^-2): 74.9381	LR: 3.11e-04	EMPP_Raw: 1.45508
2025-07-17 17:34:18,595 - logger.py:50 - Epoch 158 Training Summary: Avg Total Loss: 0.74938, Avg Main MSE: 0.74938, Time: 23.53s
2025-07-17 17:34:38,254 - logger.py:50 - Epoch 158 Summary | Train MSE (x10^-2): 74.9381 | Val MSE (x10^-2): 18.6807 | Time: 43.20s
2025-07-17 17:34:42,386 - logger.py:50 - Epoch: [159][0/6]	Total Loss: 0.76750	Main MSE (x10^-2): 76.7498	LR: 3.10e-04	EMPP_Raw: 1.49440
2025-07-17 17:35:01,642 - logger.py:50 - Epoch: [159][5/6]	Total Loss: 0.76288	Main MSE (x10^-2): 76.2876	LR: 3.10e-04	EMPP_Raw: 1.48396
2025-07-17 17:35:01,684 - logger.py:50 - Epoch 159 Training Summary: Avg Total Loss: 0.76288, Avg Main MSE: 0.76288, Time: 23.42s
2025-07-17 17:35:21,233 - logger.py:50 - Epoch 159 Summary | Train MSE (x10^-2): 76.2876 | Val MSE (x10^-2): 18.6215 | Time: 42.97s
2025-07-17 17:35:25,325 - logger.py:50 - Epoch: [160][0/6]	Total Loss: 0.74951	Main MSE (x10^-2): 74.9510	LR: 3.08e-04	EMPP_Raw: 1.45837
2025-07-17 17:35:44,645 - logger.py:50 - Epoch: [160][5/6]	Total Loss: 0.75638	Main MSE (x10^-2): 75.6383	LR: 3.08e-04	EMPP_Raw: 1.47098
2025-07-17 17:35:44,711 - logger.py:50 - Epoch 160 Training Summary: Avg Total Loss: 0.75638, Avg Main MSE: 0.75638, Time: 23.47s
2025-07-17 17:36:04,268 - logger.py:50 - Epoch 160 Summary | Train MSE (x10^-2): 75.6383 | Val MSE (x10^-2): 18.5652 | Time: 43.03s
2025-07-17 17:36:08,395 - logger.py:50 - Epoch: [161][0/6]	Total Loss: 0.74951	Main MSE (x10^-2): 74.9506	LR: 3.07e-04	EMPP_Raw: 1.46104
2025-07-17 17:36:27,706 - logger.py:50 - Epoch: [161][5/6]	Total Loss: 0.74358	Main MSE (x10^-2): 74.3580	LR: 3.07e-04	EMPP_Raw: 1.44658
2025-07-17 17:36:27,748 - logger.py:50 - Epoch 161 Training Summary: Avg Total Loss: 0.74358, Avg Main MSE: 0.74358, Time: 23.47s
2025-07-17 17:36:47,406 - logger.py:50 - Epoch 161 Summary | Train MSE (x10^-2): 74.3580 | Val MSE (x10^-2): 18.6046 | Time: 43.13s
2025-07-17 17:36:51,518 - logger.py:50 - Epoch: [162][0/6]	Total Loss: 0.73448	Main MSE (x10^-2): 73.4480	LR: 3.06e-04	EMPP_Raw: 1.43177
2025-07-17 17:37:10,834 - logger.py:50 - Epoch: [162][5/6]	Total Loss: 0.74266	Main MSE (x10^-2): 74.2657	LR: 3.06e-04	EMPP_Raw: 1.44439
2025-07-17 17:37:10,870 - logger.py:50 - Epoch 162 Training Summary: Avg Total Loss: 0.74266, Avg Main MSE: 0.74266, Time: 23.46s
2025-07-17 17:37:30,791 - logger.py:50 - Epoch 162 Summary | Train MSE (x10^-2): 74.2657 | Val MSE (x10^-2): 18.4131 | Time: 43.38s
2025-07-17 17:37:34,935 - logger.py:50 - Epoch: [163][0/6]	Total Loss: 0.77278	Main MSE (x10^-2): 77.2777	LR: 3.05e-04	EMPP_Raw: 1.50557
2025-07-17 17:37:54,377 - logger.py:50 - Epoch: [163][5/6]	Total Loss: 0.75769	Main MSE (x10^-2): 75.7694	LR: 3.05e-04	EMPP_Raw: 1.47403
2025-07-17 17:37:54,418 - logger.py:50 - Epoch 163 Training Summary: Avg Total Loss: 0.75769, Avg Main MSE: 0.75769, Time: 23.62s
2025-07-17 17:38:14,948 - logger.py:50 - Epoch 163 Summary | Train MSE (x10^-2): 75.7694 | Val MSE (x10^-2): 19.2107 | Time: 44.15s
2025-07-17 17:38:19,183 - logger.py:50 - Epoch: [164][0/6]	Total Loss: 0.71900	Main MSE (x10^-2): 71.9004	LR: 3.04e-04	EMPP_Raw: 1.40058
2025-07-17 17:38:39,366 - logger.py:50 - Epoch: [164][5/6]	Total Loss: 0.74556	Main MSE (x10^-2): 74.5558	LR: 3.04e-04	EMPP_Raw: 1.45111
2025-07-17 17:38:39,415 - logger.py:50 - Epoch 164 Training Summary: Avg Total Loss: 0.74556, Avg Main MSE: 0.74556, Time: 24.46s
2025-07-17 17:39:00,091 - logger.py:50 - Epoch 164 Summary | Train MSE (x10^-2): 74.5558 | Val MSE (x10^-2): 18.8861 | Time: 45.14s
2025-07-17 17:39:04,450 - logger.py:50 - Epoch: [165][0/6]	Total Loss: 0.74231	Main MSE (x10^-2): 74.2306	LR: 3.03e-04	EMPP_Raw: 1.44264
2025-07-17 17:39:24,773 - logger.py:50 - Epoch: [165][5/6]	Total Loss: 0.74819	Main MSE (x10^-2): 74.8192	LR: 3.03e-04	EMPP_Raw: 1.45780
2025-07-17 17:39:24,819 - logger.py:50 - Epoch 165 Training Summary: Avg Total Loss: 0.74819, Avg Main MSE: 0.74819, Time: 24.72s
2025-07-17 17:39:45,758 - logger.py:50 - Epoch 165 Summary | Train MSE (x10^-2): 74.8192 | Val MSE (x10^-2): 18.8053 | Time: 45.66s
2025-07-17 17:39:49,993 - logger.py:50 - Epoch: [166][0/6]	Total Loss: 0.75748	Main MSE (x10^-2): 75.7478	LR: 3.02e-04	EMPP_Raw: 1.47486
2025-07-17 17:40:09,988 - logger.py:50 - Epoch: [166][5/6]	Total Loss: 0.74899	Main MSE (x10^-2): 74.8990	LR: 3.02e-04	EMPP_Raw: 1.45778
2025-07-17 17:40:10,030 - logger.py:50 - Epoch 166 Training Summary: Avg Total Loss: 0.74899, Avg Main MSE: 0.74899, Time: 24.26s
2025-07-17 17:40:30,427 - logger.py:50 - Epoch 166 Summary | Train MSE (x10^-2): 74.8990 | Val MSE (x10^-2): 18.6041 | Time: 44.66s
2025-07-17 17:40:34,789 - logger.py:50 - Epoch: [167][0/6]	Total Loss: 0.72616	Main MSE (x10^-2): 72.6160	LR: 3.01e-04	EMPP_Raw: 1.41504
2025-07-17 17:40:54,745 - logger.py:50 - Epoch: [167][5/6]	Total Loss: 0.75514	Main MSE (x10^-2): 75.5135	LR: 3.01e-04	EMPP_Raw: 1.47025
2025-07-17 17:40:54,792 - logger.py:50 - Epoch 167 Training Summary: Avg Total Loss: 0.75514, Avg Main MSE: 0.75514, Time: 24.35s
2025-07-17 17:41:15,050 - logger.py:50 - Epoch 167 Summary | Train MSE (x10^-2): 75.5135 | Val MSE (x10^-2): 18.4683 | Time: 44.62s
2025-07-17 17:41:19,310 - logger.py:50 - Epoch: [168][0/6]	Total Loss: 0.74517	Main MSE (x10^-2): 74.5168	LR: 3.00e-04	EMPP_Raw: 1.44863
2025-07-17 17:41:39,517 - logger.py:50 - Epoch: [168][5/6]	Total Loss: 0.76208	Main MSE (x10^-2): 76.2079	LR: 3.00e-04	EMPP_Raw: 1.48446
2025-07-17 17:41:39,568 - logger.py:50 - Epoch 168 Training Summary: Avg Total Loss: 0.76208, Avg Main MSE: 0.76208, Time: 24.51s
2025-07-17 17:42:00,434 - logger.py:50 - Epoch 168 Summary | Train MSE (x10^-2): 76.2079 | Val MSE (x10^-2): 18.3992 | Time: 45.38s
2025-07-17 17:42:04,666 - logger.py:50 - Epoch: [169][0/6]	Total Loss: 0.73577	Main MSE (x10^-2): 73.5769	LR: 2.99e-04	EMPP_Raw: 1.43284
2025-07-17 17:42:24,681 - logger.py:50 - Epoch: [169][5/6]	Total Loss: 0.74512	Main MSE (x10^-2): 74.5121	LR: 2.99e-04	EMPP_Raw: 1.45097
2025-07-17 17:42:24,745 - logger.py:50 - Epoch 169 Training Summary: Avg Total Loss: 0.74512, Avg Main MSE: 0.74512, Time: 24.30s
2025-07-17 17:42:45,726 - logger.py:50 - Epoch 169 Summary | Train MSE (x10^-2): 74.5121 | Val MSE (x10^-2): 18.3541 | Time: 45.29s
2025-07-17 17:42:49,949 - logger.py:50 - Epoch: [170][0/6]	Total Loss: 0.73797	Main MSE (x10^-2): 73.7971	LR: 2.98e-04	EMPP_Raw: 1.43545
2025-07-17 17:43:10,115 - logger.py:50 - Epoch: [170][5/6]	Total Loss: 0.75764	Main MSE (x10^-2): 75.7641	LR: 2.98e-04	EMPP_Raw: 1.47482
2025-07-17 17:43:10,162 - logger.py:50 - Epoch 170 Training Summary: Avg Total Loss: 0.75764, Avg Main MSE: 0.75764, Time: 24.43s
2025-07-17 17:43:30,727 - logger.py:50 - Epoch 170 Summary | Train MSE (x10^-2): 75.7641 | Val MSE (x10^-2): 18.2422 | Time: 44.99s
2025-07-17 17:43:35,009 - logger.py:50 - Epoch: [171][0/6]	Total Loss: 0.73361	Main MSE (x10^-2): 73.3606	LR: 2.97e-04	EMPP_Raw: 1.42926
2025-07-17 17:43:55,064 - logger.py:50 - Epoch: [171][5/6]	Total Loss: 0.74518	Main MSE (x10^-2): 74.5179	LR: 2.97e-04	EMPP_Raw: 1.45142
2025-07-17 17:43:55,114 - logger.py:50 - Epoch 171 Training Summary: Avg Total Loss: 0.74518, Avg Main MSE: 0.74518, Time: 24.38s
2025-07-17 17:44:15,360 - logger.py:50 - Epoch 171 Summary | Train MSE (x10^-2): 74.5179 | Val MSE (x10^-2): 18.4652 | Time: 44.63s
2025-07-17 17:44:19,534 - logger.py:50 - Epoch: [172][0/6]	Total Loss: 0.76734	Main MSE (x10^-2): 76.7336	LR: 2.96e-04	EMPP_Raw: 1.49602
2025-07-17 17:44:39,538 - logger.py:50 - Epoch: [172][5/6]	Total Loss: 0.75877	Main MSE (x10^-2): 75.8767	LR: 2.96e-04	EMPP_Raw: 1.47890
2025-07-17 17:44:39,586 - logger.py:50 - Epoch 172 Training Summary: Avg Total Loss: 0.75877, Avg Main MSE: 0.75877, Time: 24.22s
2025-07-17 17:45:00,054 - logger.py:50 - Epoch 172 Summary | Train MSE (x10^-2): 75.8767 | Val MSE (x10^-2): 18.4440 | Time: 44.69s
2025-07-17 17:45:04,321 - logger.py:50 - Epoch: [173][0/6]	Total Loss: 0.73599	Main MSE (x10^-2): 73.5991	LR: 2.94e-04	EMPP_Raw: 1.43545
2025-07-17 17:45:24,398 - logger.py:50 - Epoch: [173][5/6]	Total Loss: 0.74891	Main MSE (x10^-2): 74.8907	LR: 2.94e-04	EMPP_Raw: 1.45900
2025-07-17 17:45:24,446 - logger.py:50 - Epoch 173 Training Summary: Avg Total Loss: 0.74891, Avg Main MSE: 0.74891, Time: 24.38s
2025-07-17 17:45:44,947 - logger.py:50 - Epoch 173 Summary | Train MSE (x10^-2): 74.8907 | Val MSE (x10^-2): 18.8045 | Time: 44.89s
2025-07-17 17:45:49,248 - logger.py:50 - Epoch: [174][0/6]	Total Loss: 0.74246	Main MSE (x10^-2): 74.2460	LR: 2.93e-04	EMPP_Raw: 1.44741
2025-07-17 17:46:09,203 - logger.py:50 - Epoch: [174][5/6]	Total Loss: 0.74713	Main MSE (x10^-2): 74.7135	LR: 2.93e-04	EMPP_Raw: 1.45631
2025-07-17 17:46:09,242 - logger.py:50 - Epoch 174 Training Summary: Avg Total Loss: 0.74713, Avg Main MSE: 0.74713, Time: 24.28s
2025-07-17 17:46:29,689 - logger.py:50 - Epoch 174 Summary | Train MSE (x10^-2): 74.7135 | Val MSE (x10^-2): 18.6909 | Time: 44.74s
2025-07-17 17:46:33,905 - logger.py:50 - Epoch: [175][0/6]	Total Loss: 0.75310	Main MSE (x10^-2): 75.3097	LR: 2.92e-04	EMPP_Raw: 1.46902
2025-07-17 17:46:53,723 - logger.py:50 - Epoch: [175][5/6]	Total Loss: 0.75119	Main MSE (x10^-2): 75.1194	LR: 2.92e-04	EMPP_Raw: 1.46410
2025-07-17 17:46:53,769 - logger.py:50 - Epoch 175 Training Summary: Avg Total Loss: 0.75119, Avg Main MSE: 0.75119, Time: 24.07s
2025-07-17 17:47:14,443 - logger.py:50 - Epoch 175 Summary | Train MSE (x10^-2): 75.1194 | Val MSE (x10^-2): 18.6478 | Time: 44.75s
2025-07-17 17:47:18,640 - logger.py:50 - Epoch: [176][0/6]	Total Loss: 0.75182	Main MSE (x10^-2): 75.1819	LR: 2.91e-04	EMPP_Raw: 1.46628
2025-07-17 17:47:38,598 - logger.py:50 - Epoch: [176][5/6]	Total Loss: 0.75313	Main MSE (x10^-2): 75.3130	LR: 2.91e-04	EMPP_Raw: 1.46679
2025-07-17 17:47:38,648 - logger.py:50 - Epoch 176 Training Summary: Avg Total Loss: 0.75313, Avg Main MSE: 0.75313, Time: 24.20s
2025-07-17 17:47:59,429 - logger.py:50 - Epoch 176 Summary | Train MSE (x10^-2): 75.3130 | Val MSE (x10^-2): 18.5865 | Time: 44.98s
2025-07-17 17:48:03,703 - logger.py:50 - Epoch: [177][0/6]	Total Loss: 0.73457	Main MSE (x10^-2): 73.4573	LR: 2.90e-04	EMPP_Raw: 1.42952
2025-07-17 17:48:23,674 - logger.py:50 - Epoch: [177][5/6]	Total Loss: 0.74095	Main MSE (x10^-2): 74.0947	LR: 2.90e-04	EMPP_Raw: 1.44456
2025-07-17 17:48:23,741 - logger.py:50 - Epoch 177 Training Summary: Avg Total Loss: 0.74095, Avg Main MSE: 0.74095, Time: 24.30s
2025-07-17 17:48:44,342 - logger.py:50 - Epoch 177 Summary | Train MSE (x10^-2): 74.0947 | Val MSE (x10^-2): 18.4821 | Time: 44.91s
2025-07-17 17:48:48,697 - logger.py:50 - Epoch: [178][0/6]	Total Loss: 0.75029	Main MSE (x10^-2): 75.0287	LR: 2.89e-04	EMPP_Raw: 1.46306
2025-07-17 17:49:08,780 - logger.py:50 - Epoch: [178][5/6]	Total Loss: 0.74610	Main MSE (x10^-2): 74.6104	LR: 2.89e-04	EMPP_Raw: 1.45510
2025-07-17 17:49:08,831 - logger.py:50 - Epoch 178 Training Summary: Avg Total Loss: 0.74610, Avg Main MSE: 0.74610, Time: 24.48s
2025-07-17 17:49:29,704 - logger.py:50 - Epoch 178 Summary | Train MSE (x10^-2): 74.6104 | Val MSE (x10^-2): 18.6337 | Time: 45.36s
2025-07-17 17:49:33,899 - logger.py:50 - Epoch: [179][0/6]	Total Loss: 0.74368	Main MSE (x10^-2): 74.3683	LR: 2.88e-04	EMPP_Raw: 1.45190
2025-07-17 17:49:54,277 - logger.py:50 - Epoch: [179][5/6]	Total Loss: 0.74027	Main MSE (x10^-2): 74.0267	LR: 2.88e-04	EMPP_Raw: 1.44376
2025-07-17 17:49:54,327 - logger.py:50 - Epoch 179 Training Summary: Avg Total Loss: 0.74027, Avg Main MSE: 0.74027, Time: 24.61s
2025-07-17 17:50:14,892 - logger.py:50 - Epoch 179 Summary | Train MSE (x10^-2): 74.0267 | Val MSE (x10^-2): 19.0773 | Time: 45.18s
2025-07-17 17:50:19,131 - logger.py:50 - Epoch: [180][0/6]	Total Loss: 0.74011	Main MSE (x10^-2): 74.0106	LR: 2.87e-04	EMPP_Raw: 1.43898
2025-07-17 17:50:39,206 - logger.py:50 - Epoch: [180][5/6]	Total Loss: 0.75269	Main MSE (x10^-2): 75.2688	LR: 2.87e-04	EMPP_Raw: 1.46762
2025-07-17 17:50:39,246 - logger.py:50 - Epoch 180 Training Summary: Avg Total Loss: 0.75269, Avg Main MSE: 0.75269, Time: 24.34s
2025-07-17 17:50:59,955 - logger.py:50 - Epoch 180 Summary | Train MSE (x10^-2): 75.2688 | Val MSE (x10^-2): 18.6546 | Time: 45.06s
2025-07-17 17:51:04,195 - logger.py:50 - Epoch: [181][0/6]	Total Loss: 0.75581	Main MSE (x10^-2): 75.5805	LR: 2.85e-04	EMPP_Raw: 1.47536
2025-07-17 17:51:24,176 - logger.py:50 - Epoch: [181][5/6]	Total Loss: 0.74907	Main MSE (x10^-2): 74.9070	LR: 2.85e-04	EMPP_Raw: 1.46181
2025-07-17 17:51:24,221 - logger.py:50 - Epoch 181 Training Summary: Avg Total Loss: 0.74907, Avg Main MSE: 0.74907, Time: 24.26s
2025-07-17 17:51:44,695 - logger.py:50 - Epoch 181 Summary | Train MSE (x10^-2): 74.9070 | Val MSE (x10^-2): 18.4195 | Time: 44.74s
2025-07-17 17:51:48,974 - logger.py:50 - Epoch: [182][0/6]	Total Loss: 0.73044	Main MSE (x10^-2): 73.0439	LR: 2.84e-04	EMPP_Raw: 1.42209
2025-07-17 17:52:09,059 - logger.py:50 - Epoch: [182][5/6]	Total Loss: 0.74274	Main MSE (x10^-2): 74.2735	LR: 2.84e-04	EMPP_Raw: 1.44799
2025-07-17 17:52:09,104 - logger.py:50 - Epoch 182 Training Summary: Avg Total Loss: 0.74274, Avg Main MSE: 0.74274, Time: 24.40s
2025-07-17 17:52:29,726 - logger.py:50 - Epoch 182 Summary | Train MSE (x10^-2): 74.2735 | Val MSE (x10^-2): 18.4806 | Time: 45.03s
2025-07-17 17:52:33,939 - logger.py:50 - Epoch: [183][0/6]	Total Loss: 0.75328	Main MSE (x10^-2): 75.3285	LR: 2.83e-04	EMPP_Raw: 1.47497
2025-07-17 17:52:54,125 - logger.py:50 - Epoch: [183][5/6]	Total Loss: 0.74502	Main MSE (x10^-2): 74.5024	LR: 2.83e-04	EMPP_Raw: 1.45376
2025-07-17 17:52:54,193 - logger.py:50 - Epoch 183 Training Summary: Avg Total Loss: 0.74502, Avg Main MSE: 0.74502, Time: 24.46s
2025-07-17 17:53:14,779 - logger.py:50 - Epoch 183 Summary | Train MSE (x10^-2): 74.5024 | Val MSE (x10^-2): 18.7328 | Time: 45.05s
2025-07-17 17:53:19,080 - logger.py:50 - Epoch: [184][0/6]	Total Loss: 0.76671	Main MSE (x10^-2): 76.6713	LR: 2.82e-04	EMPP_Raw: 1.49900
2025-07-17 17:53:39,108 - logger.py:50 - Epoch: [184][5/6]	Total Loss: 0.75359	Main MSE (x10^-2): 75.3591	LR: 2.82e-04	EMPP_Raw: 1.47221
2025-07-17 17:53:39,154 - logger.py:50 - Epoch 184 Training Summary: Avg Total Loss: 0.75359, Avg Main MSE: 0.75359, Time: 24.37s
2025-07-17 17:53:59,819 - logger.py:50 - Epoch 184 Summary | Train MSE (x10^-2): 75.3591 | Val MSE (x10^-2): 18.6636 | Time: 45.04s
2025-07-17 17:54:04,003 - logger.py:50 - Epoch: [185][0/6]	Total Loss: 0.72059	Main MSE (x10^-2): 72.0593	LR: 2.81e-04	EMPP_Raw: 1.40773
2025-07-17 17:54:24,186 - logger.py:50 - Epoch: [185][5/6]	Total Loss: 0.73606	Main MSE (x10^-2): 73.6061	LR: 2.81e-04	EMPP_Raw: 1.43725
2025-07-17 17:54:24,234 - logger.py:50 - Epoch 185 Training Summary: Avg Total Loss: 0.73606, Avg Main MSE: 0.73606, Time: 24.41s
2025-07-17 17:54:44,853 - logger.py:50 - Epoch 185 Summary | Train MSE (x10^-2): 73.6061 | Val MSE (x10^-2): 18.4229 | Time: 45.03s
2025-07-17 17:54:49,061 - logger.py:50 - Epoch: [186][0/6]	Total Loss: 0.72304	Main MSE (x10^-2): 72.3038	LR: 2.80e-04	EMPP_Raw: 1.41335
2025-07-17 17:55:09,028 - logger.py:50 - Epoch: [186][5/6]	Total Loss: 0.74264	Main MSE (x10^-2): 74.2643	LR: 2.80e-04	EMPP_Raw: 1.45114
2025-07-17 17:55:09,075 - logger.py:50 - Epoch 186 Training Summary: Avg Total Loss: 0.74264, Avg Main MSE: 0.74264, Time: 24.21s
2025-07-17 17:55:29,571 - logger.py:50 - Epoch 186 Summary | Train MSE (x10^-2): 74.2643 | Val MSE (x10^-2): 18.3127 | Time: 44.71s
2025-07-17 17:55:33,834 - logger.py:50 - Epoch: [187][0/6]	Total Loss: 0.74380	Main MSE (x10^-2): 74.3805	LR: 2.79e-04	EMPP_Raw: 1.45506
2025-07-17 17:55:53,773 - logger.py:50 - Epoch: [187][5/6]	Total Loss: 0.74196	Main MSE (x10^-2): 74.1959	LR: 2.79e-04	EMPP_Raw: 1.44907
2025-07-17 17:55:53,818 - logger.py:50 - Epoch 187 Training Summary: Avg Total Loss: 0.74196, Avg Main MSE: 0.74196, Time: 24.24s
2025-07-17 17:56:14,434 - logger.py:50 - Epoch 187 Summary | Train MSE (x10^-2): 74.1959 | Val MSE (x10^-2): 18.6199 | Time: 44.86s
2025-07-17 17:56:18,672 - logger.py:50 - Epoch: [188][0/6]	Total Loss: 0.75035	Main MSE (x10^-2): 75.0353	LR: 2.77e-04	EMPP_Raw: 1.46875
2025-07-17 17:56:38,844 - logger.py:50 - Epoch: [188][5/6]	Total Loss: 0.74379	Main MSE (x10^-2): 74.3795	LR: 2.77e-04	EMPP_Raw: 1.45400
2025-07-17 17:56:38,905 - logger.py:50 - Epoch 188 Training Summary: Avg Total Loss: 0.74379, Avg Main MSE: 0.74379, Time: 24.46s
2025-07-17 17:56:59,522 - logger.py:50 - Epoch 188 Summary | Train MSE (x10^-2): 74.3795 | Val MSE (x10^-2): 18.5954 | Time: 45.08s
2025-07-17 17:57:03,806 - logger.py:50 - Epoch: [189][0/6]	Total Loss: 0.74155	Main MSE (x10^-2): 74.1548	LR: 2.76e-04	EMPP_Raw: 1.45000
2025-07-17 17:57:23,769 - logger.py:50 - Epoch: [189][5/6]	Total Loss: 0.75345	Main MSE (x10^-2): 75.3453	LR: 2.76e-04	EMPP_Raw: 1.47200
2025-07-17 17:57:23,814 - logger.py:50 - Epoch 189 Training Summary: Avg Total Loss: 0.75345, Avg Main MSE: 0.75345, Time: 24.28s
2025-07-17 17:57:44,565 - logger.py:50 - Epoch 189 Summary | Train MSE (x10^-2): 75.3453 | Val MSE (x10^-2): 18.5198 | Time: 45.04s
2025-07-17 17:57:48,816 - logger.py:50 - Epoch: [190][0/6]	Total Loss: 0.73924	Main MSE (x10^-2): 73.9242	LR: 2.75e-04	EMPP_Raw: 1.44437
2025-07-17 17:58:08,890 - logger.py:50 - Epoch: [190][5/6]	Total Loss: 0.73270	Main MSE (x10^-2): 73.2705	LR: 2.75e-04	EMPP_Raw: 1.43024
2025-07-17 17:58:08,932 - logger.py:50 - Epoch 190 Training Summary: Avg Total Loss: 0.73270, Avg Main MSE: 0.73270, Time: 24.36s
2025-07-17 17:58:29,597 - logger.py:50 - Epoch 190 Summary | Train MSE (x10^-2): 73.2705 | Val MSE (x10^-2): 18.2479 | Time: 45.03s
2025-07-17 17:58:33,941 - logger.py:50 - Epoch: [191][0/6]	Total Loss: 0.76985	Main MSE (x10^-2): 76.9855	LR: 2.74e-04	EMPP_Raw: 1.50700
2025-07-17 17:58:53,984 - logger.py:50 - Epoch: [191][5/6]	Total Loss: 0.75047	Main MSE (x10^-2): 75.0473	LR: 2.74e-04	EMPP_Raw: 1.46813
2025-07-17 17:58:54,034 - logger.py:50 - Epoch 191 Training Summary: Avg Total Loss: 0.75047, Avg Main MSE: 0.75047, Time: 24.43s
2025-07-17 17:59:15,047 - logger.py:50 - Epoch 191 Summary | Train MSE (x10^-2): 75.0473 | Val MSE (x10^-2): 18.1873 | Time: 45.44s
2025-07-17 17:59:19,297 - logger.py:50 - Epoch: [192][0/6]	Total Loss: 0.73767	Main MSE (x10^-2): 73.7669	LR: 2.73e-04	EMPP_Raw: 1.43939
2025-07-17 17:59:39,299 - logger.py:50 - Epoch: [192][5/6]	Total Loss: 0.74860	Main MSE (x10^-2): 74.8597	LR: 2.73e-04	EMPP_Raw: 1.46395
2025-07-17 17:59:39,361 - logger.py:50 - Epoch 192 Training Summary: Avg Total Loss: 0.74860, Avg Main MSE: 0.74860, Time: 24.30s
2025-07-17 18:00:00,240 - logger.py:50 - Epoch 192 Summary | Train MSE (x10^-2): 74.8597 | Val MSE (x10^-2): 18.5968 | Time: 45.19s
2025-07-17 18:00:04,533 - logger.py:50 - Epoch: [193][0/6]	Total Loss: 0.75195	Main MSE (x10^-2): 75.1952	LR: 2.72e-04	EMPP_Raw: 1.47358
2025-07-17 18:00:24,704 - logger.py:50 - Epoch: [193][5/6]	Total Loss: 0.75618	Main MSE (x10^-2): 75.6179	LR: 2.72e-04	EMPP_Raw: 1.48003
2025-07-17 18:00:24,768 - logger.py:50 - Epoch 193 Training Summary: Avg Total Loss: 0.75618, Avg Main MSE: 0.75618, Time: 24.52s
2025-07-17 18:00:45,551 - logger.py:50 - Epoch 193 Summary | Train MSE (x10^-2): 75.6179 | Val MSE (x10^-2): 18.6260 | Time: 45.30s
2025-07-17 18:00:49,857 - logger.py:50 - Epoch: [194][0/6]	Total Loss: 0.73007	Main MSE (x10^-2): 73.0073	LR: 2.70e-04	EMPP_Raw: 1.42840
2025-07-17 18:01:09,864 - logger.py:50 - Epoch: [194][5/6]	Total Loss: 0.74326	Main MSE (x10^-2): 74.3262	LR: 2.70e-04	EMPP_Raw: 1.45464
2025-07-17 18:01:09,923 - logger.py:50 - Epoch 194 Training Summary: Avg Total Loss: 0.74326, Avg Main MSE: 0.74326, Time: 24.36s
2025-07-17 18:01:30,398 - logger.py:50 - Epoch 194 Summary | Train MSE (x10^-2): 74.3262 | Val MSE (x10^-2): 18.6184 | Time: 44.84s
2025-07-17 18:01:34,691 - logger.py:50 - Epoch: [195][0/6]	Total Loss: 0.75353	Main MSE (x10^-2): 75.3526	LR: 2.69e-04	EMPP_Raw: 1.47647
2025-07-17 18:01:54,795 - logger.py:50 - Epoch: [195][5/6]	Total Loss: 0.74960	Main MSE (x10^-2): 74.9603	LR: 2.69e-04	EMPP_Raw: 1.46778
2025-07-17 18:01:54,861 - logger.py:50 - Epoch 195 Training Summary: Avg Total Loss: 0.74960, Avg Main MSE: 0.74960, Time: 24.45s
2025-07-17 18:02:15,785 - logger.py:50 - Epoch 195 Summary | Train MSE (x10^-2): 74.9603 | Val MSE (x10^-2): 18.5856 | Time: 45.38s
2025-07-17 18:02:20,059 - logger.py:50 - Epoch: [196][0/6]	Total Loss: 0.73730	Main MSE (x10^-2): 73.7300	LR: 2.68e-04	EMPP_Raw: 1.44244
2025-07-17 18:02:39,974 - logger.py:50 - Epoch: [196][5/6]	Total Loss: 0.75144	Main MSE (x10^-2): 75.1439	LR: 2.68e-04	EMPP_Raw: 1.47036
2025-07-17 18:02:40,026 - logger.py:50 - Epoch 196 Training Summary: Avg Total Loss: 0.75144, Avg Main MSE: 0.75144, Time: 24.23s
2025-07-17 18:03:00,725 - logger.py:50 - Epoch 196 Summary | Train MSE (x10^-2): 75.1439 | Val MSE (x10^-2): 18.5833 | Time: 44.93s
2025-07-17 18:03:04,916 - logger.py:50 - Epoch: [197][0/6]	Total Loss: 0.73249	Main MSE (x10^-2): 73.2492	LR: 2.67e-04	EMPP_Raw: 1.43489
2025-07-17 18:03:25,031 - logger.py:50 - Epoch: [197][5/6]	Total Loss: 0.74065	Main MSE (x10^-2): 74.0649	LR: 2.67e-04	EMPP_Raw: 1.44946
2025-07-17 18:03:25,077 - logger.py:50 - Epoch 197 Training Summary: Avg Total Loss: 0.74065, Avg Main MSE: 0.74065, Time: 24.34s
2025-07-17 18:03:45,502 - logger.py:50 - Epoch 197 Summary | Train MSE (x10^-2): 74.0649 | Val MSE (x10^-2): 18.7024 | Time: 44.77s
2025-07-17 18:03:49,782 - logger.py:50 - Epoch: [198][0/6]	Total Loss: 0.73008	Main MSE (x10^-2): 73.0082	LR: 2.66e-04	EMPP_Raw: 1.42944
2025-07-17 18:04:09,695 - logger.py:50 - Epoch: [198][5/6]	Total Loss: 0.73731	Main MSE (x10^-2): 73.7314	LR: 2.66e-04	EMPP_Raw: 1.44357
2025-07-17 18:04:09,753 - logger.py:50 - Epoch 198 Training Summary: Avg Total Loss: 0.73731, Avg Main MSE: 0.73731, Time: 24.24s
2025-07-17 18:04:30,169 - logger.py:50 - Epoch 198 Summary | Train MSE (x10^-2): 73.7314 | Val MSE (x10^-2): 18.4981 | Time: 44.66s
2025-07-17 18:04:34,420 - logger.py:50 - Epoch: [199][0/6]	Total Loss: 0.76291	Main MSE (x10^-2): 76.2911	LR: 2.65e-04	EMPP_Raw: 1.49440
2025-07-17 18:04:54,327 - logger.py:50 - Epoch: [199][5/6]	Total Loss: 0.73838	Main MSE (x10^-2): 73.8384	LR: 2.65e-04	EMPP_Raw: 1.44475
2025-07-17 18:04:54,372 - logger.py:50 - Epoch 199 Training Summary: Avg Total Loss: 0.73838, Avg Main MSE: 0.73838, Time: 24.19s
2025-07-17 18:05:15,095 - logger.py:50 - Epoch 199 Summary | Train MSE (x10^-2): 73.8384 | Val MSE (x10^-2): 18.4077 | Time: 44.92s
2025-07-17 18:05:19,335 - logger.py:50 - Epoch: [200][0/6]	Total Loss: 0.75249	Main MSE (x10^-2): 75.2490	LR: 2.63e-04	EMPP_Raw: 1.47216
2025-07-17 18:05:39,236 - logger.py:50 - Epoch: [200][5/6]	Total Loss: 0.75204	Main MSE (x10^-2): 75.2036	LR: 2.63e-04	EMPP_Raw: 1.47162
2025-07-17 18:05:39,287 - logger.py:50 - Epoch 200 Training Summary: Avg Total Loss: 0.75204, Avg Main MSE: 0.75204, Time: 24.18s
2025-07-17 18:05:59,935 - logger.py:50 - Epoch 200 Summary | Train MSE (x10^-2): 75.2036 | Val MSE (x10^-2): 18.3720 | Time: 44.84s
2025-07-17 18:06:04,198 - logger.py:50 - Epoch: [201][0/6]	Total Loss: 0.75546	Main MSE (x10^-2): 75.5459	LR: 2.62e-04	EMPP_Raw: 1.47957
2025-07-17 18:06:24,107 - logger.py:50 - Epoch: [201][5/6]	Total Loss: 0.74778	Main MSE (x10^-2): 74.7785	LR: 2.62e-04	EMPP_Raw: 1.46289
2025-07-17 18:06:24,172 - logger.py:50 - Epoch 201 Training Summary: Avg Total Loss: 0.74778, Avg Main MSE: 0.74778, Time: 24.23s
2025-07-17 18:06:44,615 - logger.py:50 - Epoch 201 Summary | Train MSE (x10^-2): 74.7785 | Val MSE (x10^-2): 18.2422 | Time: 44.67s
2025-07-17 18:06:48,816 - logger.py:50 - Epoch: [202][0/6]	Total Loss: 0.71101	Main MSE (x10^-2): 71.1013	LR: 2.61e-04	EMPP_Raw: 1.38829
2025-07-17 18:07:08,629 - logger.py:50 - Epoch: [202][5/6]	Total Loss: 0.73282	Main MSE (x10^-2): 73.2822	LR: 2.61e-04	EMPP_Raw: 1.43415
2025-07-17 18:07:08,678 - logger.py:50 - Epoch 202 Training Summary: Avg Total Loss: 0.73282, Avg Main MSE: 0.73282, Time: 24.05s
2025-07-17 18:07:29,392 - logger.py:50 - Epoch 202 Summary | Train MSE (x10^-2): 73.2822 | Val MSE (x10^-2): 18.4676 | Time: 44.77s
2025-07-17 18:07:33,603 - logger.py:50 - Epoch: [203][0/6]	Total Loss: 0.74591	Main MSE (x10^-2): 74.5914	LR: 2.60e-04	EMPP_Raw: 1.46009
2025-07-17 18:07:53,587 - logger.py:50 - Epoch: [203][5/6]	Total Loss: 0.74289	Main MSE (x10^-2): 74.2895	LR: 2.60e-04	EMPP_Raw: 1.45335
2025-07-17 18:07:53,643 - logger.py:50 - Epoch 203 Training Summary: Avg Total Loss: 0.74289, Avg Main MSE: 0.74289, Time: 24.24s
2025-07-17 18:08:14,392 - logger.py:50 - Epoch 203 Summary | Train MSE (x10^-2): 74.2895 | Val MSE (x10^-2): 18.7452 | Time: 44.99s
2025-07-17 18:08:18,700 - logger.py:50 - Epoch: [204][0/6]	Total Loss: 0.73055	Main MSE (x10^-2): 73.0547	LR: 2.59e-04	EMPP_Raw: 1.42928
2025-07-17 18:08:38,599 - logger.py:50 - Epoch: [204][5/6]	Total Loss: 0.74295	Main MSE (x10^-2): 74.2949	LR: 2.59e-04	EMPP_Raw: 1.45403
2025-07-17 18:08:38,644 - logger.py:50 - Epoch 204 Training Summary: Avg Total Loss: 0.74295, Avg Main MSE: 0.74295, Time: 24.24s
2025-07-17 18:08:59,148 - logger.py:50 - Epoch 204 Summary | Train MSE (x10^-2): 74.2949 | Val MSE (x10^-2): 18.8496 | Time: 44.75s
2025-07-17 18:09:03,513 - logger.py:50 - Epoch: [205][0/6]	Total Loss: 0.73632	Main MSE (x10^-2): 73.6322	LR: 2.57e-04	EMPP_Raw: 1.43946
2025-07-17 18:09:23,720 - logger.py:50 - Epoch: [205][5/6]	Total Loss: 0.74948	Main MSE (x10^-2): 74.9481	LR: 2.57e-04	EMPP_Raw: 1.46744
2025-07-17 18:09:23,764 - logger.py:50 - Epoch 205 Training Summary: Avg Total Loss: 0.74948, Avg Main MSE: 0.74948, Time: 24.61s
2025-07-17 18:09:44,208 - logger.py:50 - Epoch 205 Summary | Train MSE (x10^-2): 74.9481 | Val MSE (x10^-2): 18.5986 | Time: 45.05s
2025-07-17 18:09:48,404 - logger.py:50 - Epoch: [206][0/6]	Total Loss: 0.74112	Main MSE (x10^-2): 74.1121	LR: 2.56e-04	EMPP_Raw: 1.45191
2025-07-17 18:10:08,496 - logger.py:50 - Epoch: [206][5/6]	Total Loss: 0.75002	Main MSE (x10^-2): 75.0018	LR: 2.56e-04	EMPP_Raw: 1.46933
2025-07-17 18:10:08,543 - logger.py:50 - Epoch 206 Training Summary: Avg Total Loss: 0.75002, Avg Main MSE: 0.75002, Time: 24.33s
2025-07-17 18:10:29,017 - logger.py:50 - Epoch 206 Summary | Train MSE (x10^-2): 75.0018 | Val MSE (x10^-2): 18.3989 | Time: 44.80s
2025-07-17 18:10:33,245 - logger.py:50 - Epoch: [207][0/6]	Total Loss: 0.76507	Main MSE (x10^-2): 76.5065	LR: 2.55e-04	EMPP_Raw: 1.50148
2025-07-17 18:10:53,246 - logger.py:50 - Epoch: [207][5/6]	Total Loss: 0.74186	Main MSE (x10^-2): 74.1861	LR: 2.55e-04	EMPP_Raw: 1.45307
2025-07-17 18:10:53,293 - logger.py:50 - Epoch 207 Training Summary: Avg Total Loss: 0.74186, Avg Main MSE: 0.74186, Time: 24.27s
2025-07-17 18:11:14,044 - logger.py:50 - Epoch 207 Summary | Train MSE (x10^-2): 74.1861 | Val MSE (x10^-2): 18.5468 | Time: 45.02s
2025-07-17 18:11:18,224 - logger.py:50 - Epoch: [208][0/6]	Total Loss: 0.74528	Main MSE (x10^-2): 74.5281	LR: 2.54e-04	EMPP_Raw: 1.46195
2025-07-17 18:11:38,214 - logger.py:50 - Epoch: [208][5/6]	Total Loss: 0.74840	Main MSE (x10^-2): 74.8399	LR: 2.54e-04	EMPP_Raw: 1.46704
2025-07-17 18:11:38,262 - logger.py:50 - Epoch 208 Training Summary: Avg Total Loss: 0.74840, Avg Main MSE: 0.74840, Time: 24.21s
2025-07-17 18:11:58,825 - logger.py:50 - Epoch 208 Summary | Train MSE (x10^-2): 74.8399 | Val MSE (x10^-2): 18.3980 | Time: 44.78s
2025-07-17 18:12:03,016 - logger.py:50 - Epoch: [209][0/6]	Total Loss: 0.73212	Main MSE (x10^-2): 73.2118	LR: 2.53e-04	EMPP_Raw: 1.43485
2025-07-17 18:12:22,956 - logger.py:50 - Epoch: [209][5/6]	Total Loss: 0.74276	Main MSE (x10^-2): 74.2765	LR: 2.53e-04	EMPP_Raw: 1.45524
2025-07-17 18:12:22,998 - logger.py:50 - Epoch 209 Training Summary: Avg Total Loss: 0.74276, Avg Main MSE: 0.74276, Time: 24.17s
2025-07-17 18:12:43,360 - logger.py:50 - Epoch 209 Summary | Train MSE (x10^-2): 74.2765 | Val MSE (x10^-2): 18.3191 | Time: 44.53s
2025-07-17 18:12:47,616 - logger.py:50 - Epoch: [210][0/6]	Total Loss: 0.74116	Main MSE (x10^-2): 74.1165	LR: 2.51e-04	EMPP_Raw: 1.45280
2025-07-17 18:13:07,494 - logger.py:50 - Epoch: [210][5/6]	Total Loss: 0.73477	Main MSE (x10^-2): 73.4770	LR: 2.51e-04	EMPP_Raw: 1.44026
2025-07-17 18:13:07,539 - logger.py:50 - Epoch 210 Training Summary: Avg Total Loss: 0.73477, Avg Main MSE: 0.73477, Time: 24.17s
2025-07-17 18:13:28,113 - logger.py:50 - Epoch 210 Summary | Train MSE (x10^-2): 73.4770 | Val MSE (x10^-2): 18.3431 | Time: 44.75s
2025-07-17 18:13:32,300 - logger.py:50 - Epoch: [211][0/6]	Total Loss: 0.76266	Main MSE (x10^-2): 76.2664	LR: 2.50e-04	EMPP_Raw: 1.49752
2025-07-17 18:13:52,264 - logger.py:50 - Epoch: [211][5/6]	Total Loss: 0.74587	Main MSE (x10^-2): 74.5867	LR: 2.50e-04	EMPP_Raw: 1.46270
2025-07-17 18:13:52,305 - logger.py:50 - Epoch 211 Training Summary: Avg Total Loss: 0.74587, Avg Main MSE: 0.74587, Time: 24.18s
2025-07-17 18:14:13,226 - logger.py:50 - Epoch 211 Summary | Train MSE (x10^-2): 74.5867 | Val MSE (x10^-2): 18.4319 | Time: 45.11s
2025-07-17 18:14:17,499 - logger.py:50 - Epoch: [212][0/6]	Total Loss: 0.71745	Main MSE (x10^-2): 71.7447	LR: 2.49e-04	EMPP_Raw: 1.40596
2025-07-17 18:14:37,563 - logger.py:50 - Epoch: [212][5/6]	Total Loss: 0.74419	Main MSE (x10^-2): 74.4188	LR: 2.49e-04	EMPP_Raw: 1.45891
2025-07-17 18:14:37,620 - logger.py:50 - Epoch 212 Training Summary: Avg Total Loss: 0.74419, Avg Main MSE: 0.74419, Time: 24.38s
2025-07-17 18:14:58,160 - logger.py:50 - Epoch 212 Summary | Train MSE (x10^-2): 74.4188 | Val MSE (x10^-2): 18.3800 | Time: 44.93s
2025-07-17 18:15:02,515 - logger.py:50 - Epoch: [213][0/6]	Total Loss: 0.73679	Main MSE (x10^-2): 73.6790	LR: 2.48e-04	EMPP_Raw: 1.44331
2025-07-17 18:15:22,627 - logger.py:50 - Epoch: [213][5/6]	Total Loss: 0.73173	Main MSE (x10^-2): 73.1726	LR: 2.48e-04	EMPP_Raw: 1.43430
2025-07-17 18:15:22,674 - logger.py:50 - Epoch 213 Training Summary: Avg Total Loss: 0.73173, Avg Main MSE: 0.73173, Time: 24.51s
2025-07-17 18:15:43,448 - logger.py:50 - Epoch 213 Summary | Train MSE (x10^-2): 73.1726 | Val MSE (x10^-2): 18.1189 | Time: 45.28s
2025-07-17 18:15:47,646 - logger.py:50 - Epoch: [214][0/6]	Total Loss: 0.75102	Main MSE (x10^-2): 75.1019	LR: 2.46e-04	EMPP_Raw: 1.47258
2025-07-17 18:16:07,728 - logger.py:50 - Epoch: [214][5/6]	Total Loss: 0.73693	Main MSE (x10^-2): 73.6933	LR: 2.46e-04	EMPP_Raw: 1.44446
2025-07-17 18:16:07,776 - logger.py:50 - Epoch 214 Training Summary: Avg Total Loss: 0.73693, Avg Main MSE: 0.73693, Time: 24.32s
2025-07-17 18:16:28,513 - logger.py:50 - Epoch 214 Summary | Train MSE (x10^-2): 73.6933 | Val MSE (x10^-2): 18.0394 | Time: 45.06s
2025-07-17 18:16:32,773 - logger.py:50 - Epoch: [215][0/6]	Total Loss: 0.74048	Main MSE (x10^-2): 74.0479	LR: 2.45e-04	EMPP_Raw: 1.45512
2025-07-17 18:16:52,781 - logger.py:50 - Epoch: [215][5/6]	Total Loss: 0.73084	Main MSE (x10^-2): 73.0839	LR: 2.45e-04	EMPP_Raw: 1.43235
2025-07-17 18:16:52,830 - logger.py:50 - Epoch 215 Training Summary: Avg Total Loss: 0.73084, Avg Main MSE: 0.73084, Time: 24.31s
2025-07-17 18:17:13,486 - logger.py:50 - Epoch 215 Summary | Train MSE (x10^-2): 73.0839 | Val MSE (x10^-2): 18.4007 | Time: 44.97s
2025-07-17 18:17:17,781 - logger.py:50 - Epoch: [216][0/6]	Total Loss: 0.73043	Main MSE (x10^-2): 73.0433	LR: 2.44e-04	EMPP_Raw: 1.43119
2025-07-17 18:17:37,650 - logger.py:50 - Epoch: [216][5/6]	Total Loss: 0.73788	Main MSE (x10^-2): 73.7885	LR: 2.44e-04	EMPP_Raw: 1.44663
2025-07-17 18:17:37,710 - logger.py:50 - Epoch 216 Training Summary: Avg Total Loss: 0.73788, Avg Main MSE: 0.73788, Time: 24.21s
2025-07-17 18:17:58,211 - logger.py:50 - Epoch 216 Summary | Train MSE (x10^-2): 73.7885 | Val MSE (x10^-2): 18.4523 | Time: 44.72s
2025-07-17 18:18:02,453 - logger.py:50 - Epoch: [217][0/6]	Total Loss: 0.73945	Main MSE (x10^-2): 73.9446	LR: 2.43e-04	EMPP_Raw: 1.45043
2025-07-17 18:18:22,356 - logger.py:50 - Epoch: [217][5/6]	Total Loss: 0.73848	Main MSE (x10^-2): 73.8480	LR: 2.43e-04	EMPP_Raw: 1.44746
2025-07-17 18:18:22,403 - logger.py:50 - Epoch 217 Training Summary: Avg Total Loss: 0.73848, Avg Main MSE: 0.73848, Time: 24.18s
2025-07-17 18:18:43,071 - logger.py:50 - Epoch 217 Summary | Train MSE (x10^-2): 73.8480 | Val MSE (x10^-2): 18.1123 | Time: 44.85s
2025-07-17 18:18:47,278 - logger.py:50 - Epoch: [218][0/6]	Total Loss: 0.73967	Main MSE (x10^-2): 73.9671	LR: 2.42e-04	EMPP_Raw: 1.45078
2025-07-17 18:19:07,351 - logger.py:50 - Epoch: [218][5/6]	Total Loss: 0.73804	Main MSE (x10^-2): 73.8038	LR: 2.42e-04	EMPP_Raw: 1.44686
2025-07-17 18:19:07,417 - logger.py:50 - Epoch 218 Training Summary: Avg Total Loss: 0.73804, Avg Main MSE: 0.73804, Time: 24.34s
2025-07-17 18:19:27,976 - logger.py:50 - Epoch 218 Summary | Train MSE (x10^-2): 73.8038 | Val MSE (x10^-2): 18.5134 | Time: 44.90s
2025-07-17 18:19:32,180 - logger.py:50 - Epoch: [219][0/6]	Total Loss: 0.75208	Main MSE (x10^-2): 75.2077	LR: 2.40e-04	EMPP_Raw: 1.47399
2025-07-17 18:19:52,142 - logger.py:50 - Epoch: [219][5/6]	Total Loss: 0.73218	Main MSE (x10^-2): 73.2178	LR: 2.40e-04	EMPP_Raw: 1.43510
2025-07-17 18:19:52,190 - logger.py:50 - Epoch 219 Training Summary: Avg Total Loss: 0.73218, Avg Main MSE: 0.73218, Time: 24.21s
2025-07-17 18:20:12,615 - logger.py:50 - Epoch 219 Summary | Train MSE (x10^-2): 73.2178 | Val MSE (x10^-2): 18.2084 | Time: 44.63s
2025-07-17 18:20:16,831 - logger.py:50 - Epoch: [220][0/6]	Total Loss: 0.75524	Main MSE (x10^-2): 75.5239	LR: 2.39e-04	EMPP_Raw: 1.48094
2025-07-17 18:20:36,842 - logger.py:50 - Epoch: [220][5/6]	Total Loss: 0.74642	Main MSE (x10^-2): 74.6417	LR: 2.39e-04	EMPP_Raw: 1.46424
2025-07-17 18:20:36,885 - logger.py:50 - Epoch 220 Training Summary: Avg Total Loss: 0.74642, Avg Main MSE: 0.74642, Time: 24.26s
2025-07-17 18:20:57,936 - logger.py:50 - Epoch 220 Summary | Train MSE (x10^-2): 74.6417 | Val MSE (x10^-2): 18.1871 | Time: 45.32s
2025-07-17 18:21:02,144 - logger.py:50 - Epoch: [221][0/6]	Total Loss: 0.75615	Main MSE (x10^-2): 75.6151	LR: 2.38e-04	EMPP_Raw: 1.48524
2025-07-17 18:21:22,068 - logger.py:50 - Epoch: [221][5/6]	Total Loss: 0.74716	Main MSE (x10^-2): 74.7156	LR: 2.38e-04	EMPP_Raw: 1.46600
2025-07-17 18:21:22,117 - logger.py:50 - Epoch 221 Training Summary: Avg Total Loss: 0.74716, Avg Main MSE: 0.74716, Time: 24.17s
2025-07-17 18:21:42,554 - logger.py:50 - Epoch 221 Summary | Train MSE (x10^-2): 74.7156 | Val MSE (x10^-2): 18.4705 | Time: 44.61s
2025-07-17 18:21:46,758 - logger.py:50 - Epoch: [222][0/6]	Total Loss: 0.73934	Main MSE (x10^-2): 73.9344	LR: 2.37e-04	EMPP_Raw: 1.45028
2025-07-17 18:22:06,738 - logger.py:50 - Epoch: [222][5/6]	Total Loss: 0.73239	Main MSE (x10^-2): 73.2390	LR: 2.37e-04	EMPP_Raw: 1.43579
2025-07-17 18:22:06,786 - logger.py:50 - Epoch 222 Training Summary: Avg Total Loss: 0.73239, Avg Main MSE: 0.73239, Time: 24.22s
2025-07-17 18:22:27,436 - logger.py:50 - Epoch 222 Summary | Train MSE (x10^-2): 73.2390 | Val MSE (x10^-2): 18.4757 | Time: 44.88s
2025-07-17 18:22:31,669 - logger.py:50 - Epoch: [223][0/6]	Total Loss: 0.74897	Main MSE (x10^-2): 74.8972	LR: 2.35e-04	EMPP_Raw: 1.46981
2025-07-17 18:22:51,700 - logger.py:50 - Epoch: [223][5/6]	Total Loss: 0.73538	Main MSE (x10^-2): 73.5382	LR: 2.35e-04	EMPP_Raw: 1.44243
2025-07-17 18:22:51,752 - logger.py:50 - Epoch 223 Training Summary: Avg Total Loss: 0.73538, Avg Main MSE: 0.73538, Time: 24.31s
2025-07-17 18:23:11,884 - logger.py:50 - Epoch 223 Summary | Train MSE (x10^-2): 73.5382 | Val MSE (x10^-2): 18.2104 | Time: 44.44s
2025-07-17 18:23:15,916 - logger.py:50 - Epoch: [224][0/6]	Total Loss: 0.75136	Main MSE (x10^-2): 75.1361	LR: 2.34e-04	EMPP_Raw: 1.47200
2025-07-17 18:23:35,173 - logger.py:50 - Epoch: [224][5/6]	Total Loss: 0.74262	Main MSE (x10^-2): 74.2624	LR: 2.34e-04	EMPP_Raw: 1.45616
2025-07-17 18:23:35,213 - logger.py:50 - Epoch 224 Training Summary: Avg Total Loss: 0.74262, Avg Main MSE: 0.74262, Time: 23.32s
2025-07-17 18:23:54,821 - logger.py:50 - Epoch 224 Summary | Train MSE (x10^-2): 74.2624 | Val MSE (x10^-2): 18.1208 | Time: 42.93s
2025-07-17 18:23:58,926 - logger.py:50 - Epoch: [225][0/6]	Total Loss: 0.73046	Main MSE (x10^-2): 73.0462	LR: 2.33e-04	EMPP_Raw: 1.43181
2025-07-17 18:24:18,164 - logger.py:50 - Epoch: [225][5/6]	Total Loss: 0.73974	Main MSE (x10^-2): 73.9743	LR: 2.33e-04	EMPP_Raw: 1.45021
2025-07-17 18:24:18,204 - logger.py:50 - Epoch 225 Training Summary: Avg Total Loss: 0.73974, Avg Main MSE: 0.73974, Time: 23.37s
2025-07-17 18:24:37,762 - logger.py:50 - Epoch 225 Summary | Train MSE (x10^-2): 73.9743 | Val MSE (x10^-2): 18.4538 | Time: 42.94s
2025-07-17 18:24:41,822 - logger.py:50 - Epoch: [226][0/6]	Total Loss: 0.73095	Main MSE (x10^-2): 73.0954	LR: 2.32e-04	EMPP_Raw: 1.43545
2025-07-17 18:25:01,165 - logger.py:50 - Epoch: [226][5/6]	Total Loss: 0.73996	Main MSE (x10^-2): 73.9963	LR: 2.32e-04	EMPP_Raw: 1.45132
2025-07-17 18:25:01,208 - logger.py:50 - Epoch 226 Training Summary: Avg Total Loss: 0.73996, Avg Main MSE: 0.73996, Time: 23.44s
2025-07-17 18:25:20,759 - logger.py:50 - Epoch 226 Summary | Train MSE (x10^-2): 73.9963 | Val MSE (x10^-2): 18.2126 | Time: 42.99s
2025-07-17 18:25:24,819 - logger.py:50 - Epoch: [227][0/6]	Total Loss: 0.75514	Main MSE (x10^-2): 75.5138	LR: 2.30e-04	EMPP_Raw: 1.48364
2025-07-17 18:25:44,076 - logger.py:50 - Epoch: [227][5/6]	Total Loss: 0.74267	Main MSE (x10^-2): 74.2667	LR: 2.30e-04	EMPP_Raw: 1.45761
2025-07-17 18:25:44,117 - logger.py:50 - Epoch 227 Training Summary: Avg Total Loss: 0.74267, Avg Main MSE: 0.74267, Time: 23.35s
2025-07-17 18:26:03,878 - logger.py:50 - Epoch 227 Summary | Train MSE (x10^-2): 74.2667 | Val MSE (x10^-2): 18.4224 | Time: 43.12s
2025-07-17 18:26:07,950 - logger.py:50 - Epoch: [228][0/6]	Total Loss: 0.72731	Main MSE (x10^-2): 72.7309	LR: 2.29e-04	EMPP_Raw: 1.42701
2025-07-17 18:26:27,214 - logger.py:50 - Epoch: [228][5/6]	Total Loss: 0.73862	Main MSE (x10^-2): 73.8619	LR: 2.29e-04	EMPP_Raw: 1.44893
2025-07-17 18:26:27,256 - logger.py:50 - Epoch 228 Training Summary: Avg Total Loss: 0.73862, Avg Main MSE: 0.73862, Time: 23.37s
2025-07-17 18:26:46,721 - logger.py:50 - Epoch 228 Summary | Train MSE (x10^-2): 73.8619 | Val MSE (x10^-2): 18.5345 | Time: 42.84s
2025-07-17 18:26:50,797 - logger.py:50 - Epoch: [229][0/6]	Total Loss: 0.75151	Main MSE (x10^-2): 75.1507	LR: 2.28e-04	EMPP_Raw: 1.47483
2025-07-17 18:27:10,034 - logger.py:50 - Epoch: [229][5/6]	Total Loss: 0.75468	Main MSE (x10^-2): 75.4680	LR: 2.28e-04	EMPP_Raw: 1.47998
2025-07-17 18:27:10,073 - logger.py:50 - Epoch 229 Training Summary: Avg Total Loss: 0.75468, Avg Main MSE: 0.75468, Time: 23.34s
2025-07-17 18:27:29,618 - logger.py:50 - Epoch 229 Summary | Train MSE (x10^-2): 75.4680 | Val MSE (x10^-2): 18.2560 | Time: 42.89s
2025-07-17 18:27:33,762 - logger.py:50 - Epoch: [230][0/6]	Total Loss: 0.74078	Main MSE (x10^-2): 74.0781	LR: 2.27e-04	EMPP_Raw: 1.45431
2025-07-17 18:27:52,982 - logger.py:50 - Epoch: [230][5/6]	Total Loss: 0.74193	Main MSE (x10^-2): 74.1927	LR: 2.27e-04	EMPP_Raw: 1.45601
2025-07-17 18:27:53,028 - logger.py:50 - Epoch 230 Training Summary: Avg Total Loss: 0.74193, Avg Main MSE: 0.74193, Time: 23.40s
2025-07-17 18:28:12,664 - logger.py:50 - Epoch 230 Summary | Train MSE (x10^-2): 74.1927 | Val MSE (x10^-2): 18.4738 | Time: 43.04s
2025-07-17 18:28:16,737 - logger.py:50 - Epoch: [231][0/6]	Total Loss: 0.74074	Main MSE (x10^-2): 74.0740	LR: 2.26e-04	EMPP_Raw: 1.45535
2025-07-17 18:28:36,031 - logger.py:50 - Epoch: [231][5/6]	Total Loss: 0.73408	Main MSE (x10^-2): 73.4084	LR: 2.26e-04	EMPP_Raw: 1.44136
2025-07-17 18:28:36,075 - logger.py:50 - Epoch 231 Training Summary: Avg Total Loss: 0.73408, Avg Main MSE: 0.73408, Time: 23.40s
2025-07-17 18:28:55,715 - logger.py:50 - Epoch 231 Summary | Train MSE (x10^-2): 73.4084 | Val MSE (x10^-2): 18.2546 | Time: 43.05s
2025-07-17 18:28:59,833 - logger.py:50 - Epoch: [232][0/6]	Total Loss: 0.73540	Main MSE (x10^-2): 73.5399	LR: 2.24e-04	EMPP_Raw: 1.44537
2025-07-17 18:29:19,171 - logger.py:50 - Epoch: [232][5/6]	Total Loss: 0.72863	Main MSE (x10^-2): 72.8631	LR: 2.24e-04	EMPP_Raw: 1.42942
2025-07-17 18:29:19,212 - logger.py:50 - Epoch 232 Training Summary: Avg Total Loss: 0.72863, Avg Main MSE: 0.72863, Time: 23.49s
2025-07-17 18:29:38,841 - logger.py:50 - Epoch 232 Summary | Train MSE (x10^-2): 72.8631 | Val MSE (x10^-2): 18.6801 | Time: 43.12s
2025-07-17 18:29:42,880 - logger.py:50 - Epoch: [233][0/6]	Total Loss: 0.70735	Main MSE (x10^-2): 70.7346	LR: 2.23e-04	EMPP_Raw: 1.38879
2025-07-17 18:30:02,128 - logger.py:50 - Epoch: [233][5/6]	Total Loss: 0.73564	Main MSE (x10^-2): 73.5635	LR: 2.23e-04	EMPP_Raw: 1.44418
2025-07-17 18:30:02,169 - logger.py:50 - Epoch 233 Training Summary: Avg Total Loss: 0.73564, Avg Main MSE: 0.73564, Time: 23.32s
2025-07-17 18:30:21,802 - logger.py:50 - Epoch 233 Summary | Train MSE (x10^-2): 73.5635 | Val MSE (x10^-2): 18.4433 | Time: 42.96s
2025-07-17 18:30:25,883 - logger.py:50 - Epoch: [234][0/6]	Total Loss: 0.75519	Main MSE (x10^-2): 75.5193	LR: 2.22e-04	EMPP_Raw: 1.48284
2025-07-17 18:30:45,182 - logger.py:50 - Epoch: [234][5/6]	Total Loss: 0.75311	Main MSE (x10^-2): 75.3112	LR: 2.22e-04	EMPP_Raw: 1.47960
2025-07-17 18:30:45,221 - logger.py:50 - Epoch 234 Training Summary: Avg Total Loss: 0.75311, Avg Main MSE: 0.75311, Time: 23.41s
2025-07-17 18:31:04,882 - logger.py:50 - Epoch 234 Summary | Train MSE (x10^-2): 75.3112 | Val MSE (x10^-2): 18.6824 | Time: 43.07s
2025-07-17 18:31:08,996 - logger.py:50 - Epoch: [235][0/6]	Total Loss: 0.74178	Main MSE (x10^-2): 74.1779	LR: 2.21e-04	EMPP_Raw: 1.45597
2025-07-17 18:31:28,286 - logger.py:50 - Epoch: [235][5/6]	Total Loss: 0.73852	Main MSE (x10^-2): 73.8519	LR: 2.21e-04	EMPP_Raw: 1.45016
2025-07-17 18:31:28,328 - logger.py:50 - Epoch 235 Training Summary: Avg Total Loss: 0.73852, Avg Main MSE: 0.73852, Time: 23.44s
2025-07-17 18:31:48,084 - logger.py:50 - Epoch 235 Summary | Train MSE (x10^-2): 73.8519 | Val MSE (x10^-2): 18.2093 | Time: 43.20s
2025-07-17 18:31:52,151 - logger.py:50 - Epoch: [236][0/6]	Total Loss: 0.73825	Main MSE (x10^-2): 73.8254	LR: 2.19e-04	EMPP_Raw: 1.44960
2025-07-17 18:32:11,500 - logger.py:50 - Epoch: [236][5/6]	Total Loss: 0.74496	Main MSE (x10^-2): 74.4961	LR: 2.19e-04	EMPP_Raw: 1.46348
2025-07-17 18:32:11,541 - logger.py:50 - Epoch 236 Training Summary: Avg Total Loss: 0.74496, Avg Main MSE: 0.74496, Time: 23.45s
2025-07-17 18:32:31,128 - logger.py:50 - Epoch 236 Summary | Train MSE (x10^-2): 74.4961 | Val MSE (x10^-2): 18.3185 | Time: 43.04s
2025-07-17 18:32:35,213 - logger.py:50 - Epoch: [237][0/6]	Total Loss: 0.72262	Main MSE (x10^-2): 72.2618	LR: 2.18e-04	EMPP_Raw: 1.42039
2025-07-17 18:32:54,547 - logger.py:50 - Epoch: [237][5/6]	Total Loss: 0.74831	Main MSE (x10^-2): 74.8307	LR: 2.18e-04	EMPP_Raw: 1.47006
2025-07-17 18:32:54,589 - logger.py:50 - Epoch 237 Training Summary: Avg Total Loss: 0.74831, Avg Main MSE: 0.74831, Time: 23.45s
2025-07-17 18:33:14,155 - logger.py:50 - Epoch 237 Summary | Train MSE (x10^-2): 74.8307 | Val MSE (x10^-2): 18.2786 | Time: 43.02s
2025-07-17 18:33:18,250 - logger.py:50 - Epoch: [238][0/6]	Total Loss: 0.73960	Main MSE (x10^-2): 73.9601	LR: 2.17e-04	EMPP_Raw: 1.45221
2025-07-17 18:33:37,538 - logger.py:50 - Epoch: [238][5/6]	Total Loss: 0.73772	Main MSE (x10^-2): 73.7725	LR: 2.17e-04	EMPP_Raw: 1.44910
2025-07-17 18:33:37,577 - logger.py:50 - Epoch 238 Training Summary: Avg Total Loss: 0.73772, Avg Main MSE: 0.73772, Time: 23.41s
2025-07-17 18:33:57,167 - logger.py:50 - Epoch 238 Summary | Train MSE (x10^-2): 73.7725 | Val MSE (x10^-2): 18.5870 | Time: 43.01s
2025-07-17 18:34:01,243 - logger.py:50 - Epoch: [239][0/6]	Total Loss: 0.72867	Main MSE (x10^-2): 72.8674	LR: 2.16e-04	EMPP_Raw: 1.43200
2025-07-17 18:34:20,509 - logger.py:50 - Epoch: [239][5/6]	Total Loss: 0.74798	Main MSE (x10^-2): 74.7980	LR: 2.16e-04	EMPP_Raw: 1.46923
2025-07-17 18:34:20,553 - logger.py:50 - Epoch 239 Training Summary: Avg Total Loss: 0.74798, Avg Main MSE: 0.74798, Time: 23.38s
2025-07-17 18:34:40,158 - logger.py:50 - Epoch 239 Summary | Train MSE (x10^-2): 74.7980 | Val MSE (x10^-2): 18.7316 | Time: 42.99s
2025-07-17 18:34:44,269 - logger.py:50 - Epoch: [240][0/6]	Total Loss: 0.74248	Main MSE (x10^-2): 74.2479	LR: 2.14e-04	EMPP_Raw: 1.45881
2025-07-17 18:35:03,560 - logger.py:50 - Epoch: [240][5/6]	Total Loss: 0.73380	Main MSE (x10^-2): 73.3796	LR: 2.14e-04	EMPP_Raw: 1.44087
2025-07-17 18:35:03,599 - logger.py:50 - Epoch 240 Training Summary: Avg Total Loss: 0.73380, Avg Main MSE: 0.73380, Time: 23.43s
2025-07-17 18:35:23,118 - logger.py:50 - Epoch 240 Summary | Train MSE (x10^-2): 73.3796 | Val MSE (x10^-2): 18.4851 | Time: 42.95s
2025-07-17 18:35:27,214 - logger.py:50 - Epoch: [241][0/6]	Total Loss: 0.73777	Main MSE (x10^-2): 73.7767	LR: 2.13e-04	EMPP_Raw: 1.45022
2025-07-17 18:35:46,498 - logger.py:50 - Epoch: [241][5/6]	Total Loss: 0.72926	Main MSE (x10^-2): 72.9263	LR: 2.13e-04	EMPP_Raw: 1.43256
2025-07-17 18:35:46,541 - logger.py:50 - Epoch 241 Training Summary: Avg Total Loss: 0.72926, Avg Main MSE: 0.72926, Time: 23.42s
2025-07-17 18:36:06,027 - logger.py:50 - Epoch 241 Summary | Train MSE (x10^-2): 72.9263 | Val MSE (x10^-2): 18.4469 | Time: 42.90s
2025-07-17 18:36:10,112 - logger.py:50 - Epoch: [242][0/6]	Total Loss: 0.71329	Main MSE (x10^-2): 71.3288	LR: 2.12e-04	EMPP_Raw: 1.40005
2025-07-17 18:36:29,406 - logger.py:50 - Epoch: [242][5/6]	Total Loss: 0.73138	Main MSE (x10^-2): 73.1381	LR: 2.12e-04	EMPP_Raw: 1.43676
2025-07-17 18:36:29,445 - logger.py:50 - Epoch 242 Training Summary: Avg Total Loss: 0.73138, Avg Main MSE: 0.73138, Time: 23.41s
2025-07-17 18:36:49,176 - logger.py:50 - Epoch 242 Summary | Train MSE (x10^-2): 73.1381 | Val MSE (x10^-2): 18.3899 | Time: 43.14s
2025-07-17 18:36:53,285 - logger.py:50 - Epoch: [243][0/6]	Total Loss: 0.74191	Main MSE (x10^-2): 74.1914	LR: 2.11e-04	EMPP_Raw: 1.45675
2025-07-17 18:37:12,524 - logger.py:50 - Epoch: [243][5/6]	Total Loss: 0.73502	Main MSE (x10^-2): 73.5019	LR: 2.11e-04	EMPP_Raw: 1.44358
2025-07-17 18:37:12,563 - logger.py:50 - Epoch 243 Training Summary: Avg Total Loss: 0.73502, Avg Main MSE: 0.73502, Time: 23.38s
2025-07-17 18:37:32,144 - logger.py:50 - Epoch 243 Summary | Train MSE (x10^-2): 73.5019 | Val MSE (x10^-2): 18.1669 | Time: 42.97s
2025-07-17 18:37:36,248 - logger.py:50 - Epoch: [244][0/6]	Total Loss: 0.75220	Main MSE (x10^-2): 75.2201	LR: 2.09e-04	EMPP_Raw: 1.47954
2025-07-17 18:37:55,481 - logger.py:50 - Epoch: [244][5/6]	Total Loss: 0.73966	Main MSE (x10^-2): 73.9662	LR: 2.09e-04	EMPP_Raw: 1.45332
2025-07-17 18:37:55,521 - logger.py:50 - Epoch 244 Training Summary: Avg Total Loss: 0.73966, Avg Main MSE: 0.73966, Time: 23.37s
2025-07-17 18:38:15,141 - logger.py:50 - Epoch 244 Summary | Train MSE (x10^-2): 73.9662 | Val MSE (x10^-2): 18.3663 | Time: 42.99s
2025-07-17 18:38:19,223 - logger.py:50 - Epoch: [245][0/6]	Total Loss: 0.76008	Main MSE (x10^-2): 76.0076	LR: 2.08e-04	EMPP_Raw: 1.49461
2025-07-17 18:38:38,413 - logger.py:50 - Epoch: [245][5/6]	Total Loss: 0.74139	Main MSE (x10^-2): 74.1389	LR: 2.08e-04	EMPP_Raw: 1.45736
2025-07-17 18:38:38,456 - logger.py:50 - Epoch 245 Training Summary: Avg Total Loss: 0.74139, Avg Main MSE: 0.74139, Time: 23.31s
2025-07-17 18:38:57,983 - logger.py:50 - Epoch 245 Summary | Train MSE (x10^-2): 74.1389 | Val MSE (x10^-2): 18.6262 | Time: 42.84s
2025-07-17 18:39:02,109 - logger.py:50 - Epoch: [246][0/6]	Total Loss: 0.75052	Main MSE (x10^-2): 75.0523	LR: 2.07e-04	EMPP_Raw: 1.47641
2025-07-17 18:39:21,401 - logger.py:50 - Epoch: [246][5/6]	Total Loss: 0.74395	Main MSE (x10^-2): 74.3952	LR: 2.07e-04	EMPP_Raw: 1.46242
2025-07-17 18:39:21,445 - logger.py:50 - Epoch 246 Training Summary: Avg Total Loss: 0.74395, Avg Main MSE: 0.74395, Time: 23.45s
2025-07-17 18:39:40,978 - logger.py:50 - Epoch 246 Summary | Train MSE (x10^-2): 74.3952 | Val MSE (x10^-2): 18.5566 | Time: 42.99s
2025-07-17 18:39:45,074 - logger.py:50 - Epoch: [247][0/6]	Total Loss: 0.72674	Main MSE (x10^-2): 72.6737	LR: 2.06e-04	EMPP_Raw: 1.42770
2025-07-17 18:40:04,271 - logger.py:50 - Epoch: [247][5/6]	Total Loss: 0.73488	Main MSE (x10^-2): 73.4880	LR: 2.06e-04	EMPP_Raw: 1.44362
2025-07-17 18:40:04,314 - logger.py:50 - Epoch 247 Training Summary: Avg Total Loss: 0.73488, Avg Main MSE: 0.73488, Time: 23.33s
2025-07-17 18:40:23,907 - logger.py:50 - Epoch 247 Summary | Train MSE (x10^-2): 73.4880 | Val MSE (x10^-2): 18.6689 | Time: 42.92s
2025-07-17 18:40:27,997 - logger.py:50 - Epoch: [248][0/6]	Total Loss: 0.72956	Main MSE (x10^-2): 72.9562	LR: 2.04e-04	EMPP_Raw: 1.43453
2025-07-17 18:40:47,245 - logger.py:50 - Epoch: [248][5/6]	Total Loss: 0.73703	Main MSE (x10^-2): 73.7026	LR: 2.04e-04	EMPP_Raw: 1.44900
2025-07-17 18:40:47,286 - logger.py:50 - Epoch 248 Training Summary: Avg Total Loss: 0.73703, Avg Main MSE: 0.73703, Time: 23.37s
2025-07-17 18:41:06,901 - logger.py:50 - Epoch 248 Summary | Train MSE (x10^-2): 73.7026 | Val MSE (x10^-2): 18.3852 | Time: 42.99s
2025-07-17 18:41:10,964 - logger.py:50 - Epoch: [249][0/6]	Total Loss: 0.72143	Main MSE (x10^-2): 72.1426	LR: 2.03e-04	EMPP_Raw: 1.41746
2025-07-17 18:41:30,223 - logger.py:50 - Epoch: [249][5/6]	Total Loss: 0.73528	Main MSE (x10^-2): 73.5284	LR: 2.03e-04	EMPP_Raw: 1.44513
2025-07-17 18:41:30,260 - logger.py:50 - Epoch 249 Training Summary: Avg Total Loss: 0.73528, Avg Main MSE: 0.73528, Time: 23.35s
2025-07-17 18:41:49,776 - logger.py:50 - Epoch 249 Summary | Train MSE (x10^-2): 73.5284 | Val MSE (x10^-2): 18.3616 | Time: 42.87s
2025-07-17 18:41:53,861 - logger.py:50 - Epoch: [250][0/6]	Total Loss: 0.74754	Main MSE (x10^-2): 74.7544	LR: 2.02e-04	EMPP_Raw: 1.46985
2025-07-17 18:42:13,269 - logger.py:50 - Epoch: [250][5/6]	Total Loss: 0.73535	Main MSE (x10^-2): 73.5348	LR: 2.02e-04	EMPP_Raw: 1.44626
2025-07-17 18:42:13,308 - logger.py:50 - Epoch 250 Training Summary: Avg Total Loss: 0.73535, Avg Main MSE: 0.73535, Time: 23.52s
2025-07-17 18:42:33,033 - logger.py:50 - Epoch 250 Summary | Train MSE (x10^-2): 73.5348 | Val MSE (x10^-2): 18.3091 | Time: 43.25s
2025-07-17 18:42:37,167 - logger.py:50 - Epoch: [251][0/6]	Total Loss: 0.71021	Main MSE (x10^-2): 71.0211	LR: 2.00e-04	EMPP_Raw: 1.39739
2025-07-17 18:42:56,424 - logger.py:50 - Epoch: [251][5/6]	Total Loss: 0.72611	Main MSE (x10^-2): 72.6106	LR: 2.00e-04	EMPP_Raw: 1.42788
2025-07-17 18:42:56,460 - logger.py:50 - Epoch 251 Training Summary: Avg Total Loss: 0.72611, Avg Main MSE: 0.72611, Time: 23.42s
2025-07-17 18:43:16,054 - logger.py:50 - Epoch 251 Summary | Train MSE (x10^-2): 72.6106 | Val MSE (x10^-2): 18.4362 | Time: 43.02s
2025-07-17 18:43:20,149 - logger.py:50 - Epoch: [252][0/6]	Total Loss: 0.73138	Main MSE (x10^-2): 73.1378	LR: 1.99e-04	EMPP_Raw: 1.43771
2025-07-17 18:43:39,382 - logger.py:50 - Epoch: [252][5/6]	Total Loss: 0.73559	Main MSE (x10^-2): 73.5592	LR: 1.99e-04	EMPP_Raw: 1.44615
2025-07-17 18:43:39,422 - logger.py:50 - Epoch 252 Training Summary: Avg Total Loss: 0.73559, Avg Main MSE: 0.73559, Time: 23.36s
2025-07-17 18:43:59,007 - logger.py:50 - Epoch 252 Summary | Train MSE (x10^-2): 73.5592 | Val MSE (x10^-2): 18.4115 | Time: 42.95s
2025-07-17 18:44:03,151 - logger.py:50 - Epoch: [253][0/6]	Total Loss: 0.75186	Main MSE (x10^-2): 75.1860	LR: 1.98e-04	EMPP_Raw: 1.47736
2025-07-17 18:44:22,385 - logger.py:50 - Epoch: [253][5/6]	Total Loss: 0.75091	Main MSE (x10^-2): 75.0915	LR: 1.98e-04	EMPP_Raw: 1.47670
2025-07-17 18:44:22,426 - logger.py:50 - Epoch 253 Training Summary: Avg Total Loss: 0.75091, Avg Main MSE: 0.75091, Time: 23.41s
2025-07-17 18:44:42,038 - logger.py:50 - Epoch 253 Summary | Train MSE (x10^-2): 75.0915 | Val MSE (x10^-2): 18.4579 | Time: 43.03s
2025-07-17 18:44:46,204 - logger.py:50 - Epoch: [254][0/6]	Total Loss: 0.75120	Main MSE (x10^-2): 75.1203	LR: 1.97e-04	EMPP_Raw: 1.47823
2025-07-17 18:45:05,454 - logger.py:50 - Epoch: [254][5/6]	Total Loss: 0.74062	Main MSE (x10^-2): 74.0621	LR: 1.97e-04	EMPP_Raw: 1.45679
2025-07-17 18:45:05,494 - logger.py:50 - Epoch 254 Training Summary: Avg Total Loss: 0.74062, Avg Main MSE: 0.74062, Time: 23.45s
2025-07-17 18:45:25,010 - logger.py:50 - Epoch 254 Summary | Train MSE (x10^-2): 74.0621 | Val MSE (x10^-2): 18.6348 | Time: 42.97s
2025-07-17 18:45:29,052 - logger.py:50 - Epoch: [255][0/6]	Total Loss: 0.75754	Main MSE (x10^-2): 75.7539	LR: 1.95e-04	EMPP_Raw: 1.49171
2025-07-17 18:45:48,373 - logger.py:50 - Epoch: [255][5/6]	Total Loss: 0.75342	Main MSE (x10^-2): 75.3417	LR: 1.95e-04	EMPP_Raw: 1.48217
2025-07-17 18:45:48,412 - logger.py:50 - Epoch 255 Training Summary: Avg Total Loss: 0.75342, Avg Main MSE: 0.75342, Time: 23.39s
2025-07-17 18:46:07,913 - logger.py:50 - Epoch 255 Summary | Train MSE (x10^-2): 75.3417 | Val MSE (x10^-2): 18.5588 | Time: 42.90s
2025-07-17 18:46:11,988 - logger.py:50 - Epoch: [256][0/6]	Total Loss: 0.72818	Main MSE (x10^-2): 72.8178	LR: 1.94e-04	EMPP_Raw: 1.42960
2025-07-17 18:46:31,208 - logger.py:50 - Epoch: [256][5/6]	Total Loss: 0.72978	Main MSE (x10^-2): 72.9778	LR: 1.94e-04	EMPP_Raw: 1.43472
2025-07-17 18:46:31,248 - logger.py:50 - Epoch 256 Training Summary: Avg Total Loss: 0.72978, Avg Main MSE: 0.72978, Time: 23.33s
2025-07-17 18:46:50,797 - logger.py:50 - Epoch 256 Summary | Train MSE (x10^-2): 72.9778 | Val MSE (x10^-2): 18.3114 | Time: 42.88s
2025-07-17 18:46:54,890 - logger.py:50 - Epoch: [257][0/6]	Total Loss: 0.74551	Main MSE (x10^-2): 74.5506	LR: 1.93e-04	EMPP_Raw: 1.46615
2025-07-17 18:47:14,135 - logger.py:50 - Epoch: [257][5/6]	Total Loss: 0.73993	Main MSE (x10^-2): 73.9931	LR: 1.93e-04	EMPP_Raw: 1.45558
2025-07-17 18:47:14,176 - logger.py:50 - Epoch 257 Training Summary: Avg Total Loss: 0.73993, Avg Main MSE: 0.73993, Time: 23.37s
2025-07-17 18:47:33,797 - logger.py:50 - Epoch 257 Summary | Train MSE (x10^-2): 73.9931 | Val MSE (x10^-2): 18.4325 | Time: 42.99s
2025-07-17 18:47:37,911 - logger.py:50 - Epoch: [258][0/6]	Total Loss: 0.72888	Main MSE (x10^-2): 72.8880	LR: 1.92e-04	EMPP_Raw: 1.43234
2025-07-17 18:47:57,239 - logger.py:50 - Epoch: [258][5/6]	Total Loss: 0.73738	Main MSE (x10^-2): 73.7376	LR: 1.92e-04	EMPP_Raw: 1.44947
2025-07-17 18:47:57,280 - logger.py:50 - Epoch 258 Training Summary: Avg Total Loss: 0.73738, Avg Main MSE: 0.73738, Time: 23.48s
2025-07-17 18:48:16,879 - logger.py:50 - Epoch 258 Summary | Train MSE (x10^-2): 73.7376 | Val MSE (x10^-2): 18.2855 | Time: 43.08s
2025-07-17 18:48:21,003 - logger.py:50 - Epoch: [259][0/6]	Total Loss: 0.73672	Main MSE (x10^-2): 73.6723	LR: 1.90e-04	EMPP_Raw: 1.44858
2025-07-17 18:48:40,376 - logger.py:50 - Epoch: [259][5/6]	Total Loss: 0.73156	Main MSE (x10^-2): 73.1559	LR: 1.90e-04	EMPP_Raw: 1.43838
2025-07-17 18:48:40,420 - logger.py:50 - Epoch 259 Training Summary: Avg Total Loss: 0.73156, Avg Main MSE: 0.73156, Time: 23.53s
2025-07-17 18:49:00,046 - logger.py:50 - Epoch 259 Summary | Train MSE (x10^-2): 73.1559 | Val MSE (x10^-2): 18.4919 | Time: 43.16s
2025-07-17 18:49:04,127 - logger.py:50 - Epoch: [260][0/6]	Total Loss: 0.75926	Main MSE (x10^-2): 75.9259	LR: 1.89e-04	EMPP_Raw: 1.49330
2025-07-17 18:49:23,411 - logger.py:50 - Epoch: [260][5/6]	Total Loss: 0.73856	Main MSE (x10^-2): 73.8560	LR: 1.89e-04	EMPP_Raw: 1.45236
2025-07-17 18:49:23,467 - logger.py:50 - Epoch 260 Training Summary: Avg Total Loss: 0.73856, Avg Main MSE: 0.73856, Time: 23.41s
2025-07-17 18:49:42,968 - logger.py:50 - Epoch 260 Summary | Train MSE (x10^-2): 73.8560 | Val MSE (x10^-2): 18.3458 | Time: 42.92s
2025-07-17 18:49:47,042 - logger.py:50 - Epoch: [261][0/6]	Total Loss: 0.74306	Main MSE (x10^-2): 74.3061	LR: 1.88e-04	EMPP_Raw: 1.46141
2025-07-17 18:50:06,380 - logger.py:50 - Epoch: [261][5/6]	Total Loss: 0.73315	Main MSE (x10^-2): 73.3155	LR: 1.88e-04	EMPP_Raw: 1.44263
2025-07-17 18:50:06,420 - logger.py:50 - Epoch 261 Training Summary: Avg Total Loss: 0.73315, Avg Main MSE: 0.73315, Time: 23.44s
2025-07-17 18:50:26,152 - logger.py:50 - Epoch 261 Summary | Train MSE (x10^-2): 73.3155 | Val MSE (x10^-2): 18.3713 | Time: 43.18s
2025-07-17 18:50:30,246 - logger.py:50 - Epoch: [262][0/6]	Total Loss: 0.74356	Main MSE (x10^-2): 74.3557	LR: 1.87e-04	EMPP_Raw: 1.46344
2025-07-17 18:50:49,603 - logger.py:50 - Epoch: [262][5/6]	Total Loss: 0.74181	Main MSE (x10^-2): 74.1813	LR: 1.87e-04	EMPP_Raw: 1.45970
2025-07-17 18:50:49,642 - logger.py:50 - Epoch 262 Training Summary: Avg Total Loss: 0.74181, Avg Main MSE: 0.74181, Time: 23.48s
2025-07-17 18:51:09,243 - logger.py:50 - Epoch 262 Summary | Train MSE (x10^-2): 74.1813 | Val MSE (x10^-2): 18.4734 | Time: 43.09s
2025-07-17 18:51:13,348 - logger.py:50 - Epoch: [263][0/6]	Total Loss: 0.73297	Main MSE (x10^-2): 73.2965	LR: 1.85e-04	EMPP_Raw: 1.44174
2025-07-17 18:51:32,643 - logger.py:50 - Epoch: [263][5/6]	Total Loss: 0.73446	Main MSE (x10^-2): 73.4459	LR: 1.85e-04	EMPP_Raw: 1.44507
2025-07-17 18:51:32,685 - logger.py:50 - Epoch 263 Training Summary: Avg Total Loss: 0.73446, Avg Main MSE: 0.73446, Time: 23.43s
2025-07-17 18:51:52,180 - logger.py:50 - Epoch 263 Summary | Train MSE (x10^-2): 73.4459 | Val MSE (x10^-2): 18.6577 | Time: 42.93s
2025-07-17 18:51:56,273 - logger.py:50 - Epoch: [264][0/6]	Total Loss: 0.72543	Main MSE (x10^-2): 72.5429	LR: 1.84e-04	EMPP_Raw: 1.42557
2025-07-17 18:52:15,494 - logger.py:50 - Epoch: [264][5/6]	Total Loss: 0.72920	Main MSE (x10^-2): 72.9201	LR: 1.84e-04	EMPP_Raw: 1.43423
2025-07-17 18:52:15,535 - logger.py:50 - Epoch 264 Training Summary: Avg Total Loss: 0.72920, Avg Main MSE: 0.72920, Time: 23.35s
2025-07-17 18:52:35,111 - logger.py:50 - Epoch 264 Summary | Train MSE (x10^-2): 72.9201 | Val MSE (x10^-2): 18.5375 | Time: 42.93s
2025-07-17 18:52:39,197 - logger.py:50 - Epoch: [265][0/6]	Total Loss: 0.72743	Main MSE (x10^-2): 72.7430	LR: 1.83e-04	EMPP_Raw: 1.43048
2025-07-17 18:52:58,398 - logger.py:50 - Epoch: [265][5/6]	Total Loss: 0.73473	Main MSE (x10^-2): 73.4732	LR: 1.83e-04	EMPP_Raw: 1.44614
2025-07-17 18:52:58,441 - logger.py:50 - Epoch 265 Training Summary: Avg Total Loss: 0.73473, Avg Main MSE: 0.73473, Time: 23.32s
2025-07-17 18:53:17,959 - logger.py:50 - Epoch 265 Summary | Train MSE (x10^-2): 73.4732 | Val MSE (x10^-2): 18.2633 | Time: 42.84s
2025-07-17 18:53:22,083 - logger.py:50 - Epoch: [266][0/6]	Total Loss: 0.74348	Main MSE (x10^-2): 74.3484	LR: 1.82e-04	EMPP_Raw: 1.46361
2025-07-17 18:53:41,269 - logger.py:50 - Epoch: [266][5/6]	Total Loss: 0.73521	Main MSE (x10^-2): 73.5213	LR: 1.82e-04	EMPP_Raw: 1.44645
2025-07-17 18:53:41,309 - logger.py:50 - Epoch 266 Training Summary: Avg Total Loss: 0.73521, Avg Main MSE: 0.73521, Time: 23.34s
2025-07-17 18:54:00,826 - logger.py:50 - Epoch 266 Summary | Train MSE (x10^-2): 73.5213 | Val MSE (x10^-2): 18.5162 | Time: 42.86s
2025-07-17 18:54:04,915 - logger.py:50 - Epoch: [267][0/6]	Total Loss: 0.75367	Main MSE (x10^-2): 75.3667	LR: 1.80e-04	EMPP_Raw: 1.48421
2025-07-17 18:54:24,123 - logger.py:50 - Epoch: [267][5/6]	Total Loss: 0.74183	Main MSE (x10^-2): 74.1825	LR: 1.80e-04	EMPP_Raw: 1.46054
2025-07-17 18:54:24,164 - logger.py:50 - Epoch 267 Training Summary: Avg Total Loss: 0.74183, Avg Main MSE: 0.74183, Time: 23.33s
2025-07-17 18:54:43,771 - logger.py:50 - Epoch 267 Summary | Train MSE (x10^-2): 74.1825 | Val MSE (x10^-2): 18.5214 | Time: 42.94s
2025-07-17 18:54:47,845 - logger.py:50 - Epoch: [268][0/6]	Total Loss: 0.75445	Main MSE (x10^-2): 75.4451	LR: 1.79e-04	EMPP_Raw: 1.48409
2025-07-17 18:55:07,069 - logger.py:50 - Epoch: [268][5/6]	Total Loss: 0.73413	Main MSE (x10^-2): 73.4128	LR: 1.79e-04	EMPP_Raw: 1.44554
2025-07-17 18:55:07,111 - logger.py:50 - Epoch 268 Training Summary: Avg Total Loss: 0.73413, Avg Main MSE: 0.73413, Time: 23.33s
2025-07-17 18:55:26,693 - logger.py:50 - Epoch 268 Summary | Train MSE (x10^-2): 73.4128 | Val MSE (x10^-2): 18.2715 | Time: 42.92s
2025-07-17 18:55:30,774 - logger.py:50 - Epoch: [269][0/6]	Total Loss: 0.73636	Main MSE (x10^-2): 73.6364	LR: 1.78e-04	EMPP_Raw: 1.44838
2025-07-17 18:55:50,021 - logger.py:50 - Epoch: [269][5/6]	Total Loss: 0.73284	Main MSE (x10^-2): 73.2835	LR: 1.78e-04	EMPP_Raw: 1.44180
2025-07-17 18:55:50,060 - logger.py:50 - Epoch 269 Training Summary: Avg Total Loss: 0.73284, Avg Main MSE: 0.73284, Time: 23.36s
2025-07-17 18:56:09,701 - logger.py:50 - Epoch 269 Summary | Train MSE (x10^-2): 73.2835 | Val MSE (x10^-2): 18.7092 | Time: 43.00s
2025-07-17 18:56:13,781 - logger.py:50 - Epoch: [270][0/6]	Total Loss: 0.71735	Main MSE (x10^-2): 71.7355	LR: 1.77e-04	EMPP_Raw: 1.41110
2025-07-17 18:56:33,104 - logger.py:50 - Epoch: [270][5/6]	Total Loss: 0.73143	Main MSE (x10^-2): 73.1429	LR: 1.77e-04	EMPP_Raw: 1.43931
2025-07-17 18:56:33,148 - logger.py:50 - Epoch 270 Training Summary: Avg Total Loss: 0.73143, Avg Main MSE: 0.73143, Time: 23.44s
2025-07-17 18:56:52,755 - logger.py:50 - Epoch 270 Summary | Train MSE (x10^-2): 73.1429 | Val MSE (x10^-2): 18.3366 | Time: 43.05s
2025-07-17 18:56:56,856 - logger.py:50 - Epoch: [271][0/6]	Total Loss: 0.74730	Main MSE (x10^-2): 74.7299	LR: 1.75e-04	EMPP_Raw: 1.47291
2025-07-17 18:57:16,132 - logger.py:50 - Epoch: [271][5/6]	Total Loss: 0.74621	Main MSE (x10^-2): 74.6212	LR: 1.75e-04	EMPP_Raw: 1.46960
2025-07-17 18:57:16,171 - logger.py:50 - Epoch 271 Training Summary: Avg Total Loss: 0.74621, Avg Main MSE: 0.74621, Time: 23.41s
2025-07-17 18:57:35,703 - logger.py:50 - Epoch 271 Summary | Train MSE (x10^-2): 74.6212 | Val MSE (x10^-2): 18.1025 | Time: 42.94s
2025-07-17 18:57:39,784 - logger.py:50 - Epoch: [272][0/6]	Total Loss: 0.73749	Main MSE (x10^-2): 73.7493	LR: 1.74e-04	EMPP_Raw: 1.44927
2025-07-17 18:57:59,062 - logger.py:50 - Epoch: [272][5/6]	Total Loss: 0.74202	Main MSE (x10^-2): 74.2017	LR: 1.74e-04	EMPP_Raw: 1.46012
2025-07-17 18:57:59,106 - logger.py:50 - Epoch 272 Training Summary: Avg Total Loss: 0.74202, Avg Main MSE: 0.74202, Time: 23.39s
2025-07-17 18:58:18,627 - logger.py:50 - Epoch 272 Summary | Train MSE (x10^-2): 74.2017 | Val MSE (x10^-2): 18.4365 | Time: 42.92s
2025-07-17 18:58:22,704 - logger.py:50 - Epoch: [273][0/6]	Total Loss: 0.74192	Main MSE (x10^-2): 74.1916	LR: 1.73e-04	EMPP_Raw: 1.46109
2025-07-17 18:58:41,935 - logger.py:50 - Epoch: [273][5/6]	Total Loss: 0.73625	Main MSE (x10^-2): 73.6253	LR: 1.73e-04	EMPP_Raw: 1.44943
2025-07-17 18:58:41,976 - logger.py:50 - Epoch 273 Training Summary: Avg Total Loss: 0.73625, Avg Main MSE: 0.73625, Time: 23.34s
2025-07-17 18:59:01,583 - logger.py:50 - Epoch 273 Summary | Train MSE (x10^-2): 73.6253 | Val MSE (x10^-2): 18.3839 | Time: 42.95s
2025-07-17 18:59:05,663 - logger.py:50 - Epoch: [274][0/6]	Total Loss: 0.73942	Main MSE (x10^-2): 73.9419	LR: 1.72e-04	EMPP_Raw: 1.45615
2025-07-17 18:59:24,963 - logger.py:50 - Epoch: [274][5/6]	Total Loss: 0.73183	Main MSE (x10^-2): 73.1827	LR: 1.72e-04	EMPP_Raw: 1.44004
2025-07-17 18:59:25,006 - logger.py:50 - Epoch 274 Training Summary: Avg Total Loss: 0.73183, Avg Main MSE: 0.73183, Time: 23.41s
2025-07-17 18:59:44,665 - logger.py:50 - Epoch 274 Summary | Train MSE (x10^-2): 73.1827 | Val MSE (x10^-2): 18.3426 | Time: 43.08s
2025-07-17 18:59:48,779 - logger.py:50 - Epoch: [275][0/6]	Total Loss: 0.74298	Main MSE (x10^-2): 74.2979	LR: 1.71e-04	EMPP_Raw: 1.46194
2025-07-17 19:00:08,059 - logger.py:50 - Epoch: [275][5/6]	Total Loss: 0.73274	Main MSE (x10^-2): 73.2738	LR: 1.71e-04	EMPP_Raw: 1.44236
2025-07-17 19:00:08,097 - logger.py:50 - Epoch 275 Training Summary: Avg Total Loss: 0.73274, Avg Main MSE: 0.73274, Time: 23.42s
2025-07-17 19:00:27,659 - logger.py:50 - Epoch 275 Summary | Train MSE (x10^-2): 73.2738 | Val MSE (x10^-2): 18.2782 | Time: 42.99s
2025-07-17 19:00:31,736 - logger.py:50 - Epoch: [276][0/6]	Total Loss: 0.74717	Main MSE (x10^-2): 74.7167	LR: 1.69e-04	EMPP_Raw: 1.47002
2025-07-17 19:00:51,040 - logger.py:50 - Epoch: [276][5/6]	Total Loss: 0.73757	Main MSE (x10^-2): 73.7575	LR: 1.69e-04	EMPP_Raw: 1.45193
2025-07-17 19:00:51,082 - logger.py:50 - Epoch 276 Training Summary: Avg Total Loss: 0.73757, Avg Main MSE: 0.73757, Time: 23.41s
2025-07-17 19:01:10,650 - logger.py:50 - Epoch 276 Summary | Train MSE (x10^-2): 73.7575 | Val MSE (x10^-2): 18.2874 | Time: 42.98s
2025-07-17 19:01:14,715 - logger.py:50 - Epoch: [277][0/6]	Total Loss: 0.74092	Main MSE (x10^-2): 74.0924	LR: 1.68e-04	EMPP_Raw: 1.46076
2025-07-17 19:01:34,023 - logger.py:50 - Epoch: [277][5/6]	Total Loss: 0.73747	Main MSE (x10^-2): 73.7474	LR: 1.68e-04	EMPP_Raw: 1.45270
2025-07-17 19:01:34,064 - logger.py:50 - Epoch 277 Training Summary: Avg Total Loss: 0.73747, Avg Main MSE: 0.73747, Time: 23.41s
2025-07-17 19:01:53,632 - logger.py:50 - Epoch 277 Summary | Train MSE (x10^-2): 73.7474 | Val MSE (x10^-2): 18.5093 | Time: 42.98s
2025-07-17 19:01:57,714 - logger.py:50 - Epoch: [278][0/6]	Total Loss: 0.72729	Main MSE (x10^-2): 72.7292	LR: 1.67e-04	EMPP_Raw: 1.43230
2025-07-17 19:02:17,010 - logger.py:50 - Epoch: [278][5/6]	Total Loss: 0.73024	Main MSE (x10^-2): 73.0235	LR: 1.67e-04	EMPP_Raw: 1.43819
2025-07-17 19:02:17,051 - logger.py:50 - Epoch 278 Training Summary: Avg Total Loss: 0.73024, Avg Main MSE: 0.73024, Time: 23.41s
2025-07-17 19:02:36,640 - logger.py:50 - Epoch 278 Summary | Train MSE (x10^-2): 73.0235 | Val MSE (x10^-2): 18.4602 | Time: 43.00s
2025-07-17 19:02:40,733 - logger.py:50 - Epoch: [279][0/6]	Total Loss: 0.73684	Main MSE (x10^-2): 73.6839	LR: 1.66e-04	EMPP_Raw: 1.44985
2025-07-17 19:03:00,022 - logger.py:50 - Epoch: [279][5/6]	Total Loss: 0.74585	Main MSE (x10^-2): 74.5853	LR: 1.66e-04	EMPP_Raw: 1.46889
2025-07-17 19:03:00,062 - logger.py:50 - Epoch 279 Training Summary: Avg Total Loss: 0.74585, Avg Main MSE: 0.74585, Time: 23.41s
2025-07-17 19:03:19,567 - logger.py:50 - Epoch 279 Summary | Train MSE (x10^-2): 74.5853 | Val MSE (x10^-2): 18.4685 | Time: 42.92s
2025-07-17 19:03:23,666 - logger.py:50 - Epoch: [280][0/6]	Total Loss: 0.75486	Main MSE (x10^-2): 75.4859	LR: 1.64e-04	EMPP_Raw: 1.48640
2025-07-17 19:03:42,987 - logger.py:50 - Epoch: [280][5/6]	Total Loss: 0.74685	Main MSE (x10^-2): 74.6854	LR: 1.64e-04	EMPP_Raw: 1.47094
2025-07-17 19:03:43,028 - logger.py:50 - Epoch 280 Training Summary: Avg Total Loss: 0.74685, Avg Main MSE: 0.74685, Time: 23.45s
2025-07-17 19:04:02,650 - logger.py:50 - Epoch 280 Summary | Train MSE (x10^-2): 74.6854 | Val MSE (x10^-2): 18.3892 | Time: 43.08s
2025-07-17 19:04:06,778 - logger.py:50 - Epoch: [281][0/6]	Total Loss: 0.73650	Main MSE (x10^-2): 73.6502	LR: 1.63e-04	EMPP_Raw: 1.45082
2025-07-17 19:04:26,099 - logger.py:50 - Epoch: [281][5/6]	Total Loss: 0.73384	Main MSE (x10^-2): 73.3840	LR: 1.63e-04	EMPP_Raw: 1.44637
2025-07-17 19:04:26,143 - logger.py:50 - Epoch 281 Training Summary: Avg Total Loss: 0.73384, Avg Main MSE: 0.73384, Time: 23.48s
2025-07-17 19:04:45,660 - logger.py:50 - Epoch 281 Summary | Train MSE (x10^-2): 73.3840 | Val MSE (x10^-2): 18.3355 | Time: 43.00s
2025-07-17 19:04:49,748 - logger.py:50 - Epoch: [282][0/6]	Total Loss: 0.72127	Main MSE (x10^-2): 72.1266	LR: 1.62e-04	EMPP_Raw: 1.42009
2025-07-17 19:05:08,972 - logger.py:50 - Epoch: [282][5/6]	Total Loss: 0.73279	Main MSE (x10^-2): 73.2793	LR: 1.62e-04	EMPP_Raw: 1.44259
2025-07-17 19:05:09,014 - logger.py:50 - Epoch 282 Training Summary: Avg Total Loss: 0.73279, Avg Main MSE: 0.73279, Time: 23.35s
2025-07-17 19:05:28,733 - logger.py:50 - Epoch 282 Summary | Train MSE (x10^-2): 73.2793 | Val MSE (x10^-2): 18.3734 | Time: 43.07s
2025-07-17 19:05:32,819 - logger.py:50 - Epoch: [283][0/6]	Total Loss: 0.73953	Main MSE (x10^-2): 73.9532	LR: 1.61e-04	EMPP_Raw: 1.45826
2025-07-17 19:05:52,107 - logger.py:50 - Epoch: [283][5/6]	Total Loss: 0.73777	Main MSE (x10^-2): 73.7771	LR: 1.61e-04	EMPP_Raw: 1.45355
2025-07-17 19:05:52,146 - logger.py:50 - Epoch 283 Training Summary: Avg Total Loss: 0.73777, Avg Main MSE: 0.73777, Time: 23.40s
2025-07-17 19:06:11,698 - logger.py:50 - Epoch 283 Summary | Train MSE (x10^-2): 73.7771 | Val MSE (x10^-2): 18.3478 | Time: 42.96s
2025-07-17 19:06:15,806 - logger.py:50 - Epoch: [284][0/6]	Total Loss: 0.74826	Main MSE (x10^-2): 74.8261	LR: 1.59e-04	EMPP_Raw: 1.47392
2025-07-17 19:06:35,141 - logger.py:50 - Epoch: [284][5/6]	Total Loss: 0.74178	Main MSE (x10^-2): 74.1780	LR: 1.59e-04	EMPP_Raw: 1.46121
2025-07-17 19:06:35,184 - logger.py:50 - Epoch 284 Training Summary: Avg Total Loss: 0.74178, Avg Main MSE: 0.74178, Time: 23.48s
2025-07-17 19:06:54,688 - logger.py:50 - Epoch 284 Summary | Train MSE (x10^-2): 74.1780 | Val MSE (x10^-2): 18.5085 | Time: 42.98s
2025-07-17 19:06:59,140 - logger.py:50 - Epoch: [285][0/6]	Total Loss: 0.75510	Main MSE (x10^-2): 75.5096	LR: 1.58e-04	EMPP_Raw: 1.48871
2025-07-17 19:07:18,456 - logger.py:50 - Epoch: [285][5/6]	Total Loss: 0.74711	Main MSE (x10^-2): 74.7114	LR: 1.58e-04	EMPP_Raw: 1.47221
2025-07-17 19:07:18,501 - logger.py:50 - Epoch 285 Training Summary: Avg Total Loss: 0.74711, Avg Main MSE: 0.74711, Time: 23.80s
2025-07-17 19:07:38,179 - logger.py:50 - Epoch 285 Summary | Train MSE (x10^-2): 74.7114 | Val MSE (x10^-2): 18.4920 | Time: 43.49s
2025-07-17 19:07:42,307 - logger.py:50 - Epoch: [286][0/6]	Total Loss: 0.71945	Main MSE (x10^-2): 71.9447	LR: 1.57e-04	EMPP_Raw: 1.41525
2025-07-17 19:08:01,529 - logger.py:50 - Epoch: [286][5/6]	Total Loss: 0.73556	Main MSE (x10^-2): 73.5557	LR: 1.57e-04	EMPP_Raw: 1.44856
2025-07-17 19:08:01,571 - logger.py:50 - Epoch 286 Training Summary: Avg Total Loss: 0.73556, Avg Main MSE: 0.73556, Time: 23.38s
2025-07-17 19:08:21,145 - logger.py:50 - Epoch 286 Summary | Train MSE (x10^-2): 73.5557 | Val MSE (x10^-2): 18.2002 | Time: 42.96s
2025-07-17 19:08:25,196 - logger.py:50 - Epoch: [287][0/6]	Total Loss: 0.74471	Main MSE (x10^-2): 74.4713	LR: 1.56e-04	EMPP_Raw: 1.46534
2025-07-17 19:08:44,390 - logger.py:50 - Epoch: [287][5/6]	Total Loss: 0.73959	Main MSE (x10^-2): 73.9593	LR: 1.56e-04	EMPP_Raw: 1.45690
2025-07-17 19:08:44,431 - logger.py:50 - Epoch 287 Training Summary: Avg Total Loss: 0.73959, Avg Main MSE: 0.73959, Time: 23.28s
2025-07-17 19:09:03,998 - logger.py:50 - Epoch 287 Summary | Train MSE (x10^-2): 73.9593 | Val MSE (x10^-2): 18.4255 | Time: 42.85s
2025-07-17 19:09:08,053 - logger.py:50 - Epoch: [288][0/6]	Total Loss: 0.72467	Main MSE (x10^-2): 72.4669	LR: 1.55e-04	EMPP_Raw: 1.42558
2025-07-17 19:09:27,283 - logger.py:50 - Epoch: [288][5/6]	Total Loss: 0.72680	Main MSE (x10^-2): 72.6796	LR: 1.55e-04	EMPP_Raw: 1.43130
2025-07-17 19:09:27,326 - logger.py:50 - Epoch 288 Training Summary: Avg Total Loss: 0.72680, Avg Main MSE: 0.72680, Time: 23.32s
2025-07-17 19:09:46,966 - logger.py:50 - Epoch 288 Summary | Train MSE (x10^-2): 72.6796 | Val MSE (x10^-2): 18.3196 | Time: 42.97s
2025-07-17 19:09:51,081 - logger.py:50 - Epoch: [289][0/6]	Total Loss: 0.75802	Main MSE (x10^-2): 75.8022	LR: 1.53e-04	EMPP_Raw: 1.49516
2025-07-17 19:10:10,407 - logger.py:50 - Epoch: [289][5/6]	Total Loss: 0.73145	Main MSE (x10^-2): 73.1455	LR: 1.53e-04	EMPP_Raw: 1.44129
2025-07-17 19:10:10,452 - logger.py:50 - Epoch 289 Training Summary: Avg Total Loss: 0.73145, Avg Main MSE: 0.73145, Time: 23.48s
2025-07-17 19:10:30,064 - logger.py:50 - Epoch 289 Summary | Train MSE (x10^-2): 73.1455 | Val MSE (x10^-2): 18.2634 | Time: 43.09s
2025-07-17 19:10:34,138 - logger.py:50 - Epoch: [290][0/6]	Total Loss: 0.74477	Main MSE (x10^-2): 74.4768	LR: 1.52e-04	EMPP_Raw: 1.46955
2025-07-17 19:10:53,429 - logger.py:50 - Epoch: [290][5/6]	Total Loss: 0.73255	Main MSE (x10^-2): 73.2547	LR: 1.52e-04	EMPP_Raw: 1.44366
2025-07-17 19:10:53,467 - logger.py:50 - Epoch 290 Training Summary: Avg Total Loss: 0.73255, Avg Main MSE: 0.73255, Time: 23.39s
2025-07-17 19:11:13,071 - logger.py:50 - Epoch 290 Summary | Train MSE (x10^-2): 73.2547 | Val MSE (x10^-2): 18.3171 | Time: 43.00s
2025-07-17 19:11:17,144 - logger.py:50 - Epoch: [291][0/6]	Total Loss: 0.73139	Main MSE (x10^-2): 73.1395	LR: 1.51e-04	EMPP_Raw: 1.44228
2025-07-17 19:11:36,362 - logger.py:50 - Epoch: [291][5/6]	Total Loss: 0.73064	Main MSE (x10^-2): 73.0635	LR: 1.51e-04	EMPP_Raw: 1.43955
2025-07-17 19:11:36,407 - logger.py:50 - Epoch 291 Training Summary: Avg Total Loss: 0.73064, Avg Main MSE: 0.73064, Time: 23.33s
2025-07-17 19:11:55,922 - logger.py:50 - Epoch 291 Summary | Train MSE (x10^-2): 73.0635 | Val MSE (x10^-2): 18.3604 | Time: 42.85s
2025-07-17 19:11:59,989 - logger.py:50 - Epoch: [292][0/6]	Total Loss: 0.72801	Main MSE (x10^-2): 72.8005	LR: 1.50e-04	EMPP_Raw: 1.43520
2025-07-17 19:12:19,203 - logger.py:50 - Epoch: [292][5/6]	Total Loss: 0.73101	Main MSE (x10^-2): 73.1009	LR: 1.50e-04	EMPP_Raw: 1.44074
2025-07-17 19:12:19,243 - logger.py:50 - Epoch 292 Training Summary: Avg Total Loss: 0.73101, Avg Main MSE: 0.73101, Time: 23.31s
2025-07-17 19:12:38,753 - logger.py:50 - Epoch 292 Summary | Train MSE (x10^-2): 73.1009 | Val MSE (x10^-2): 18.1286 | Time: 42.83s
2025-07-17 19:12:42,852 - logger.py:50 - Epoch: [293][0/6]	Total Loss: 0.71561	Main MSE (x10^-2): 71.5607	LR: 1.48e-04	EMPP_Raw: 1.40974
2025-07-17 19:13:02,178 - logger.py:50 - Epoch: [293][5/6]	Total Loss: 0.73629	Main MSE (x10^-2): 73.6289	LR: 1.48e-04	EMPP_Raw: 1.45057
2025-07-17 19:13:02,222 - logger.py:50 - Epoch 293 Training Summary: Avg Total Loss: 0.73629, Avg Main MSE: 0.73629, Time: 23.46s
2025-07-17 19:13:21,828 - logger.py:50 - Epoch 293 Summary | Train MSE (x10^-2): 73.6289 | Val MSE (x10^-2): 18.1532 | Time: 43.07s
2025-07-17 19:13:25,970 - logger.py:50 - Epoch: [294][0/6]	Total Loss: 0.71846	Main MSE (x10^-2): 71.8455	LR: 1.47e-04	EMPP_Raw: 1.41559
2025-07-17 19:13:45,210 - logger.py:50 - Epoch: [294][5/6]	Total Loss: 0.73248	Main MSE (x10^-2): 73.2475	LR: 1.47e-04	EMPP_Raw: 1.44294
2025-07-17 19:13:45,252 - logger.py:50 - Epoch 294 Training Summary: Avg Total Loss: 0.73248, Avg Main MSE: 0.73248, Time: 23.41s
2025-07-17 19:14:04,770 - logger.py:50 - Epoch 294 Summary | Train MSE (x10^-2): 73.2475 | Val MSE (x10^-2): 18.3414 | Time: 42.94s
2025-07-17 19:14:08,849 - logger.py:50 - Epoch: [295][0/6]	Total Loss: 0.74563	Main MSE (x10^-2): 74.5631	LR: 1.46e-04	EMPP_Raw: 1.47019
2025-07-17 19:14:28,114 - logger.py:50 - Epoch: [295][5/6]	Total Loss: 0.74091	Main MSE (x10^-2): 74.0906	LR: 1.46e-04	EMPP_Raw: 1.46057
2025-07-17 19:14:28,156 - logger.py:50 - Epoch 295 Training Summary: Avg Total Loss: 0.74091, Avg Main MSE: 0.74091, Time: 23.38s
2025-07-17 19:14:47,765 - logger.py:50 - Epoch 295 Summary | Train MSE (x10^-2): 74.0906 | Val MSE (x10^-2): 18.1965 | Time: 42.99s
2025-07-17 19:14:51,835 - logger.py:50 - Epoch: [296][0/6]	Total Loss: 0.72815	Main MSE (x10^-2): 72.8153	LR: 1.45e-04	EMPP_Raw: 1.43510
2025-07-17 19:15:10,989 - logger.py:50 - Epoch: [296][5/6]	Total Loss: 0.73696	Main MSE (x10^-2): 73.6956	LR: 1.45e-04	EMPP_Raw: 1.45226
2025-07-17 19:15:11,035 - logger.py:50 - Epoch 296 Training Summary: Avg Total Loss: 0.73696, Avg Main MSE: 0.73696, Time: 23.26s
2025-07-17 19:15:30,666 - logger.py:50 - Epoch 296 Summary | Train MSE (x10^-2): 73.6956 | Val MSE (x10^-2): 18.4206 | Time: 42.90s
2025-07-17 19:15:34,785 - logger.py:50 - Epoch: [297][0/6]	Total Loss: 0.71195	Main MSE (x10^-2): 71.1946	LR: 1.44e-04	EMPP_Raw: 1.40282
2025-07-17 19:15:54,015 - logger.py:50 - Epoch: [297][5/6]	Total Loss: 0.73619	Main MSE (x10^-2): 73.6193	LR: 1.44e-04	EMPP_Raw: 1.45033
2025-07-17 19:15:54,057 - logger.py:50 - Epoch 297 Training Summary: Avg Total Loss: 0.73619, Avg Main MSE: 0.73619, Time: 23.38s
2025-07-17 19:16:13,612 - logger.py:50 - Epoch 297 Summary | Train MSE (x10^-2): 73.6193 | Val MSE (x10^-2): 18.3822 | Time: 42.94s
2025-07-17 19:16:17,683 - logger.py:50 - Epoch: [298][0/6]	Total Loss: 0.73508	Main MSE (x10^-2): 73.5083	LR: 1.42e-04	EMPP_Raw: 1.44757
2025-07-17 19:16:36,979 - logger.py:50 - Epoch: [298][5/6]	Total Loss: 0.73240	Main MSE (x10^-2): 73.2400	LR: 1.42e-04	EMPP_Raw: 1.44332
2025-07-17 19:16:37,025 - logger.py:50 - Epoch 298 Training Summary: Avg Total Loss: 0.73240, Avg Main MSE: 0.73240, Time: 23.40s
2025-07-17 19:16:56,668 - logger.py:50 - Epoch 298 Summary | Train MSE (x10^-2): 73.2400 | Val MSE (x10^-2): 18.2124 | Time: 43.05s
2025-07-17 19:17:00,827 - logger.py:50 - Epoch: [299][0/6]	Total Loss: 0.76757	Main MSE (x10^-2): 76.7574	LR: 1.41e-04	EMPP_Raw: 1.51440
2025-07-17 19:17:20,156 - logger.py:50 - Epoch: [299][5/6]	Total Loss: 0.74360	Main MSE (x10^-2): 74.3595	LR: 1.41e-04	EMPP_Raw: 1.46572
2025-07-17 19:17:20,199 - logger.py:50 - Epoch 299 Training Summary: Avg Total Loss: 0.74360, Avg Main MSE: 0.74360, Time: 23.52s
2025-07-17 19:17:39,777 - logger.py:50 - Epoch 299 Summary | Train MSE (x10^-2): 74.3595 | Val MSE (x10^-2): 18.2427 | Time: 43.10s
2025-07-17 19:17:43,840 - logger.py:50 - Epoch: [300][0/6]	Total Loss: 0.70947	Main MSE (x10^-2): 70.9469	LR: 1.40e-04	EMPP_Raw: 1.39829
2025-07-17 19:18:03,073 - logger.py:50 - Epoch: [300][5/6]	Total Loss: 0.73250	Main MSE (x10^-2): 73.2499	LR: 1.40e-04	EMPP_Raw: 1.44435
2025-07-17 19:18:03,113 - logger.py:50 - Epoch 300 Training Summary: Avg Total Loss: 0.73250, Avg Main MSE: 0.73250, Time: 23.33s
2025-07-17 19:18:22,606 - logger.py:50 - Epoch 300 Summary | Train MSE (x10^-2): 73.2499 | Val MSE (x10^-2): 18.4080 | Time: 42.82s
2025-07-17 19:18:26,656 - logger.py:50 - Epoch: [301][0/6]	Total Loss: 0.72604	Main MSE (x10^-2): 72.6042	LR: 1.39e-04	EMPP_Raw: 1.43196
2025-07-17 19:18:45,949 - logger.py:50 - Epoch: [301][5/6]	Total Loss: 0.73325	Main MSE (x10^-2): 73.3253	LR: 1.39e-04	EMPP_Raw: 1.44564
2025-07-17 19:18:45,993 - logger.py:50 - Epoch 301 Training Summary: Avg Total Loss: 0.73325, Avg Main MSE: 0.73325, Time: 23.38s
2025-07-17 19:19:05,541 - logger.py:50 - Epoch 301 Summary | Train MSE (x10^-2): 73.3253 | Val MSE (x10^-2): 18.2523 | Time: 42.93s
2025-07-17 19:19:09,698 - logger.py:50 - Epoch: [302][0/6]	Total Loss: 0.74394	Main MSE (x10^-2): 74.3938	LR: 1.38e-04	EMPP_Raw: 1.46659
2025-07-17 19:19:28,974 - logger.py:50 - Epoch: [302][5/6]	Total Loss: 0.73121	Main MSE (x10^-2): 73.1207	LR: 1.38e-04	EMPP_Raw: 1.44133
2025-07-17 19:19:29,014 - logger.py:50 - Epoch 302 Training Summary: Avg Total Loss: 0.73121, Avg Main MSE: 0.73121, Time: 23.47s
2025-07-17 19:19:48,567 - logger.py:50 - Epoch 302 Summary | Train MSE (x10^-2): 73.1207 | Val MSE (x10^-2): 18.4399 | Time: 43.02s
2025-07-17 19:19:52,670 - logger.py:50 - Epoch: [303][0/6]	Total Loss: 0.75413	Main MSE (x10^-2): 75.4130	LR: 1.36e-04	EMPP_Raw: 1.48701
2025-07-17 19:20:12,000 - logger.py:50 - Epoch: [303][5/6]	Total Loss: 0.73955	Main MSE (x10^-2): 73.9553	LR: 1.36e-04	EMPP_Raw: 1.45849
2025-07-17 19:20:12,055 - logger.py:50 - Epoch 303 Training Summary: Avg Total Loss: 0.73955, Avg Main MSE: 0.73955, Time: 23.48s
2025-07-17 19:20:31,512 - logger.py:50 - Epoch 303 Summary | Train MSE (x10^-2): 73.9553 | Val MSE (x10^-2): 18.3800 | Time: 42.94s
2025-07-17 19:20:35,572 - logger.py:50 - Epoch: [304][0/6]	Total Loss: 0.70970	Main MSE (x10^-2): 70.9699	LR: 1.35e-04	EMPP_Raw: 1.39928
2025-07-17 19:20:54,855 - logger.py:50 - Epoch: [304][5/6]	Total Loss: 0.73500	Main MSE (x10^-2): 73.5005	LR: 1.35e-04	EMPP_Raw: 1.44886
2025-07-17 19:20:54,897 - logger.py:50 - Epoch 304 Training Summary: Avg Total Loss: 0.73500, Avg Main MSE: 0.73500, Time: 23.38s
2025-07-17 19:21:14,381 - logger.py:50 - Epoch 304 Summary | Train MSE (x10^-2): 73.5005 | Val MSE (x10^-2): 18.2297 | Time: 42.86s
2025-07-17 19:21:18,467 - logger.py:50 - Epoch: [305][0/6]	Total Loss: 0.76101	Main MSE (x10^-2): 76.1007	LR: 1.34e-04	EMPP_Raw: 1.50062
2025-07-17 19:21:37,756 - logger.py:50 - Epoch: [305][5/6]	Total Loss: 0.74189	Main MSE (x10^-2): 74.1888	LR: 1.34e-04	EMPP_Raw: 1.46265
2025-07-17 19:21:37,799 - logger.py:50 - Epoch 305 Training Summary: Avg Total Loss: 0.74189, Avg Main MSE: 0.74189, Time: 23.41s
2025-07-17 19:21:57,310 - logger.py:50 - Epoch 305 Summary | Train MSE (x10^-2): 74.1888 | Val MSE (x10^-2): 18.2493 | Time: 42.92s
2025-07-17 19:22:01,410 - logger.py:50 - Epoch: [306][0/6]	Total Loss: 0.75896	Main MSE (x10^-2): 75.8957	LR: 1.33e-04	EMPP_Raw: 1.49662
2025-07-17 19:22:20,659 - logger.py:50 - Epoch: [306][5/6]	Total Loss: 0.73810	Main MSE (x10^-2): 73.8105	LR: 1.33e-04	EMPP_Raw: 1.45554
2025-07-17 19:22:20,699 - logger.py:50 - Epoch 306 Training Summary: Avg Total Loss: 0.73810, Avg Main MSE: 0.73810, Time: 23.38s
2025-07-17 19:22:40,256 - logger.py:50 - Epoch 306 Summary | Train MSE (x10^-2): 73.8105 | Val MSE (x10^-2): 18.6092 | Time: 42.94s
2025-07-17 19:22:44,349 - logger.py:50 - Epoch: [307][0/6]	Total Loss: 0.75161	Main MSE (x10^-2): 75.1610	LR: 1.32e-04	EMPP_Raw: 1.48282
2025-07-17 19:23:03,607 - logger.py:50 - Epoch: [307][5/6]	Total Loss: 0.74485	Main MSE (x10^-2): 74.4854	LR: 1.32e-04	EMPP_Raw: 1.46882
2025-07-17 19:23:03,661 - logger.py:50 - Epoch 307 Training Summary: Avg Total Loss: 0.74485, Avg Main MSE: 0.74485, Time: 23.40s
2025-07-17 19:23:23,273 - logger.py:50 - Epoch 307 Summary | Train MSE (x10^-2): 74.4854 | Val MSE (x10^-2): 18.6107 | Time: 43.01s
2025-07-17 19:23:27,379 - logger.py:50 - Epoch: [308][0/6]	Total Loss: 0.75832	Main MSE (x10^-2): 75.8322	LR: 1.31e-04	EMPP_Raw: 1.49487
2025-07-17 19:23:46,748 - logger.py:50 - Epoch: [308][5/6]	Total Loss: 0.74139	Main MSE (x10^-2): 74.1389	LR: 1.31e-04	EMPP_Raw: 1.46215
2025-07-17 19:23:46,789 - logger.py:50 - Epoch 308 Training Summary: Avg Total Loss: 0.74139, Avg Main MSE: 0.74139, Time: 23.51s
2025-07-17 19:24:06,675 - logger.py:50 - Epoch 308 Summary | Train MSE (x10^-2): 74.1389 | Val MSE (x10^-2): 18.2380 | Time: 43.40s
2025-07-17 19:24:10,823 - logger.py:50 - Epoch: [309][0/6]	Total Loss: 0.71459	Main MSE (x10^-2): 71.4586	LR: 1.29e-04	EMPP_Raw: 1.40848
2025-07-17 19:24:30,067 - logger.py:50 - Epoch: [309][5/6]	Total Loss: 0.72608	Main MSE (x10^-2): 72.6077	LR: 1.29e-04	EMPP_Raw: 1.43126
2025-07-17 19:24:30,126 - logger.py:50 - Epoch 309 Training Summary: Avg Total Loss: 0.72608, Avg Main MSE: 0.72608, Time: 23.45s
2025-07-17 19:24:50,017 - logger.py:50 - Epoch 309 Summary | Train MSE (x10^-2): 72.6077 | Val MSE (x10^-2): 18.2996 | Time: 43.34s
2025-07-17 19:24:54,122 - logger.py:50 - Epoch: [310][0/6]	Total Loss: 0.73095	Main MSE (x10^-2): 73.0945	LR: 1.28e-04	EMPP_Raw: 1.44122
2025-07-17 19:25:13,496 - logger.py:50 - Epoch: [310][5/6]	Total Loss: 0.73565	Main MSE (x10^-2): 73.5654	LR: 1.28e-04	EMPP_Raw: 1.45129
2025-07-17 19:25:13,539 - logger.py:50 - Epoch 310 Training Summary: Avg Total Loss: 0.73565, Avg Main MSE: 0.73565, Time: 23.51s
2025-07-17 19:25:33,268 - logger.py:50 - Epoch 310 Summary | Train MSE (x10^-2): 73.5654 | Val MSE (x10^-2): 18.1975 | Time: 43.25s
2025-07-17 19:25:37,364 - logger.py:50 - Epoch: [311][0/6]	Total Loss: 0.74357	Main MSE (x10^-2): 74.3574	LR: 1.27e-04	EMPP_Raw: 1.46710
2025-07-17 19:25:56,630 - logger.py:50 - Epoch: [311][5/6]	Total Loss: 0.73264	Main MSE (x10^-2): 73.2639	LR: 1.27e-04	EMPP_Raw: 1.44491
2025-07-17 19:25:56,672 - logger.py:50 - Epoch 311 Training Summary: Avg Total Loss: 0.73264, Avg Main MSE: 0.73264, Time: 23.40s
2025-07-17 19:26:16,262 - logger.py:50 - Epoch 311 Summary | Train MSE (x10^-2): 73.2639 | Val MSE (x10^-2): 18.2994 | Time: 42.99s
2025-07-17 19:26:20,363 - logger.py:50 - Epoch: [312][0/6]	Total Loss: 0.70926	Main MSE (x10^-2): 70.9263	LR: 1.26e-04	EMPP_Raw: 1.39729
2025-07-17 19:26:39,713 - logger.py:50 - Epoch: [312][5/6]	Total Loss: 0.72500	Main MSE (x10^-2): 72.5004	LR: 1.26e-04	EMPP_Raw: 1.42927
2025-07-17 19:26:39,754 - logger.py:50 - Epoch 312 Training Summary: Avg Total Loss: 0.72500, Avg Main MSE: 0.72500, Time: 23.48s
2025-07-17 19:26:59,459 - logger.py:50 - Epoch 312 Summary | Train MSE (x10^-2): 72.5004 | Val MSE (x10^-2): 18.3408 | Time: 43.19s
2025-07-17 19:27:03,537 - logger.py:50 - Epoch: [313][0/6]	Total Loss: 0.72577	Main MSE (x10^-2): 72.5767	LR: 1.25e-04	EMPP_Raw: 1.43167
2025-07-17 19:27:22,796 - logger.py:50 - Epoch: [313][5/6]	Total Loss: 0.72429	Main MSE (x10^-2): 72.4295	LR: 1.25e-04	EMPP_Raw: 1.42819
2025-07-17 19:27:22,839 - logger.py:50 - Epoch 313 Training Summary: Avg Total Loss: 0.72429, Avg Main MSE: 0.72429, Time: 23.37s
2025-07-17 19:27:42,380 - logger.py:50 - Epoch 313 Summary | Train MSE (x10^-2): 72.4295 | Val MSE (x10^-2): 18.2973 | Time: 42.92s
2025-07-17 19:27:46,463 - logger.py:50 - Epoch: [314][0/6]	Total Loss: 0.73765	Main MSE (x10^-2): 73.7655	LR: 1.24e-04	EMPP_Raw: 1.45549
2025-07-17 19:28:05,828 - logger.py:50 - Epoch: [314][5/6]	Total Loss: 0.74050	Main MSE (x10^-2): 74.0495	LR: 1.24e-04	EMPP_Raw: 1.46064
2025-07-17 19:28:05,868 - logger.py:50 - Epoch 314 Training Summary: Avg Total Loss: 0.74050, Avg Main MSE: 0.74050, Time: 23.48s
2025-07-17 19:28:25,448 - logger.py:50 - Epoch 314 Summary | Train MSE (x10^-2): 74.0495 | Val MSE (x10^-2): 18.3946 | Time: 43.06s
2025-07-17 19:28:29,540 - logger.py:50 - Epoch: [315][0/6]	Total Loss: 0.73345	Main MSE (x10^-2): 73.3448	LR: 1.22e-04	EMPP_Raw: 1.44667
2025-07-17 19:28:48,816 - logger.py:50 - Epoch: [315][5/6]	Total Loss: 0.72942	Main MSE (x10^-2): 72.9417	LR: 1.22e-04	EMPP_Raw: 1.43848
2025-07-17 19:28:48,857 - logger.py:50 - Epoch 315 Training Summary: Avg Total Loss: 0.72942, Avg Main MSE: 0.72942, Time: 23.40s
2025-07-17 19:29:08,536 - logger.py:50 - Epoch 315 Summary | Train MSE (x10^-2): 72.9417 | Val MSE (x10^-2): 18.3250 | Time: 43.08s
2025-07-17 19:29:12,698 - logger.py:50 - Epoch: [316][0/6]	Total Loss: 0.71948	Main MSE (x10^-2): 71.9480	LR: 1.21e-04	EMPP_Raw: 1.41846
2025-07-17 19:29:32,094 - logger.py:50 - Epoch: [316][5/6]	Total Loss: 0.73037	Main MSE (x10^-2): 73.0369	LR: 1.21e-04	EMPP_Raw: 1.44071
2025-07-17 19:29:32,145 - logger.py:50 - Epoch 316 Training Summary: Avg Total Loss: 0.73037, Avg Main MSE: 0.73037, Time: 23.60s
2025-07-17 19:29:51,821 - logger.py:50 - Epoch 316 Summary | Train MSE (x10^-2): 73.0369 | Val MSE (x10^-2): 18.3862 | Time: 43.28s
2025-07-17 19:29:55,988 - logger.py:50 - Epoch: [317][0/6]	Total Loss: 0.72883	Main MSE (x10^-2): 72.8828	LR: 1.20e-04	EMPP_Raw: 1.43889
2025-07-17 19:30:15,321 - logger.py:50 - Epoch: [317][5/6]	Total Loss: 0.73721	Main MSE (x10^-2): 73.7207	LR: 1.20e-04	EMPP_Raw: 1.45444
2025-07-17 19:30:15,362 - logger.py:50 - Epoch 317 Training Summary: Avg Total Loss: 0.73721, Avg Main MSE: 0.73721, Time: 23.53s
2025-07-17 19:30:35,058 - logger.py:50 - Epoch 317 Summary | Train MSE (x10^-2): 73.7207 | Val MSE (x10^-2): 18.3118 | Time: 43.23s
2025-07-17 19:30:39,192 - logger.py:50 - Epoch: [318][0/6]	Total Loss: 0.72708	Main MSE (x10^-2): 72.7085	LR: 1.19e-04	EMPP_Raw: 1.43430
2025-07-17 19:30:58,530 - logger.py:50 - Epoch: [318][5/6]	Total Loss: 0.73524	Main MSE (x10^-2): 73.5240	LR: 1.19e-04	EMPP_Raw: 1.45033
2025-07-17 19:30:58,569 - logger.py:50 - Epoch 318 Training Summary: Avg Total Loss: 0.73524, Avg Main MSE: 0.73524, Time: 23.50s
2025-07-17 19:31:18,305 - logger.py:50 - Epoch 318 Summary | Train MSE (x10^-2): 73.5240 | Val MSE (x10^-2): 18.3820 | Time: 43.24s
2025-07-17 19:31:22,451 - logger.py:50 - Epoch: [319][0/6]	Total Loss: 0.72115	Main MSE (x10^-2): 72.1151	LR: 1.18e-04	EMPP_Raw: 1.42266
2025-07-17 19:31:41,856 - logger.py:50 - Epoch: [319][5/6]	Total Loss: 0.71954	Main MSE (x10^-2): 71.9538	LR: 1.18e-04	EMPP_Raw: 1.41945
2025-07-17 19:31:41,896 - logger.py:50 - Epoch 319 Training Summary: Avg Total Loss: 0.71954, Avg Main MSE: 0.71954, Time: 23.58s
2025-07-17 19:32:01,513 - logger.py:50 - Epoch 319 Summary | Train MSE (x10^-2): 71.9538 | Val MSE (x10^-2): 18.4174 | Time: 43.20s
2025-07-17 19:32:05,610 - logger.py:50 - Epoch: [320][0/6]	Total Loss: 0.71497	Main MSE (x10^-2): 71.4966	LR: 1.17e-04	EMPP_Raw: 1.40999
2025-07-17 19:32:25,063 - logger.py:50 - Epoch: [320][5/6]	Total Loss: 0.73843	Main MSE (x10^-2): 73.8428	LR: 1.17e-04	EMPP_Raw: 1.45695
2025-07-17 19:32:25,107 - logger.py:50 - Epoch 320 Training Summary: Avg Total Loss: 0.73843, Avg Main MSE: 0.73843, Time: 23.59s
2025-07-17 19:32:44,807 - logger.py:50 - Epoch 320 Summary | Train MSE (x10^-2): 73.8428 | Val MSE (x10^-2): 18.2146 | Time: 43.29s
2025-07-17 19:32:48,942 - logger.py:50 - Epoch: [321][0/6]	Total Loss: 0.74368	Main MSE (x10^-2): 74.3678	LR: 1.16e-04	EMPP_Raw: 1.46723
2025-07-17 19:33:08,290 - logger.py:50 - Epoch: [321][5/6]	Total Loss: 0.73495	Main MSE (x10^-2): 73.4947	LR: 1.16e-04	EMPP_Raw: 1.45013
2025-07-17 19:33:08,329 - logger.py:50 - Epoch 321 Training Summary: Avg Total Loss: 0.73495, Avg Main MSE: 0.73495, Time: 23.51s
2025-07-17 19:33:27,889 - logger.py:50 - Epoch 321 Summary | Train MSE (x10^-2): 73.4947 | Val MSE (x10^-2): 18.3604 | Time: 43.08s
2025-07-17 19:33:31,976 - logger.py:50 - Epoch: [322][0/6]	Total Loss: 0.74518	Main MSE (x10^-2): 74.5185	LR: 1.14e-04	EMPP_Raw: 1.47047
2025-07-17 19:33:51,295 - logger.py:50 - Epoch: [322][5/6]	Total Loss: 0.74417	Main MSE (x10^-2): 74.4173	LR: 1.14e-04	EMPP_Raw: 1.46853
2025-07-17 19:33:51,336 - logger.py:50 - Epoch 322 Training Summary: Avg Total Loss: 0.74417, Avg Main MSE: 0.74417, Time: 23.44s
2025-07-17 19:34:10,946 - logger.py:50 - Epoch 322 Summary | Train MSE (x10^-2): 74.4173 | Val MSE (x10^-2): 18.3612 | Time: 43.05s
2025-07-17 19:34:15,113 - logger.py:50 - Epoch: [323][0/6]	Total Loss: 0.72075	Main MSE (x10^-2): 72.0752	LR: 1.13e-04	EMPP_Raw: 1.42119
2025-07-17 19:34:34,439 - logger.py:50 - Epoch: [323][5/6]	Total Loss: 0.73494	Main MSE (x10^-2): 73.4945	LR: 1.13e-04	EMPP_Raw: 1.44953
2025-07-17 19:34:34,478 - logger.py:50 - Epoch 323 Training Summary: Avg Total Loss: 0.73494, Avg Main MSE: 0.73494, Time: 23.52s
2025-07-17 19:34:54,149 - logger.py:50 - Epoch 323 Summary | Train MSE (x10^-2): 73.4945 | Val MSE (x10^-2): 18.1429 | Time: 43.20s
2025-07-17 19:34:58,248 - logger.py:50 - Epoch: [324][0/6]	Total Loss: 0.72882	Main MSE (x10^-2): 72.8824	LR: 1.12e-04	EMPP_Raw: 1.43763
2025-07-17 19:35:17,557 - logger.py:50 - Epoch: [324][5/6]	Total Loss: 0.73502	Main MSE (x10^-2): 73.5023	LR: 1.12e-04	EMPP_Raw: 1.45032
2025-07-17 19:35:17,602 - logger.py:50 - Epoch 324 Training Summary: Avg Total Loss: 0.73502, Avg Main MSE: 0.73502, Time: 23.45s
2025-07-17 19:35:37,291 - logger.py:50 - Epoch 324 Summary | Train MSE (x10^-2): 73.5023 | Val MSE (x10^-2): 18.3225 | Time: 43.14s
2025-07-17 19:35:41,390 - logger.py:50 - Epoch: [325][0/6]	Total Loss: 0.74411	Main MSE (x10^-2): 74.4112	LR: 1.11e-04	EMPP_Raw: 1.46743
2025-07-17 19:36:00,712 - logger.py:50 - Epoch: [325][5/6]	Total Loss: 0.73054	Main MSE (x10^-2): 73.0544	LR: 1.11e-04	EMPP_Raw: 1.44099
2025-07-17 19:36:00,757 - logger.py:50 - Epoch 325 Training Summary: Avg Total Loss: 0.73054, Avg Main MSE: 0.73054, Time: 23.46s
2025-07-17 19:36:20,348 - logger.py:50 - Epoch 325 Summary | Train MSE (x10^-2): 73.0544 | Val MSE (x10^-2): 18.2065 | Time: 43.05s
2025-07-17 19:36:24,440 - logger.py:50 - Epoch: [326][0/6]	Total Loss: 0.72487	Main MSE (x10^-2): 72.4871	LR: 1.10e-04	EMPP_Raw: 1.43003
2025-07-17 19:36:43,730 - logger.py:50 - Epoch: [326][5/6]	Total Loss: 0.74073	Main MSE (x10^-2): 74.0735	LR: 1.10e-04	EMPP_Raw: 1.46173
2025-07-17 19:36:43,793 - logger.py:50 - Epoch 326 Training Summary: Avg Total Loss: 0.74073, Avg Main MSE: 0.74073, Time: 23.44s
2025-07-17 19:37:03,456 - logger.py:50 - Epoch 326 Summary | Train MSE (x10^-2): 74.0735 | Val MSE (x10^-2): 18.3783 | Time: 43.10s
2025-07-17 19:37:07,554 - logger.py:50 - Epoch: [327][0/6]	Total Loss: 0.74101	Main MSE (x10^-2): 74.1010	LR: 1.09e-04	EMPP_Raw: 1.46387
2025-07-17 19:37:26,788 - logger.py:50 - Epoch: [327][5/6]	Total Loss: 0.73765	Main MSE (x10^-2): 73.7650	LR: 1.09e-04	EMPP_Raw: 1.45627
2025-07-17 19:37:26,832 - logger.py:50 - Epoch 327 Training Summary: Avg Total Loss: 0.73765, Avg Main MSE: 0.73765, Time: 23.37s
2025-07-17 19:37:46,453 - logger.py:50 - Epoch 327 Summary | Train MSE (x10^-2): 73.7650 | Val MSE (x10^-2): 18.2453 | Time: 42.99s
2025-07-17 19:37:50,582 - logger.py:50 - Epoch: [328][0/6]	Total Loss: 0.74565	Main MSE (x10^-2): 74.5649	LR: 1.08e-04	EMPP_Raw: 1.47214
2025-07-17 19:38:09,825 - logger.py:50 - Epoch: [328][5/6]	Total Loss: 0.73959	Main MSE (x10^-2): 73.9590	LR: 1.08e-04	EMPP_Raw: 1.46015
2025-07-17 19:38:09,869 - logger.py:50 - Epoch 328 Training Summary: Avg Total Loss: 0.73959, Avg Main MSE: 0.73959, Time: 23.41s
2025-07-17 19:38:29,830 - logger.py:50 - Epoch 328 Summary | Train MSE (x10^-2): 73.9590 | Val MSE (x10^-2): 18.3206 | Time: 43.37s
2025-07-17 19:38:33,918 - logger.py:50 - Epoch: [329][0/6]	Total Loss: 0.74750	Main MSE (x10^-2): 74.7499	LR: 1.07e-04	EMPP_Raw: 1.47511
2025-07-17 19:38:53,226 - logger.py:50 - Epoch: [329][5/6]	Total Loss: 0.74450	Main MSE (x10^-2): 74.4500	LR: 1.07e-04	EMPP_Raw: 1.46964
2025-07-17 19:38:53,266 - logger.py:50 - Epoch 329 Training Summary: Avg Total Loss: 0.74450, Avg Main MSE: 0.74450, Time: 23.43s
2025-07-17 19:39:13,129 - logger.py:50 - Epoch 329 Summary | Train MSE (x10^-2): 74.4500 | Val MSE (x10^-2): 18.2504 | Time: 43.29s
2025-07-17 19:39:17,180 - logger.py:50 - Epoch: [330][0/6]	Total Loss: 0.74967	Main MSE (x10^-2): 74.9667	LR: 1.05e-04	EMPP_Raw: 1.48019
2025-07-17 19:39:36,493 - logger.py:50 - Epoch: [330][5/6]	Total Loss: 0.72621	Main MSE (x10^-2): 72.6208	LR: 1.05e-04	EMPP_Raw: 1.43320
2025-07-17 19:39:36,535 - logger.py:50 - Epoch 330 Training Summary: Avg Total Loss: 0.72621, Avg Main MSE: 0.72621, Time: 23.40s
2025-07-17 19:39:56,192 - logger.py:50 - Epoch 330 Summary | Train MSE (x10^-2): 72.6208 | Val MSE (x10^-2): 18.3667 | Time: 43.06s
2025-07-17 19:40:00,378 - logger.py:50 - Epoch: [331][0/6]	Total Loss: 0.72867	Main MSE (x10^-2): 72.8671	LR: 1.04e-04	EMPP_Raw: 1.43826
2025-07-17 19:40:19,841 - logger.py:50 - Epoch: [331][5/6]	Total Loss: 0.73395	Main MSE (x10^-2): 73.3949	LR: 1.04e-04	EMPP_Raw: 1.44878
2025-07-17 19:40:19,903 - logger.py:50 - Epoch 331 Training Summary: Avg Total Loss: 0.73395, Avg Main MSE: 0.73395, Time: 23.70s
2025-07-17 19:40:39,639 - logger.py:50 - Epoch 331 Summary | Train MSE (x10^-2): 73.3949 | Val MSE (x10^-2): 18.3944 | Time: 43.44s
2025-07-17 19:40:43,715 - logger.py:50 - Epoch: [332][0/6]	Total Loss: 0.72382	Main MSE (x10^-2): 72.3824	LR: 1.03e-04	EMPP_Raw: 1.42798
2025-07-17 19:41:03,057 - logger.py:50 - Epoch: [332][5/6]	Total Loss: 0.73247	Main MSE (x10^-2): 73.2468	LR: 1.03e-04	EMPP_Raw: 1.44591
2025-07-17 19:41:03,098 - logger.py:50 - Epoch 332 Training Summary: Avg Total Loss: 0.73247, Avg Main MSE: 0.73247, Time: 23.45s
2025-07-17 19:41:22,761 - logger.py:50 - Epoch 332 Summary | Train MSE (x10^-2): 73.2468 | Val MSE (x10^-2): 18.2995 | Time: 43.12s
2025-07-17 19:41:26,863 - logger.py:50 - Epoch: [333][0/6]	Total Loss: 0.71876	Main MSE (x10^-2): 71.8762	LR: 1.02e-04	EMPP_Raw: 1.41897
2025-07-17 19:41:46,098 - logger.py:50 - Epoch: [333][5/6]	Total Loss: 0.73275	Main MSE (x10^-2): 73.2752	LR: 1.02e-04	EMPP_Raw: 1.44650
2025-07-17 19:41:46,141 - logger.py:50 - Epoch 333 Training Summary: Avg Total Loss: 0.73275, Avg Main MSE: 0.73275, Time: 23.37s
2025-07-17 19:42:05,875 - logger.py:50 - Epoch 333 Summary | Train MSE (x10^-2): 73.2752 | Val MSE (x10^-2): 18.3053 | Time: 43.11s
2025-07-17 19:42:09,981 - logger.py:50 - Epoch: [334][0/6]	Total Loss: 0.71334	Main MSE (x10^-2): 71.3338	LR: 1.01e-04	EMPP_Raw: 1.40697
2025-07-17 19:42:29,226 - logger.py:50 - Epoch: [334][5/6]	Total Loss: 0.72345	Main MSE (x10^-2): 72.3448	LR: 1.01e-04	EMPP_Raw: 1.42746
2025-07-17 19:42:29,263 - logger.py:50 - Epoch 334 Training Summary: Avg Total Loss: 0.72345, Avg Main MSE: 0.72345, Time: 23.38s
2025-07-17 19:42:48,763 - logger.py:50 - Epoch 334 Summary | Train MSE (x10^-2): 72.3448 | Val MSE (x10^-2): 18.2756 | Time: 42.88s
2025-07-17 19:42:52,848 - logger.py:50 - Epoch: [335][0/6]	Total Loss: 0.72233	Main MSE (x10^-2): 72.2326	LR: 1.00e-04	EMPP_Raw: 1.42573
2025-07-17 19:43:12,234 - logger.py:50 - Epoch: [335][5/6]	Total Loss: 0.72378	Main MSE (x10^-2): 72.3775	LR: 1.00e-04	EMPP_Raw: 1.42845
2025-07-17 19:43:12,275 - logger.py:50 - Epoch 335 Training Summary: Avg Total Loss: 0.72378, Avg Main MSE: 0.72378, Time: 23.50s
2025-07-17 19:43:31,807 - logger.py:50 - Epoch 335 Summary | Train MSE (x10^-2): 72.3775 | Val MSE (x10^-2): 18.4632 | Time: 43.04s
2025-07-17 19:43:36,015 - logger.py:50 - Epoch: [336][0/6]	Total Loss: 0.74718	Main MSE (x10^-2): 74.7178	LR: 9.89e-05	EMPP_Raw: 1.47587
2025-07-17 19:43:55,598 - logger.py:50 - Epoch: [336][5/6]	Total Loss: 0.73722	Main MSE (x10^-2): 73.7215	LR: 9.89e-05	EMPP_Raw: 1.45517
2025-07-17 19:43:55,643 - logger.py:50 - Epoch 336 Training Summary: Avg Total Loss: 0.73722, Avg Main MSE: 0.73722, Time: 23.83s
2025-07-17 19:44:15,416 - logger.py:50 - Epoch 336 Summary | Train MSE (x10^-2): 73.7215 | Val MSE (x10^-2): 18.2813 | Time: 43.60s
2025-07-17 19:44:19,575 - logger.py:50 - Epoch: [337][0/6]	Total Loss: 0.73371	Main MSE (x10^-2): 73.3705	LR: 9.79e-05	EMPP_Raw: 1.44881
2025-07-17 19:44:38,924 - logger.py:50 - Epoch: [337][5/6]	Total Loss: 0.72240	Main MSE (x10^-2): 72.2401	LR: 9.79e-05	EMPP_Raw: 1.42591
2025-07-17 19:44:38,974 - logger.py:50 - Epoch 337 Training Summary: Avg Total Loss: 0.72240, Avg Main MSE: 0.72240, Time: 23.55s
2025-07-17 19:44:58,607 - logger.py:50 - Epoch 337 Summary | Train MSE (x10^-2): 72.2401 | Val MSE (x10^-2): 18.3119 | Time: 43.18s
2025-07-17 19:45:02,697 - logger.py:50 - Epoch: [338][0/6]	Total Loss: 0.73466	Main MSE (x10^-2): 73.4663	LR: 9.68e-05	EMPP_Raw: 1.44948
2025-07-17 19:45:22,126 - logger.py:50 - Epoch: [338][5/6]	Total Loss: 0.73780	Main MSE (x10^-2): 73.7801	LR: 9.68e-05	EMPP_Raw: 1.45630
2025-07-17 19:45:22,168 - logger.py:50 - Epoch 338 Training Summary: Avg Total Loss: 0.73780, Avg Main MSE: 0.73780, Time: 23.55s
2025-07-17 19:45:41,835 - logger.py:50 - Epoch 338 Summary | Train MSE (x10^-2): 73.7801 | Val MSE (x10^-2): 18.2897 | Time: 43.22s
2025-07-17 19:45:45,905 - logger.py:50 - Epoch: [339][0/6]	Total Loss: 0.72390	Main MSE (x10^-2): 72.3903	LR: 9.57e-05	EMPP_Raw: 1.42814
2025-07-17 19:46:05,221 - logger.py:50 - Epoch: [339][5/6]	Total Loss: 0.72273	Main MSE (x10^-2): 72.2732	LR: 9.57e-05	EMPP_Raw: 1.42647
2025-07-17 19:46:05,260 - logger.py:50 - Epoch 339 Training Summary: Avg Total Loss: 0.72273, Avg Main MSE: 0.72273, Time: 23.42s
2025-07-17 19:46:24,894 - logger.py:50 - Epoch 339 Summary | Train MSE (x10^-2): 72.2732 | Val MSE (x10^-2): 18.3514 | Time: 43.05s
2025-07-17 19:46:29,063 - logger.py:50 - Epoch: [340][0/6]	Total Loss: 0.72037	Main MSE (x10^-2): 72.0373	LR: 9.47e-05	EMPP_Raw: 1.42251
2025-07-17 19:46:48,545 - logger.py:50 - Epoch: [340][5/6]	Total Loss: 0.73545	Main MSE (x10^-2): 73.5447	LR: 9.47e-05	EMPP_Raw: 1.45175
2025-07-17 19:46:48,588 - logger.py:50 - Epoch 340 Training Summary: Avg Total Loss: 0.73545, Avg Main MSE: 0.73545, Time: 23.68s
2025-07-17 19:47:08,385 - logger.py:50 - Epoch 340 Summary | Train MSE (x10^-2): 73.5447 | Val MSE (x10^-2): 18.2574 | Time: 43.48s
2025-07-17 19:47:12,487 - logger.py:50 - Epoch: [341][0/6]	Total Loss: 0.73462	Main MSE (x10^-2): 73.4616	LR: 9.36e-05	EMPP_Raw: 1.45005
2025-07-17 19:47:31,809 - logger.py:50 - Epoch: [341][5/6]	Total Loss: 0.74321	Main MSE (x10^-2): 74.3214	LR: 9.36e-05	EMPP_Raw: 1.46736
2025-07-17 19:47:31,865 - logger.py:50 - Epoch 341 Training Summary: Avg Total Loss: 0.74321, Avg Main MSE: 0.74321, Time: 23.47s
2025-07-17 19:47:51,617 - logger.py:50 - Epoch 341 Summary | Train MSE (x10^-2): 74.3214 | Val MSE (x10^-2): 18.3932 | Time: 43.23s
2025-07-17 19:47:55,729 - logger.py:50 - Epoch: [342][0/6]	Total Loss: 0.70649	Main MSE (x10^-2): 70.6488	LR: 9.25e-05	EMPP_Raw: 1.39494
2025-07-17 19:48:15,120 - logger.py:50 - Epoch: [342][5/6]	Total Loss: 0.72724	Main MSE (x10^-2): 72.7243	LR: 9.25e-05	EMPP_Raw: 1.43534
2025-07-17 19:48:15,167 - logger.py:50 - Epoch 342 Training Summary: Avg Total Loss: 0.72724, Avg Main MSE: 0.72724, Time: 23.54s
2025-07-17 19:48:34,753 - logger.py:50 - Epoch 342 Summary | Train MSE (x10^-2): 72.7243 | Val MSE (x10^-2): 18.2405 | Time: 43.13s
2025-07-17 19:48:38,898 - logger.py:50 - Epoch: [343][0/6]	Total Loss: 0.73427	Main MSE (x10^-2): 73.4273	LR: 9.15e-05	EMPP_Raw: 1.44839
2025-07-17 19:48:58,269 - logger.py:50 - Epoch: [343][5/6]	Total Loss: 0.72516	Main MSE (x10^-2): 72.5155	LR: 9.15e-05	EMPP_Raw: 1.43089
2025-07-17 19:48:58,328 - logger.py:50 - Epoch 343 Training Summary: Avg Total Loss: 0.72516, Avg Main MSE: 0.72516, Time: 23.57s
2025-07-17 19:49:18,183 - logger.py:50 - Epoch 343 Summary | Train MSE (x10^-2): 72.5155 | Val MSE (x10^-2): 18.2088 | Time: 43.43s
2025-07-17 19:49:22,296 - logger.py:50 - Epoch: [344][0/6]	Total Loss: 0.72322	Main MSE (x10^-2): 72.3219	LR: 9.04e-05	EMPP_Raw: 1.42832
2025-07-17 19:49:41,569 - logger.py:50 - Epoch: [344][5/6]	Total Loss: 0.73837	Main MSE (x10^-2): 73.8370	LR: 9.04e-05	EMPP_Raw: 1.45783
2025-07-17 19:49:41,610 - logger.py:50 - Epoch 344 Training Summary: Avg Total Loss: 0.73837, Avg Main MSE: 0.73837, Time: 23.42s
2025-07-17 19:50:01,263 - logger.py:50 - Epoch 344 Summary | Train MSE (x10^-2): 73.8370 | Val MSE (x10^-2): 18.3294 | Time: 43.07s
2025-07-17 19:50:05,388 - logger.py:50 - Epoch: [345][0/6]	Total Loss: 0.72712	Main MSE (x10^-2): 72.7124	LR: 8.94e-05	EMPP_Raw: 1.43510
2025-07-17 19:50:24,756 - logger.py:50 - Epoch: [345][5/6]	Total Loss: 0.72026	Main MSE (x10^-2): 72.0259	LR: 8.94e-05	EMPP_Raw: 1.42187
2025-07-17 19:50:24,799 - logger.py:50 - Epoch 345 Training Summary: Avg Total Loss: 0.72026, Avg Main MSE: 0.72026, Time: 23.53s
2025-07-17 19:50:44,531 - logger.py:50 - Epoch 345 Summary | Train MSE (x10^-2): 72.0259 | Val MSE (x10^-2): 18.2633 | Time: 43.26s
2025-07-17 19:50:48,618 - logger.py:50 - Epoch: [346][0/6]	Total Loss: 0.73379	Main MSE (x10^-2): 73.3795	LR: 8.84e-05	EMPP_Raw: 1.44958
2025-07-17 19:51:08,013 - logger.py:50 - Epoch: [346][5/6]	Total Loss: 0.73077	Main MSE (x10^-2): 73.0772	LR: 8.84e-05	EMPP_Raw: 1.44268
2025-07-17 19:51:08,052 - logger.py:50 - Epoch 346 Training Summary: Avg Total Loss: 0.73077, Avg Main MSE: 0.73077, Time: 23.51s
2025-07-17 19:51:27,753 - logger.py:50 - Epoch 346 Summary | Train MSE (x10^-2): 73.0772 | Val MSE (x10^-2): 18.2083 | Time: 43.22s
2025-07-17 19:51:31,844 - logger.py:50 - Epoch: [347][0/6]	Total Loss: 0.74156	Main MSE (x10^-2): 74.1555	LR: 8.73e-05	EMPP_Raw: 1.46408
2025-07-17 19:51:51,284 - logger.py:50 - Epoch: [347][5/6]	Total Loss: 0.73563	Main MSE (x10^-2): 73.5627	LR: 8.73e-05	EMPP_Raw: 1.45247
2025-07-17 19:51:51,323 - logger.py:50 - Epoch 347 Training Summary: Avg Total Loss: 0.73563, Avg Main MSE: 0.73563, Time: 23.56s
2025-07-17 19:52:10,969 - logger.py:50 - Epoch 347 Summary | Train MSE (x10^-2): 73.5627 | Val MSE (x10^-2): 18.3456 | Time: 43.21s
2025-07-17 19:52:15,103 - logger.py:50 - Epoch: [348][0/6]	Total Loss: 0.73052	Main MSE (x10^-2): 73.0520	LR: 8.63e-05	EMPP_Raw: 1.44190
2025-07-17 19:52:34,450 - logger.py:50 - Epoch: [348][5/6]	Total Loss: 0.72809	Main MSE (x10^-2): 72.8095	LR: 8.63e-05	EMPP_Raw: 1.43734
2025-07-17 19:52:34,497 - logger.py:50 - Epoch 348 Training Summary: Avg Total Loss: 0.72809, Avg Main MSE: 0.72809, Time: 23.52s
2025-07-17 19:52:54,103 - logger.py:50 - Epoch 348 Summary | Train MSE (x10^-2): 72.8095 | Val MSE (x10^-2): 18.1540 | Time: 43.13s
2025-07-17 19:52:58,172 - logger.py:50 - Epoch: [349][0/6]	Total Loss: 0.74047	Main MSE (x10^-2): 74.0467	LR: 8.53e-05	EMPP_Raw: 1.46321
2025-07-17 19:53:17,543 - logger.py:50 - Epoch: [349][5/6]	Total Loss: 0.72896	Main MSE (x10^-2): 72.8959	LR: 8.53e-05	EMPP_Raw: 1.43922
2025-07-17 19:53:17,583 - logger.py:50 - Epoch 349 Training Summary: Avg Total Loss: 0.72896, Avg Main MSE: 0.72896, Time: 23.47s
2025-07-17 19:53:37,428 - logger.py:50 - Epoch 349 Summary | Train MSE (x10^-2): 72.8959 | Val MSE (x10^-2): 18.4555 | Time: 43.32s
2025-07-17 19:53:41,561 - logger.py:50 - Epoch: [350][0/6]	Total Loss: 0.72681	Main MSE (x10^-2): 72.6806	LR: 8.43e-05	EMPP_Raw: 1.43565
2025-07-17 19:54:01,111 - logger.py:50 - Epoch: [350][5/6]	Total Loss: 0.73473	Main MSE (x10^-2): 73.4735	LR: 8.43e-05	EMPP_Raw: 1.45084
2025-07-17 19:54:01,154 - logger.py:50 - Epoch 350 Training Summary: Avg Total Loss: 0.73473, Avg Main MSE: 0.73473, Time: 23.72s
2025-07-17 19:54:20,807 - logger.py:50 - Epoch 350 Summary | Train MSE (x10^-2): 73.4735 | Val MSE (x10^-2): 18.2526 | Time: 43.37s
2025-07-17 19:54:24,905 - logger.py:50 - Epoch: [351][0/6]	Total Loss: 0.73207	Main MSE (x10^-2): 73.2073	LR: 8.32e-05	EMPP_Raw: 1.44624
2025-07-17 19:54:44,281 - logger.py:50 - Epoch: [351][5/6]	Total Loss: 0.72529	Main MSE (x10^-2): 72.5293	LR: 8.32e-05	EMPP_Raw: 1.43182
2025-07-17 19:54:44,332 - logger.py:50 - Epoch 351 Training Summary: Avg Total Loss: 0.72529, Avg Main MSE: 0.72529, Time: 23.52s
2025-07-17 19:55:03,927 - logger.py:50 - Epoch 351 Summary | Train MSE (x10^-2): 72.5293 | Val MSE (x10^-2): 18.2537 | Time: 43.11s
2025-07-17 19:55:08,012 - logger.py:50 - Epoch: [352][0/6]	Total Loss: 0.71047	Main MSE (x10^-2): 71.0473	LR: 8.22e-05	EMPP_Raw: 1.40245
2025-07-17 19:55:27,264 - logger.py:50 - Epoch: [352][5/6]	Total Loss: 0.73429	Main MSE (x10^-2): 73.4287	LR: 8.22e-05	EMPP_Raw: 1.44995
2025-07-17 19:55:27,306 - logger.py:50 - Epoch 352 Training Summary: Avg Total Loss: 0.73429, Avg Main MSE: 0.73429, Time: 23.37s
2025-07-17 19:55:47,140 - logger.py:50 - Epoch 352 Summary | Train MSE (x10^-2): 73.4287 | Val MSE (x10^-2): 18.3916 | Time: 43.21s
2025-07-17 19:55:51,246 - logger.py:50 - Epoch: [353][0/6]	Total Loss: 0.72516	Main MSE (x10^-2): 72.5160	LR: 8.12e-05	EMPP_Raw: 1.43194
2025-07-17 19:56:10,600 - logger.py:50 - Epoch: [353][5/6]	Total Loss: 0.72651	Main MSE (x10^-2): 72.6515	LR: 8.12e-05	EMPP_Raw: 1.43472
2025-07-17 19:56:10,660 - logger.py:50 - Epoch 353 Training Summary: Avg Total Loss: 0.72651, Avg Main MSE: 0.72651, Time: 23.51s
2025-07-17 19:56:30,329 - logger.py:50 - Epoch 353 Summary | Train MSE (x10^-2): 72.6515 | Val MSE (x10^-2): 18.2378 | Time: 43.18s
2025-07-17 19:56:34,420 - logger.py:50 - Epoch: [354][0/6]	Total Loss: 0.73795	Main MSE (x10^-2): 73.7953	LR: 8.02e-05	EMPP_Raw: 1.45747
2025-07-17 19:56:53,834 - logger.py:50 - Epoch: [354][5/6]	Total Loss: 0.72500	Main MSE (x10^-2): 72.4996	LR: 8.02e-05	EMPP_Raw: 1.43181
2025-07-17 19:56:53,875 - logger.py:50 - Epoch 354 Training Summary: Avg Total Loss: 0.72500, Avg Main MSE: 0.72500, Time: 23.54s
2025-07-17 19:57:13,419 - logger.py:50 - Epoch 354 Summary | Train MSE (x10^-2): 72.4996 | Val MSE (x10^-2): 18.2686 | Time: 43.08s
2025-07-17 19:57:17,559 - logger.py:50 - Epoch: [355][0/6]	Total Loss: 0.74177	Main MSE (x10^-2): 74.1772	LR: 7.92e-05	EMPP_Raw: 1.46462
2025-07-17 19:57:36,857 - logger.py:50 - Epoch: [355][5/6]	Total Loss: 0.73035	Main MSE (x10^-2): 73.0348	LR: 7.92e-05	EMPP_Raw: 1.44230
2025-07-17 19:57:36,900 - logger.py:50 - Epoch 355 Training Summary: Avg Total Loss: 0.73035, Avg Main MSE: 0.73035, Time: 23.47s
2025-07-17 19:57:56,629 - logger.py:50 - Epoch 355 Summary | Train MSE (x10^-2): 73.0348 | Val MSE (x10^-2): 18.2826 | Time: 43.20s
2025-07-17 19:58:00,825 - logger.py:50 - Epoch: [356][0/6]	Total Loss: 0.73622	Main MSE (x10^-2): 73.6220	LR: 7.82e-05	EMPP_Raw: 1.45555
2025-07-17 19:58:20,143 - logger.py:50 - Epoch: [356][5/6]	Total Loss: 0.72472	Main MSE (x10^-2): 72.4723	LR: 7.82e-05	EMPP_Raw: 1.43140
2025-07-17 19:58:20,191 - logger.py:50 - Epoch 356 Training Summary: Avg Total Loss: 0.72472, Avg Main MSE: 0.72472, Time: 23.55s
2025-07-17 19:58:39,915 - logger.py:50 - Epoch 356 Summary | Train MSE (x10^-2): 72.4723 | Val MSE (x10^-2): 18.2054 | Time: 43.28s
2025-07-17 19:58:44,060 - logger.py:50 - Epoch: [357][0/6]	Total Loss: 0.74160	Main MSE (x10^-2): 74.1597	LR: 7.72e-05	EMPP_Raw: 1.46470
2025-07-17 19:59:03,730 - logger.py:50 - Epoch: [357][5/6]	Total Loss: 0.72297	Main MSE (x10^-2): 72.2968	LR: 7.72e-05	EMPP_Raw: 1.42759
2025-07-17 19:59:03,779 - logger.py:50 - Epoch 357 Training Summary: Avg Total Loss: 0.72297, Avg Main MSE: 0.72297, Time: 23.85s
2025-07-17 19:59:23,521 - logger.py:50 - Epoch 357 Summary | Train MSE (x10^-2): 72.2968 | Val MSE (x10^-2): 18.2943 | Time: 43.60s
2025-07-17 19:59:27,615 - logger.py:50 - Epoch: [358][0/6]	Total Loss: 0.72615	Main MSE (x10^-2): 72.6147	LR: 7.63e-05	EMPP_Raw: 1.43507
2025-07-17 19:59:46,925 - logger.py:50 - Epoch: [358][5/6]	Total Loss: 0.73790	Main MSE (x10^-2): 73.7905	LR: 7.63e-05	EMPP_Raw: 1.45754
2025-07-17 19:59:46,967 - logger.py:50 - Epoch 358 Training Summary: Avg Total Loss: 0.73790, Avg Main MSE: 0.73790, Time: 23.43s
2025-07-17 20:00:06,700 - logger.py:50 - Epoch 358 Summary | Train MSE (x10^-2): 73.7905 | Val MSE (x10^-2): 18.1938 | Time: 43.17s
2025-07-17 20:00:10,814 - logger.py:50 - Epoch: [359][0/6]	Total Loss: 0.72086	Main MSE (x10^-2): 72.0856	LR: 7.53e-05	EMPP_Raw: 1.42433
2025-07-17 20:00:30,101 - logger.py:50 - Epoch: [359][5/6]	Total Loss: 0.72677	Main MSE (x10^-2): 72.6769	LR: 7.53e-05	EMPP_Raw: 1.43528
2025-07-17 20:00:30,142 - logger.py:50 - Epoch 359 Training Summary: Avg Total Loss: 0.72677, Avg Main MSE: 0.72677, Time: 23.43s
2025-07-17 20:00:49,834 - logger.py:50 - Epoch 359 Summary | Train MSE (x10^-2): 72.6769 | Val MSE (x10^-2): 18.2333 | Time: 43.13s
2025-07-17 20:00:53,879 - logger.py:50 - Epoch: [360][0/6]	Total Loss: 0.73006	Main MSE (x10^-2): 73.0061	LR: 7.43e-05	EMPP_Raw: 1.44264
2025-07-17 20:01:13,138 - logger.py:50 - Epoch: [360][5/6]	Total Loss: 0.73097	Main MSE (x10^-2): 73.0969	LR: 7.43e-05	EMPP_Raw: 1.44417
2025-07-17 20:01:13,179 - logger.py:50 - Epoch 360 Training Summary: Avg Total Loss: 0.73097, Avg Main MSE: 0.73097, Time: 23.34s
2025-07-17 20:01:33,100 - logger.py:50 - Epoch 360 Summary | Train MSE (x10^-2): 73.0969 | Val MSE (x10^-2): 18.2481 | Time: 43.26s
2025-07-17 20:01:37,218 - logger.py:50 - Epoch: [361][0/6]	Total Loss: 0.73158	Main MSE (x10^-2): 73.1579	LR: 7.33e-05	EMPP_Raw: 1.44506
2025-07-17 20:01:56,726 - logger.py:50 - Epoch: [361][5/6]	Total Loss: 0.73726	Main MSE (x10^-2): 73.7260	LR: 7.33e-05	EMPP_Raw: 1.45607
2025-07-17 20:01:56,767 - logger.py:50 - Epoch 361 Training Summary: Avg Total Loss: 0.73726, Avg Main MSE: 0.73726, Time: 23.66s
2025-07-17 20:02:16,429 - logger.py:50 - Epoch 361 Summary | Train MSE (x10^-2): 73.7260 | Val MSE (x10^-2): 18.2530 | Time: 43.32s
2025-07-17 20:02:20,495 - logger.py:50 - Epoch: [362][0/6]	Total Loss: 0.72237	Main MSE (x10^-2): 72.2365	LR: 7.24e-05	EMPP_Raw: 1.42689
2025-07-17 20:02:39,919 - logger.py:50 - Epoch: [362][5/6]	Total Loss: 0.73833	Main MSE (x10^-2): 73.8333	LR: 7.24e-05	EMPP_Raw: 1.45861
2025-07-17 20:02:39,960 - logger.py:50 - Epoch 362 Training Summary: Avg Total Loss: 0.73833, Avg Main MSE: 0.73833, Time: 23.52s
2025-07-17 20:02:59,615 - logger.py:50 - Epoch 362 Summary | Train MSE (x10^-2): 73.8333 | Val MSE (x10^-2): 18.2612 | Time: 43.18s
2025-07-17 20:03:03,795 - logger.py:50 - Epoch: [363][0/6]	Total Loss: 0.72382	Main MSE (x10^-2): 72.3817	LR: 7.14e-05	EMPP_Raw: 1.42968
2025-07-17 20:03:23,170 - logger.py:50 - Epoch: [363][5/6]	Total Loss: 0.73558	Main MSE (x10^-2): 73.5580	LR: 7.14e-05	EMPP_Raw: 1.45322
2025-07-17 20:03:23,213 - logger.py:50 - Epoch 363 Training Summary: Avg Total Loss: 0.73558, Avg Main MSE: 0.73558, Time: 23.59s
2025-07-17 20:03:42,806 - logger.py:50 - Epoch 363 Summary | Train MSE (x10^-2): 73.5580 | Val MSE (x10^-2): 18.3505 | Time: 43.19s
2025-07-17 20:03:46,873 - logger.py:50 - Epoch: [364][0/6]	Total Loss: 0.72294	Main MSE (x10^-2): 72.2942	LR: 7.05e-05	EMPP_Raw: 1.42778
2025-07-17 20:04:06,098 - logger.py:50 - Epoch: [364][5/6]	Total Loss: 0.73130	Main MSE (x10^-2): 73.1299	LR: 7.05e-05	EMPP_Raw: 1.44466
2025-07-17 20:04:06,140 - logger.py:50 - Epoch 364 Training Summary: Avg Total Loss: 0.73130, Avg Main MSE: 0.73130, Time: 23.33s
2025-07-17 20:04:25,814 - logger.py:50 - Epoch 364 Summary | Train MSE (x10^-2): 73.1299 | Val MSE (x10^-2): 18.2654 | Time: 43.00s
2025-07-17 20:04:29,935 - logger.py:50 - Epoch: [365][0/6]	Total Loss: 0.71279	Main MSE (x10^-2): 71.2788	LR: 6.95e-05	EMPP_Raw: 1.40590
2025-07-17 20:04:49,155 - logger.py:50 - Epoch: [365][5/6]	Total Loss: 0.73272	Main MSE (x10^-2): 73.2715	LR: 6.95e-05	EMPP_Raw: 1.44727
2025-07-17 20:04:49,198 - logger.py:50 - Epoch 365 Training Summary: Avg Total Loss: 0.73272, Avg Main MSE: 0.73272, Time: 23.38s
2025-07-17 20:05:08,963 - logger.py:50 - Epoch 365 Summary | Train MSE (x10^-2): 73.2715 | Val MSE (x10^-2): 18.1923 | Time: 43.14s
2025-07-17 20:05:13,080 - logger.py:50 - Epoch: [366][0/6]	Total Loss: 0.76037	Main MSE (x10^-2): 76.0372	LR: 6.86e-05	EMPP_Raw: 1.50365
2025-07-17 20:05:32,456 - logger.py:50 - Epoch: [366][5/6]	Total Loss: 0.72940	Main MSE (x10^-2): 72.9400	LR: 6.86e-05	EMPP_Raw: 1.44061
2025-07-17 20:05:32,501 - logger.py:50 - Epoch 366 Training Summary: Avg Total Loss: 0.72940, Avg Main MSE: 0.72940, Time: 23.53s
2025-07-17 20:05:52,024 - logger.py:50 - Epoch 366 Summary | Train MSE (x10^-2): 72.9400 | Val MSE (x10^-2): 18.3713 | Time: 43.06s
2025-07-17 20:05:56,125 - logger.py:50 - Epoch: [367][0/6]	Total Loss: 0.73730	Main MSE (x10^-2): 73.7302	LR: 6.76e-05	EMPP_Raw: 1.45684
2025-07-17 20:06:15,448 - logger.py:50 - Epoch: [367][5/6]	Total Loss: 0.73358	Main MSE (x10^-2): 73.3584	LR: 6.76e-05	EMPP_Raw: 1.44903
2025-07-17 20:06:15,492 - logger.py:50 - Epoch 367 Training Summary: Avg Total Loss: 0.73358, Avg Main MSE: 0.73358, Time: 23.46s
2025-07-17 20:06:35,005 - logger.py:50 - Epoch 367 Summary | Train MSE (x10^-2): 73.3584 | Val MSE (x10^-2): 18.2753 | Time: 42.98s
2025-07-17 20:06:39,178 - logger.py:50 - Epoch: [368][0/6]	Total Loss: 0.72847	Main MSE (x10^-2): 72.8469	LR: 6.67e-05	EMPP_Raw: 1.43877
2025-07-17 20:06:58,450 - logger.py:50 - Epoch: [368][5/6]	Total Loss: 0.73389	Main MSE (x10^-2): 73.3892	LR: 6.67e-05	EMPP_Raw: 1.44958
2025-07-17 20:06:58,492 - logger.py:50 - Epoch 368 Training Summary: Avg Total Loss: 0.73389, Avg Main MSE: 0.73389, Time: 23.48s
2025-07-17 20:07:18,207 - logger.py:50 - Epoch 368 Summary | Train MSE (x10^-2): 73.3892 | Val MSE (x10^-2): 18.2372 | Time: 43.20s
2025-07-17 20:07:22,321 - logger.py:50 - Epoch: [369][0/6]	Total Loss: 0.73007	Main MSE (x10^-2): 73.0066	LR: 6.58e-05	EMPP_Raw: 1.44136
2025-07-17 20:07:41,665 - logger.py:50 - Epoch: [369][5/6]	Total Loss: 0.73758	Main MSE (x10^-2): 73.7576	LR: 6.58e-05	EMPP_Raw: 1.45713
2025-07-17 20:07:41,706 - logger.py:50 - Epoch 369 Training Summary: Avg Total Loss: 0.73758, Avg Main MSE: 0.73758, Time: 23.49s
2025-07-17 20:08:01,270 - logger.py:50 - Epoch 369 Summary | Train MSE (x10^-2): 73.7576 | Val MSE (x10^-2): 18.3552 | Time: 43.06s
2025-07-17 20:08:05,422 - logger.py:50 - Epoch: [370][0/6]	Total Loss: 0.73554	Main MSE (x10^-2): 73.5540	LR: 6.48e-05	EMPP_Raw: 1.45296
2025-07-17 20:08:24,710 - logger.py:50 - Epoch: [370][5/6]	Total Loss: 0.73999	Main MSE (x10^-2): 73.9988	LR: 6.48e-05	EMPP_Raw: 1.46198
2025-07-17 20:08:24,753 - logger.py:50 - Epoch 370 Training Summary: Avg Total Loss: 0.73999, Avg Main MSE: 0.73999, Time: 23.47s
2025-07-17 20:08:44,377 - logger.py:50 - Epoch 370 Summary | Train MSE (x10^-2): 73.9988 | Val MSE (x10^-2): 18.1876 | Time: 43.10s
2025-07-17 20:08:48,602 - logger.py:50 - Epoch: [371][0/6]	Total Loss: 0.73905	Main MSE (x10^-2): 73.9054	LR: 6.39e-05	EMPP_Raw: 1.45899
2025-07-17 20:09:08,226 - logger.py:50 - Epoch: [371][5/6]	Total Loss: 0.73986	Main MSE (x10^-2): 73.9855	LR: 6.39e-05	EMPP_Raw: 1.46180
2025-07-17 20:09:08,273 - logger.py:50 - Epoch 371 Training Summary: Avg Total Loss: 0.73986, Avg Main MSE: 0.73986, Time: 23.88s
2025-07-17 20:09:28,259 - logger.py:50 - Epoch 371 Summary | Train MSE (x10^-2): 73.9855 | Val MSE (x10^-2): 18.3468 | Time: 43.87s
2025-07-17 20:09:32,503 - logger.py:50 - Epoch: [372][0/6]	Total Loss: 0.74240	Main MSE (x10^-2): 74.2396	LR: 6.30e-05	EMPP_Raw: 1.46663
2025-07-17 20:09:52,264 - logger.py:50 - Epoch: [372][5/6]	Total Loss: 0.72737	Main MSE (x10^-2): 72.7365	LR: 6.30e-05	EMPP_Raw: 1.43679
2025-07-17 20:09:52,326 - logger.py:50 - Epoch 372 Training Summary: Avg Total Loss: 0.72737, Avg Main MSE: 0.72737, Time: 24.06s
2025-07-17 20:10:12,010 - logger.py:50 - Epoch 372 Summary | Train MSE (x10^-2): 72.7365 | Val MSE (x10^-2): 18.2177 | Time: 43.75s
2025-07-17 20:10:16,086 - logger.py:50 - Epoch: [373][0/6]	Total Loss: 0.73697	Main MSE (x10^-2): 73.6971	LR: 6.21e-05	EMPP_Raw: 1.45542
2025-07-17 20:10:35,450 - logger.py:50 - Epoch: [373][5/6]	Total Loss: 0.72661	Main MSE (x10^-2): 72.6611	LR: 6.21e-05	EMPP_Raw: 1.43521
2025-07-17 20:10:35,490 - logger.py:50 - Epoch 373 Training Summary: Avg Total Loss: 0.72661, Avg Main MSE: 0.72661, Time: 23.47s
2025-07-17 20:10:55,125 - logger.py:50 - Epoch 373 Summary | Train MSE (x10^-2): 72.6611 | Val MSE (x10^-2): 18.2240 | Time: 43.11s
2025-07-17 20:10:59,210 - logger.py:50 - Epoch: [374][0/6]	Total Loss: 0.71787	Main MSE (x10^-2): 71.7868	LR: 6.12e-05	EMPP_Raw: 1.41764
2025-07-17 20:11:18,573 - logger.py:50 - Epoch: [374][5/6]	Total Loss: 0.73431	Main MSE (x10^-2): 73.4311	LR: 6.12e-05	EMPP_Raw: 1.45092
2025-07-17 20:11:18,612 - logger.py:50 - Epoch 374 Training Summary: Avg Total Loss: 0.73431, Avg Main MSE: 0.73431, Time: 23.48s
2025-07-17 20:11:38,327 - logger.py:50 - Epoch 374 Summary | Train MSE (x10^-2): 73.4311 | Val MSE (x10^-2): 18.2597 | Time: 43.20s
2025-07-17 20:11:42,451 - logger.py:50 - Epoch: [375][0/6]	Total Loss: 0.73028	Main MSE (x10^-2): 73.0282	LR: 6.03e-05	EMPP_Raw: 1.44255
2025-07-17 20:12:01,732 - logger.py:50 - Epoch: [375][5/6]	Total Loss: 0.72688	Main MSE (x10^-2): 72.6884	LR: 6.03e-05	EMPP_Raw: 1.43634
2025-07-17 20:12:01,770 - logger.py:50 - Epoch 375 Training Summary: Avg Total Loss: 0.72688, Avg Main MSE: 0.72688, Time: 23.43s
2025-07-17 20:12:21,459 - logger.py:50 - Epoch 375 Summary | Train MSE (x10^-2): 72.6884 | Val MSE (x10^-2): 18.2227 | Time: 43.13s
2025-07-17 20:12:25,560 - logger.py:50 - Epoch: [376][0/6]	Total Loss: 0.72604	Main MSE (x10^-2): 72.6040	LR: 5.94e-05	EMPP_Raw: 1.43392
2025-07-17 20:12:44,878 - logger.py:50 - Epoch: [376][5/6]	Total Loss: 0.72328	Main MSE (x10^-2): 72.3276	LR: 5.94e-05	EMPP_Raw: 1.42897
2025-07-17 20:12:44,929 - logger.py:50 - Epoch 376 Training Summary: Avg Total Loss: 0.72328, Avg Main MSE: 0.72328, Time: 23.46s
2025-07-17 20:13:04,671 - logger.py:50 - Epoch 376 Summary | Train MSE (x10^-2): 72.3276 | Val MSE (x10^-2): 18.2546 | Time: 43.21s
2025-07-17 20:13:08,782 - logger.py:50 - Epoch: [377][0/6]	Total Loss: 0.73183	Main MSE (x10^-2): 73.1829	LR: 5.85e-05	EMPP_Raw: 1.44579
2025-07-17 20:13:28,122 - logger.py:50 - Epoch: [377][5/6]	Total Loss: 0.73645	Main MSE (x10^-2): 73.6447	LR: 5.85e-05	EMPP_Raw: 1.45501
2025-07-17 20:13:28,162 - logger.py:50 - Epoch 377 Training Summary: Avg Total Loss: 0.73645, Avg Main MSE: 0.73645, Time: 23.48s
2025-07-17 20:13:48,057 - logger.py:50 - Epoch 377 Summary | Train MSE (x10^-2): 73.6447 | Val MSE (x10^-2): 18.2955 | Time: 43.38s
2025-07-17 20:13:52,180 - logger.py:50 - Epoch: [378][0/6]	Total Loss: 0.74496	Main MSE (x10^-2): 74.4957	LR: 5.77e-05	EMPP_Raw: 1.47183
2025-07-17 20:14:11,454 - logger.py:50 - Epoch: [378][5/6]	Total Loss: 0.73081	Main MSE (x10^-2): 73.0809	LR: 5.77e-05	EMPP_Raw: 1.44399
2025-07-17 20:14:11,497 - logger.py:50 - Epoch 378 Training Summary: Avg Total Loss: 0.73081, Avg Main MSE: 0.73081, Time: 23.43s
2025-07-17 20:14:31,051 - logger.py:50 - Epoch 378 Summary | Train MSE (x10^-2): 73.0809 | Val MSE (x10^-2): 18.3114 | Time: 42.99s
2025-07-17 20:14:35,112 - logger.py:50 - Epoch: [379][0/6]	Total Loss: 0.74480	Main MSE (x10^-2): 74.4796	LR: 5.68e-05	EMPP_Raw: 1.47223
2025-07-17 20:14:54,412 - logger.py:50 - Epoch: [379][5/6]	Total Loss: 0.73948	Main MSE (x10^-2): 73.9484	LR: 5.68e-05	EMPP_Raw: 1.46152
2025-07-17 20:14:54,452 - logger.py:50 - Epoch 379 Training Summary: Avg Total Loss: 0.73948, Avg Main MSE: 0.73948, Time: 23.39s
2025-07-17 20:15:14,158 - logger.py:50 - Epoch 379 Summary | Train MSE (x10^-2): 73.9484 | Val MSE (x10^-2): 18.2385 | Time: 43.10s
2025-07-17 20:15:18,330 - logger.py:50 - Epoch: [380][0/6]	Total Loss: 0.73953	Main MSE (x10^-2): 73.9531	LR: 5.59e-05	EMPP_Raw: 1.46185
2025-07-17 20:15:37,683 - logger.py:50 - Epoch: [380][5/6]	Total Loss: 0.73824	Main MSE (x10^-2): 73.8241	LR: 5.59e-05	EMPP_Raw: 1.45853
2025-07-17 20:15:37,729 - logger.py:50 - Epoch 380 Training Summary: Avg Total Loss: 0.73824, Avg Main MSE: 0.73824, Time: 23.56s
2025-07-17 20:15:57,418 - logger.py:50 - Epoch 380 Summary | Train MSE (x10^-2): 73.8241 | Val MSE (x10^-2): 18.3703 | Time: 43.25s
2025-07-17 20:16:01,519 - logger.py:50 - Epoch: [381][0/6]	Total Loss: 0.74795	Main MSE (x10^-2): 74.7947	LR: 5.51e-05	EMPP_Raw: 1.47808
2025-07-17 20:16:20,858 - logger.py:50 - Epoch: [381][5/6]	Total Loss: 0.73842	Main MSE (x10^-2): 73.8419	LR: 5.51e-05	EMPP_Raw: 1.45922
2025-07-17 20:16:20,898 - logger.py:50 - Epoch 381 Training Summary: Avg Total Loss: 0.73842, Avg Main MSE: 0.73842, Time: 23.47s
2025-07-17 20:16:40,715 - logger.py:50 - Epoch 381 Summary | Train MSE (x10^-2): 73.8419 | Val MSE (x10^-2): 18.3419 | Time: 43.29s
2025-07-17 20:16:44,973 - logger.py:50 - Epoch: [382][0/6]	Total Loss: 0.73311	Main MSE (x10^-2): 73.3112	LR: 5.42e-05	EMPP_Raw: 1.44922
2025-07-17 20:17:04,353 - logger.py:50 - Epoch: [382][5/6]	Total Loss: 0.73444	Main MSE (x10^-2): 73.4441	LR: 5.42e-05	EMPP_Raw: 1.45158
2025-07-17 20:17:04,396 - logger.py:50 - Epoch 382 Training Summary: Avg Total Loss: 0.73444, Avg Main MSE: 0.73444, Time: 23.67s
2025-07-17 20:17:24,177 - logger.py:50 - Epoch 382 Summary | Train MSE (x10^-2): 73.4441 | Val MSE (x10^-2): 18.1983 | Time: 43.45s
2025-07-17 20:17:28,273 - logger.py:50 - Epoch: [383][0/6]	Total Loss: 0.71969	Main MSE (x10^-2): 71.9687	LR: 5.34e-05	EMPP_Raw: 1.42125
2025-07-17 20:17:47,620 - logger.py:50 - Epoch: [383][5/6]	Total Loss: 0.72458	Main MSE (x10^-2): 72.4576	LR: 5.34e-05	EMPP_Raw: 1.43156
2025-07-17 20:17:47,659 - logger.py:50 - Epoch 383 Training Summary: Avg Total Loss: 0.72458, Avg Main MSE: 0.72458, Time: 23.47s
2025-07-17 20:18:07,503 - logger.py:50 - Epoch 383 Summary | Train MSE (x10^-2): 72.4576 | Val MSE (x10^-2): 18.3441 | Time: 43.32s
2025-07-17 20:18:11,571 - logger.py:50 - Epoch: [384][0/6]	Total Loss: 0.73161	Main MSE (x10^-2): 73.1613	LR: 5.25e-05	EMPP_Raw: 1.44580
2025-07-17 20:18:30,844 - logger.py:50 - Epoch: [384][5/6]	Total Loss: 0.73139	Main MSE (x10^-2): 73.1391	LR: 5.25e-05	EMPP_Raw: 1.44535
2025-07-17 20:18:30,888 - logger.py:50 - Epoch 384 Training Summary: Avg Total Loss: 0.73139, Avg Main MSE: 0.73139, Time: 23.38s
2025-07-17 20:18:50,501 - logger.py:50 - Epoch 384 Summary | Train MSE (x10^-2): 73.1391 | Val MSE (x10^-2): 18.2766 | Time: 42.99s
2025-07-17 20:18:54,638 - logger.py:50 - Epoch: [385][0/6]	Total Loss: 0.74246	Main MSE (x10^-2): 74.2459	LR: 5.17e-05	EMPP_Raw: 1.46782
2025-07-17 20:19:13,948 - logger.py:50 - Epoch: [385][5/6]	Total Loss: 0.73577	Main MSE (x10^-2): 73.5772	LR: 5.17e-05	EMPP_Raw: 1.45378
2025-07-17 20:19:13,986 - logger.py:50 - Epoch 385 Training Summary: Avg Total Loss: 0.73577, Avg Main MSE: 0.73577, Time: 23.48s
2025-07-17 20:19:33,644 - logger.py:50 - Epoch 385 Summary | Train MSE (x10^-2): 73.5772 | Val MSE (x10^-2): 18.2807 | Time: 43.14s
2025-07-17 20:19:37,738 - logger.py:50 - Epoch: [386][0/6]	Total Loss: 0.72811	Main MSE (x10^-2): 72.8110	LR: 5.09e-05	EMPP_Raw: 1.43958
2025-07-17 20:19:56,965 - logger.py:50 - Epoch: [386][5/6]	Total Loss: 0.73203	Main MSE (x10^-2): 73.2031	LR: 5.09e-05	EMPP_Raw: 1.44616
2025-07-17 20:19:57,005 - logger.py:50 - Epoch 386 Training Summary: Avg Total Loss: 0.73203, Avg Main MSE: 0.73203, Time: 23.35s
2025-07-17 20:20:16,912 - logger.py:50 - Epoch 386 Summary | Train MSE (x10^-2): 73.2031 | Val MSE (x10^-2): 18.3421 | Time: 43.26s
2025-07-17 20:20:20,982 - logger.py:50 - Epoch: [387][0/6]	Total Loss: 0.74237	Main MSE (x10^-2): 74.2370	LR: 5.00e-05	EMPP_Raw: 1.46737
2025-07-17 20:20:40,356 - logger.py:50 - Epoch: [387][5/6]	Total Loss: 0.73247	Main MSE (x10^-2): 73.2473	LR: 5.00e-05	EMPP_Raw: 1.44739
2025-07-17 20:20:40,399 - logger.py:50 - Epoch 387 Training Summary: Avg Total Loss: 0.73247, Avg Main MSE: 0.73247, Time: 23.48s
2025-07-17 20:21:00,484 - logger.py:50 - Epoch 387 Summary | Train MSE (x10^-2): 73.2473 | Val MSE (x10^-2): 18.2717 | Time: 43.57s
2025-07-17 20:21:04,649 - logger.py:50 - Epoch: [388][0/6]	Total Loss: 0.71553	Main MSE (x10^-2): 71.5525	LR: 4.92e-05	EMPP_Raw: 1.41335
2025-07-17 20:21:24,208 - logger.py:50 - Epoch: [388][5/6]	Total Loss: 0.73662	Main MSE (x10^-2): 73.6622	LR: 4.92e-05	EMPP_Raw: 1.45596
2025-07-17 20:21:24,247 - logger.py:50 - Epoch 388 Training Summary: Avg Total Loss: 0.73662, Avg Main MSE: 0.73662, Time: 23.75s
2025-07-17 20:21:44,012 - logger.py:50 - Epoch 388 Summary | Train MSE (x10^-2): 73.6622 | Val MSE (x10^-2): 18.2953 | Time: 43.52s
2025-07-17 20:21:48,137 - logger.py:50 - Epoch: [389][0/6]	Total Loss: 0.71087	Main MSE (x10^-2): 71.0871	LR: 4.84e-05	EMPP_Raw: 1.40433
2025-07-17 20:22:07,407 - logger.py:50 - Epoch: [389][5/6]	Total Loss: 0.72898	Main MSE (x10^-2): 72.8977	LR: 4.84e-05	EMPP_Raw: 1.44080
2025-07-17 20:22:07,447 - logger.py:50 - Epoch 389 Training Summary: Avg Total Loss: 0.72898, Avg Main MSE: 0.72898, Time: 23.43s
2025-07-17 20:22:27,134 - logger.py:50 - Epoch 389 Summary | Train MSE (x10^-2): 72.8977 | Val MSE (x10^-2): 18.3488 | Time: 43.12s
2025-07-17 20:22:31,306 - logger.py:50 - Epoch: [390][0/6]	Total Loss: 0.74186	Main MSE (x10^-2): 74.1857	LR: 4.76e-05	EMPP_Raw: 1.46780
2025-07-17 20:22:50,758 - logger.py:50 - Epoch: [390][5/6]	Total Loss: 0.72828	Main MSE (x10^-2): 72.8277	LR: 4.76e-05	EMPP_Raw: 1.43970
2025-07-17 20:22:50,801 - logger.py:50 - Epoch 390 Training Summary: Avg Total Loss: 0.72828, Avg Main MSE: 0.72828, Time: 23.66s
2025-07-17 20:23:10,461 - logger.py:50 - Epoch 390 Summary | Train MSE (x10^-2): 72.8277 | Val MSE (x10^-2): 18.2457 | Time: 43.32s
2025-07-17 20:23:14,610 - logger.py:50 - Epoch: [391][0/6]	Total Loss: 0.76666	Main MSE (x10^-2): 76.6659	LR: 4.68e-05	EMPP_Raw: 1.51646
2025-07-17 20:23:33,907 - logger.py:50 - Epoch: [391][5/6]	Total Loss: 0.73908	Main MSE (x10^-2): 73.9080	LR: 4.68e-05	EMPP_Raw: 1.46135
2025-07-17 20:23:33,948 - logger.py:50 - Epoch 391 Training Summary: Avg Total Loss: 0.73908, Avg Main MSE: 0.73908, Time: 23.48s
2025-07-17 20:23:53,561 - logger.py:50 - Epoch 391 Summary | Train MSE (x10^-2): 73.9080 | Val MSE (x10^-2): 18.2543 | Time: 43.09s
2025-07-17 20:23:57,690 - logger.py:50 - Epoch: [392][0/6]	Total Loss: 0.72493	Main MSE (x10^-2): 72.4932	LR: 4.60e-05	EMPP_Raw: 1.43153
2025-07-17 20:24:17,041 - logger.py:50 - Epoch: [392][5/6]	Total Loss: 0.73242	Main MSE (x10^-2): 73.2422	LR: 4.60e-05	EMPP_Raw: 1.44743
2025-07-17 20:24:17,085 - logger.py:50 - Epoch 392 Training Summary: Avg Total Loss: 0.73242, Avg Main MSE: 0.73242, Time: 23.51s
2025-07-17 20:24:36,883 - logger.py:50 - Epoch 392 Summary | Train MSE (x10^-2): 73.2422 | Val MSE (x10^-2): 18.3190 | Time: 43.32s
2025-07-17 20:24:40,995 - logger.py:50 - Epoch: [393][0/6]	Total Loss: 0.72923	Main MSE (x10^-2): 72.9230	LR: 4.52e-05	EMPP_Raw: 1.44139
2025-07-17 20:25:00,286 - logger.py:50 - Epoch: [393][5/6]	Total Loss: 0.73117	Main MSE (x10^-2): 73.1174	LR: 4.52e-05	EMPP_Raw: 1.44508
2025-07-17 20:25:00,327 - logger.py:50 - Epoch 393 Training Summary: Avg Total Loss: 0.73117, Avg Main MSE: 0.73117, Time: 23.44s
2025-07-17 20:25:19,873 - logger.py:50 - Epoch 393 Summary | Train MSE (x10^-2): 73.1174 | Val MSE (x10^-2): 18.3331 | Time: 42.98s
2025-07-17 20:25:24,002 - logger.py:50 - Epoch: [394][0/6]	Total Loss: 0.75089	Main MSE (x10^-2): 75.0886	LR: 4.44e-05	EMPP_Raw: 1.48421
2025-07-17 20:25:43,251 - logger.py:50 - Epoch: [394][5/6]	Total Loss: 0.73241	Main MSE (x10^-2): 73.2415	LR: 4.44e-05	EMPP_Raw: 1.44719
2025-07-17 20:25:43,294 - logger.py:50 - Epoch 394 Training Summary: Avg Total Loss: 0.73241, Avg Main MSE: 0.73241, Time: 23.41s
2025-07-17 20:26:02,865 - logger.py:50 - Epoch 394 Summary | Train MSE (x10^-2): 73.2415 | Val MSE (x10^-2): 18.2992 | Time: 42.99s
2025-07-17 20:26:06,973 - logger.py:50 - Epoch: [395][0/6]	Total Loss: 0.72801	Main MSE (x10^-2): 72.8007	LR: 4.36e-05	EMPP_Raw: 1.43860
2025-07-17 20:26:26,392 - logger.py:50 - Epoch: [395][5/6]	Total Loss: 0.72112	Main MSE (x10^-2): 72.1118	LR: 4.36e-05	EMPP_Raw: 1.42455
2025-07-17 20:26:26,434 - logger.py:50 - Epoch 395 Training Summary: Avg Total Loss: 0.72112, Avg Main MSE: 0.72112, Time: 23.56s
2025-07-17 20:26:46,089 - logger.py:50 - Epoch 395 Summary | Train MSE (x10^-2): 72.1118 | Val MSE (x10^-2): 18.2374 | Time: 43.22s
2025-07-17 20:26:50,160 - logger.py:50 - Epoch: [396][0/6]	Total Loss: 0.73088	Main MSE (x10^-2): 73.0879	LR: 4.29e-05	EMPP_Raw: 1.44461
2025-07-17 20:27:09,526 - logger.py:50 - Epoch: [396][5/6]	Total Loss: 0.72852	Main MSE (x10^-2): 72.8518	LR: 4.29e-05	EMPP_Raw: 1.43993
2025-07-17 20:27:09,566 - logger.py:50 - Epoch 396 Training Summary: Avg Total Loss: 0.72852, Avg Main MSE: 0.72852, Time: 23.47s
2025-07-17 20:27:29,148 - logger.py:50 - Epoch 396 Summary | Train MSE (x10^-2): 72.8518 | Val MSE (x10^-2): 18.3307 | Time: 43.05s
2025-07-17 20:27:33,239 - logger.py:50 - Epoch: [397][0/6]	Total Loss: 0.72178	Main MSE (x10^-2): 72.1783	LR: 4.21e-05	EMPP_Raw: 1.42726
2025-07-17 20:27:52,642 - logger.py:50 - Epoch: [397][5/6]	Total Loss: 0.72909	Main MSE (x10^-2): 72.9093	LR: 4.21e-05	EMPP_Raw: 1.44127
2025-07-17 20:27:52,686 - logger.py:50 - Epoch 397 Training Summary: Avg Total Loss: 0.72909, Avg Main MSE: 0.72909, Time: 23.53s
2025-07-17 20:28:12,674 - logger.py:50 - Epoch 397 Summary | Train MSE (x10^-2): 72.9093 | Val MSE (x10^-2): 18.3070 | Time: 43.52s
2025-07-17 20:28:16,837 - logger.py:50 - Epoch: [398][0/6]	Total Loss: 0.73913	Main MSE (x10^-2): 73.9127	LR: 4.13e-05	EMPP_Raw: 1.46096
2025-07-17 20:28:36,151 - logger.py:50 - Epoch: [398][5/6]	Total Loss: 0.73336	Main MSE (x10^-2): 73.3363	LR: 4.13e-05	EMPP_Raw: 1.44924
2025-07-17 20:28:36,195 - logger.py:50 - Epoch 398 Training Summary: Avg Total Loss: 0.73336, Avg Main MSE: 0.73336, Time: 23.51s
2025-07-17 20:28:55,924 - logger.py:50 - Epoch 398 Summary | Train MSE (x10^-2): 73.3363 | Val MSE (x10^-2): 18.2759 | Time: 43.24s
2025-07-17 20:29:00,094 - logger.py:50 - Epoch: [399][0/6]	Total Loss: 0.72786	Main MSE (x10^-2): 72.7859	LR: 4.06e-05	EMPP_Raw: 1.43888
2025-07-17 20:29:19,642 - logger.py:50 - Epoch: [399][5/6]	Total Loss: 0.73612	Main MSE (x10^-2): 73.6124	LR: 4.06e-05	EMPP_Raw: 1.45518
2025-07-17 20:29:19,694 - logger.py:50 - Epoch 399 Training Summary: Avg Total Loss: 0.73612, Avg Main MSE: 0.73612, Time: 23.76s
2025-07-17 20:29:39,605 - logger.py:50 - Epoch 399 Summary | Train MSE (x10^-2): 73.6124 | Val MSE (x10^-2): 18.3428 | Time: 43.68s
2025-07-17 20:29:43,672 - logger.py:50 - Epoch: [400][0/6]	Total Loss: 0.73394	Main MSE (x10^-2): 73.3935	LR: 3.98e-05	EMPP_Raw: 1.44942
2025-07-17 20:30:03,172 - logger.py:50 - Epoch: [400][5/6]	Total Loss: 0.72542	Main MSE (x10^-2): 72.5425	LR: 3.98e-05	EMPP_Raw: 1.43383
2025-07-17 20:30:03,214 - logger.py:50 - Epoch 400 Training Summary: Avg Total Loss: 0.72542, Avg Main MSE: 0.72542, Time: 23.60s
2025-07-17 20:30:22,970 - logger.py:50 - Epoch 400 Summary | Train MSE (x10^-2): 72.5425 | Val MSE (x10^-2): 18.2653 | Time: 43.36s
2025-07-17 20:30:27,073 - logger.py:50 - Epoch: [401][0/6]	Total Loss: 0.73902	Main MSE (x10^-2): 73.9016	LR: 3.91e-05	EMPP_Raw: 1.46032
2025-07-17 20:30:46,623 - logger.py:50 - Epoch: [401][5/6]	Total Loss: 0.72407	Main MSE (x10^-2): 72.4072	LR: 3.91e-05	EMPP_Raw: 1.43078
2025-07-17 20:30:46,664 - logger.py:50 - Epoch 401 Training Summary: Avg Total Loss: 0.72407, Avg Main MSE: 0.72407, Time: 23.69s
2025-07-17 20:31:06,406 - logger.py:50 - Epoch 401 Summary | Train MSE (x10^-2): 72.4072 | Val MSE (x10^-2): 18.2580 | Time: 43.43s
2025-07-17 20:31:10,531 - logger.py:50 - Epoch: [402][0/6]	Total Loss: 0.72586	Main MSE (x10^-2): 72.5861	LR: 3.84e-05	EMPP_Raw: 1.43416
2025-07-17 20:31:30,097 - logger.py:50 - Epoch: [402][5/6]	Total Loss: 0.72821	Main MSE (x10^-2): 72.8210	LR: 3.84e-05	EMPP_Raw: 1.43945
2025-07-17 20:31:30,141 - logger.py:50 - Epoch 402 Training Summary: Avg Total Loss: 0.72821, Avg Main MSE: 0.72821, Time: 23.73s
2025-07-17 20:31:50,022 - logger.py:50 - Epoch 402 Summary | Train MSE (x10^-2): 72.8210 | Val MSE (x10^-2): 18.2901 | Time: 43.61s
2025-07-17 20:31:54,118 - logger.py:50 - Epoch: [403][0/6]	Total Loss: 0.72828	Main MSE (x10^-2): 72.8280	LR: 3.76e-05	EMPP_Raw: 1.43957
2025-07-17 20:32:13,330 - logger.py:50 - Epoch: [403][5/6]	Total Loss: 0.73684	Main MSE (x10^-2): 73.6845	LR: 3.76e-05	EMPP_Raw: 1.45657
2025-07-17 20:32:13,371 - logger.py:50 - Epoch 403 Training Summary: Avg Total Loss: 0.73684, Avg Main MSE: 0.73684, Time: 23.34s
2025-07-17 20:32:33,032 - logger.py:50 - Epoch 403 Summary | Train MSE (x10^-2): 73.6845 | Val MSE (x10^-2): 18.2931 | Time: 43.00s
2025-07-17 20:32:37,287 - logger.py:50 - Epoch: [404][0/6]	Total Loss: 0.74507	Main MSE (x10^-2): 74.5070	LR: 3.69e-05	EMPP_Raw: 1.47393
2025-07-17 20:32:56,659 - logger.py:50 - Epoch: [404][5/6]	Total Loss: 0.73684	Main MSE (x10^-2): 73.6839	LR: 3.69e-05	EMPP_Raw: 1.45664
2025-07-17 20:32:56,699 - logger.py:50 - Epoch 404 Training Summary: Avg Total Loss: 0.73684, Avg Main MSE: 0.73684, Time: 23.66s
2025-07-17 20:33:16,536 - logger.py:50 - Epoch 404 Summary | Train MSE (x10^-2): 73.6839 | Val MSE (x10^-2): 18.1790 | Time: 43.50s
2025-07-17 20:33:20,647 - logger.py:50 - Epoch: [405][0/6]	Total Loss: 0.74192	Main MSE (x10^-2): 74.1922	LR: 3.62e-05	EMPP_Raw: 1.46819
2025-07-17 20:33:40,029 - logger.py:50 - Epoch: [405][5/6]	Total Loss: 0.73189	Main MSE (x10^-2): 73.1887	LR: 3.62e-05	EMPP_Raw: 1.44682
2025-07-17 20:33:40,067 - logger.py:50 - Epoch 405 Training Summary: Avg Total Loss: 0.73189, Avg Main MSE: 0.73189, Time: 23.52s
2025-07-17 20:33:59,748 - logger.py:50 - Epoch 405 Summary | Train MSE (x10^-2): 73.1887 | Val MSE (x10^-2): 18.2961 | Time: 43.21s
2025-07-17 20:34:03,830 - logger.py:50 - Epoch: [406][0/6]	Total Loss: 0.71128	Main MSE (x10^-2): 71.1278	LR: 3.55e-05	EMPP_Raw: 1.40543
2025-07-17 20:34:23,213 - logger.py:50 - Epoch: [406][5/6]	Total Loss: 0.73425	Main MSE (x10^-2): 73.4255	LR: 3.55e-05	EMPP_Raw: 1.45140
2025-07-17 20:34:23,252 - logger.py:50 - Epoch 406 Training Summary: Avg Total Loss: 0.73425, Avg Main MSE: 0.73425, Time: 23.49s
2025-07-17 20:34:42,750 - logger.py:50 - Epoch 406 Summary | Train MSE (x10^-2): 73.4255 | Val MSE (x10^-2): 18.2077 | Time: 43.00s
2025-07-17 20:34:46,828 - logger.py:50 - Epoch: [407][0/6]	Total Loss: 0.72232	Main MSE (x10^-2): 72.2323	LR: 3.48e-05	EMPP_Raw: 1.42804
2025-07-17 20:35:06,152 - logger.py:50 - Epoch: [407][5/6]	Total Loss: 0.73037	Main MSE (x10^-2): 73.0367	LR: 3.48e-05	EMPP_Raw: 1.44339
2025-07-17 20:35:06,192 - logger.py:50 - Epoch 407 Training Summary: Avg Total Loss: 0.73037, Avg Main MSE: 0.73037, Time: 23.44s
2025-07-17 20:35:25,860 - logger.py:50 - Epoch 407 Summary | Train MSE (x10^-2): 73.0367 | Val MSE (x10^-2): 18.2028 | Time: 43.11s
2025-07-17 20:35:29,985 - logger.py:50 - Epoch: [408][0/6]	Total Loss: 0.74999	Main MSE (x10^-2): 74.9991	LR: 3.41e-05	EMPP_Raw: 1.48297
2025-07-17 20:35:49,309 - logger.py:50 - Epoch: [408][5/6]	Total Loss: 0.73588	Main MSE (x10^-2): 73.5880	LR: 3.41e-05	EMPP_Raw: 1.45473
2025-07-17 20:35:49,350 - logger.py:50 - Epoch 408 Training Summary: Avg Total Loss: 0.73588, Avg Main MSE: 0.73588, Time: 23.48s
2025-07-17 20:36:08,913 - logger.py:50 - Epoch 408 Summary | Train MSE (x10^-2): 73.5880 | Val MSE (x10^-2): 18.3663 | Time: 43.05s
2025-07-17 20:36:13,025 - logger.py:50 - Epoch: [409][0/6]	Total Loss: 0.72139	Main MSE (x10^-2): 72.1389	LR: 3.34e-05	EMPP_Raw: 1.42613
2025-07-17 20:36:32,452 - logger.py:50 - Epoch: [409][5/6]	Total Loss: 0.72431	Main MSE (x10^-2): 72.4306	LR: 3.34e-05	EMPP_Raw: 1.43175
2025-07-17 20:36:32,492 - logger.py:50 - Epoch 409 Training Summary: Avg Total Loss: 0.72431, Avg Main MSE: 0.72431, Time: 23.57s
2025-07-17 20:36:52,091 - logger.py:50 - Epoch 409 Summary | Train MSE (x10^-2): 72.4306 | Val MSE (x10^-2): 18.1713 | Time: 43.17s
2025-07-17 20:36:56,176 - logger.py:50 - Epoch: [410][0/6]	Total Loss: 0.72458	Main MSE (x10^-2): 72.4578	LR: 3.27e-05	EMPP_Raw: 1.43216
2025-07-17 20:37:15,463 - logger.py:50 - Epoch: [410][5/6]	Total Loss: 0.72077	Main MSE (x10^-2): 72.0767	LR: 3.27e-05	EMPP_Raw: 1.42484
2025-07-17 20:37:15,505 - logger.py:50 - Epoch 410 Training Summary: Avg Total Loss: 0.72077, Avg Main MSE: 0.72077, Time: 23.41s
2025-07-17 20:37:35,263 - logger.py:50 - Epoch 410 Summary | Train MSE (x10^-2): 72.0767 | Val MSE (x10^-2): 18.2795 | Time: 43.17s
2025-07-17 20:37:39,369 - logger.py:50 - Epoch: [411][0/6]	Total Loss: 0.71839	Main MSE (x10^-2): 71.8392	LR: 3.21e-05	EMPP_Raw: 1.41881
2025-07-17 20:37:58,641 - logger.py:50 - Epoch: [411][5/6]	Total Loss: 0.73905	Main MSE (x10^-2): 73.9046	LR: 3.21e-05	EMPP_Raw: 1.46117
2025-07-17 20:37:58,683 - logger.py:50 - Epoch 411 Training Summary: Avg Total Loss: 0.73905, Avg Main MSE: 0.73905, Time: 23.41s
2025-07-17 20:38:18,420 - logger.py:50 - Epoch 411 Summary | Train MSE (x10^-2): 73.9046 | Val MSE (x10^-2): 18.2554 | Time: 43.15s
2025-07-17 20:38:22,540 - logger.py:50 - Epoch: [412][0/6]	Total Loss: 0.70355	Main MSE (x10^-2): 70.3547	LR: 3.14e-05	EMPP_Raw: 1.38981
2025-07-17 20:38:41,830 - logger.py:50 - Epoch: [412][5/6]	Total Loss: 0.72631	Main MSE (x10^-2): 72.6309	LR: 3.14e-05	EMPP_Raw: 1.43598
2025-07-17 20:38:41,872 - logger.py:50 - Epoch 412 Training Summary: Avg Total Loss: 0.72631, Avg Main MSE: 0.72631, Time: 23.44s
2025-07-17 20:39:01,487 - logger.py:50 - Epoch 412 Summary | Train MSE (x10^-2): 72.6309 | Val MSE (x10^-2): 18.2203 | Time: 43.06s
2025-07-17 20:39:05,535 - logger.py:50 - Epoch: [413][0/6]	Total Loss: 0.72861	Main MSE (x10^-2): 72.8614	LR: 3.07e-05	EMPP_Raw: 1.44092
2025-07-17 20:39:24,836 - logger.py:50 - Epoch: [413][5/6]	Total Loss: 0.73184	Main MSE (x10^-2): 73.1836	LR: 3.07e-05	EMPP_Raw: 1.44712
2025-07-17 20:39:24,880 - logger.py:50 - Epoch 413 Training Summary: Avg Total Loss: 0.73184, Avg Main MSE: 0.73184, Time: 23.38s
2025-07-17 20:39:44,467 - logger.py:50 - Epoch 413 Summary | Train MSE (x10^-2): 73.1836 | Val MSE (x10^-2): 18.2551 | Time: 42.97s
2025-07-17 20:39:48,580 - logger.py:50 - Epoch: [414][0/6]	Total Loss: 0.72984	Main MSE (x10^-2): 72.9838	LR: 3.01e-05	EMPP_Raw: 1.44326
2025-07-17 20:40:07,880 - logger.py:50 - Epoch: [414][5/6]	Total Loss: 0.73725	Main MSE (x10^-2): 73.7246	LR: 3.01e-05	EMPP_Raw: 1.45812
2025-07-17 20:40:07,926 - logger.py:50 - Epoch 414 Training Summary: Avg Total Loss: 0.73725, Avg Main MSE: 0.73725, Time: 23.45s
2025-07-17 20:40:27,571 - logger.py:50 - Epoch 414 Summary | Train MSE (x10^-2): 73.7246 | Val MSE (x10^-2): 18.2058 | Time: 43.10s
2025-07-17 20:40:31,665 - logger.py:50 - Epoch: [415][0/6]	Total Loss: 0.71273	Main MSE (x10^-2): 71.2733	LR: 2.94e-05	EMPP_Raw: 1.40813
2025-07-17 20:40:50,968 - logger.py:50 - Epoch: [415][5/6]	Total Loss: 0.72068	Main MSE (x10^-2): 72.0679	LR: 2.94e-05	EMPP_Raw: 1.42441
2025-07-17 20:40:51,010 - logger.py:50 - Epoch 415 Training Summary: Avg Total Loss: 0.72068, Avg Main MSE: 0.72068, Time: 23.43s
2025-07-17 20:41:10,606 - logger.py:50 - Epoch 415 Summary | Train MSE (x10^-2): 72.0679 | Val MSE (x10^-2): 18.2878 | Time: 43.03s
2025-07-17 20:41:14,734 - logger.py:50 - Epoch: [416][0/6]	Total Loss: 0.74301	Main MSE (x10^-2): 74.3010	LR: 2.88e-05	EMPP_Raw: 1.46880
2025-07-17 20:41:34,021 - logger.py:50 - Epoch: [416][5/6]	Total Loss: 0.72581	Main MSE (x10^-2): 72.5811	LR: 2.88e-05	EMPP_Raw: 1.43466
2025-07-17 20:41:34,065 - logger.py:50 - Epoch 416 Training Summary: Avg Total Loss: 0.72581, Avg Main MSE: 0.72581, Time: 23.45s
2025-07-17 20:41:53,831 - logger.py:50 - Epoch 416 Summary | Train MSE (x10^-2): 72.5811 | Val MSE (x10^-2): 18.2397 | Time: 43.22s
2025-07-17 20:41:57,967 - logger.py:50 - Epoch: [417][0/6]	Total Loss: 0.73377	Main MSE (x10^-2): 73.3772	LR: 2.81e-05	EMPP_Raw: 1.45082
2025-07-17 20:42:17,220 - logger.py:50 - Epoch: [417][5/6]	Total Loss: 0.72315	Main MSE (x10^-2): 72.3154	LR: 2.81e-05	EMPP_Raw: 1.42979
2025-07-17 20:42:17,261 - logger.py:50 - Epoch 417 Training Summary: Avg Total Loss: 0.72315, Avg Main MSE: 0.72315, Time: 23.42s
2025-07-17 20:42:36,813 - logger.py:50 - Epoch 417 Summary | Train MSE (x10^-2): 72.3154 | Val MSE (x10^-2): 18.1486 | Time: 42.98s
2025-07-17 20:42:40,908 - logger.py:50 - Epoch: [418][0/6]	Total Loss: 0.74206	Main MSE (x10^-2): 74.2056	LR: 2.75e-05	EMPP_Raw: 1.46796
2025-07-17 20:43:00,222 - logger.py:50 - Epoch: [418][5/6]	Total Loss: 0.72874	Main MSE (x10^-2): 72.8740	LR: 2.75e-05	EMPP_Raw: 1.44063
2025-07-17 20:43:00,264 - logger.py:50 - Epoch 418 Training Summary: Avg Total Loss: 0.72874, Avg Main MSE: 0.72874, Time: 23.44s
2025-07-17 20:43:19,852 - logger.py:50 - Epoch 418 Summary | Train MSE (x10^-2): 72.8740 | Val MSE (x10^-2): 18.2798 | Time: 43.03s
2025-07-17 20:43:23,935 - logger.py:50 - Epoch: [419][0/6]	Total Loss: 0.75568	Main MSE (x10^-2): 75.5677	LR: 2.69e-05	EMPP_Raw: 1.49476
2025-07-17 20:43:43,254 - logger.py:50 - Epoch: [419][5/6]	Total Loss: 0.72980	Main MSE (x10^-2): 72.9797	LR: 2.69e-05	EMPP_Raw: 1.44271
2025-07-17 20:43:43,295 - logger.py:50 - Epoch 419 Training Summary: Avg Total Loss: 0.72980, Avg Main MSE: 0.72980, Time: 23.44s
2025-07-17 20:44:02,853 - logger.py:50 - Epoch 419 Summary | Train MSE (x10^-2): 72.9797 | Val MSE (x10^-2): 18.2142 | Time: 43.00s
2025-07-17 20:44:06,957 - logger.py:50 - Epoch: [420][0/6]	Total Loss: 0.74577	Main MSE (x10^-2): 74.5773	LR: 2.63e-05	EMPP_Raw: 1.47500
2025-07-17 20:44:26,385 - logger.py:50 - Epoch: [420][5/6]	Total Loss: 0.73392	Main MSE (x10^-2): 73.3917	LR: 2.63e-05	EMPP_Raw: 1.45109
2025-07-17 20:44:26,425 - logger.py:50 - Epoch 420 Training Summary: Avg Total Loss: 0.73392, Avg Main MSE: 0.73392, Time: 23.56s
2025-07-17 20:44:45,968 - logger.py:50 - Epoch 420 Summary | Train MSE (x10^-2): 73.3917 | Val MSE (x10^-2): 18.2455 | Time: 43.11s
2025-07-17 20:44:50,084 - logger.py:50 - Epoch: [421][0/6]	Total Loss: 0.73238	Main MSE (x10^-2): 73.2383	LR: 2.57e-05	EMPP_Raw: 1.44961
2025-07-17 20:45:09,522 - logger.py:50 - Epoch: [421][5/6]	Total Loss: 0.72920	Main MSE (x10^-2): 72.9204	LR: 2.57e-05	EMPP_Raw: 1.44180
2025-07-17 20:45:09,561 - logger.py:50 - Epoch 421 Training Summary: Avg Total Loss: 0.72920, Avg Main MSE: 0.72920, Time: 23.58s
2025-07-17 20:45:29,154 - logger.py:50 - Epoch 421 Summary | Train MSE (x10^-2): 72.9204 | Val MSE (x10^-2): 18.2314 | Time: 43.18s
2025-07-17 20:45:33,234 - logger.py:50 - Epoch: [422][0/6]	Total Loss: 0.73710	Main MSE (x10^-2): 73.7104	LR: 2.51e-05	EMPP_Raw: 1.45740
2025-07-17 20:45:52,524 - logger.py:50 - Epoch: [422][5/6]	Total Loss: 0.73173	Main MSE (x10^-2): 73.1732	LR: 2.51e-05	EMPP_Raw: 1.44652
2025-07-17 20:45:52,567 - logger.py:50 - Epoch 422 Training Summary: Avg Total Loss: 0.73173, Avg Main MSE: 0.73173, Time: 23.41s
2025-07-17 20:46:12,213 - logger.py:50 - Epoch 422 Summary | Train MSE (x10^-2): 73.1732 | Val MSE (x10^-2): 18.2774 | Time: 43.06s
2025-07-17 20:46:16,297 - logger.py:50 - Epoch: [423][0/6]	Total Loss: 0.72387	Main MSE (x10^-2): 72.3874	LR: 2.45e-05	EMPP_Raw: 1.43041
2025-07-17 20:46:35,762 - logger.py:50 - Epoch: [423][5/6]	Total Loss: 0.73575	Main MSE (x10^-2): 73.5750	LR: 2.45e-05	EMPP_Raw: 1.45435
2025-07-17 20:46:35,804 - logger.py:50 - Epoch 423 Training Summary: Avg Total Loss: 0.73575, Avg Main MSE: 0.73575, Time: 23.58s
2025-07-17 20:46:55,458 - logger.py:50 - Epoch 423 Summary | Train MSE (x10^-2): 73.5750 | Val MSE (x10^-2): 18.1946 | Time: 43.24s
2025-07-17 20:46:59,565 - logger.py:50 - Epoch: [424][0/6]	Total Loss: 0.73644	Main MSE (x10^-2): 73.6441	LR: 2.39e-05	EMPP_Raw: 1.45686
2025-07-17 20:47:18,872 - logger.py:50 - Epoch: [424][5/6]	Total Loss: 0.73332	Main MSE (x10^-2): 73.3324	LR: 2.39e-05	EMPP_Raw: 1.45004
2025-07-17 20:47:18,914 - logger.py:50 - Epoch 424 Training Summary: Avg Total Loss: 0.73332, Avg Main MSE: 0.73332, Time: 23.45s
2025-07-17 20:47:38,509 - logger.py:50 - Epoch 424 Summary | Train MSE (x10^-2): 73.3324 | Val MSE (x10^-2): 18.2316 | Time: 43.05s
2025-07-17 20:47:42,654 - logger.py:50 - Epoch: [425][0/6]	Total Loss: 0.72264	Main MSE (x10^-2): 72.2639	LR: 2.33e-05	EMPP_Raw: 1.42962
2025-07-17 20:48:01,975 - logger.py:50 - Epoch: [425][5/6]	Total Loss: 0.73513	Main MSE (x10^-2): 73.5133	LR: 2.33e-05	EMPP_Raw: 1.45413
2025-07-17 20:48:02,019 - logger.py:50 - Epoch 425 Training Summary: Avg Total Loss: 0.73513, Avg Main MSE: 0.73513, Time: 23.50s
2025-07-17 20:48:21,601 - logger.py:50 - Epoch 425 Summary | Train MSE (x10^-2): 73.5133 | Val MSE (x10^-2): 18.2735 | Time: 43.09s
2025-07-17 20:48:25,726 - logger.py:50 - Epoch: [426][0/6]	Total Loss: 0.71616	Main MSE (x10^-2): 71.6161	LR: 2.27e-05	EMPP_Raw: 1.41567
2025-07-17 20:48:45,108 - logger.py:50 - Epoch: [426][5/6]	Total Loss: 0.71465	Main MSE (x10^-2): 71.4649	LR: 2.27e-05	EMPP_Raw: 1.41286
2025-07-17 20:48:45,154 - logger.py:50 - Epoch 426 Training Summary: Avg Total Loss: 0.71465, Avg Main MSE: 0.71465, Time: 23.54s
2025-07-17 20:49:04,831 - logger.py:50 - Epoch 426 Summary | Train MSE (x10^-2): 71.4649 | Val MSE (x10^-2): 18.2875 | Time: 43.23s
2025-07-17 20:49:08,922 - logger.py:50 - Epoch: [427][0/6]	Total Loss: 0.74277	Main MSE (x10^-2): 74.2774	LR: 2.22e-05	EMPP_Raw: 1.46854
2025-07-17 20:49:28,308 - logger.py:50 - Epoch: [427][5/6]	Total Loss: 0.72044	Main MSE (x10^-2): 72.0444	LR: 2.22e-05	EMPP_Raw: 1.42385
2025-07-17 20:49:28,349 - logger.py:50 - Epoch 427 Training Summary: Avg Total Loss: 0.72044, Avg Main MSE: 0.72044, Time: 23.51s
2025-07-17 20:49:48,026 - logger.py:50 - Epoch 427 Summary | Train MSE (x10^-2): 72.0444 | Val MSE (x10^-2): 18.2948 | Time: 43.19s
2025-07-17 20:49:52,108 - logger.py:50 - Epoch: [428][0/6]	Total Loss: 0.72084	Main MSE (x10^-2): 72.0840	LR: 2.16e-05	EMPP_Raw: 1.42469
2025-07-17 20:50:11,426 - logger.py:50 - Epoch: [428][5/6]	Total Loss: 0.73340	Main MSE (x10^-2): 73.3396	LR: 2.16e-05	EMPP_Raw: 1.45012
2025-07-17 20:50:11,469 - logger.py:50 - Epoch 428 Training Summary: Avg Total Loss: 0.73340, Avg Main MSE: 0.73340, Time: 23.43s
2025-07-17 20:50:31,105 - logger.py:50 - Epoch 428 Summary | Train MSE (x10^-2): 73.3396 | Val MSE (x10^-2): 18.2860 | Time: 43.07s
2025-07-17 20:50:35,196 - logger.py:50 - Epoch: [429][0/6]	Total Loss: 0.73292	Main MSE (x10^-2): 73.2915	LR: 2.11e-05	EMPP_Raw: 1.44936
2025-07-17 20:50:54,417 - logger.py:50 - Epoch: [429][5/6]	Total Loss: 0.72967	Main MSE (x10^-2): 72.9670	LR: 2.11e-05	EMPP_Raw: 1.44290
2025-07-17 20:50:54,457 - logger.py:50 - Epoch 429 Training Summary: Avg Total Loss: 0.72967, Avg Main MSE: 0.72967, Time: 23.34s
2025-07-17 20:51:14,121 - logger.py:50 - Epoch 429 Summary | Train MSE (x10^-2): 72.9670 | Val MSE (x10^-2): 18.2399 | Time: 43.01s
2025-07-17 20:51:18,232 - logger.py:50 - Epoch: [430][0/6]	Total Loss: 0.73600	Main MSE (x10^-2): 73.6002	LR: 2.05e-05	EMPP_Raw: 1.45492
2025-07-17 20:51:37,518 - logger.py:50 - Epoch: [430][5/6]	Total Loss: 0.73886	Main MSE (x10^-2): 73.8864	LR: 2.05e-05	EMPP_Raw: 1.46042
2025-07-17 20:51:37,559 - logger.py:50 - Epoch 430 Training Summary: Avg Total Loss: 0.73886, Avg Main MSE: 0.73886, Time: 23.43s
2025-07-17 20:51:57,233 - logger.py:50 - Epoch 430 Summary | Train MSE (x10^-2): 73.8864 | Val MSE (x10^-2): 18.2629 | Time: 43.11s
2025-07-17 20:52:01,308 - logger.py:50 - Epoch: [431][0/6]	Total Loss: 0.70964	Main MSE (x10^-2): 70.9643	LR: 2.00e-05	EMPP_Raw: 1.40339
2025-07-17 20:52:20,652 - logger.py:50 - Epoch: [431][5/6]	Total Loss: 0.72892	Main MSE (x10^-2): 72.8916	LR: 2.00e-05	EMPP_Raw: 1.44116
2025-07-17 20:52:20,693 - logger.py:50 - Epoch 431 Training Summary: Avg Total Loss: 0.72892, Avg Main MSE: 0.72892, Time: 23.45s
2025-07-17 20:52:40,253 - logger.py:50 - Epoch 431 Summary | Train MSE (x10^-2): 72.8916 | Val MSE (x10^-2): 18.2660 | Time: 43.01s
2025-07-17 20:52:44,341 - logger.py:50 - Epoch: [432][0/6]	Total Loss: 0.74040	Main MSE (x10^-2): 74.0397	LR: 1.95e-05	EMPP_Raw: 1.46446
2025-07-17 20:53:03,632 - logger.py:50 - Epoch: [432][5/6]	Total Loss: 0.72838	Main MSE (x10^-2): 72.8380	LR: 1.95e-05	EMPP_Raw: 1.43989
2025-07-17 20:53:03,686 - logger.py:50 - Epoch 432 Training Summary: Avg Total Loss: 0.72838, Avg Main MSE: 0.72838, Time: 23.42s
2025-07-17 20:53:23,294 - logger.py:50 - Epoch 432 Summary | Train MSE (x10^-2): 72.8380 | Val MSE (x10^-2): 18.2642 | Time: 43.04s
2025-07-17 20:53:27,393 - logger.py:50 - Epoch: [433][0/6]	Total Loss: 0.72369	Main MSE (x10^-2): 72.3687	LR: 1.89e-05	EMPP_Raw: 1.43086
2025-07-17 20:53:46,622 - logger.py:50 - Epoch: [433][5/6]	Total Loss: 0.73482	Main MSE (x10^-2): 73.4822	LR: 1.89e-05	EMPP_Raw: 1.45296
2025-07-17 20:53:46,665 - logger.py:50 - Epoch 433 Training Summary: Avg Total Loss: 0.73482, Avg Main MSE: 0.73482, Time: 23.36s
2025-07-17 20:54:06,317 - logger.py:50 - Epoch 433 Summary | Train MSE (x10^-2): 73.4822 | Val MSE (x10^-2): 18.2744 | Time: 43.02s
2025-07-17 20:54:10,423 - logger.py:50 - Epoch: [434][0/6]	Total Loss: 0.72345	Main MSE (x10^-2): 72.3455	LR: 1.84e-05	EMPP_Raw: 1.42940
2025-07-17 20:54:29,704 - logger.py:50 - Epoch: [434][5/6]	Total Loss: 0.72018	Main MSE (x10^-2): 72.0180	LR: 1.84e-05	EMPP_Raw: 1.42354
2025-07-17 20:54:29,745 - logger.py:50 - Epoch 434 Training Summary: Avg Total Loss: 0.72018, Avg Main MSE: 0.72018, Time: 23.42s
2025-07-17 20:54:49,488 - logger.py:50 - Epoch 434 Summary | Train MSE (x10^-2): 72.0180 | Val MSE (x10^-2): 18.2197 | Time: 43.17s
2025-07-17 20:54:53,565 - logger.py:50 - Epoch: [435][0/6]	Total Loss: 0.73052	Main MSE (x10^-2): 73.0516	LR: 1.79e-05	EMPP_Raw: 1.44463
2025-07-17 20:55:12,950 - logger.py:50 - Epoch: [435][5/6]	Total Loss: 0.73479	Main MSE (x10^-2): 73.4790	LR: 1.79e-05	EMPP_Raw: 1.45278
2025-07-17 20:55:12,993 - logger.py:50 - Epoch 435 Training Summary: Avg Total Loss: 0.73479, Avg Main MSE: 0.73479, Time: 23.50s
2025-07-17 20:55:32,686 - logger.py:50 - Epoch 435 Summary | Train MSE (x10^-2): 73.4790 | Val MSE (x10^-2): 18.2615 | Time: 43.19s
2025-07-17 20:55:36,781 - logger.py:50 - Epoch: [436][0/6]	Total Loss: 0.76307	Main MSE (x10^-2): 76.3068	LR: 1.74e-05	EMPP_Raw: 1.50933
2025-07-17 20:55:56,106 - logger.py:50 - Epoch: [436][5/6]	Total Loss: 0.73465	Main MSE (x10^-2): 73.4645	LR: 1.74e-05	EMPP_Raw: 1.45255
2025-07-17 20:55:56,146 - logger.py:50 - Epoch 436 Training Summary: Avg Total Loss: 0.73465, Avg Main MSE: 0.73465, Time: 23.45s
2025-07-17 20:56:15,737 - logger.py:50 - Epoch 436 Summary | Train MSE (x10^-2): 73.4645 | Val MSE (x10^-2): 18.2755 | Time: 43.05s
2025-07-17 20:56:19,875 - logger.py:50 - Epoch: [437][0/6]	Total Loss: 0.70979	Main MSE (x10^-2): 70.9787	LR: 1.69e-05	EMPP_Raw: 1.40182
2025-07-17 20:56:39,194 - logger.py:50 - Epoch: [437][5/6]	Total Loss: 0.72502	Main MSE (x10^-2): 72.5016	LR: 1.69e-05	EMPP_Raw: 1.43310
2025-07-17 20:56:39,256 - logger.py:50 - Epoch 437 Training Summary: Avg Total Loss: 0.72502, Avg Main MSE: 0.72502, Time: 23.51s
2025-07-17 20:56:58,882 - logger.py:50 - Epoch 437 Summary | Train MSE (x10^-2): 72.5016 | Val MSE (x10^-2): 18.2459 | Time: 43.14s
2025-07-17 20:57:03,007 - logger.py:50 - Epoch: [438][0/6]	Total Loss: 0.75082	Main MSE (x10^-2): 75.0820	LR: 1.64e-05	EMPP_Raw: 1.48512
2025-07-17 20:57:22,361 - logger.py:50 - Epoch: [438][5/6]	Total Loss: 0.73042	Main MSE (x10^-2): 73.0416	LR: 1.64e-05	EMPP_Raw: 1.44440
2025-07-17 20:57:22,401 - logger.py:50 - Epoch 438 Training Summary: Avg Total Loss: 0.73042, Avg Main MSE: 0.73042, Time: 23.51s
2025-07-17 20:57:41,985 - logger.py:50 - Epoch 438 Summary | Train MSE (x10^-2): 73.0416 | Val MSE (x10^-2): 18.2299 | Time: 43.10s
2025-07-17 20:57:46,021 - logger.py:50 - Epoch: [439][0/6]	Total Loss: 0.72316	Main MSE (x10^-2): 72.3164	LR: 1.59e-05	EMPP_Raw: 1.42862
2025-07-17 20:58:05,337 - logger.py:50 - Epoch: [439][5/6]	Total Loss: 0.72966	Main MSE (x10^-2): 72.9656	LR: 1.59e-05	EMPP_Raw: 1.44222
2025-07-17 20:58:05,381 - logger.py:50 - Epoch 439 Training Summary: Avg Total Loss: 0.72966, Avg Main MSE: 0.72966, Time: 23.39s
2025-07-17 20:58:24,930 - logger.py:50 - Epoch 439 Summary | Train MSE (x10^-2): 72.9656 | Val MSE (x10^-2): 18.2016 | Time: 42.94s
2025-07-17 20:58:29,043 - logger.py:50 - Epoch: [440][0/6]	Total Loss: 0.72019	Main MSE (x10^-2): 72.0194	LR: 1.55e-05	EMPP_Raw: 1.42286
2025-07-17 20:58:48,289 - logger.py:50 - Epoch: [440][5/6]	Total Loss: 0.72842	Main MSE (x10^-2): 72.8420	LR: 1.55e-05	EMPP_Raw: 1.43946
2025-07-17 20:58:48,330 - logger.py:50 - Epoch 440 Training Summary: Avg Total Loss: 0.72842, Avg Main MSE: 0.72842, Time: 23.39s
2025-07-17 20:59:08,003 - logger.py:50 - Epoch 440 Summary | Train MSE (x10^-2): 72.8420 | Val MSE (x10^-2): 18.2625 | Time: 43.07s
2025-07-17 20:59:12,064 - logger.py:50 - Epoch: [441][0/6]	Total Loss: 0.72997	Main MSE (x10^-2): 72.9972	LR: 1.50e-05	EMPP_Raw: 1.44264
2025-07-17 20:59:31,414 - logger.py:50 - Epoch: [441][5/6]	Total Loss: 0.72909	Main MSE (x10^-2): 72.9086	LR: 1.50e-05	EMPP_Raw: 1.44150
2025-07-17 20:59:31,455 - logger.py:50 - Epoch 441 Training Summary: Avg Total Loss: 0.72909, Avg Main MSE: 0.72909, Time: 23.44s
2025-07-17 20:59:50,973 - logger.py:50 - Epoch 441 Summary | Train MSE (x10^-2): 72.9086 | Val MSE (x10^-2): 18.2530 | Time: 42.96s
2025-07-17 20:59:55,020 - logger.py:50 - Epoch: [442][0/6]	Total Loss: 0.73367	Main MSE (x10^-2): 73.3668	LR: 1.46e-05	EMPP_Raw: 1.45020
2025-07-17 21:00:14,264 - logger.py:50 - Epoch: [442][5/6]	Total Loss: 0.74106	Main MSE (x10^-2): 74.1060	LR: 1.46e-05	EMPP_Raw: 1.46531
2025-07-17 21:00:14,306 - logger.py:50 - Epoch 442 Training Summary: Avg Total Loss: 0.74106, Avg Main MSE: 0.74106, Time: 23.32s
2025-07-17 21:00:33,897 - logger.py:50 - Epoch 442 Summary | Train MSE (x10^-2): 74.1060 | Val MSE (x10^-2): 18.2624 | Time: 42.92s
2025-07-17 21:00:37,992 - logger.py:50 - Epoch: [443][0/6]	Total Loss: 0.73401	Main MSE (x10^-2): 73.4006	LR: 1.41e-05	EMPP_Raw: 1.45182
2025-07-17 21:00:57,328 - logger.py:50 - Epoch: [443][5/6]	Total Loss: 0.73932	Main MSE (x10^-2): 73.9319	LR: 1.41e-05	EMPP_Raw: 1.46208
2025-07-17 21:00:57,378 - logger.py:50 - Epoch 443 Training Summary: Avg Total Loss: 0.73932, Avg Main MSE: 0.73932, Time: 23.47s
2025-07-17 21:01:17,010 - logger.py:50 - Epoch 443 Summary | Train MSE (x10^-2): 73.9319 | Val MSE (x10^-2): 18.2745 | Time: 43.11s
2025-07-17 21:01:21,120 - logger.py:50 - Epoch: [444][0/6]	Total Loss: 0.72935	Main MSE (x10^-2): 72.9351	LR: 1.37e-05	EMPP_Raw: 1.44254
2025-07-17 21:01:40,452 - logger.py:50 - Epoch: [444][5/6]	Total Loss: 0.73059	Main MSE (x10^-2): 73.0586	LR: 1.37e-05	EMPP_Raw: 1.44501
2025-07-17 21:01:40,496 - logger.py:50 - Epoch 444 Training Summary: Avg Total Loss: 0.73059, Avg Main MSE: 0.73059, Time: 23.48s
2025-07-17 21:02:00,088 - logger.py:50 - Epoch 444 Summary | Train MSE (x10^-2): 73.0586 | Val MSE (x10^-2): 18.2389 | Time: 43.07s
2025-07-17 21:02:04,193 - logger.py:50 - Epoch: [445][0/6]	Total Loss: 0.71871	Main MSE (x10^-2): 71.8712	LR: 1.32e-05	EMPP_Raw: 1.42079
2025-07-17 21:02:23,468 - logger.py:50 - Epoch: [445][5/6]	Total Loss: 0.73054	Main MSE (x10^-2): 73.0539	LR: 1.32e-05	EMPP_Raw: 1.44450
2025-07-17 21:02:23,509 - logger.py:50 - Epoch 445 Training Summary: Avg Total Loss: 0.73054, Avg Main MSE: 0.73054, Time: 23.41s
2025-07-17 21:02:43,074 - logger.py:50 - Epoch 445 Summary | Train MSE (x10^-2): 73.0539 | Val MSE (x10^-2): 18.2651 | Time: 42.98s
2025-07-17 21:02:47,169 - logger.py:50 - Epoch: [446][0/6]	Total Loss: 0.75004	Main MSE (x10^-2): 75.0041	LR: 1.28e-05	EMPP_Raw: 1.48368
2025-07-17 21:03:06,386 - logger.py:50 - Epoch: [446][5/6]	Total Loss: 0.73202	Main MSE (x10^-2): 73.2016	LR: 1.28e-05	EMPP_Raw: 1.44711
2025-07-17 21:03:06,428 - logger.py:50 - Epoch 446 Training Summary: Avg Total Loss: 0.73202, Avg Main MSE: 0.73202, Time: 23.35s
2025-07-17 21:03:26,072 - logger.py:50 - Epoch 446 Summary | Train MSE (x10^-2): 73.2016 | Val MSE (x10^-2): 18.3125 | Time: 43.00s
2025-07-17 21:03:30,182 - logger.py:50 - Epoch: [447][0/6]	Total Loss: 0.71191	Main MSE (x10^-2): 71.1912	LR: 1.24e-05	EMPP_Raw: 1.40839
2025-07-17 21:03:49,554 - logger.py:50 - Epoch: [447][5/6]	Total Loss: 0.73865	Main MSE (x10^-2): 73.8647	LR: 1.24e-05	EMPP_Raw: 1.46084
2025-07-17 21:03:49,594 - logger.py:50 - Epoch 447 Training Summary: Avg Total Loss: 0.73865, Avg Main MSE: 0.73865, Time: 23.51s
2025-07-17 21:04:09,275 - logger.py:50 - Epoch 447 Summary | Train MSE (x10^-2): 73.8647 | Val MSE (x10^-2): 18.2735 | Time: 43.20s
2025-07-17 21:04:13,369 - logger.py:50 - Epoch: [448][0/6]	Total Loss: 0.74948	Main MSE (x10^-2): 74.9481	LR: 1.20e-05	EMPP_Raw: 1.48215
2025-07-17 21:04:32,654 - logger.py:50 - Epoch: [448][5/6]	Total Loss: 0.73439	Main MSE (x10^-2): 73.4389	LR: 1.20e-05	EMPP_Raw: 1.45210
2025-07-17 21:04:32,694 - logger.py:50 - Epoch 448 Training Summary: Avg Total Loss: 0.73439, Avg Main MSE: 0.73439, Time: 23.41s
2025-07-17 21:04:52,418 - logger.py:50 - Epoch 448 Summary | Train MSE (x10^-2): 73.4389 | Val MSE (x10^-2): 18.2391 | Time: 43.14s
2025-07-17 21:04:56,505 - logger.py:50 - Epoch: [449][0/6]	Total Loss: 0.74770	Main MSE (x10^-2): 74.7704	LR: 1.16e-05	EMPP_Raw: 1.47951
2025-07-17 21:05:15,860 - logger.py:50 - Epoch: [449][5/6]	Total Loss: 0.73275	Main MSE (x10^-2): 73.2754	LR: 1.16e-05	EMPP_Raw: 1.44924
2025-07-17 21:05:15,902 - logger.py:50 - Epoch 449 Training Summary: Avg Total Loss: 0.73275, Avg Main MSE: 0.73275, Time: 23.47s
2025-07-17 21:05:35,447 - logger.py:50 - Epoch 449 Summary | Train MSE (x10^-2): 73.2754 | Val MSE (x10^-2): 18.2430 | Time: 43.02s
2025-07-17 21:05:39,543 - logger.py:50 - Epoch: [450][0/6]	Total Loss: 0.70585	Main MSE (x10^-2): 70.5850	LR: 1.12e-05	EMPP_Raw: 1.39505
2025-07-17 21:05:58,816 - logger.py:50 - Epoch: [450][5/6]	Total Loss: 0.72966	Main MSE (x10^-2): 72.9661	LR: 1.12e-05	EMPP_Raw: 1.44281
2025-07-17 21:05:58,859 - logger.py:50 - Epoch 450 Training Summary: Avg Total Loss: 0.72966, Avg Main MSE: 0.72966, Time: 23.40s
2025-07-17 21:06:18,423 - logger.py:50 - Epoch 450 Summary | Train MSE (x10^-2): 72.9661 | Val MSE (x10^-2): 18.2515 | Time: 42.97s
2025-07-17 21:06:22,545 - logger.py:50 - Epoch: [451][0/6]	Total Loss: 0.74024	Main MSE (x10^-2): 74.0240	LR: 1.08e-05	EMPP_Raw: 1.46384
2025-07-17 21:06:41,958 - logger.py:50 - Epoch: [451][5/6]	Total Loss: 0.73660	Main MSE (x10^-2): 73.6595	LR: 1.08e-05	EMPP_Raw: 1.45688
2025-07-17 21:06:42,000 - logger.py:50 - Epoch 451 Training Summary: Avg Total Loss: 0.73660, Avg Main MSE: 0.73660, Time: 23.56s
2025-07-17 21:07:01,562 - logger.py:50 - Epoch 451 Summary | Train MSE (x10^-2): 73.6595 | Val MSE (x10^-2): 18.2329 | Time: 43.13s
2025-07-17 21:07:05,639 - logger.py:50 - Epoch: [452][0/6]	Total Loss: 0.73417	Main MSE (x10^-2): 73.4170	LR: 1.04e-05	EMPP_Raw: 1.45184
2025-07-17 21:07:24,940 - logger.py:50 - Epoch: [452][5/6]	Total Loss: 0.73468	Main MSE (x10^-2): 73.4682	LR: 1.04e-05	EMPP_Raw: 1.45264
2025-07-17 21:07:24,979 - logger.py:50 - Epoch 452 Training Summary: Avg Total Loss: 0.73468, Avg Main MSE: 0.73468, Time: 23.41s
2025-07-17 21:07:44,514 - logger.py:50 - Epoch 452 Summary | Train MSE (x10^-2): 73.4682 | Val MSE (x10^-2): 18.2453 | Time: 42.95s
2025-07-17 21:07:48,627 - logger.py:50 - Epoch: [453][0/6]	Total Loss: 0.73107	Main MSE (x10^-2): 73.1074	LR: 1.00e-05	EMPP_Raw: 1.44609
2025-07-17 21:08:08,091 - logger.py:50 - Epoch: [453][5/6]	Total Loss: 0.72449	Main MSE (x10^-2): 72.4486	LR: 1.00e-05	EMPP_Raw: 1.43258
2025-07-17 21:08:08,137 - logger.py:50 - Epoch 453 Training Summary: Avg Total Loss: 0.72449, Avg Main MSE: 0.72449, Time: 23.61s
2025-07-17 21:08:27,923 - logger.py:50 - Epoch 453 Summary | Train MSE (x10^-2): 72.4486 | Val MSE (x10^-2): 18.2440 | Time: 43.40s
2025-07-17 21:08:32,019 - logger.py:50 - Epoch: [454][0/6]	Total Loss: 0.74087	Main MSE (x10^-2): 74.0873	LR: 9.64e-06	EMPP_Raw: 1.46345
2025-07-17 21:08:51,277 - logger.py:50 - Epoch: [454][5/6]	Total Loss: 0.73375	Main MSE (x10^-2): 73.3747	LR: 9.64e-06	EMPP_Raw: 1.45075
2025-07-17 21:08:51,321 - logger.py:50 - Epoch 454 Training Summary: Avg Total Loss: 0.73375, Avg Main MSE: 0.73375, Time: 23.39s
2025-07-17 21:09:11,182 - logger.py:50 - Epoch 454 Summary | Train MSE (x10^-2): 73.3747 | Val MSE (x10^-2): 18.2480 | Time: 43.25s
2025-07-17 21:09:15,297 - logger.py:50 - Epoch: [455][0/6]	Total Loss: 0.73873	Main MSE (x10^-2): 73.8726	LR: 9.27e-06	EMPP_Raw: 1.46108
2025-07-17 21:09:34,578 - logger.py:50 - Epoch: [455][5/6]	Total Loss: 0.73491	Main MSE (x10^-2): 73.4906	LR: 9.27e-06	EMPP_Raw: 1.45346
2025-07-17 21:09:34,618 - logger.py:50 - Epoch 455 Training Summary: Avg Total Loss: 0.73491, Avg Main MSE: 0.73491, Time: 23.43s
2025-07-17 21:09:54,182 - logger.py:50 - Epoch 455 Summary | Train MSE (x10^-2): 73.4906 | Val MSE (x10^-2): 18.2524 | Time: 42.99s
2025-07-17 21:09:58,264 - logger.py:50 - Epoch: [456][0/6]	Total Loss: 0.75695	Main MSE (x10^-2): 75.6950	LR: 8.92e-06	EMPP_Raw: 1.49805
2025-07-17 21:10:17,499 - logger.py:50 - Epoch: [456][5/6]	Total Loss: 0.73748	Main MSE (x10^-2): 73.7484	LR: 8.92e-06	EMPP_Raw: 1.45859
2025-07-17 21:10:17,552 - logger.py:50 - Epoch 456 Training Summary: Avg Total Loss: 0.73748, Avg Main MSE: 0.73748, Time: 23.36s
2025-07-17 21:10:37,076 - logger.py:50 - Epoch 456 Summary | Train MSE (x10^-2): 73.7484 | Val MSE (x10^-2): 18.2636 | Time: 42.89s
2025-07-17 21:10:41,154 - logger.py:50 - Epoch: [457][0/6]	Total Loss: 0.71166	Main MSE (x10^-2): 71.1659	LR: 8.58e-06	EMPP_Raw: 1.40623
2025-07-17 21:11:00,460 - logger.py:50 - Epoch: [457][5/6]	Total Loss: 0.72384	Main MSE (x10^-2): 72.3842	LR: 8.58e-06	EMPP_Raw: 1.43143
2025-07-17 21:11:00,502 - logger.py:50 - Epoch 457 Training Summary: Avg Total Loss: 0.72384, Avg Main MSE: 0.72384, Time: 23.42s
2025-07-17 21:11:20,080 - logger.py:50 - Epoch 457 Summary | Train MSE (x10^-2): 72.3842 | Val MSE (x10^-2): 18.2615 | Time: 43.00s
2025-07-17 21:11:24,246 - logger.py:50 - Epoch: [458][0/6]	Total Loss: 0.72299	Main MSE (x10^-2): 72.2986	LR: 8.24e-06	EMPP_Raw: 1.42978
2025-07-17 21:11:43,628 - logger.py:50 - Epoch: [458][5/6]	Total Loss: 0.72639	Main MSE (x10^-2): 72.6388	LR: 8.24e-06	EMPP_Raw: 1.43614
2025-07-17 21:11:43,675 - logger.py:50 - Epoch 458 Training Summary: Avg Total Loss: 0.72639, Avg Main MSE: 0.72639, Time: 23.59s
2025-07-17 21:12:03,196 - logger.py:50 - Epoch 458 Summary | Train MSE (x10^-2): 72.6388 | Val MSE (x10^-2): 18.2612 | Time: 43.11s
2025-07-17 21:12:07,279 - logger.py:50 - Epoch: [459][0/6]	Total Loss: 0.72500	Main MSE (x10^-2): 72.4995	LR: 7.91e-06	EMPP_Raw: 1.43408
2025-07-17 21:12:26,604 - logger.py:50 - Epoch: [459][5/6]	Total Loss: 0.73773	Main MSE (x10^-2): 73.7725	LR: 7.91e-06	EMPP_Raw: 1.45931
2025-07-17 21:12:26,645 - logger.py:50 - Epoch 459 Training Summary: Avg Total Loss: 0.73773, Avg Main MSE: 0.73773, Time: 23.44s
2025-07-17 21:12:46,438 - logger.py:50 - Epoch 459 Summary | Train MSE (x10^-2): 73.7725 | Val MSE (x10^-2): 18.2496 | Time: 43.24s
2025-07-17 21:12:50,503 - logger.py:50 - Epoch: [460][0/6]	Total Loss: 0.74529	Main MSE (x10^-2): 74.5294	LR: 7.58e-06	EMPP_Raw: 1.47422
2025-07-17 21:13:09,819 - logger.py:50 - Epoch: [460][5/6]	Total Loss: 0.73505	Main MSE (x10^-2): 73.5052	LR: 7.58e-06	EMPP_Raw: 1.45343
2025-07-17 21:13:09,863 - logger.py:50 - Epoch 460 Training Summary: Avg Total Loss: 0.73505, Avg Main MSE: 0.73505, Time: 23.42s
2025-07-17 21:13:29,481 - logger.py:50 - Epoch 460 Summary | Train MSE (x10^-2): 73.5052 | Val MSE (x10^-2): 18.2254 | Time: 43.04s
2025-07-17 21:13:33,630 - logger.py:50 - Epoch: [461][0/6]	Total Loss: 0.74893	Main MSE (x10^-2): 74.8931	LR: 7.27e-06	EMPP_Raw: 1.48210
2025-07-17 21:13:53,047 - logger.py:50 - Epoch: [461][5/6]	Total Loss: 0.73786	Main MSE (x10^-2): 73.7862	LR: 7.27e-06	EMPP_Raw: 1.45958
2025-07-17 21:13:53,088 - logger.py:50 - Epoch 461 Training Summary: Avg Total Loss: 0.73786, Avg Main MSE: 0.73786, Time: 23.60s
2025-07-17 21:14:12,745 - logger.py:50 - Epoch 461 Summary | Train MSE (x10^-2): 73.7862 | Val MSE (x10^-2): 18.2306 | Time: 43.26s
2025-07-17 21:14:16,816 - logger.py:50 - Epoch: [462][0/6]	Total Loss: 0.73797	Main MSE (x10^-2): 73.7973	LR: 6.96e-06	EMPP_Raw: 1.45978
2025-07-17 21:14:36,082 - logger.py:50 - Epoch: [462][5/6]	Total Loss: 0.73324	Main MSE (x10^-2): 73.3236	LR: 6.96e-06	EMPP_Raw: 1.45022
2025-07-17 21:14:36,129 - logger.py:50 - Epoch 462 Training Summary: Avg Total Loss: 0.73324, Avg Main MSE: 0.73324, Time: 23.37s
2025-07-17 21:14:55,864 - logger.py:50 - Epoch 462 Summary | Train MSE (x10^-2): 73.3236 | Val MSE (x10^-2): 18.2573 | Time: 43.11s
2025-07-17 21:14:59,948 - logger.py:50 - Epoch: [463][0/6]	Total Loss: 0.75360	Main MSE (x10^-2): 75.3598	LR: 6.66e-06	EMPP_Raw: 1.49164
2025-07-17 21:15:19,308 - logger.py:50 - Epoch: [463][5/6]	Total Loss: 0.73505	Main MSE (x10^-2): 73.5047	LR: 6.66e-06	EMPP_Raw: 1.45425
2025-07-17 21:15:19,348 - logger.py:50 - Epoch 463 Training Summary: Avg Total Loss: 0.73505, Avg Main MSE: 0.73505, Time: 23.48s
2025-07-17 21:15:38,926 - logger.py:50 - Epoch 463 Summary | Train MSE (x10^-2): 73.5047 | Val MSE (x10^-2): 18.2766 | Time: 43.06s
2025-07-17 21:15:43,032 - logger.py:50 - Epoch: [464][0/6]	Total Loss: 0.72001	Main MSE (x10^-2): 72.0009	LR: 6.37e-06	EMPP_Raw: 1.42261
2025-07-17 21:16:02,380 - logger.py:50 - Epoch: [464][5/6]	Total Loss: 0.73795	Main MSE (x10^-2): 73.7946	LR: 6.37e-06	EMPP_Raw: 1.45921
2025-07-17 21:16:02,425 - logger.py:50 - Epoch 464 Training Summary: Avg Total Loss: 0.73795, Avg Main MSE: 0.73795, Time: 23.49s
2025-07-17 21:16:22,049 - logger.py:50 - Epoch 464 Summary | Train MSE (x10^-2): 73.7946 | Val MSE (x10^-2): 18.2801 | Time: 43.12s
2025-07-17 21:16:26,126 - logger.py:50 - Epoch: [465][0/6]	Total Loss: 0.78311	Main MSE (x10^-2): 78.3110	LR: 6.08e-06	EMPP_Raw: 1.55028
2025-07-17 21:16:45,514 - logger.py:50 - Epoch: [465][5/6]	Total Loss: 0.73405	Main MSE (x10^-2): 73.4054	LR: 6.08e-06	EMPP_Raw: 1.45154
2025-07-17 21:16:45,556 - logger.py:50 - Epoch 465 Training Summary: Avg Total Loss: 0.73405, Avg Main MSE: 0.73405, Time: 23.50s
2025-07-17 21:17:05,122 - logger.py:50 - Epoch 465 Summary | Train MSE (x10^-2): 73.4054 | Val MSE (x10^-2): 18.2939 | Time: 43.07s
2025-07-17 21:17:09,294 - logger.py:50 - Epoch: [466][0/6]	Total Loss: 0.71269	Main MSE (x10^-2): 71.2686	LR: 5.80e-06	EMPP_Raw: 1.40891
2025-07-17 21:17:28,729 - logger.py:50 - Epoch: [466][5/6]	Total Loss: 0.72795	Main MSE (x10^-2): 72.7946	LR: 5.80e-06	EMPP_Raw: 1.43965
2025-07-17 21:17:28,768 - logger.py:50 - Epoch 466 Training Summary: Avg Total Loss: 0.72795, Avg Main MSE: 0.72795, Time: 23.64s
2025-07-17 21:17:48,304 - logger.py:50 - Epoch 466 Summary | Train MSE (x10^-2): 72.7946 | Val MSE (x10^-2): 18.2856 | Time: 43.18s
2025-07-17 21:17:52,399 - logger.py:50 - Epoch: [467][0/6]	Total Loss: 0.72831	Main MSE (x10^-2): 72.8308	LR: 5.54e-06	EMPP_Raw: 1.44002
2025-07-17 21:18:11,676 - logger.py:50 - Epoch: [467][5/6]	Total Loss: 0.72197	Main MSE (x10^-2): 72.1970	LR: 5.54e-06	EMPP_Raw: 1.42758
2025-07-17 21:18:11,720 - logger.py:50 - Epoch 467 Training Summary: Avg Total Loss: 0.72197, Avg Main MSE: 0.72197, Time: 23.41s
2025-07-17 21:18:31,301 - logger.py:50 - Epoch 467 Summary | Train MSE (x10^-2): 72.1970 | Val MSE (x10^-2): 18.2595 | Time: 42.99s
2025-07-17 21:18:35,406 - logger.py:50 - Epoch: [468][0/6]	Total Loss: 0.72759	Main MSE (x10^-2): 72.7592	LR: 5.27e-06	EMPP_Raw: 1.43927
2025-07-17 21:18:54,749 - logger.py:50 - Epoch: [468][5/6]	Total Loss: 0.73006	Main MSE (x10^-2): 73.0058	LR: 5.27e-06	EMPP_Raw: 1.44369
2025-07-17 21:18:54,791 - logger.py:50 - Epoch 468 Training Summary: Avg Total Loss: 0.73006, Avg Main MSE: 0.73006, Time: 23.48s
2025-07-17 21:19:14,402 - logger.py:50 - Epoch 468 Summary | Train MSE (x10^-2): 73.0058 | Val MSE (x10^-2): 18.2359 | Time: 43.10s
2025-07-17 21:19:18,461 - logger.py:50 - Epoch: [469][0/6]	Total Loss: 0.74096	Main MSE (x10^-2): 74.0962	LR: 5.02e-06	EMPP_Raw: 1.46621
2025-07-17 21:19:37,729 - logger.py:50 - Epoch: [469][5/6]	Total Loss: 0.73409	Main MSE (x10^-2): 73.4093	LR: 5.02e-06	EMPP_Raw: 1.45203
2025-07-17 21:19:37,772 - logger.py:50 - Epoch 469 Training Summary: Avg Total Loss: 0.73409, Avg Main MSE: 0.73409, Time: 23.36s
2025-07-17 21:19:57,338 - logger.py:50 - Epoch 469 Summary | Train MSE (x10^-2): 73.4093 | Val MSE (x10^-2): 18.2083 | Time: 42.93s
2025-07-17 21:20:01,427 - logger.py:50 - Epoch: [470][0/6]	Total Loss: 0.74921	Main MSE (x10^-2): 74.9206	LR: 4.77e-06	EMPP_Raw: 1.48234
2025-07-17 21:20:20,721 - logger.py:50 - Epoch: [470][5/6]	Total Loss: 0.72503	Main MSE (x10^-2): 72.5027	LR: 4.77e-06	EMPP_Raw: 1.43383
2025-07-17 21:20:20,765 - logger.py:50 - Epoch 470 Training Summary: Avg Total Loss: 0.72503, Avg Main MSE: 0.72503, Time: 23.42s
2025-07-17 21:20:40,378 - logger.py:50 - Epoch 470 Summary | Train MSE (x10^-2): 72.5027 | Val MSE (x10^-2): 18.2160 | Time: 43.03s
2025-07-17 21:20:44,540 - logger.py:50 - Epoch: [471][0/6]	Total Loss: 0.73979	Main MSE (x10^-2): 73.9791	LR: 4.53e-06	EMPP_Raw: 1.46258
2025-07-17 21:21:03,840 - logger.py:50 - Epoch: [471][5/6]	Total Loss: 0.73366	Main MSE (x10^-2): 73.3655	LR: 4.53e-06	EMPP_Raw: 1.45059
2025-07-17 21:21:03,879 - logger.py:50 - Epoch 471 Training Summary: Avg Total Loss: 0.73366, Avg Main MSE: 0.73366, Time: 23.49s
2025-07-17 21:21:23,498 - logger.py:50 - Epoch 471 Summary | Train MSE (x10^-2): 73.3655 | Val MSE (x10^-2): 18.2452 | Time: 43.11s
2025-07-17 21:21:27,655 - logger.py:50 - Epoch: [472][0/6]	Total Loss: 0.72831	Main MSE (x10^-2): 72.8311	LR: 4.30e-06	EMPP_Raw: 1.44103
2025-07-17 21:21:47,105 - logger.py:50 - Epoch: [472][5/6]	Total Loss: 0.72329	Main MSE (x10^-2): 72.3285	LR: 4.30e-06	EMPP_Raw: 1.43015
2025-07-17 21:21:47,147 - logger.py:50 - Epoch 472 Training Summary: Avg Total Loss: 0.72329, Avg Main MSE: 0.72329, Time: 23.64s
2025-07-17 21:22:06,884 - logger.py:50 - Epoch 472 Summary | Train MSE (x10^-2): 72.3285 | Val MSE (x10^-2): 18.2696 | Time: 43.38s
2025-07-17 21:22:10,990 - logger.py:50 - Epoch: [473][0/6]	Total Loss: 0.72802	Main MSE (x10^-2): 72.8024	LR: 4.08e-06	EMPP_Raw: 1.43791
2025-07-17 21:22:30,281 - logger.py:50 - Epoch: [473][5/6]	Total Loss: 0.73604	Main MSE (x10^-2): 73.6041	LR: 4.08e-06	EMPP_Raw: 1.45559
2025-07-17 21:22:30,324 - logger.py:50 - Epoch 473 Training Summary: Avg Total Loss: 0.73604, Avg Main MSE: 0.73604, Time: 23.43s
2025-07-17 21:22:49,986 - logger.py:50 - Epoch 473 Summary | Train MSE (x10^-2): 73.6041 | Val MSE (x10^-2): 18.2861 | Time: 43.10s
2025-07-17 21:22:54,078 - logger.py:50 - Epoch: [474][0/6]	Total Loss: 0.72070	Main MSE (x10^-2): 72.0701	LR: 3.86e-06	EMPP_Raw: 1.42617
2025-07-17 21:23:13,387 - logger.py:50 - Epoch: [474][5/6]	Total Loss: 0.73346	Main MSE (x10^-2): 73.3462	LR: 3.86e-06	EMPP_Raw: 1.45040
2025-07-17 21:23:13,428 - logger.py:50 - Epoch 474 Training Summary: Avg Total Loss: 0.73346, Avg Main MSE: 0.73346, Time: 23.44s
2025-07-17 21:23:33,130 - logger.py:50 - Epoch 474 Summary | Train MSE (x10^-2): 73.3462 | Val MSE (x10^-2): 18.2783 | Time: 43.14s
2025-07-17 21:23:37,249 - logger.py:50 - Epoch: [475][0/6]	Total Loss: 0.73375	Main MSE (x10^-2): 73.3754	LR: 3.66e-06	EMPP_Raw: 1.45109
2025-07-17 21:23:56,662 - logger.py:50 - Epoch: [475][5/6]	Total Loss: 0.73133	Main MSE (x10^-2): 73.1334	LR: 3.66e-06	EMPP_Raw: 1.44605
2025-07-17 21:23:56,708 - logger.py:50 - Epoch 475 Training Summary: Avg Total Loss: 0.73133, Avg Main MSE: 0.73133, Time: 23.57s
2025-07-17 21:24:16,565 - logger.py:50 - Epoch 475 Summary | Train MSE (x10^-2): 73.1334 | Val MSE (x10^-2): 18.2561 | Time: 43.43s
2025-07-17 21:24:20,680 - logger.py:50 - Epoch: [476][0/6]	Total Loss: 0.73715	Main MSE (x10^-2): 73.7154	LR: 3.46e-06	EMPP_Raw: 1.45831
2025-07-17 21:24:40,055 - logger.py:50 - Epoch: [476][5/6]	Total Loss: 0.72472	Main MSE (x10^-2): 72.4724	LR: 3.46e-06	EMPP_Raw: 1.43327
2025-07-17 21:24:40,098 - logger.py:50 - Epoch 476 Training Summary: Avg Total Loss: 0.72472, Avg Main MSE: 0.72472, Time: 23.52s
2025-07-17 21:24:59,638 - logger.py:50 - Epoch 476 Summary | Train MSE (x10^-2): 72.4724 | Val MSE (x10^-2): 18.2458 | Time: 43.07s
2025-07-17 21:25:03,876 - logger.py:50 - Epoch: [477][0/6]	Total Loss: 0.72562	Main MSE (x10^-2): 72.5622	LR: 3.26e-06	EMPP_Raw: 1.43320
2025-07-17 21:25:23,202 - logger.py:50 - Epoch: [477][5/6]	Total Loss: 0.73355	Main MSE (x10^-2): 73.3547	LR: 3.26e-06	EMPP_Raw: 1.45057
2025-07-17 21:25:23,243 - logger.py:50 - Epoch 477 Training Summary: Avg Total Loss: 0.73355, Avg Main MSE: 0.73355, Time: 23.60s
2025-07-17 21:25:42,975 - logger.py:50 - Epoch 477 Summary | Train MSE (x10^-2): 73.3547 | Val MSE (x10^-2): 18.2501 | Time: 43.33s
2025-07-17 21:25:47,151 - logger.py:50 - Epoch: [478][0/6]	Total Loss: 0.73468	Main MSE (x10^-2): 73.4679	LR: 3.08e-06	EMPP_Raw: 1.45223
2025-07-17 21:26:06,544 - logger.py:50 - Epoch: [478][5/6]	Total Loss: 0.72347	Main MSE (x10^-2): 72.3475	LR: 3.08e-06	EMPP_Raw: 1.43050
2025-07-17 21:26:06,587 - logger.py:50 - Epoch 478 Training Summary: Avg Total Loss: 0.72347, Avg Main MSE: 0.72347, Time: 23.60s
2025-07-17 21:26:26,132 - logger.py:50 - Epoch 478 Summary | Train MSE (x10^-2): 72.3475 | Val MSE (x10^-2): 18.2683 | Time: 43.15s
2025-07-17 21:26:30,228 - logger.py:50 - Epoch: [479][0/6]	Total Loss: 0.72777	Main MSE (x10^-2): 72.7768	LR: 2.90e-06	EMPP_Raw: 1.43948
2025-07-17 21:26:49,608 - logger.py:50 - Epoch: [479][5/6]	Total Loss: 0.73405	Main MSE (x10^-2): 73.4055	LR: 2.90e-06	EMPP_Raw: 1.45219
2025-07-17 21:26:49,650 - logger.py:50 - Epoch 479 Training Summary: Avg Total Loss: 0.73405, Avg Main MSE: 0.73405, Time: 23.51s
2025-07-17 21:27:09,287 - logger.py:50 - Epoch 479 Summary | Train MSE (x10^-2): 73.4055 | Val MSE (x10^-2): 18.2801 | Time: 43.15s
2025-07-17 21:27:13,416 - logger.py:50 - Epoch: [480][0/6]	Total Loss: 0.71917	Main MSE (x10^-2): 71.9166	LR: 2.73e-06	EMPP_Raw: 1.42144
2025-07-17 21:27:32,779 - logger.py:50 - Epoch: [480][5/6]	Total Loss: 0.73432	Main MSE (x10^-2): 73.4325	LR: 2.73e-06	EMPP_Raw: 1.45224
2025-07-17 21:27:32,831 - logger.py:50 - Epoch 480 Training Summary: Avg Total Loss: 0.73432, Avg Main MSE: 0.73432, Time: 23.54s
2025-07-17 21:27:52,493 - logger.py:50 - Epoch 480 Summary | Train MSE (x10^-2): 73.4325 | Val MSE (x10^-2): 18.2779 | Time: 43.20s
2025-07-17 21:27:56,625 - logger.py:50 - Epoch: [481][0/6]	Total Loss: 0.73503	Main MSE (x10^-2): 73.5029	LR: 2.57e-06	EMPP_Raw: 1.45284
2025-07-17 21:28:15,889 - logger.py:50 - Epoch: [481][5/6]	Total Loss: 0.73105	Main MSE (x10^-2): 73.1051	LR: 2.57e-06	EMPP_Raw: 1.44551
2025-07-17 21:28:15,928 - logger.py:50 - Epoch 481 Training Summary: Avg Total Loss: 0.73105, Avg Main MSE: 0.73105, Time: 23.43s
2025-07-17 21:28:35,558 - logger.py:50 - Epoch 481 Summary | Train MSE (x10^-2): 73.1051 | Val MSE (x10^-2): 18.2695 | Time: 43.06s
2025-07-17 21:28:39,703 - logger.py:50 - Epoch: [482][0/6]	Total Loss: 0.72690	Main MSE (x10^-2): 72.6898	LR: 2.42e-06	EMPP_Raw: 1.43854
2025-07-17 21:28:58,983 - logger.py:50 - Epoch: [482][5/6]	Total Loss: 0.73081	Main MSE (x10^-2): 73.0807	LR: 2.42e-06	EMPP_Raw: 1.44554
2025-07-17 21:28:59,023 - logger.py:50 - Epoch 482 Training Summary: Avg Total Loss: 0.73081, Avg Main MSE: 0.73081, Time: 23.46s
2025-07-17 21:29:18,774 - logger.py:50 - Epoch 482 Summary | Train MSE (x10^-2): 73.0807 | Val MSE (x10^-2): 18.2607 | Time: 43.21s
2025-07-17 21:29:22,888 - logger.py:50 - Epoch: [483][0/6]	Total Loss: 0.75722	Main MSE (x10^-2): 75.7220	LR: 2.27e-06	EMPP_Raw: 1.49870
2025-07-17 21:29:42,140 - logger.py:50 - Epoch: [483][5/6]	Total Loss: 0.73229	Main MSE (x10^-2): 73.2290	LR: 2.27e-06	EMPP_Raw: 1.44850
2025-07-17 21:29:42,180 - logger.py:50 - Epoch 483 Training Summary: Avg Total Loss: 0.73229, Avg Main MSE: 0.73229, Time: 23.40s
2025-07-17 21:30:01,780 - logger.py:50 - Epoch 483 Summary | Train MSE (x10^-2): 73.2290 | Val MSE (x10^-2): 18.2613 | Time: 43.00s
2025-07-17 21:30:05,826 - logger.py:50 - Epoch: [484][0/6]	Total Loss: 0.74473	Main MSE (x10^-2): 74.4725	LR: 2.14e-06	EMPP_Raw: 1.47459
2025-07-17 21:30:25,139 - logger.py:50 - Epoch: [484][5/6]	Total Loss: 0.73770	Main MSE (x10^-2): 73.7699	LR: 2.14e-06	EMPP_Raw: 1.45929
2025-07-17 21:30:25,184 - logger.py:50 - Epoch 484 Training Summary: Avg Total Loss: 0.73770, Avg Main MSE: 0.73770, Time: 23.40s
2025-07-17 21:30:44,875 - logger.py:50 - Epoch 484 Summary | Train MSE (x10^-2): 73.7699 | Val MSE (x10^-2): 18.2614 | Time: 43.09s
2025-07-17 21:30:48,945 - logger.py:50 - Epoch: [485][0/6]	Total Loss: 0.74242	Main MSE (x10^-2): 74.2416	LR: 2.01e-06	EMPP_Raw: 1.46865
2025-07-17 21:31:08,217 - logger.py:50 - Epoch: [485][5/6]	Total Loss: 0.73174	Main MSE (x10^-2): 73.1739	LR: 2.01e-06	EMPP_Raw: 1.44765
2025-07-17 21:31:08,263 - logger.py:50 - Epoch 485 Training Summary: Avg Total Loss: 0.73174, Avg Main MSE: 0.73174, Time: 23.38s
2025-07-17 21:31:27,855 - logger.py:50 - Epoch 485 Summary | Train MSE (x10^-2): 73.1739 | Val MSE (x10^-2): 18.2476 | Time: 42.97s
2025-07-17 21:31:31,947 - logger.py:50 - Epoch: [486][0/6]	Total Loss: 0.72857	Main MSE (x10^-2): 72.8570	LR: 1.89e-06	EMPP_Raw: 1.44190
2025-07-17 21:31:51,208 - logger.py:50 - Epoch: [486][5/6]	Total Loss: 0.73091	Main MSE (x10^-2): 73.0910	LR: 1.89e-06	EMPP_Raw: 1.44561
2025-07-17 21:31:51,248 - logger.py:50 - Epoch 486 Training Summary: Avg Total Loss: 0.73091, Avg Main MSE: 0.73091, Time: 23.38s
2025-07-17 21:32:10,787 - logger.py:50 - Epoch 486 Summary | Train MSE (x10^-2): 73.0910 | Val MSE (x10^-2): 18.2370 | Time: 42.93s
2025-07-17 21:32:14,872 - logger.py:50 - Epoch: [487][0/6]	Total Loss: 0.72511	Main MSE (x10^-2): 72.5108	LR: 1.77e-06	EMPP_Raw: 1.43528
2025-07-17 21:32:34,178 - logger.py:50 - Epoch: [487][5/6]	Total Loss: 0.73102	Main MSE (x10^-2): 73.1023	LR: 1.77e-06	EMPP_Raw: 1.44583
2025-07-17 21:32:34,222 - logger.py:50 - Epoch 487 Training Summary: Avg Total Loss: 0.73102, Avg Main MSE: 0.73102, Time: 23.43s
2025-07-17 21:32:53,830 - logger.py:50 - Epoch 487 Summary | Train MSE (x10^-2): 73.1023 | Val MSE (x10^-2): 18.2344 | Time: 43.04s
2025-07-17 21:32:57,952 - logger.py:50 - Epoch: [488][0/6]	Total Loss: 0.72595	Main MSE (x10^-2): 72.5946	LR: 1.67e-06	EMPP_Raw: 1.43434
2025-07-17 21:33:17,221 - logger.py:50 - Epoch: [488][5/6]	Total Loss: 0.73057	Main MSE (x10^-2): 73.0567	LR: 1.67e-06	EMPP_Raw: 1.44501
2025-07-17 21:33:17,261 - logger.py:50 - Epoch 488 Training Summary: Avg Total Loss: 0.73057, Avg Main MSE: 0.73057, Time: 23.42s
2025-07-17 21:33:36,958 - logger.py:50 - Epoch 488 Summary | Train MSE (x10^-2): 73.0567 | Val MSE (x10^-2): 18.2383 | Time: 43.12s
2025-07-17 21:33:41,091 - logger.py:50 - Epoch: [489][0/6]	Total Loss: 0.73536	Main MSE (x10^-2): 73.5365	LR: 1.57e-06	EMPP_Raw: 1.45482
2025-07-17 21:34:00,466 - logger.py:50 - Epoch: [489][5/6]	Total Loss: 0.73761	Main MSE (x10^-2): 73.7611	LR: 1.57e-06	EMPP_Raw: 1.45901
2025-07-17 21:34:00,506 - logger.py:50 - Epoch 489 Training Summary: Avg Total Loss: 0.73761, Avg Main MSE: 0.73761, Time: 23.54s
2025-07-17 21:34:20,128 - logger.py:50 - Epoch 489 Summary | Train MSE (x10^-2): 73.7611 | Val MSE (x10^-2): 18.2442 | Time: 43.17s
2025-07-17 21:34:24,191 - logger.py:50 - Epoch: [490][0/6]	Total Loss: 0.72044	Main MSE (x10^-2): 72.0444	LR: 1.48e-06	EMPP_Raw: 1.42413
2025-07-17 21:34:43,378 - logger.py:50 - Epoch: [490][5/6]	Total Loss: 0.72254	Main MSE (x10^-2): 72.2545	LR: 1.48e-06	EMPP_Raw: 1.42874
2025-07-17 21:34:43,419 - logger.py:50 - Epoch 490 Training Summary: Avg Total Loss: 0.72254, Avg Main MSE: 0.72254, Time: 23.28s
2025-07-17 21:35:03,037 - logger.py:50 - Epoch 490 Summary | Train MSE (x10^-2): 72.2545 | Val MSE (x10^-2): 18.2551 | Time: 42.90s
2025-07-17 21:35:07,116 - logger.py:50 - Epoch: [491][0/6]	Total Loss: 0.73117	Main MSE (x10^-2): 73.1170	LR: 1.39e-06	EMPP_Raw: 1.44702
2025-07-17 21:35:26,349 - logger.py:50 - Epoch: [491][5/6]	Total Loss: 0.72552	Main MSE (x10^-2): 72.5525	LR: 1.39e-06	EMPP_Raw: 1.43487
2025-07-17 21:35:26,391 - logger.py:50 - Epoch 491 Training Summary: Avg Total Loss: 0.72552, Avg Main MSE: 0.72552, Time: 23.35s
2025-07-17 21:35:45,945 - logger.py:50 - Epoch 491 Summary | Train MSE (x10^-2): 72.5525 | Val MSE (x10^-2): 18.2572 | Time: 42.90s
2025-07-17 21:35:50,049 - logger.py:50 - Epoch: [492][0/6]	Total Loss: 0.73829	Main MSE (x10^-2): 73.8289	LR: 1.32e-06	EMPP_Raw: 1.45984
2025-07-17 21:36:09,325 - logger.py:50 - Epoch: [492][5/6]	Total Loss: 0.73281	Main MSE (x10^-2): 73.2810	LR: 1.32e-06	EMPP_Raw: 1.44942
2025-07-17 21:36:09,365 - logger.py:50 - Epoch 492 Training Summary: Avg Total Loss: 0.73281, Avg Main MSE: 0.73281, Time: 23.41s
2025-07-17 21:36:28,913 - logger.py:50 - Epoch 492 Summary | Train MSE (x10^-2): 73.2810 | Val MSE (x10^-2): 18.2594 | Time: 42.96s
2025-07-17 21:36:32,991 - logger.py:50 - Epoch: [493][0/6]	Total Loss: 0.71916	Main MSE (x10^-2): 71.9162	LR: 1.25e-06	EMPP_Raw: 1.42197
2025-07-17 21:36:52,235 - logger.py:50 - Epoch: [493][5/6]	Total Loss: 0.72524	Main MSE (x10^-2): 72.5240	LR: 1.25e-06	EMPP_Raw: 1.43433
2025-07-17 21:36:52,274 - logger.py:50 - Epoch 493 Training Summary: Avg Total Loss: 0.72524, Avg Main MSE: 0.72524, Time: 23.36s
2025-07-17 21:37:11,983 - logger.py:50 - Epoch 493 Summary | Train MSE (x10^-2): 72.5240 | Val MSE (x10^-2): 18.2583 | Time: 43.07s
2025-07-17 21:37:16,065 - logger.py:50 - Epoch: [494][0/6]	Total Loss: 0.75471	Main MSE (x10^-2): 75.4710	LR: 1.19e-06	EMPP_Raw: 1.49245
2025-07-17 21:37:35,313 - logger.py:50 - Epoch: [494][5/6]	Total Loss: 0.73781	Main MSE (x10^-2): 73.7806	LR: 1.19e-06	EMPP_Raw: 1.45943
2025-07-17 21:37:35,355 - logger.py:50 - Epoch 494 Training Summary: Avg Total Loss: 0.73781, Avg Main MSE: 0.73781, Time: 23.36s
2025-07-17 21:37:54,945 - logger.py:50 - Epoch 494 Summary | Train MSE (x10^-2): 73.7806 | Val MSE (x10^-2): 18.2576 | Time: 42.96s
2025-07-17 21:37:59,043 - logger.py:50 - Epoch: [495][0/6]	Total Loss: 0.72367	Main MSE (x10^-2): 72.3668	LR: 1.14e-06	EMPP_Raw: 1.43058
2025-07-17 21:38:18,383 - logger.py:50 - Epoch: [495][5/6]	Total Loss: 0.72974	Main MSE (x10^-2): 72.9740	LR: 1.14e-06	EMPP_Raw: 1.44314
2025-07-17 21:38:18,423 - logger.py:50 - Epoch 495 Training Summary: Avg Total Loss: 0.72974, Avg Main MSE: 0.72974, Time: 23.47s
2025-07-17 21:38:38,041 - logger.py:50 - Epoch 495 Summary | Train MSE (x10^-2): 72.9740 | Val MSE (x10^-2): 18.2574 | Time: 43.09s
2025-07-17 21:38:42,180 - logger.py:50 - Epoch: [496][0/6]	Total Loss: 0.71000	Main MSE (x10^-2): 71.0000	LR: 1.10e-06	EMPP_Raw: 1.40382
2025-07-17 21:39:01,466 - logger.py:50 - Epoch: [496][5/6]	Total Loss: 0.73698	Main MSE (x10^-2): 73.6982	LR: 1.10e-06	EMPP_Raw: 1.45772
2025-07-17 21:39:01,509 - logger.py:50 - Epoch 496 Training Summary: Avg Total Loss: 0.73698, Avg Main MSE: 0.73698, Time: 23.46s
2025-07-17 21:39:21,090 - logger.py:50 - Epoch 496 Summary | Train MSE (x10^-2): 73.6982 | Val MSE (x10^-2): 18.2527 | Time: 43.04s
2025-07-17 21:39:25,198 - logger.py:50 - Epoch: [497][0/6]	Total Loss: 0.73770	Main MSE (x10^-2): 73.7700	LR: 1.06e-06	EMPP_Raw: 1.45991
2025-07-17 21:39:44,430 - logger.py:50 - Epoch: [497][5/6]	Total Loss: 0.73404	Main MSE (x10^-2): 73.4043	LR: 1.06e-06	EMPP_Raw: 1.45163
2025-07-17 21:39:44,473 - logger.py:50 - Epoch 497 Training Summary: Avg Total Loss: 0.73404, Avg Main MSE: 0.73404, Time: 23.37s
2025-07-17 21:40:04,158 - logger.py:50 - Epoch 497 Summary | Train MSE (x10^-2): 73.4043 | Val MSE (x10^-2): 18.2526 | Time: 43.06s
2025-07-17 21:40:08,268 - logger.py:50 - Epoch: [498][0/6]	Total Loss: 0.72952	Main MSE (x10^-2): 72.9516	LR: 1.04e-06	EMPP_Raw: 1.44382
2025-07-17 21:40:27,619 - logger.py:50 - Epoch: [498][5/6]	Total Loss: 0.73119	Main MSE (x10^-2): 73.1192	LR: 1.04e-06	EMPP_Raw: 1.44635
2025-07-17 21:40:27,659 - logger.py:50 - Epoch 498 Training Summary: Avg Total Loss: 0.73119, Avg Main MSE: 0.73119, Time: 23.49s
2025-07-17 21:40:47,234 - logger.py:50 - Epoch 498 Summary | Train MSE (x10^-2): 73.1192 | Val MSE (x10^-2): 18.2535 | Time: 43.07s
2025-07-17 21:40:51,296 - logger.py:50 - Epoch: [499][0/6]	Total Loss: 0.74118	Main MSE (x10^-2): 74.1183	LR: 1.02e-06	EMPP_Raw: 1.46512
2025-07-17 21:41:10,558 - logger.py:50 - Epoch: [499][5/6]	Total Loss: 0.73645	Main MSE (x10^-2): 73.6446	LR: 1.02e-06	EMPP_Raw: 1.45684
2025-07-17 21:41:10,607 - logger.py:50 - Epoch 499 Training Summary: Avg Total Loss: 0.73645, Avg Main MSE: 0.73645, Time: 23.36s
2025-07-17 21:41:30,182 - logger.py:50 - Epoch 499 Summary | Train MSE (x10^-2): 73.6446 | Val MSE (x10^-2): 18.2516 | Time: 42.94s
2025-07-17 21:41:30,188 - logger.py:50 - --- Finished training for aspirin ---
2025-07-17 21:41:30,188 - logger.py:50 - Final Best Val MSE (at Epoch 44): 0.164067 (x10^-2: 16.4067)
2025-07-17 21:41:30,189 - logger.py:50 - Final Test MSE (at Best Val Epoch): 0.161888 (x10^-2: 16.1888)
2025-07-17 21:41:30,200 - logger.py:50 - --- Starting training for benzene ---
2025-07-17 21:41:30,200 - logger.py:50 - Namespace(amp=False, batch_size=80, clip_grad=1.0, contrastive_aug_mask_ratio=0.15, contrastive_loss_weight=0.1, contrastive_mask_token_idx=0, contrastive_prioritize_heteroatoms=False, contrastive_projection_dim=128, contrastive_temp=0.1, cooldown_epochs=10, data_path='data/md17', decay_rate=0.1, delta_frame=3000, device='cuda:0', drop_path=0.0, empp_atom_type_embed_irreps='16x0e', empp_loss_weight=0.5, empp_num_mask=1, empp_pos_pred_num_s2_channels=32, empp_pos_pred_res_s2grid=100, empp_pos_pred_temp_label=0.1, empp_pos_pred_temp_softmax=0.1, empp_prioritize_heteroatoms=True, empp_ssp_feature_dim='16x0e', enable_contrastive=False, epochs=500, exp_name='md17_final_run_20250717_152800', logger=<logger.FileLogger object at 0x7f24b6ddf520>, loss='l2', lr=0.0004, max_test_samples=2000, max_train_samples=500, max_val_samples=2000, min_lr=1e-06, model_name='graph_attention_transformer_nonlinear_l2', molecule_type='benzene', momentum=0.9, num_basis=128, opt='adamw', opt_betas=None, opt_eps=1e-08, output_dir='outputs/md17_final_run_20250717_152800', patience_epochs=10, pin_mem=True, print_freq=50, radius=5.0, sched='cosine', seed=42, ssp=True, warmup_epochs=10, warmup_lr=1e-06, weight_decay=1e-06, workers=8)
2025-07-17 21:41:30,201 - logger.py:50 - Loading datasets...
2025-07-17 21:41:48,788 - logger.py:50 - Creating model...
2025-07-17 21:41:56,987 - logger.py:50 - Number of params: 3,205,881
2025-07-17 21:42:01,037 - logger.py:50 - Epoch: [0][0/6]	Total Loss: 3.86992	Main MSE (x10^-2): 386.9919	LR: 1.00e-06	EMPP_Raw: 2.50323
2025-07-17 21:42:17,287 - logger.py:50 - Epoch: [0][5/6]	Total Loss: 3.83059	Main MSE (x10^-2): 383.0586	LR: 1.00e-06	EMPP_Raw: 2.48497
2025-07-17 21:42:17,333 - logger.py:50 - Epoch 0 Training Summary: Avg Total Loss: 3.83059, Avg Main MSE: 3.83059, Time: 20.34s
2025-07-17 21:42:54,328 - logger.py:50 - *** New Best Val MSE (x10^-2): 263.7404, Corresponding Test MSE (x10^-2): 264.6415 at Epoch 0 ***
2025-07-17 21:42:54,373 - logger.py:50 - Epoch 0 Summary | Train MSE (x10^-2): 383.0586 | Val MSE (x10^-2): 263.7404 | Time: 57.38s
2025-07-17 21:42:57,495 - logger.py:50 - Epoch: [1][0/6]	Total Loss: 3.78068	Main MSE (x10^-2): 378.0682	LR: 1.00e-06	EMPP_Raw: 2.35444
2025-07-17 21:43:11,665 - logger.py:50 - Epoch: [1][5/6]	Total Loss: 3.80733	Main MSE (x10^-2): 380.7329	LR: 1.00e-06	EMPP_Raw: 2.41785
2025-07-17 21:43:11,705 - logger.py:50 - Epoch 1 Training Summary: Avg Total Loss: 3.80733, Avg Main MSE: 3.80733, Time: 17.33s
2025-07-17 21:43:48,580 - logger.py:50 - *** New Best Val MSE (x10^-2): 263.6241, Corresponding Test MSE (x10^-2): 264.5251 at Epoch 1 ***
2025-07-17 21:43:48,626 - logger.py:50 - Epoch 1 Summary | Train MSE (x10^-2): 380.7329 | Val MSE (x10^-2): 263.6241 | Time: 54.25s
2025-07-17 21:43:51,787 - logger.py:50 - Epoch: [2][0/6]	Total Loss: 3.81467	Main MSE (x10^-2): 381.4672	LR: 4.09e-05	EMPP_Raw: 2.36567
2025-07-17 21:44:05,969 - logger.py:50 - Epoch: [2][5/6]	Total Loss: 3.63828	Main MSE (x10^-2): 363.8280	LR: 4.09e-05	EMPP_Raw: 2.14978
2025-07-17 21:44:06,009 - logger.py:50 - Epoch 2 Training Summary: Avg Total Loss: 3.63828, Avg Main MSE: 3.63828, Time: 17.38s
2025-07-17 21:44:43,012 - logger.py:50 - *** New Best Val MSE (x10^-2): 259.0421, Corresponding Test MSE (x10^-2): 259.9367 at Epoch 2 ***
2025-07-17 21:44:43,061 - logger.py:50 - Epoch 2 Summary | Train MSE (x10^-2): 363.8280 | Val MSE (x10^-2): 259.0421 | Time: 54.43s
2025-07-17 21:44:46,141 - logger.py:50 - Epoch: [3][0/6]	Total Loss: 3.41148	Main MSE (x10^-2): 341.1476	LR: 8.08e-05	EMPP_Raw: 1.93549
2025-07-17 21:45:00,530 - logger.py:50 - Epoch: [3][5/6]	Total Loss: 3.46213	Main MSE (x10^-2): 346.2126	LR: 8.08e-05	EMPP_Raw: 1.93870
2025-07-17 21:45:00,572 - logger.py:50 - Epoch 3 Training Summary: Avg Total Loss: 3.46213, Avg Main MSE: 3.46213, Time: 17.51s
2025-07-17 21:45:37,249 - logger.py:50 - *** New Best Val MSE (x10^-2): 246.8181, Corresponding Test MSE (x10^-2): 247.6890 at Epoch 3 ***
2025-07-17 21:45:37,297 - logger.py:50 - Epoch 3 Summary | Train MSE (x10^-2): 346.2126 | Val MSE (x10^-2): 246.8181 | Time: 54.24s
2025-07-17 21:45:40,431 - logger.py:50 - Epoch: [4][0/6]	Total Loss: 3.26540	Main MSE (x10^-2): 326.5403	LR: 1.21e-04	EMPP_Raw: 1.79507
2025-07-17 21:45:54,741 - logger.py:50 - Epoch: [4][5/6]	Total Loss: 3.25011	Main MSE (x10^-2): 325.0113	LR: 1.21e-04	EMPP_Raw: 1.83178
2025-07-17 21:45:54,778 - logger.py:50 - Epoch 4 Training Summary: Avg Total Loss: 3.25011, Avg Main MSE: 3.25011, Time: 17.48s
2025-07-17 21:46:31,525 - logger.py:50 - *** New Best Val MSE (x10^-2): 224.8717, Corresponding Test MSE (x10^-2): 225.6848 at Epoch 4 ***
2025-07-17 21:46:31,571 - logger.py:50 - Epoch 4 Summary | Train MSE (x10^-2): 325.0113 | Val MSE (x10^-2): 224.8717 | Time: 54.27s
2025-07-17 21:46:34,759 - logger.py:50 - Epoch: [5][0/6]	Total Loss: 3.11884	Main MSE (x10^-2): 311.8844	LR: 1.61e-04	EMPP_Raw: 1.83399
2025-07-17 21:46:48,799 - logger.py:50 - Epoch: [5][5/6]	Total Loss: 3.03612	Main MSE (x10^-2): 303.6117	LR: 1.61e-04	EMPP_Raw: 1.83057
2025-07-17 21:46:48,835 - logger.py:50 - Epoch 5 Training Summary: Avg Total Loss: 3.03612, Avg Main MSE: 3.03612, Time: 17.26s
2025-07-17 21:47:25,641 - logger.py:50 - *** New Best Val MSE (x10^-2): 204.9837, Corresponding Test MSE (x10^-2): 205.6741 at Epoch 5 ***
2025-07-17 21:47:25,688 - logger.py:50 - Epoch 5 Summary | Train MSE (x10^-2): 303.6117 | Val MSE (x10^-2): 204.9837 | Time: 54.12s
2025-07-17 21:47:29,047 - logger.py:50 - Epoch: [6][0/6]	Total Loss: 2.94086	Main MSE (x10^-2): 294.0864	LR: 2.00e-04	EMPP_Raw: 1.78019
2025-07-17 21:47:43,530 - logger.py:50 - Epoch: [6][5/6]	Total Loss: 2.90871	Main MSE (x10^-2): 290.8711	LR: 2.00e-04	EMPP_Raw: 1.74720
2025-07-17 21:47:43,571 - logger.py:50 - Epoch 6 Training Summary: Avg Total Loss: 2.90871, Avg Main MSE: 2.90871, Time: 17.88s
2025-07-17 21:48:02,022 - logger.py:50 - Epoch 6 Summary | Train MSE (x10^-2): 290.8711 | Val MSE (x10^-2): 206.4229 | Time: 36.33s
2025-07-17 21:48:05,255 - logger.py:50 - Epoch: [7][0/6]	Total Loss: 2.97851	Main MSE (x10^-2): 297.8511	LR: 2.40e-04	EMPP_Raw: 1.76056
2025-07-17 21:48:19,406 - logger.py:50 - Epoch: [7][5/6]	Total Loss: 2.89951	Main MSE (x10^-2): 289.9511	LR: 2.40e-04	EMPP_Raw: 1.78696
2025-07-17 21:48:19,450 - logger.py:50 - Epoch 7 Training Summary: Avg Total Loss: 2.89951, Avg Main MSE: 2.89951, Time: 17.42s
2025-07-17 21:48:56,160 - logger.py:50 - *** New Best Val MSE (x10^-2): 202.5931, Corresponding Test MSE (x10^-2): 203.2726 at Epoch 7 ***
2025-07-17 21:48:56,208 - logger.py:50 - Epoch 7 Summary | Train MSE (x10^-2): 289.9511 | Val MSE (x10^-2): 202.5931 | Time: 54.18s
2025-07-17 21:48:59,390 - logger.py:50 - Epoch: [8][0/6]	Total Loss: 2.86681	Main MSE (x10^-2): 286.6807	LR: 2.80e-04	EMPP_Raw: 1.85890
2025-07-17 21:49:13,431 - logger.py:50 - Epoch: [8][5/6]	Total Loss: 2.87685	Main MSE (x10^-2): 287.6848	LR: 2.80e-04	EMPP_Raw: 1.77742
2025-07-17 21:49:13,468 - logger.py:50 - Epoch 8 Training Summary: Avg Total Loss: 2.87685, Avg Main MSE: 2.87685, Time: 17.26s
2025-07-17 21:49:50,209 - logger.py:50 - *** New Best Val MSE (x10^-2): 202.3529, Corresponding Test MSE (x10^-2): 203.0015 at Epoch 8 ***
2025-07-17 21:49:50,256 - logger.py:50 - Epoch 8 Summary | Train MSE (x10^-2): 287.6848 | Val MSE (x10^-2): 202.3529 | Time: 54.05s
2025-07-17 21:49:53,307 - logger.py:50 - Epoch: [9][0/6]	Total Loss: 2.77653	Main MSE (x10^-2): 277.6532	LR: 3.20e-04	EMPP_Raw: 1.62021
2025-07-17 21:50:07,411 - logger.py:50 - Epoch: [9][5/6]	Total Loss: 2.86386	Main MSE (x10^-2): 286.3865	LR: 3.20e-04	EMPP_Raw: 1.74964
2025-07-17 21:50:07,450 - logger.py:50 - Epoch 9 Training Summary: Avg Total Loss: 2.86386, Avg Main MSE: 2.86386, Time: 17.19s
2025-07-17 21:50:25,932 - logger.py:50 - Epoch 9 Summary | Train MSE (x10^-2): 286.3865 | Val MSE (x10^-2): 202.5703 | Time: 35.68s
2025-07-17 21:50:28,998 - logger.py:50 - Epoch: [10][0/6]	Total Loss: 2.87458	Main MSE (x10^-2): 287.4583	LR: 3.60e-04	EMPP_Raw: 1.88839
2025-07-17 21:50:43,120 - logger.py:50 - Epoch: [10][5/6]	Total Loss: 2.85312	Main MSE (x10^-2): 285.3117	LR: 3.60e-04	EMPP_Raw: 1.73837
2025-07-17 21:50:43,160 - logger.py:50 - Epoch 10 Training Summary: Avg Total Loss: 2.85312, Avg Main MSE: 2.85312, Time: 17.22s
2025-07-17 21:51:20,525 - logger.py:50 - *** New Best Val MSE (x10^-2): 202.3422, Corresponding Test MSE (x10^-2): 203.0147 at Epoch 10 ***
2025-07-17 21:51:20,572 - logger.py:50 - Epoch 10 Summary | Train MSE (x10^-2): 285.3117 | Val MSE (x10^-2): 202.3422 | Time: 54.63s
2025-07-17 21:51:23,663 - logger.py:50 - Epoch: [11][0/6]	Total Loss: 2.78444	Main MSE (x10^-2): 278.4444	LR: 4.00e-04	EMPP_Raw: 1.54385
2025-07-17 21:51:37,796 - logger.py:50 - Epoch: [11][5/6]	Total Loss: 2.85850	Main MSE (x10^-2): 285.8498	LR: 4.00e-04	EMPP_Raw: 1.73040
2025-07-17 21:51:37,834 - logger.py:50 - Epoch 11 Training Summary: Avg Total Loss: 2.85850, Avg Main MSE: 2.85850, Time: 17.26s
2025-07-17 21:52:14,696 - logger.py:50 - *** New Best Val MSE (x10^-2): 202.2972, Corresponding Test MSE (x10^-2): 202.9300 at Epoch 11 ***
2025-07-17 21:52:14,744 - logger.py:50 - Epoch 11 Summary | Train MSE (x10^-2): 285.8498 | Val MSE (x10^-2): 202.2972 | Time: 54.17s
2025-07-17 21:52:17,829 - logger.py:50 - Epoch: [12][0/6]	Total Loss: 2.90579	Main MSE (x10^-2): 290.5795	LR: 4.00e-04	EMPP_Raw: 1.74082
2025-07-17 21:52:32,021 - logger.py:50 - Epoch: [12][5/6]	Total Loss: 2.83067	Main MSE (x10^-2): 283.0668	LR: 4.00e-04	EMPP_Raw: 1.69221
2025-07-17 21:52:32,067 - logger.py:50 - Epoch 12 Training Summary: Avg Total Loss: 2.83067, Avg Main MSE: 2.83067, Time: 17.32s
2025-07-17 21:53:08,886 - logger.py:50 - *** New Best Val MSE (x10^-2): 201.8890, Corresponding Test MSE (x10^-2): 202.5331 at Epoch 12 ***
2025-07-17 21:53:08,933 - logger.py:50 - Epoch 12 Summary | Train MSE (x10^-2): 283.0668 | Val MSE (x10^-2): 201.8890 | Time: 54.19s
2025-07-17 21:53:12,087 - logger.py:50 - Epoch: [13][0/6]	Total Loss: 2.91809	Main MSE (x10^-2): 291.8091	LR: 3.99e-04	EMPP_Raw: 1.78868
2025-07-17 21:53:26,385 - logger.py:50 - Epoch: [13][5/6]	Total Loss: 2.85128	Main MSE (x10^-2): 285.1278	LR: 3.99e-04	EMPP_Raw: 1.73529
2025-07-17 21:53:26,432 - logger.py:50 - Epoch 13 Training Summary: Avg Total Loss: 2.85128, Avg Main MSE: 2.85128, Time: 17.50s
2025-07-17 21:54:03,127 - logger.py:50 - *** New Best Val MSE (x10^-2): 201.8849, Corresponding Test MSE (x10^-2): 202.5214 at Epoch 13 ***
2025-07-17 21:54:03,173 - logger.py:50 - Epoch 13 Summary | Train MSE (x10^-2): 285.1278 | Val MSE (x10^-2): 201.8849 | Time: 54.24s
2025-07-17 21:54:06,195 - logger.py:50 - Epoch: [14][0/6]	Total Loss: 2.87254	Main MSE (x10^-2): 287.2543	LR: 3.99e-04	EMPP_Raw: 1.75185
2025-07-17 21:54:20,485 - logger.py:50 - Epoch: [14][5/6]	Total Loss: 2.84404	Main MSE (x10^-2): 284.4040	LR: 3.99e-04	EMPP_Raw: 1.70271
2025-07-17 21:54:20,525 - logger.py:50 - Epoch 14 Training Summary: Avg Total Loss: 2.84404, Avg Main MSE: 2.84404, Time: 17.35s
2025-07-17 21:54:38,792 - logger.py:50 - Epoch 14 Summary | Train MSE (x10^-2): 284.4040 | Val MSE (x10^-2): 202.3973 | Time: 35.62s
2025-07-17 21:54:41,824 - logger.py:50 - Epoch: [15][0/6]	Total Loss: 2.91048	Main MSE (x10^-2): 291.0485	LR: 3.99e-04	EMPP_Raw: 1.73362
2025-07-17 21:54:55,995 - logger.py:50 - Epoch: [15][5/6]	Total Loss: 2.82495	Main MSE (x10^-2): 282.4952	LR: 3.99e-04	EMPP_Raw: 1.67359
2025-07-17 21:54:56,037 - logger.py:50 - Epoch 15 Training Summary: Avg Total Loss: 2.82495, Avg Main MSE: 2.82495, Time: 17.23s
2025-07-17 21:55:32,726 - logger.py:50 - *** New Best Val MSE (x10^-2): 201.8485, Corresponding Test MSE (x10^-2): 202.4749 at Epoch 15 ***
2025-07-17 21:55:32,773 - logger.py:50 - Epoch 15 Summary | Train MSE (x10^-2): 282.4952 | Val MSE (x10^-2): 201.8485 | Time: 53.97s
2025-07-17 21:55:35,895 - logger.py:50 - Epoch: [16][0/6]	Total Loss: 2.87856	Main MSE (x10^-2): 287.8564	LR: 3.99e-04	EMPP_Raw: 1.61492
2025-07-17 21:55:50,106 - logger.py:50 - Epoch: [16][5/6]	Total Loss: 2.85993	Main MSE (x10^-2): 285.9932	LR: 3.99e-04	EMPP_Raw: 1.74859
2025-07-17 21:55:50,147 - logger.py:50 - Epoch 16 Training Summary: Avg Total Loss: 2.85993, Avg Main MSE: 2.85993, Time: 17.37s
2025-07-17 21:56:08,560 - logger.py:50 - Epoch 16 Summary | Train MSE (x10^-2): 285.9932 | Val MSE (x10^-2): 201.9386 | Time: 35.79s
2025-07-17 21:56:11,635 - logger.py:50 - Epoch: [17][0/6]	Total Loss: 2.71455	Main MSE (x10^-2): 271.4554	LR: 3.99e-04	EMPP_Raw: 1.62767
2025-07-17 21:56:25,757 - logger.py:50 - Epoch: [17][5/6]	Total Loss: 2.81007	Main MSE (x10^-2): 281.0069	LR: 3.99e-04	EMPP_Raw: 1.66602
2025-07-17 21:56:25,808 - logger.py:50 - Epoch 17 Training Summary: Avg Total Loss: 2.81007, Avg Main MSE: 2.81007, Time: 17.24s
2025-07-17 21:56:44,490 - logger.py:50 - Epoch 17 Summary | Train MSE (x10^-2): 281.0069 | Val MSE (x10^-2): 202.2750 | Time: 35.93s
2025-07-17 21:56:47,550 - logger.py:50 - Epoch: [18][0/6]	Total Loss: 2.87074	Main MSE (x10^-2): 287.0744	LR: 3.99e-04	EMPP_Raw: 1.79165
2025-07-17 21:57:01,737 - logger.py:50 - Epoch: [18][5/6]	Total Loss: 2.85023	Main MSE (x10^-2): 285.0231	LR: 3.99e-04	EMPP_Raw: 1.71776
2025-07-17 21:57:01,799 - logger.py:50 - Epoch 18 Training Summary: Avg Total Loss: 2.85023, Avg Main MSE: 2.85023, Time: 17.30s
2025-07-17 21:57:20,403 - logger.py:50 - Epoch 18 Summary | Train MSE (x10^-2): 285.0231 | Val MSE (x10^-2): 204.0058 | Time: 35.91s
2025-07-17 21:57:23,450 - logger.py:50 - Epoch: [19][0/6]	Total Loss: 2.76419	Main MSE (x10^-2): 276.4191	LR: 3.99e-04	EMPP_Raw: 1.55109
2025-07-17 21:57:37,517 - logger.py:50 - Epoch: [19][5/6]	Total Loss: 2.82987	Main MSE (x10^-2): 282.9870	LR: 3.99e-04	EMPP_Raw: 1.67818
2025-07-17 21:57:37,558 - logger.py:50 - Epoch 19 Training Summary: Avg Total Loss: 2.82987, Avg Main MSE: 2.82987, Time: 17.15s
2025-07-17 21:57:55,866 - logger.py:50 - Epoch 19 Summary | Train MSE (x10^-2): 282.9870 | Val MSE (x10^-2): 202.8970 | Time: 35.46s
2025-07-17 21:57:59,079 - logger.py:50 - Epoch: [20][0/6]	Total Loss: 2.80206	Main MSE (x10^-2): 280.2062	LR: 3.99e-04	EMPP_Raw: 1.65098
2025-07-17 21:58:13,120 - logger.py:50 - Epoch: [20][5/6]	Total Loss: 2.80835	Main MSE (x10^-2): 280.8345	LR: 3.99e-04	EMPP_Raw: 1.65038
2025-07-17 21:58:13,162 - logger.py:50 - Epoch 20 Training Summary: Avg Total Loss: 2.80835, Avg Main MSE: 2.80835, Time: 17.29s
2025-07-17 21:58:31,475 - logger.py:50 - Epoch 20 Summary | Train MSE (x10^-2): 280.8345 | Val MSE (x10^-2): 202.9444 | Time: 35.60s
2025-07-17 21:58:34,708 - logger.py:50 - Epoch: [21][0/6]	Total Loss: 2.88122	Main MSE (x10^-2): 288.1216	LR: 3.98e-04	EMPP_Raw: 1.60934
2025-07-17 21:58:48,771 - logger.py:50 - Epoch: [21][5/6]	Total Loss: 2.82657	Main MSE (x10^-2): 282.6567	LR: 3.98e-04	EMPP_Raw: 1.68224
2025-07-17 21:58:48,815 - logger.py:50 - Epoch 21 Training Summary: Avg Total Loss: 2.82657, Avg Main MSE: 2.82657, Time: 17.33s
2025-07-17 21:59:25,575 - logger.py:50 - *** New Best Val MSE (x10^-2): 201.8294, Corresponding Test MSE (x10^-2): 202.4309 at Epoch 21 ***
2025-07-17 21:59:25,624 - logger.py:50 - Epoch 21 Summary | Train MSE (x10^-2): 282.6567 | Val MSE (x10^-2): 201.8294 | Time: 54.14s
2025-07-17 21:59:28,650 - logger.py:50 - Epoch: [22][0/6]	Total Loss: 2.78012	Main MSE (x10^-2): 278.0119	LR: 3.98e-04	EMPP_Raw: 1.65006
2025-07-17 21:59:42,712 - logger.py:50 - Epoch: [22][5/6]	Total Loss: 2.80271	Main MSE (x10^-2): 280.2709	LR: 3.98e-04	EMPP_Raw: 1.63326
2025-07-17 21:59:42,753 - logger.py:50 - Epoch 22 Training Summary: Avg Total Loss: 2.80271, Avg Main MSE: 2.80271, Time: 17.12s
2025-07-17 22:00:01,127 - logger.py:50 - Epoch 22 Summary | Train MSE (x10^-2): 280.2709 | Val MSE (x10^-2): 201.8307 | Time: 35.50s
2025-07-17 22:00:04,317 - logger.py:50 - Epoch: [23][0/6]	Total Loss: 2.84540	Main MSE (x10^-2): 284.5396	LR: 3.98e-04	EMPP_Raw: 1.68580
2025-07-17 22:00:18,339 - logger.py:50 - Epoch: [23][5/6]	Total Loss: 2.81955	Main MSE (x10^-2): 281.9552	LR: 3.98e-04	EMPP_Raw: 1.67265
2025-07-17 22:00:18,379 - logger.py:50 - Epoch 23 Training Summary: Avg Total Loss: 2.81955, Avg Main MSE: 2.81955, Time: 17.24s
2025-07-17 22:00:36,731 - logger.py:50 - Epoch 23 Summary | Train MSE (x10^-2): 281.9552 | Val MSE (x10^-2): 202.1551 | Time: 35.60s
2025-07-17 22:00:39,951 - logger.py:50 - Epoch: [24][0/6]	Total Loss: 2.93313	Main MSE (x10^-2): 293.3133	LR: 3.98e-04	EMPP_Raw: 1.69370
2025-07-17 22:00:54,005 - logger.py:50 - Epoch: [24][5/6]	Total Loss: 2.82075	Main MSE (x10^-2): 282.0749	LR: 3.98e-04	EMPP_Raw: 1.67885
2025-07-17 22:00:54,048 - logger.py:50 - Epoch 24 Training Summary: Avg Total Loss: 2.82075, Avg Main MSE: 2.82075, Time: 17.31s
2025-07-17 22:01:12,472 - logger.py:50 - Epoch 24 Summary | Train MSE (x10^-2): 282.0749 | Val MSE (x10^-2): 202.1014 | Time: 35.73s
2025-07-17 22:01:15,525 - logger.py:50 - Epoch: [25][0/6]	Total Loss: 2.72075	Main MSE (x10^-2): 272.0751	LR: 3.98e-04	EMPP_Raw: 1.61214
2025-07-17 22:01:29,755 - logger.py:50 - Epoch: [25][5/6]	Total Loss: 2.79337	Main MSE (x10^-2): 279.3373	LR: 3.98e-04	EMPP_Raw: 1.61905
2025-07-17 22:01:29,796 - logger.py:50 - Epoch 25 Training Summary: Avg Total Loss: 2.79337, Avg Main MSE: 2.79337, Time: 17.31s
2025-07-17 22:01:48,198 - logger.py:50 - Epoch 25 Summary | Train MSE (x10^-2): 279.3373 | Val MSE (x10^-2): 202.0960 | Time: 35.72s
2025-07-17 22:01:51,251 - logger.py:50 - Epoch: [26][0/6]	Total Loss: 2.83830	Main MSE (x10^-2): 283.8302	LR: 3.98e-04	EMPP_Raw: 1.65565
2025-07-17 22:02:05,364 - logger.py:50 - Epoch: [26][5/6]	Total Loss: 2.80237	Main MSE (x10^-2): 280.2374	LR: 3.98e-04	EMPP_Raw: 1.63485
2025-07-17 22:02:05,408 - logger.py:50 - Epoch 26 Training Summary: Avg Total Loss: 2.80237, Avg Main MSE: 2.80237, Time: 17.20s
2025-07-17 22:02:23,879 - logger.py:50 - Epoch 26 Summary | Train MSE (x10^-2): 280.2374 | Val MSE (x10^-2): 202.0764 | Time: 35.68s
2025-07-17 22:02:26,967 - logger.py:50 - Epoch: [27][0/6]	Total Loss: 2.79957	Main MSE (x10^-2): 279.9574	LR: 3.97e-04	EMPP_Raw: 1.62511
2025-07-17 22:02:41,016 - logger.py:50 - Epoch: [27][5/6]	Total Loss: 2.77660	Main MSE (x10^-2): 277.6602	LR: 3.97e-04	EMPP_Raw: 1.59856
2025-07-17 22:02:41,057 - logger.py:50 - Epoch 27 Training Summary: Avg Total Loss: 2.77660, Avg Main MSE: 2.77660, Time: 17.17s
2025-07-17 22:02:59,449 - logger.py:50 - Epoch 27 Summary | Train MSE (x10^-2): 277.6602 | Val MSE (x10^-2): 202.0309 | Time: 35.57s
2025-07-17 22:03:02,565 - logger.py:50 - Epoch: [28][0/6]	Total Loss: 2.91577	Main MSE (x10^-2): 291.5771	LR: 3.97e-04	EMPP_Raw: 1.80124
2025-07-17 22:03:16,645 - logger.py:50 - Epoch: [28][5/6]	Total Loss: 2.84940	Main MSE (x10^-2): 284.9401	LR: 3.97e-04	EMPP_Raw: 1.74054
2025-07-17 22:03:16,699 - logger.py:50 - Epoch 28 Training Summary: Avg Total Loss: 2.84940, Avg Main MSE: 2.84940, Time: 17.24s
2025-07-17 22:03:35,431 - logger.py:50 - Epoch 28 Summary | Train MSE (x10^-2): 284.9401 | Val MSE (x10^-2): 201.8515 | Time: 35.98s
2025-07-17 22:03:38,674 - logger.py:50 - Epoch: [29][0/6]	Total Loss: 2.76190	Main MSE (x10^-2): 276.1903	LR: 3.97e-04	EMPP_Raw: 1.75073
2025-07-17 22:03:52,788 - logger.py:50 - Epoch: [29][5/6]	Total Loss: 2.80114	Main MSE (x10^-2): 280.1143	LR: 3.97e-04	EMPP_Raw: 1.65763
2025-07-17 22:03:52,849 - logger.py:50 - Epoch 29 Training Summary: Avg Total Loss: 2.80114, Avg Main MSE: 2.80114, Time: 17.41s
2025-07-17 22:04:29,851 - logger.py:50 - *** New Best Val MSE (x10^-2): 201.7398, Corresponding Test MSE (x10^-2): 202.3115 at Epoch 29 ***
2025-07-17 22:04:29,899 - logger.py:50 - Epoch 29 Summary | Train MSE (x10^-2): 280.1143 | Val MSE (x10^-2): 201.7398 | Time: 54.46s
2025-07-17 22:04:32,939 - logger.py:50 - Epoch: [30][0/6]	Total Loss: 2.68561	Main MSE (x10^-2): 268.5615	LR: 3.97e-04	EMPP_Raw: 1.60550
2025-07-17 22:04:47,045 - logger.py:50 - Epoch: [30][5/6]	Total Loss: 2.82405	Main MSE (x10^-2): 282.4047	LR: 3.97e-04	EMPP_Raw: 1.67439
2025-07-17 22:04:47,084 - logger.py:50 - Epoch 30 Training Summary: Avg Total Loss: 2.82405, Avg Main MSE: 2.82405, Time: 17.18s
2025-07-17 22:05:05,671 - logger.py:50 - Epoch 30 Summary | Train MSE (x10^-2): 282.4047 | Val MSE (x10^-2): 201.8540 | Time: 35.77s
2025-07-17 22:05:08,768 - logger.py:50 - Epoch: [31][0/6]	Total Loss: 2.82528	Main MSE (x10^-2): 282.5284	LR: 3.96e-04	EMPP_Raw: 1.73650
2025-07-17 22:05:22,836 - logger.py:50 - Epoch: [31][5/6]	Total Loss: 2.80488	Main MSE (x10^-2): 280.4881	LR: 3.96e-04	EMPP_Raw: 1.66863
2025-07-17 22:05:22,879 - logger.py:50 - Epoch 31 Training Summary: Avg Total Loss: 2.80488, Avg Main MSE: 2.80488, Time: 17.20s
2025-07-17 22:05:41,194 - logger.py:50 - Epoch 31 Summary | Train MSE (x10^-2): 280.4881 | Val MSE (x10^-2): 201.7593 | Time: 35.52s
2025-07-17 22:05:44,424 - logger.py:50 - Epoch: [32][0/6]	Total Loss: 2.94493	Main MSE (x10^-2): 294.4930	LR: 3.96e-04	EMPP_Raw: 1.70322
2025-07-17 22:05:58,454 - logger.py:50 - Epoch: [32][5/6]	Total Loss: 2.81089	Main MSE (x10^-2): 281.0886	LR: 3.96e-04	EMPP_Raw: 1.65656
2025-07-17 22:05:58,507 - logger.py:50 - Epoch 32 Training Summary: Avg Total Loss: 2.81089, Avg Main MSE: 2.81089, Time: 17.30s
2025-07-17 22:06:17,076 - logger.py:50 - Epoch 32 Summary | Train MSE (x10^-2): 281.0886 | Val MSE (x10^-2): 201.9580 | Time: 35.88s
2025-07-17 22:06:20,290 - logger.py:50 - Epoch: [33][0/6]	Total Loss: 2.83781	Main MSE (x10^-2): 283.7811	LR: 3.96e-04	EMPP_Raw: 1.63561
2025-07-17 22:06:34,606 - logger.py:50 - Epoch: [33][5/6]	Total Loss: 2.79102	Main MSE (x10^-2): 279.1017	LR: 3.96e-04	EMPP_Raw: 1.61115
2025-07-17 22:06:34,652 - logger.py:50 - Epoch 33 Training Summary: Avg Total Loss: 2.79102, Avg Main MSE: 2.79102, Time: 17.57s
2025-07-17 22:07:11,736 - logger.py:50 - *** New Best Val MSE (x10^-2): 201.6670, Corresponding Test MSE (x10^-2): 202.2594 at Epoch 33 ***
2025-07-17 22:07:11,783 - logger.py:50 - Epoch 33 Summary | Train MSE (x10^-2): 279.1017 | Val MSE (x10^-2): 201.6670 | Time: 54.70s
2025-07-17 22:07:14,831 - logger.py:50 - Epoch: [34][0/6]	Total Loss: 2.86839	Main MSE (x10^-2): 286.8385	LR: 3.96e-04	EMPP_Raw: 1.62849
2025-07-17 22:07:28,924 - logger.py:50 - Epoch: [34][5/6]	Total Loss: 2.78936	Main MSE (x10^-2): 278.9358	LR: 3.96e-04	EMPP_Raw: 1.61479
2025-07-17 22:07:28,967 - logger.py:50 - Epoch 34 Training Summary: Avg Total Loss: 2.78936, Avg Main MSE: 2.78936, Time: 17.18s
2025-07-17 22:08:06,085 - logger.py:50 - *** New Best Val MSE (x10^-2): 201.5762, Corresponding Test MSE (x10^-2): 202.1641 at Epoch 34 ***
2025-07-17 22:08:06,142 - logger.py:50 - Epoch 34 Summary | Train MSE (x10^-2): 278.9358 | Val MSE (x10^-2): 201.5762 | Time: 54.36s
2025-07-17 22:08:09,206 - logger.py:50 - Epoch: [35][0/6]	Total Loss: 2.77947	Main MSE (x10^-2): 277.9466	LR: 3.95e-04	EMPP_Raw: 1.58336
2025-07-17 22:08:23,379 - logger.py:50 - Epoch: [35][5/6]	Total Loss: 2.79703	Main MSE (x10^-2): 279.7029	LR: 3.95e-04	EMPP_Raw: 1.64291
2025-07-17 22:08:23,422 - logger.py:50 - Epoch 35 Training Summary: Avg Total Loss: 2.79703, Avg Main MSE: 2.79703, Time: 17.28s
2025-07-17 22:09:00,184 - logger.py:50 - *** New Best Val MSE (x10^-2): 201.5279, Corresponding Test MSE (x10^-2): 202.0954 at Epoch 35 ***
2025-07-17 22:09:00,231 - logger.py:50 - Epoch 35 Summary | Train MSE (x10^-2): 279.7029 | Val MSE (x10^-2): 201.5279 | Time: 54.09s
2025-07-17 22:09:03,322 - logger.py:50 - Epoch: [36][0/6]	Total Loss: 2.76626	Main MSE (x10^-2): 276.6262	LR: 3.95e-04	EMPP_Raw: 1.64553
2025-07-17 22:09:17,532 - logger.py:50 - Epoch: [36][5/6]	Total Loss: 2.79570	Main MSE (x10^-2): 279.5702	LR: 3.95e-04	EMPP_Raw: 1.62245
2025-07-17 22:09:17,573 - logger.py:50 - Epoch 36 Training Summary: Avg Total Loss: 2.79570, Avg Main MSE: 2.79570, Time: 17.34s
2025-07-17 22:09:35,915 - logger.py:50 - Epoch 36 Summary | Train MSE (x10^-2): 279.5702 | Val MSE (x10^-2): 202.1315 | Time: 35.68s
2025-07-17 22:09:39,040 - logger.py:50 - Epoch: [37][0/6]	Total Loss: 2.74560	Main MSE (x10^-2): 274.5596	LR: 3.95e-04	EMPP_Raw: 1.62566
2025-07-17 22:09:53,305 - logger.py:50 - Epoch: [37][5/6]	Total Loss: 2.78244	Main MSE (x10^-2): 278.2439	LR: 3.95e-04	EMPP_Raw: 1.62996
2025-07-17 22:09:53,347 - logger.py:50 - Epoch 37 Training Summary: Avg Total Loss: 2.78244, Avg Main MSE: 2.78244, Time: 17.42s
2025-07-17 22:10:30,483 - logger.py:50 - *** New Best Val MSE (x10^-2): 200.2163, Corresponding Test MSE (x10^-2): 200.7662 at Epoch 37 ***
2025-07-17 22:10:30,530 - logger.py:50 - Epoch 37 Summary | Train MSE (x10^-2): 278.2439 | Val MSE (x10^-2): 200.2163 | Time: 54.61s
2025-07-17 22:10:33,608 - logger.py:50 - Epoch: [38][0/6]	Total Loss: 2.76002	Main MSE (x10^-2): 276.0015	LR: 3.95e-04	EMPP_Raw: 1.66141
2025-07-17 22:10:47,857 - logger.py:50 - Epoch: [38][5/6]	Total Loss: 3.02395	Main MSE (x10^-2): 302.3946	LR: 3.95e-04	EMPP_Raw: 1.66307
2025-07-17 22:10:47,905 - logger.py:50 - Epoch 38 Training Summary: Avg Total Loss: 3.02395, Avg Main MSE: 3.02395, Time: 17.37s
2025-07-17 22:11:06,242 - logger.py:50 - Epoch 38 Summary | Train MSE (x10^-2): 302.3946 | Val MSE (x10^-2): 209.1650 | Time: 35.71s
2025-07-17 22:11:09,294 - logger.py:50 - Epoch: [39][0/6]	Total Loss: 2.87716	Main MSE (x10^-2): 287.7162	LR: 3.94e-04	EMPP_Raw: 1.52233
2025-07-17 22:11:23,418 - logger.py:50 - Epoch: [39][5/6]	Total Loss: 2.80940	Main MSE (x10^-2): 280.9403	LR: 3.94e-04	EMPP_Raw: 1.61395
2025-07-17 22:11:23,463 - logger.py:50 - Epoch 39 Training Summary: Avg Total Loss: 2.80940, Avg Main MSE: 2.80940, Time: 17.21s
2025-07-17 22:11:41,754 - logger.py:50 - Epoch 39 Summary | Train MSE (x10^-2): 280.9403 | Val MSE (x10^-2): 203.3604 | Time: 35.51s
2025-07-17 22:11:44,988 - logger.py:50 - Epoch: [40][0/6]	Total Loss: 2.77672	Main MSE (x10^-2): 277.6724	LR: 3.94e-04	EMPP_Raw: 1.72751
2025-07-17 22:11:59,109 - logger.py:50 - Epoch: [40][5/6]	Total Loss: 2.79439	Main MSE (x10^-2): 279.4388	LR: 3.94e-04	EMPP_Raw: 1.60729
2025-07-17 22:11:59,149 - logger.py:50 - Epoch 40 Training Summary: Avg Total Loss: 2.79439, Avg Main MSE: 2.79439, Time: 17.39s
2025-07-17 22:12:17,482 - logger.py:50 - Epoch 40 Summary | Train MSE (x10^-2): 279.4388 | Val MSE (x10^-2): 201.7217 | Time: 35.72s
2025-07-17 22:12:20,722 - logger.py:50 - Epoch: [41][0/6]	Total Loss: 2.85332	Main MSE (x10^-2): 285.3322	LR: 3.94e-04	EMPP_Raw: 1.66747
2025-07-17 22:12:34,722 - logger.py:50 - Epoch: [41][5/6]	Total Loss: 2.79669	Main MSE (x10^-2): 279.6690	LR: 3.94e-04	EMPP_Raw: 1.63875
2025-07-17 22:12:34,785 - logger.py:50 - Epoch 41 Training Summary: Avg Total Loss: 2.79669, Avg Main MSE: 2.79669, Time: 17.29s
2025-07-17 22:12:53,177 - logger.py:50 - Epoch 41 Summary | Train MSE (x10^-2): 279.6690 | Val MSE (x10^-2): 201.3762 | Time: 35.69s
2025-07-17 22:12:56,576 - logger.py:50 - Epoch: [42][0/6]	Total Loss: 2.86426	Main MSE (x10^-2): 286.4262	LR: 3.93e-04	EMPP_Raw: 1.70151
2025-07-17 22:13:10,706 - logger.py:50 - Epoch: [42][5/6]	Total Loss: 2.77906	Main MSE (x10^-2): 277.9059	LR: 3.93e-04	EMPP_Raw: 1.60249
2025-07-17 22:13:10,769 - logger.py:50 - Epoch 42 Training Summary: Avg Total Loss: 2.77906, Avg Main MSE: 2.77906, Time: 17.58s
2025-07-17 22:13:29,118 - logger.py:50 - Epoch 42 Summary | Train MSE (x10^-2): 277.9059 | Val MSE (x10^-2): 201.1554 | Time: 35.93s
2025-07-17 22:13:32,309 - logger.py:50 - Epoch: [43][0/6]	Total Loss: 2.82618	Main MSE (x10^-2): 282.6180	LR: 3.93e-04	EMPP_Raw: 1.69155
2025-07-17 22:13:46,400 - logger.py:50 - Epoch: [43][5/6]	Total Loss: 2.80887	Main MSE (x10^-2): 280.8867	LR: 3.93e-04	EMPP_Raw: 1.65083
2025-07-17 22:13:46,444 - logger.py:50 - Epoch 43 Training Summary: Avg Total Loss: 2.80887, Avg Main MSE: 2.80887, Time: 17.32s
2025-07-17 22:14:04,850 - logger.py:50 - Epoch 43 Summary | Train MSE (x10^-2): 280.8867 | Val MSE (x10^-2): 202.0753 | Time: 35.73s
2025-07-17 22:14:07,881 - logger.py:50 - Epoch: [44][0/6]	Total Loss: 2.73951	Main MSE (x10^-2): 273.9511	LR: 3.93e-04	EMPP_Raw: 1.61825
2025-07-17 22:14:22,085 - logger.py:50 - Epoch: [44][5/6]	Total Loss: 2.79048	Main MSE (x10^-2): 279.0478	LR: 3.93e-04	EMPP_Raw: 1.67460
2025-07-17 22:14:22,133 - logger.py:50 - Epoch 44 Training Summary: Avg Total Loss: 2.79048, Avg Main MSE: 2.79048, Time: 17.27s
2025-07-17 22:14:58,872 - logger.py:50 - *** New Best Val MSE (x10^-2): 197.6390, Corresponding Test MSE (x10^-2): 198.0818 at Epoch 44 ***
2025-07-17 22:14:58,919 - logger.py:50 - Epoch 44 Summary | Train MSE (x10^-2): 279.0478 | Val MSE (x10^-2): 197.6390 | Time: 54.06s
2025-07-17 22:15:02,006 - logger.py:50 - Epoch: [45][0/6]	Total Loss: 2.81425	Main MSE (x10^-2): 281.4247	LR: 3.92e-04	EMPP_Raw: 1.75380
2025-07-17 22:15:16,222 - logger.py:50 - Epoch: [45][5/6]	Total Loss: 2.77002	Main MSE (x10^-2): 277.0022	LR: 3.92e-04	EMPP_Raw: 1.66655
2025-07-17 22:15:16,258 - logger.py:50 - Epoch 45 Training Summary: Avg Total Loss: 2.77002, Avg Main MSE: 2.77002, Time: 17.34s
2025-07-17 22:15:53,039 - logger.py:50 - *** New Best Val MSE (x10^-2): 190.8511, Corresponding Test MSE (x10^-2): 190.5940 at Epoch 45 ***
2025-07-17 22:15:53,086 - logger.py:50 - Epoch 45 Summary | Train MSE (x10^-2): 277.0022 | Val MSE (x10^-2): 190.8511 | Time: 54.17s
2025-07-17 22:15:56,131 - logger.py:50 - Epoch: [46][0/6]	Total Loss: 2.69082	Main MSE (x10^-2): 269.0819	LR: 3.92e-04	EMPP_Raw: 1.65195
2025-07-17 22:16:10,356 - logger.py:50 - Epoch: [46][5/6]	Total Loss: 2.80257	Main MSE (x10^-2): 280.2571	LR: 3.92e-04	EMPP_Raw: 1.65792
2025-07-17 22:16:10,394 - logger.py:50 - Epoch 46 Training Summary: Avg Total Loss: 2.80257, Avg Main MSE: 2.80257, Time: 17.30s
2025-07-17 22:16:28,854 - logger.py:50 - Epoch 46 Summary | Train MSE (x10^-2): 280.2571 | Val MSE (x10^-2): 204.7139 | Time: 35.77s
2025-07-17 22:16:31,928 - logger.py:50 - Epoch: [47][0/6]	Total Loss: 2.81697	Main MSE (x10^-2): 281.6971	LR: 3.92e-04	EMPP_Raw: 1.55247
2025-07-17 22:16:46,065 - logger.py:50 - Epoch: [47][5/6]	Total Loss: 2.78069	Main MSE (x10^-2): 278.0695	LR: 3.92e-04	EMPP_Raw: 1.60638
2025-07-17 22:16:46,109 - logger.py:50 - Epoch 47 Training Summary: Avg Total Loss: 2.78069, Avg Main MSE: 2.78069, Time: 17.24s
2025-07-17 22:17:04,792 - logger.py:50 - Epoch 47 Summary | Train MSE (x10^-2): 278.0695 | Val MSE (x10^-2): 201.8735 | Time: 35.93s
2025-07-17 22:17:07,841 - logger.py:50 - Epoch: [48][0/6]	Total Loss: 2.67638	Main MSE (x10^-2): 267.6383	LR: 3.91e-04	EMPP_Raw: 1.62321
2025-07-17 22:17:21,953 - logger.py:50 - Epoch: [48][5/6]	Total Loss: 2.76990	Main MSE (x10^-2): 276.9898	LR: 3.91e-04	EMPP_Raw: 1.64611
2025-07-17 22:17:21,994 - logger.py:50 - Epoch 48 Training Summary: Avg Total Loss: 2.76990, Avg Main MSE: 2.76990, Time: 17.19s
2025-07-17 22:17:40,556 - logger.py:50 - Epoch 48 Summary | Train MSE (x10^-2): 276.9898 | Val MSE (x10^-2): 191.5898 | Time: 35.76s
2025-07-17 22:17:43,643 - logger.py:50 - Epoch: [49][0/6]	Total Loss: 2.73055	Main MSE (x10^-2): 273.0550	LR: 3.91e-04	EMPP_Raw: 1.75223
2025-07-17 22:17:57,823 - logger.py:50 - Epoch: [49][5/6]	Total Loss: 2.67856	Main MSE (x10^-2): 267.8560	LR: 3.91e-04	EMPP_Raw: 1.62867
2025-07-17 22:17:57,866 - logger.py:50 - Epoch 49 Training Summary: Avg Total Loss: 2.67856, Avg Main MSE: 2.67856, Time: 17.30s
2025-07-17 22:18:34,613 - logger.py:50 - *** New Best Val MSE (x10^-2): 181.3005, Corresponding Test MSE (x10^-2): 181.0658 at Epoch 49 ***
2025-07-17 22:18:34,660 - logger.py:50 - Epoch 49 Summary | Train MSE (x10^-2): 267.8560 | Val MSE (x10^-2): 181.3005 | Time: 54.10s
2025-07-17 22:18:37,728 - logger.py:50 - Epoch: [50][0/6]	Total Loss: 2.60369	Main MSE (x10^-2): 260.3693	LR: 3.91e-04	EMPP_Raw: 1.71592
2025-07-17 22:18:51,800 - logger.py:50 - Epoch: [50][5/6]	Total Loss: 2.65976	Main MSE (x10^-2): 265.9758	LR: 3.91e-04	EMPP_Raw: 1.62283
2025-07-17 22:18:51,836 - logger.py:50 - Epoch 50 Training Summary: Avg Total Loss: 2.65976, Avg Main MSE: 2.65976, Time: 17.17s
2025-07-17 22:19:10,319 - logger.py:50 - Epoch 50 Summary | Train MSE (x10^-2): 265.9758 | Val MSE (x10^-2): 193.7872 | Time: 35.66s
2025-07-17 22:19:13,400 - logger.py:50 - Epoch: [51][0/6]	Total Loss: 2.73819	Main MSE (x10^-2): 273.8189	LR: 3.90e-04	EMPP_Raw: 1.57517
2025-07-17 22:19:27,497 - logger.py:50 - Epoch: [51][5/6]	Total Loss: 2.67251	Main MSE (x10^-2): 267.2506	LR: 3.90e-04	EMPP_Raw: 1.60865
2025-07-17 22:19:27,543 - logger.py:50 - Epoch 51 Training Summary: Avg Total Loss: 2.67251, Avg Main MSE: 2.67251, Time: 17.22s
2025-07-17 22:20:04,582 - logger.py:50 - *** New Best Val MSE (x10^-2): 175.4742, Corresponding Test MSE (x10^-2): 175.1578 at Epoch 51 ***
2025-07-17 22:20:04,632 - logger.py:50 - Epoch 51 Summary | Train MSE (x10^-2): 267.2506 | Val MSE (x10^-2): 175.4742 | Time: 54.31s
2025-07-17 22:20:07,658 - logger.py:50 - Epoch: [52][0/6]	Total Loss: 2.65916	Main MSE (x10^-2): 265.9158	LR: 3.90e-04	EMPP_Raw: 1.69898
2025-07-17 22:20:21,770 - logger.py:50 - Epoch: [52][5/6]	Total Loss: 2.61299	Main MSE (x10^-2): 261.2988	LR: 3.90e-04	EMPP_Raw: 1.63555
2025-07-17 22:20:21,823 - logger.py:50 - Epoch 52 Training Summary: Avg Total Loss: 2.61299, Avg Main MSE: 2.61299, Time: 17.19s
2025-07-17 22:20:58,746 - logger.py:50 - *** New Best Val MSE (x10^-2): 144.7011, Corresponding Test MSE (x10^-2): 145.0457 at Epoch 52 ***
2025-07-17 22:20:58,794 - logger.py:50 - Epoch 52 Summary | Train MSE (x10^-2): 261.2988 | Val MSE (x10^-2): 144.7011 | Time: 54.16s
2025-07-17 22:21:01,865 - logger.py:50 - Epoch: [53][0/6]	Total Loss: 2.25727	Main MSE (x10^-2): 225.7267	LR: 3.89e-04	EMPP_Raw: 1.54060
2025-07-17 22:21:15,940 - logger.py:50 - Epoch: [53][5/6]	Total Loss: 2.37558	Main MSE (x10^-2): 237.5576	LR: 3.89e-04	EMPP_Raw: 1.61105
2025-07-17 22:21:15,984 - logger.py:50 - Epoch 53 Training Summary: Avg Total Loss: 2.37558, Avg Main MSE: 2.37558, Time: 17.19s
2025-07-17 22:21:34,533 - logger.py:50 - Epoch 53 Summary | Train MSE (x10^-2): 237.5576 | Val MSE (x10^-2): 147.1833 | Time: 35.74s
2025-07-17 22:21:37,640 - logger.py:50 - Epoch: [54][0/6]	Total Loss: 2.27900	Main MSE (x10^-2): 227.9001	LR: 3.89e-04	EMPP_Raw: 1.68182
2025-07-17 22:21:51,737 - logger.py:50 - Epoch: [54][5/6]	Total Loss: 2.16117	Main MSE (x10^-2): 216.1173	LR: 3.89e-04	EMPP_Raw: 1.64150
2025-07-17 22:21:51,781 - logger.py:50 - Epoch 54 Training Summary: Avg Total Loss: 2.16117, Avg Main MSE: 2.16117, Time: 17.24s
2025-07-17 22:22:28,577 - logger.py:50 - *** New Best Val MSE (x10^-2): 112.6947, Corresponding Test MSE (x10^-2): 113.3240 at Epoch 54 ***
2025-07-17 22:22:28,624 - logger.py:50 - Epoch 54 Summary | Train MSE (x10^-2): 216.1173 | Val MSE (x10^-2): 112.6947 | Time: 54.08s
2025-07-17 22:22:31,648 - logger.py:50 - Epoch: [55][0/6]	Total Loss: 1.95578	Main MSE (x10^-2): 195.5776	LR: 3.89e-04	EMPP_Raw: 1.60977
2025-07-17 22:22:45,697 - logger.py:50 - Epoch: [55][5/6]	Total Loss: 2.14599	Main MSE (x10^-2): 214.5985	LR: 3.89e-04	EMPP_Raw: 1.68234
2025-07-17 22:22:45,740 - logger.py:50 - Epoch 55 Training Summary: Avg Total Loss: 2.14599, Avg Main MSE: 2.14599, Time: 17.11s
2025-07-17 22:23:04,222 - logger.py:50 - Epoch 55 Summary | Train MSE (x10^-2): 214.5985 | Val MSE (x10^-2): 127.9325 | Time: 35.60s
2025-07-17 22:23:07,309 - logger.py:50 - Epoch: [56][0/6]	Total Loss: 2.03123	Main MSE (x10^-2): 203.1232	LR: 3.88e-04	EMPP_Raw: 1.58799
2025-07-17 22:23:21,404 - logger.py:50 - Epoch: [56][5/6]	Total Loss: 2.02763	Main MSE (x10^-2): 202.7634	LR: 3.88e-04	EMPP_Raw: 1.59133
2025-07-17 22:23:21,448 - logger.py:50 - Epoch 56 Training Summary: Avg Total Loss: 2.02763, Avg Main MSE: 2.02763, Time: 17.22s
2025-07-17 22:23:39,950 - logger.py:50 - Epoch 56 Summary | Train MSE (x10^-2): 202.7634 | Val MSE (x10^-2): 132.5550 | Time: 35.72s
2025-07-17 22:23:43,044 - logger.py:50 - Epoch: [57][0/6]	Total Loss: 2.18714	Main MSE (x10^-2): 218.7143	LR: 3.88e-04	EMPP_Raw: 1.65064
2025-07-17 22:23:57,116 - logger.py:50 - Epoch: [57][5/6]	Total Loss: 2.02000	Main MSE (x10^-2): 202.0000	LR: 3.88e-04	EMPP_Raw: 1.60363
2025-07-17 22:23:57,157 - logger.py:50 - Epoch 57 Training Summary: Avg Total Loss: 2.02000, Avg Main MSE: 2.02000, Time: 17.20s
2025-07-17 22:24:15,539 - logger.py:50 - Epoch 57 Summary | Train MSE (x10^-2): 202.0000 | Val MSE (x10^-2): 123.3401 | Time: 35.58s
2025-07-17 22:24:19,010 - logger.py:50 - Epoch: [58][0/6]	Total Loss: 2.13603	Main MSE (x10^-2): 213.6034	LR: 3.87e-04	EMPP_Raw: 1.66910
2025-07-17 22:24:33,004 - logger.py:50 - Epoch: [58][5/6]	Total Loss: 1.95956	Main MSE (x10^-2): 195.9564	LR: 3.87e-04	EMPP_Raw: 1.68249
2025-07-17 22:24:33,056 - logger.py:50 - Epoch 58 Training Summary: Avg Total Loss: 1.95956, Avg Main MSE: 1.95956, Time: 17.51s
2025-07-17 22:25:09,875 - logger.py:50 - *** New Best Val MSE (x10^-2): 112.2531, Corresponding Test MSE (x10^-2): 112.8517 at Epoch 58 ***
2025-07-17 22:25:09,922 - logger.py:50 - Epoch 58 Summary | Train MSE (x10^-2): 195.9564 | Val MSE (x10^-2): 112.2531 | Time: 54.38s
2025-07-17 22:25:12,940 - logger.py:50 - Epoch: [59][0/6]	Total Loss: 1.94076	Main MSE (x10^-2): 194.0765	LR: 3.87e-04	EMPP_Raw: 1.60496
2025-07-17 22:25:26,999 - logger.py:50 - Epoch: [59][5/6]	Total Loss: 1.81057	Main MSE (x10^-2): 181.0566	LR: 3.87e-04	EMPP_Raw: 1.61753
2025-07-17 22:25:27,043 - logger.py:50 - Epoch 59 Training Summary: Avg Total Loss: 1.81057, Avg Main MSE: 1.81057, Time: 17.12s
2025-07-17 22:26:04,077 - logger.py:50 - *** New Best Val MSE (x10^-2): 88.3141, Corresponding Test MSE (x10^-2): 88.9150 at Epoch 59 ***
2025-07-17 22:26:04,128 - logger.py:50 - Epoch 59 Summary | Train MSE (x10^-2): 181.0566 | Val MSE (x10^-2): 88.3141 | Time: 54.20s
2025-07-17 22:26:07,149 - logger.py:50 - Epoch: [60][0/6]	Total Loss: 1.73822	Main MSE (x10^-2): 173.8218	LR: 3.86e-04	EMPP_Raw: 1.66876
2025-07-17 22:26:21,319 - logger.py:50 - Epoch: [60][5/6]	Total Loss: 1.64873	Main MSE (x10^-2): 164.8728	LR: 3.86e-04	EMPP_Raw: 1.63337
2025-07-17 22:26:21,358 - logger.py:50 - Epoch 60 Training Summary: Avg Total Loss: 1.64873, Avg Main MSE: 1.64873, Time: 17.23s
2025-07-17 22:26:58,317 - logger.py:50 - *** New Best Val MSE (x10^-2): 73.5414, Corresponding Test MSE (x10^-2): 73.7306 at Epoch 60 ***
2025-07-17 22:26:58,364 - logger.py:50 - Epoch 60 Summary | Train MSE (x10^-2): 164.8728 | Val MSE (x10^-2): 73.5414 | Time: 54.24s
2025-07-17 22:27:01,476 - logger.py:50 - Epoch: [61][0/6]	Total Loss: 1.44388	Main MSE (x10^-2): 144.3881	LR: 3.86e-04	EMPP_Raw: 1.53219
2025-07-17 22:27:15,670 - logger.py:50 - Epoch: [61][5/6]	Total Loss: 1.56143	Main MSE (x10^-2): 156.1426	LR: 3.86e-04	EMPP_Raw: 1.63594
2025-07-17 22:27:15,711 - logger.py:50 - Epoch 61 Training Summary: Avg Total Loss: 1.56143, Avg Main MSE: 1.56143, Time: 17.34s
2025-07-17 22:27:52,520 - logger.py:50 - *** New Best Val MSE (x10^-2): 68.3747, Corresponding Test MSE (x10^-2): 69.2848 at Epoch 61 ***
2025-07-17 22:27:52,568 - logger.py:50 - Epoch 61 Summary | Train MSE (x10^-2): 156.1426 | Val MSE (x10^-2): 68.3747 | Time: 54.20s
2025-07-17 22:27:55,604 - logger.py:50 - Epoch: [62][0/6]	Total Loss: 1.49841	Main MSE (x10^-2): 149.8406	LR: 3.86e-04	EMPP_Raw: 1.59617
2025-07-17 22:28:09,856 - logger.py:50 - Epoch: [62][5/6]	Total Loss: 1.60481	Main MSE (x10^-2): 160.4806	LR: 3.86e-04	EMPP_Raw: 1.63674
2025-07-17 22:28:09,899 - logger.py:50 - Epoch 62 Training Summary: Avg Total Loss: 1.60481, Avg Main MSE: 1.60481, Time: 17.33s
2025-07-17 22:28:28,415 - logger.py:50 - Epoch 62 Summary | Train MSE (x10^-2): 160.4806 | Val MSE (x10^-2): 69.5986 | Time: 35.85s
2025-07-17 22:28:31,462 - logger.py:50 - Epoch: [63][0/6]	Total Loss: 1.60376	Main MSE (x10^-2): 160.3759	LR: 3.85e-04	EMPP_Raw: 1.71766
2025-07-17 22:28:45,512 - logger.py:50 - Epoch: [63][5/6]	Total Loss: 1.47571	Main MSE (x10^-2): 147.5707	LR: 3.85e-04	EMPP_Raw: 1.63195
2025-07-17 22:28:45,561 - logger.py:50 - Epoch 63 Training Summary: Avg Total Loss: 1.47571, Avg Main MSE: 1.47571, Time: 17.14s
2025-07-17 22:29:22,496 - logger.py:50 - *** New Best Val MSE (x10^-2): 54.1804, Corresponding Test MSE (x10^-2): 55.0680 at Epoch 63 ***
2025-07-17 22:29:22,546 - logger.py:50 - Epoch 63 Summary | Train MSE (x10^-2): 147.5707 | Val MSE (x10^-2): 54.1804 | Time: 54.13s
2025-07-17 22:29:25,593 - logger.py:50 - Epoch: [64][0/6]	Total Loss: 1.38865	Main MSE (x10^-2): 138.8647	LR: 3.85e-04	EMPP_Raw: 1.60581
2025-07-17 22:29:39,873 - logger.py:50 - Epoch: [64][5/6]	Total Loss: 1.38086	Main MSE (x10^-2): 138.0864	LR: 3.85e-04	EMPP_Raw: 1.57797
2025-07-17 22:29:39,910 - logger.py:50 - Epoch 64 Training Summary: Avg Total Loss: 1.38086, Avg Main MSE: 1.38086, Time: 17.36s
2025-07-17 22:30:16,461 - logger.py:50 - *** New Best Val MSE (x10^-2): 51.8430, Corresponding Test MSE (x10^-2): 52.8948 at Epoch 64 ***
2025-07-17 22:30:16,508 - logger.py:50 - Epoch 64 Summary | Train MSE (x10^-2): 138.0864 | Val MSE (x10^-2): 51.8430 | Time: 53.96s
2025-07-17 22:30:19,566 - logger.py:50 - Epoch: [65][0/6]	Total Loss: 1.32303	Main MSE (x10^-2): 132.3030	LR: 3.84e-04	EMPP_Raw: 1.59943
2025-07-17 22:30:33,754 - logger.py:50 - Epoch: [65][5/6]	Total Loss: 1.39560	Main MSE (x10^-2): 139.5596	LR: 3.84e-04	EMPP_Raw: 1.57107
2025-07-17 22:30:33,792 - logger.py:50 - Epoch 65 Training Summary: Avg Total Loss: 1.39560, Avg Main MSE: 1.39560, Time: 17.28s
2025-07-17 22:30:52,337 - logger.py:50 - Epoch 65 Summary | Train MSE (x10^-2): 139.5596 | Val MSE (x10^-2): 57.2815 | Time: 35.83s
2025-07-17 22:30:55,429 - logger.py:50 - Epoch: [66][0/6]	Total Loss: 1.41655	Main MSE (x10^-2): 141.6546	LR: 3.84e-04	EMPP_Raw: 1.61052
2025-07-17 22:31:09,598 - logger.py:50 - Epoch: [66][5/6]	Total Loss: 1.39188	Main MSE (x10^-2): 139.1882	LR: 3.84e-04	EMPP_Raw: 1.56732
2025-07-17 22:31:09,642 - logger.py:50 - Epoch 66 Training Summary: Avg Total Loss: 1.39188, Avg Main MSE: 1.39188, Time: 17.30s
2025-07-17 22:31:27,957 - logger.py:50 - Epoch 66 Summary | Train MSE (x10^-2): 139.1882 | Val MSE (x10^-2): 60.3240 | Time: 35.61s
2025-07-17 22:31:30,996 - logger.py:50 - Epoch: [67][0/6]	Total Loss: 1.36524	Main MSE (x10^-2): 136.5238	LR: 3.83e-04	EMPP_Raw: 1.55263
2025-07-17 22:31:45,114 - logger.py:50 - Epoch: [67][5/6]	Total Loss: 1.37597	Main MSE (x10^-2): 137.5973	LR: 3.83e-04	EMPP_Raw: 1.59321
2025-07-17 22:31:45,156 - logger.py:50 - Epoch 67 Training Summary: Avg Total Loss: 1.37597, Avg Main MSE: 1.37597, Time: 17.19s
2025-07-17 22:32:21,911 - logger.py:50 - *** New Best Val MSE (x10^-2): 51.1155, Corresponding Test MSE (x10^-2): 51.8120 at Epoch 67 ***
2025-07-17 22:32:21,958 - logger.py:50 - Epoch 67 Summary | Train MSE (x10^-2): 137.5973 | Val MSE (x10^-2): 51.1155 | Time: 54.00s
2025-07-17 22:32:25,024 - logger.py:50 - Epoch: [68][0/6]	Total Loss: 1.34457	Main MSE (x10^-2): 134.4565	LR: 3.83e-04	EMPP_Raw: 1.59155
2025-07-17 22:32:39,149 - logger.py:50 - Epoch: [68][5/6]	Total Loss: 1.35993	Main MSE (x10^-2): 135.9935	LR: 3.83e-04	EMPP_Raw: 1.59451
2025-07-17 22:32:39,191 - logger.py:50 - Epoch 68 Training Summary: Avg Total Loss: 1.35993, Avg Main MSE: 1.35993, Time: 17.23s
2025-07-17 22:33:16,196 - logger.py:50 - *** New Best Val MSE (x10^-2): 43.8655, Corresponding Test MSE (x10^-2): 44.2504 at Epoch 68 ***
2025-07-17 22:33:16,245 - logger.py:50 - Epoch 68 Summary | Train MSE (x10^-2): 135.9935 | Val MSE (x10^-2): 43.8655 | Time: 54.29s
2025-07-17 22:33:19,286 - logger.py:50 - Epoch: [69][0/6]	Total Loss: 1.29461	Main MSE (x10^-2): 129.4606	LR: 3.82e-04	EMPP_Raw: 1.67555
2025-07-17 22:33:33,538 - logger.py:50 - Epoch: [69][5/6]	Total Loss: 1.29660	Main MSE (x10^-2): 129.6602	LR: 3.82e-04	EMPP_Raw: 1.58904
2025-07-17 22:33:33,578 - logger.py:50 - Epoch 69 Training Summary: Avg Total Loss: 1.29660, Avg Main MSE: 1.29660, Time: 17.33s
2025-07-17 22:33:51,897 - logger.py:50 - Epoch 69 Summary | Train MSE (x10^-2): 129.6602 | Val MSE (x10^-2): 45.7564 | Time: 35.65s
2025-07-17 22:33:54,954 - logger.py:50 - Epoch: [70][0/6]	Total Loss: 1.34643	Main MSE (x10^-2): 134.6428	LR: 3.82e-04	EMPP_Raw: 1.63054
2025-07-17 22:34:09,042 - logger.py:50 - Epoch: [70][5/6]	Total Loss: 1.23254	Main MSE (x10^-2): 123.2536	LR: 3.82e-04	EMPP_Raw: 1.54330
2025-07-17 22:34:09,094 - logger.py:50 - Epoch 70 Training Summary: Avg Total Loss: 1.23254, Avg Main MSE: 1.23254, Time: 17.19s
2025-07-17 22:34:46,082 - logger.py:50 - *** New Best Val MSE (x10^-2): 40.5680, Corresponding Test MSE (x10^-2): 41.0449 at Epoch 70 ***
2025-07-17 22:34:46,129 - logger.py:50 - Epoch 70 Summary | Train MSE (x10^-2): 123.2536 | Val MSE (x10^-2): 40.5680 | Time: 54.23s
2025-07-17 22:34:49,223 - logger.py:50 - Epoch: [71][0/6]	Total Loss: 1.36861	Main MSE (x10^-2): 136.8611	LR: 3.81e-04	EMPP_Raw: 1.73731
2025-07-17 22:35:03,315 - logger.py:50 - Epoch: [71][5/6]	Total Loss: 1.24304	Main MSE (x10^-2): 124.3043	LR: 3.81e-04	EMPP_Raw: 1.60584
2025-07-17 22:35:03,362 - logger.py:50 - Epoch 71 Training Summary: Avg Total Loss: 1.24304, Avg Main MSE: 1.24304, Time: 17.23s
2025-07-17 22:35:40,272 - logger.py:50 - *** New Best Val MSE (x10^-2): 40.4649, Corresponding Test MSE (x10^-2): 41.1339 at Epoch 71 ***
2025-07-17 22:35:40,319 - logger.py:50 - Epoch 71 Summary | Train MSE (x10^-2): 124.3043 | Val MSE (x10^-2): 40.4649 | Time: 54.19s
2025-07-17 22:35:43,348 - logger.py:50 - Epoch: [72][0/6]	Total Loss: 1.16041	Main MSE (x10^-2): 116.0412	LR: 3.80e-04	EMPP_Raw: 1.50409
2025-07-17 22:35:57,588 - logger.py:50 - Epoch: [72][5/6]	Total Loss: 1.19398	Main MSE (x10^-2): 119.3982	LR: 3.80e-04	EMPP_Raw: 1.57160
2025-07-17 22:35:57,628 - logger.py:50 - Epoch 72 Training Summary: Avg Total Loss: 1.19398, Avg Main MSE: 1.19398, Time: 17.31s
2025-07-17 22:36:34,195 - logger.py:50 - *** New Best Val MSE (x10^-2): 32.5544, Corresponding Test MSE (x10^-2): 33.3021 at Epoch 72 ***
2025-07-17 22:36:34,242 - logger.py:50 - Epoch 72 Summary | Train MSE (x10^-2): 119.3982 | Val MSE (x10^-2): 32.5544 | Time: 53.92s
2025-07-17 22:36:37,343 - logger.py:50 - Epoch: [73][0/6]	Total Loss: 1.16094	Main MSE (x10^-2): 116.0938	LR: 3.80e-04	EMPP_Raw: 1.59318
2025-07-17 22:36:51,593 - logger.py:50 - Epoch: [73][5/6]	Total Loss: 1.17140	Main MSE (x10^-2): 117.1404	LR: 3.80e-04	EMPP_Raw: 1.60879
2025-07-17 22:36:51,630 - logger.py:50 - Epoch 73 Training Summary: Avg Total Loss: 1.17140, Avg Main MSE: 1.17140, Time: 17.38s
2025-07-17 22:37:10,024 - logger.py:50 - Epoch 73 Summary | Train MSE (x10^-2): 117.1404 | Val MSE (x10^-2): 32.7563 | Time: 35.78s
2025-07-17 22:37:13,085 - logger.py:50 - Epoch: [74][0/6]	Total Loss: 1.18877	Main MSE (x10^-2): 118.8772	LR: 3.79e-04	EMPP_Raw: 1.60845
2025-07-17 22:37:27,219 - logger.py:50 - Epoch: [74][5/6]	Total Loss: 1.16402	Main MSE (x10^-2): 116.4020	LR: 3.79e-04	EMPP_Raw: 1.58767
2025-07-17 22:37:27,261 - logger.py:50 - Epoch 74 Training Summary: Avg Total Loss: 1.16402, Avg Main MSE: 1.16402, Time: 17.23s
2025-07-17 22:38:04,289 - logger.py:50 - *** New Best Val MSE (x10^-2): 31.7449, Corresponding Test MSE (x10^-2): 32.4196 at Epoch 74 ***
2025-07-17 22:38:04,336 - logger.py:50 - Epoch 74 Summary | Train MSE (x10^-2): 116.4020 | Val MSE (x10^-2): 31.7449 | Time: 54.31s
2025-07-17 22:38:07,359 - logger.py:50 - Epoch: [75][0/6]	Total Loss: 1.14181	Main MSE (x10^-2): 114.1806	LR: 3.79e-04	EMPP_Raw: 1.62458
2025-07-17 22:38:21,542 - logger.py:50 - Epoch: [75][5/6]	Total Loss: 1.20782	Main MSE (x10^-2): 120.7822	LR: 3.79e-04	EMPP_Raw: 1.61294
2025-07-17 22:38:21,578 - logger.py:50 - Epoch 75 Training Summary: Avg Total Loss: 1.20782, Avg Main MSE: 1.20782, Time: 17.24s
2025-07-17 22:38:39,983 - logger.py:50 - Epoch 75 Summary | Train MSE (x10^-2): 120.7822 | Val MSE (x10^-2): 38.3518 | Time: 35.65s
2025-07-17 22:38:43,075 - logger.py:50 - Epoch: [76][0/6]	Total Loss: 1.17935	Main MSE (x10^-2): 117.9354	LR: 3.78e-04	EMPP_Raw: 1.53156
2025-07-17 22:38:57,155 - logger.py:50 - Epoch: [76][5/6]	Total Loss: 1.19208	Main MSE (x10^-2): 119.2076	LR: 3.78e-04	EMPP_Raw: 1.56127
2025-07-17 22:38:57,201 - logger.py:50 - Epoch 76 Training Summary: Avg Total Loss: 1.19208, Avg Main MSE: 1.19208, Time: 17.21s
2025-07-17 22:39:15,641 - logger.py:50 - Epoch 76 Summary | Train MSE (x10^-2): 119.2076 | Val MSE (x10^-2): 32.6655 | Time: 35.65s
2025-07-17 22:39:18,668 - logger.py:50 - Epoch: [77][0/6]	Total Loss: 1.17039	Main MSE (x10^-2): 117.0389	LR: 3.78e-04	EMPP_Raw: 1.69726
2025-07-17 22:39:32,705 - logger.py:50 - Epoch: [77][5/6]	Total Loss: 1.17736	Main MSE (x10^-2): 117.7355	LR: 3.78e-04	EMPP_Raw: 1.62590
2025-07-17 22:39:32,749 - logger.py:50 - Epoch 77 Training Summary: Avg Total Loss: 1.17736, Avg Main MSE: 1.17736, Time: 17.10s
2025-07-17 22:40:09,620 - logger.py:50 - *** New Best Val MSE (x10^-2): 29.7284, Corresponding Test MSE (x10^-2): 30.6786 at Epoch 77 ***
2025-07-17 22:40:09,668 - logger.py:50 - Epoch 77 Summary | Train MSE (x10^-2): 117.7355 | Val MSE (x10^-2): 29.7284 | Time: 54.02s
2025-07-17 22:40:12,748 - logger.py:50 - Epoch: [78][0/6]	Total Loss: 1.04652	Main MSE (x10^-2): 104.6525	LR: 3.77e-04	EMPP_Raw: 1.48288
2025-07-17 22:40:26,985 - logger.py:50 - Epoch: [78][5/6]	Total Loss: 1.11883	Main MSE (x10^-2): 111.8831	LR: 3.77e-04	EMPP_Raw: 1.58154
2025-07-17 22:40:27,022 - logger.py:50 - Epoch 78 Training Summary: Avg Total Loss: 1.11883, Avg Main MSE: 1.11883, Time: 17.35s
2025-07-17 22:40:45,422 - logger.py:50 - Epoch 78 Summary | Train MSE (x10^-2): 111.8831 | Val MSE (x10^-2): 30.5251 | Time: 35.75s
2025-07-17 22:40:48,511 - logger.py:50 - Epoch: [79][0/6]	Total Loss: 1.15101	Main MSE (x10^-2): 115.1009	LR: 3.77e-04	EMPP_Raw: 1.54678
2025-07-17 22:41:02,598 - logger.py:50 - Epoch: [79][5/6]	Total Loss: 1.11027	Main MSE (x10^-2): 111.0272	LR: 3.77e-04	EMPP_Raw: 1.57597
2025-07-17 22:41:02,641 - logger.py:50 - Epoch 79 Training Summary: Avg Total Loss: 1.11027, Avg Main MSE: 1.11027, Time: 17.21s
2025-07-17 22:41:39,471 - logger.py:50 - *** New Best Val MSE (x10^-2): 28.6624, Corresponding Test MSE (x10^-2): 29.5097 at Epoch 79 ***
2025-07-17 22:41:39,521 - logger.py:50 - Epoch 79 Summary | Train MSE (x10^-2): 111.0272 | Val MSE (x10^-2): 28.6624 | Time: 54.09s
2025-07-17 22:41:42,542 - logger.py:50 - Epoch: [80][0/6]	Total Loss: 1.09978	Main MSE (x10^-2): 109.9778	LR: 3.76e-04	EMPP_Raw: 1.54262
2025-07-17 22:41:56,686 - logger.py:50 - Epoch: [80][5/6]	Total Loss: 1.10725	Main MSE (x10^-2): 110.7251	LR: 3.76e-04	EMPP_Raw: 1.57928
2025-07-17 22:41:56,725 - logger.py:50 - Epoch 80 Training Summary: Avg Total Loss: 1.10725, Avg Main MSE: 1.10725, Time: 17.20s
2025-07-17 22:42:15,202 - logger.py:50 - Epoch 80 Summary | Train MSE (x10^-2): 110.7251 | Val MSE (x10^-2): 28.6785 | Time: 35.68s
2025-07-17 22:42:18,235 - logger.py:50 - Epoch: [81][0/6]	Total Loss: 1.02111	Main MSE (x10^-2): 102.1114	LR: 3.75e-04	EMPP_Raw: 1.55419
2025-07-17 22:42:32,371 - logger.py:50 - Epoch: [81][5/6]	Total Loss: 1.10029	Main MSE (x10^-2): 110.0289	LR: 3.75e-04	EMPP_Raw: 1.60492
2025-07-17 22:42:32,434 - logger.py:50 - Epoch 81 Training Summary: Avg Total Loss: 1.10029, Avg Main MSE: 1.10029, Time: 17.22s
2025-07-17 22:43:09,368 - logger.py:50 - *** New Best Val MSE (x10^-2): 27.5513, Corresponding Test MSE (x10^-2): 28.4262 at Epoch 81 ***
2025-07-17 22:43:09,416 - logger.py:50 - Epoch 81 Summary | Train MSE (x10^-2): 110.0289 | Val MSE (x10^-2): 27.5513 | Time: 54.21s
2025-07-17 22:43:12,496 - logger.py:50 - Epoch: [82][0/6]	Total Loss: 1.07612	Main MSE (x10^-2): 107.6117	LR: 3.75e-04	EMPP_Raw: 1.62310
2025-07-17 22:43:26,749 - logger.py:50 - Epoch: [82][5/6]	Total Loss: 1.09910	Main MSE (x10^-2): 109.9099	LR: 3.75e-04	EMPP_Raw: 1.61289
2025-07-17 22:43:26,794 - logger.py:50 - Epoch 82 Training Summary: Avg Total Loss: 1.09910, Avg Main MSE: 1.09910, Time: 17.37s
2025-07-17 22:43:45,165 - logger.py:50 - Epoch 82 Summary | Train MSE (x10^-2): 109.9099 | Val MSE (x10^-2): 30.4372 | Time: 35.75s
2025-07-17 22:43:48,293 - logger.py:50 - Epoch: [83][0/6]	Total Loss: 1.14380	Main MSE (x10^-2): 114.3803	LR: 3.74e-04	EMPP_Raw: 1.61585
2025-07-17 22:44:02,345 - logger.py:50 - Epoch: [83][5/6]	Total Loss: 1.14148	Main MSE (x10^-2): 114.1476	LR: 3.74e-04	EMPP_Raw: 1.60589
2025-07-17 22:44:02,391 - logger.py:50 - Epoch 83 Training Summary: Avg Total Loss: 1.14148, Avg Main MSE: 1.14148, Time: 17.22s
2025-07-17 22:44:20,740 - logger.py:50 - Epoch 83 Summary | Train MSE (x10^-2): 114.1476 | Val MSE (x10^-2): 30.8342 | Time: 35.57s
2025-07-17 22:44:23,791 - logger.py:50 - Epoch: [84][0/6]	Total Loss: 1.15635	Main MSE (x10^-2): 115.6346	LR: 3.73e-04	EMPP_Raw: 1.60052
2025-07-17 22:44:37,839 - logger.py:50 - Epoch: [84][5/6]	Total Loss: 1.14241	Main MSE (x10^-2): 114.2406	LR: 3.73e-04	EMPP_Raw: 1.59899
2025-07-17 22:44:37,883 - logger.py:50 - Epoch 84 Training Summary: Avg Total Loss: 1.14241, Avg Main MSE: 1.14241, Time: 17.13s
2025-07-17 22:44:56,134 - logger.py:50 - Epoch 84 Summary | Train MSE (x10^-2): 114.2406 | Val MSE (x10^-2): 28.5954 | Time: 35.39s
2025-07-17 22:44:59,341 - logger.py:50 - Epoch: [85][0/6]	Total Loss: 1.06444	Main MSE (x10^-2): 106.4445	LR: 3.73e-04	EMPP_Raw: 1.50785
2025-07-17 22:45:13,404 - logger.py:50 - Epoch: [85][5/6]	Total Loss: 1.05377	Main MSE (x10^-2): 105.3772	LR: 3.73e-04	EMPP_Raw: 1.52005
2025-07-17 22:45:13,444 - logger.py:50 - Epoch 85 Training Summary: Avg Total Loss: 1.05377, Avg Main MSE: 1.05377, Time: 17.30s
2025-07-17 22:45:31,854 - logger.py:50 - Epoch 85 Summary | Train MSE (x10^-2): 105.3772 | Val MSE (x10^-2): 28.2939 | Time: 35.71s
2025-07-17 22:45:35,063 - logger.py:50 - Epoch: [86][0/6]	Total Loss: 1.04838	Main MSE (x10^-2): 104.8382	LR: 3.72e-04	EMPP_Raw: 1.57247
2025-07-17 22:45:49,071 - logger.py:50 - Epoch: [86][5/6]	Total Loss: 1.10548	Main MSE (x10^-2): 110.5479	LR: 3.72e-04	EMPP_Raw: 1.57755
2025-07-17 22:45:49,132 - logger.py:50 - Epoch 86 Training Summary: Avg Total Loss: 1.10548, Avg Main MSE: 1.10548, Time: 17.27s
2025-07-17 22:46:07,592 - logger.py:50 - Epoch 86 Summary | Train MSE (x10^-2): 110.5479 | Val MSE (x10^-2): 46.3769 | Time: 35.73s
2025-07-17 22:46:10,873 - logger.py:50 - Epoch: [87][0/6]	Total Loss: 1.25721	Main MSE (x10^-2): 125.7213	LR: 3.72e-04	EMPP_Raw: 1.58288
2025-07-17 22:46:25,027 - logger.py:50 - Epoch: [87][5/6]	Total Loss: 1.15495	Main MSE (x10^-2): 115.4952	LR: 3.72e-04	EMPP_Raw: 1.56195
2025-07-17 22:46:25,072 - logger.py:50 - Epoch 87 Training Summary: Avg Total Loss: 1.15495, Avg Main MSE: 1.15495, Time: 17.47s
2025-07-17 22:46:43,364 - logger.py:50 - Epoch 87 Summary | Train MSE (x10^-2): 115.4952 | Val MSE (x10^-2): 32.2618 | Time: 35.77s
2025-07-17 22:46:46,410 - logger.py:50 - Epoch: [88][0/6]	Total Loss: 1.14440	Main MSE (x10^-2): 114.4404	LR: 3.71e-04	EMPP_Raw: 1.59565
2025-07-17 22:47:00,614 - logger.py:50 - Epoch: [88][5/6]	Total Loss: 1.11103	Main MSE (x10^-2): 111.1030	LR: 3.71e-04	EMPP_Raw: 1.56995
2025-07-17 22:47:00,665 - logger.py:50 - Epoch 88 Training Summary: Avg Total Loss: 1.11103, Avg Main MSE: 1.11103, Time: 17.29s
2025-07-17 22:47:19,091 - logger.py:50 - Epoch 88 Summary | Train MSE (x10^-2): 111.1030 | Val MSE (x10^-2): 29.4987 | Time: 35.72s
2025-07-17 22:47:22,136 - logger.py:50 - Epoch: [89][0/6]	Total Loss: 1.03010	Main MSE (x10^-2): 103.0096	LR: 3.70e-04	EMPP_Raw: 1.47371
2025-07-17 22:47:36,360 - logger.py:50 - Epoch: [89][5/6]	Total Loss: 1.07210	Main MSE (x10^-2): 107.2097	LR: 3.70e-04	EMPP_Raw: 1.54365
2025-07-17 22:47:36,403 - logger.py:50 - Epoch 89 Training Summary: Avg Total Loss: 1.07210, Avg Main MSE: 1.07210, Time: 17.30s
2025-07-17 22:48:13,414 - logger.py:50 - *** New Best Val MSE (x10^-2): 27.1288, Corresponding Test MSE (x10^-2): 27.8623 at Epoch 89 ***
2025-07-17 22:48:13,461 - logger.py:50 - Epoch 89 Summary | Train MSE (x10^-2): 107.2097 | Val MSE (x10^-2): 27.1288 | Time: 54.37s
2025-07-17 22:48:16,554 - logger.py:50 - Epoch: [90][0/6]	Total Loss: 1.02215	Main MSE (x10^-2): 102.2149	LR: 3.70e-04	EMPP_Raw: 1.53886
2025-07-17 22:48:30,899 - logger.py:50 - Epoch: [90][5/6]	Total Loss: 1.05445	Main MSE (x10^-2): 105.4451	LR: 3.70e-04	EMPP_Raw: 1.54781
2025-07-17 22:48:30,939 - logger.py:50 - Epoch 90 Training Summary: Avg Total Loss: 1.05445, Avg Main MSE: 1.05445, Time: 17.47s
2025-07-17 22:48:49,332 - logger.py:50 - Epoch 90 Summary | Train MSE (x10^-2): 105.4451 | Val MSE (x10^-2): 28.8910 | Time: 35.87s
2025-07-17 22:48:52,456 - logger.py:50 - Epoch: [91][0/6]	Total Loss: 1.11037	Main MSE (x10^-2): 111.0366	LR: 3.69e-04	EMPP_Raw: 1.60000
2025-07-17 22:49:06,523 - logger.py:50 - Epoch: [91][5/6]	Total Loss: 1.09106	Main MSE (x10^-2): 109.1058	LR: 3.69e-04	EMPP_Raw: 1.57385
2025-07-17 22:49:06,567 - logger.py:50 - Epoch 91 Training Summary: Avg Total Loss: 1.09106, Avg Main MSE: 1.09106, Time: 17.23s
2025-07-17 22:49:25,048 - logger.py:50 - Epoch 91 Summary | Train MSE (x10^-2): 109.1058 | Val MSE (x10^-2): 31.9039 | Time: 35.71s
2025-07-17 22:49:28,146 - logger.py:50 - Epoch: [92][0/6]	Total Loss: 1.05677	Main MSE (x10^-2): 105.6774	LR: 3.68e-04	EMPP_Raw: 1.52348
2025-07-17 22:49:42,263 - logger.py:50 - Epoch: [92][5/6]	Total Loss: 1.08494	Main MSE (x10^-2): 108.4941	LR: 3.68e-04	EMPP_Raw: 1.54221
2025-07-17 22:49:42,312 - logger.py:50 - Epoch 92 Training Summary: Avg Total Loss: 1.08494, Avg Main MSE: 1.08494, Time: 17.26s
2025-07-17 22:50:00,741 - logger.py:50 - Epoch 92 Summary | Train MSE (x10^-2): 108.4941 | Val MSE (x10^-2): 30.3805 | Time: 35.69s
2025-07-17 22:50:03,777 - logger.py:50 - Epoch: [93][0/6]	Total Loss: 1.08650	Main MSE (x10^-2): 108.6502	LR: 3.68e-04	EMPP_Raw: 1.53181
2025-07-17 22:50:17,762 - logger.py:50 - Epoch: [93][5/6]	Total Loss: 1.07151	Main MSE (x10^-2): 107.1510	LR: 3.68e-04	EMPP_Raw: 1.57708
2025-07-17 22:50:17,802 - logger.py:50 - Epoch 93 Training Summary: Avg Total Loss: 1.07151, Avg Main MSE: 1.07151, Time: 17.05s
2025-07-17 22:50:54,652 - logger.py:50 - *** New Best Val MSE (x10^-2): 26.0490, Corresponding Test MSE (x10^-2): 26.7294 at Epoch 93 ***
2025-07-17 22:50:54,700 - logger.py:50 - Epoch 93 Summary | Train MSE (x10^-2): 107.1510 | Val MSE (x10^-2): 26.0490 | Time: 53.95s
2025-07-17 22:50:57,818 - logger.py:50 - Epoch: [94][0/6]	Total Loss: 1.03312	Main MSE (x10^-2): 103.3118	LR: 3.67e-04	EMPP_Raw: 1.56499
2025-07-17 22:51:12,114 - logger.py:50 - Epoch: [94][5/6]	Total Loss: 1.06410	Main MSE (x10^-2): 106.4098	LR: 3.67e-04	EMPP_Raw: 1.56629
2025-07-17 22:51:12,155 - logger.py:50 - Epoch 94 Training Summary: Avg Total Loss: 1.06410, Avg Main MSE: 1.06410, Time: 17.45s
2025-07-17 22:51:49,218 - logger.py:50 - *** New Best Val MSE (x10^-2): 26.0100, Corresponding Test MSE (x10^-2): 26.5516 at Epoch 94 ***
2025-07-17 22:51:49,266 - logger.py:50 - Epoch 94 Summary | Train MSE (x10^-2): 106.4098 | Val MSE (x10^-2): 26.0100 | Time: 54.57s
2025-07-17 22:51:52,304 - logger.py:50 - Epoch: [95][0/6]	Total Loss: 1.03656	Main MSE (x10^-2): 103.6562	LR: 3.66e-04	EMPP_Raw: 1.52379
2025-07-17 22:52:06,485 - logger.py:50 - Epoch: [95][5/6]	Total Loss: 1.02667	Main MSE (x10^-2): 102.6666	LR: 3.66e-04	EMPP_Raw: 1.53364
2025-07-17 22:52:06,530 - logger.py:50 - Epoch 95 Training Summary: Avg Total Loss: 1.02667, Avg Main MSE: 1.02667, Time: 17.26s
2025-07-17 22:52:25,415 - logger.py:50 - Epoch 95 Summary | Train MSE (x10^-2): 102.6666 | Val MSE (x10^-2): 27.3302 | Time: 36.15s
2025-07-17 22:52:28,442 - logger.py:50 - Epoch: [96][0/6]	Total Loss: 0.91788	Main MSE (x10^-2): 91.7884	LR: 3.66e-04	EMPP_Raw: 1.36914
2025-07-17 22:52:42,512 - logger.py:50 - Epoch: [96][5/6]	Total Loss: 1.05986	Main MSE (x10^-2): 105.9864	LR: 3.66e-04	EMPP_Raw: 1.55675
2025-07-17 22:52:42,549 - logger.py:50 - Epoch 96 Training Summary: Avg Total Loss: 1.05986, Avg Main MSE: 1.05986, Time: 17.12s
2025-07-17 22:53:01,120 - logger.py:50 - Epoch 96 Summary | Train MSE (x10^-2): 105.9864 | Val MSE (x10^-2): 31.0236 | Time: 35.70s
2025-07-17 22:53:04,225 - logger.py:50 - Epoch: [97][0/6]	Total Loss: 0.99633	Main MSE (x10^-2): 99.6328	LR: 3.65e-04	EMPP_Raw: 1.41194
2025-07-17 22:53:18,260 - logger.py:50 - Epoch: [97][5/6]	Total Loss: 1.03395	Main MSE (x10^-2): 103.3953	LR: 3.65e-04	EMPP_Raw: 1.50502
2025-07-17 22:53:18,305 - logger.py:50 - Epoch 97 Training Summary: Avg Total Loss: 1.03395, Avg Main MSE: 1.03395, Time: 17.18s
2025-07-17 22:53:36,778 - logger.py:50 - Epoch 97 Summary | Train MSE (x10^-2): 103.3953 | Val MSE (x10^-2): 26.5331 | Time: 35.65s
2025-07-17 22:53:39,815 - logger.py:50 - Epoch: [98][0/6]	Total Loss: 1.03512	Main MSE (x10^-2): 103.5122	LR: 3.64e-04	EMPP_Raw: 1.55490
2025-07-17 22:53:54,000 - logger.py:50 - Epoch: [98][5/6]	Total Loss: 1.05244	Main MSE (x10^-2): 105.2440	LR: 3.64e-04	EMPP_Raw: 1.58609
2025-07-17 22:53:54,041 - logger.py:50 - Epoch 98 Training Summary: Avg Total Loss: 1.05244, Avg Main MSE: 1.05244, Time: 17.25s
2025-07-17 22:54:12,613 - logger.py:50 - Epoch 98 Summary | Train MSE (x10^-2): 105.2440 | Val MSE (x10^-2): 26.0533 | Time: 35.83s
2025-07-17 22:54:15,810 - logger.py:50 - Epoch: [99][0/6]	Total Loss: 1.10895	Main MSE (x10^-2): 110.8951	LR: 3.63e-04	EMPP_Raw: 1.67876
2025-07-17 22:54:29,886 - logger.py:50 - Epoch: [99][5/6]	Total Loss: 1.06207	Main MSE (x10^-2): 106.2075	LR: 3.63e-04	EMPP_Raw: 1.54730
2025-07-17 22:54:29,932 - logger.py:50 - Epoch 99 Training Summary: Avg Total Loss: 1.06207, Avg Main MSE: 1.06207, Time: 17.31s
2025-07-17 22:54:48,425 - logger.py:50 - Epoch 99 Summary | Train MSE (x10^-2): 106.2075 | Val MSE (x10^-2): 30.1893 | Time: 35.81s
2025-07-17 22:54:51,627 - logger.py:50 - Epoch: [100][0/6]	Total Loss: 1.09799	Main MSE (x10^-2): 109.7990	LR: 3.63e-04	EMPP_Raw: 1.56050
2025-07-17 22:55:05,698 - logger.py:50 - Epoch: [100][5/6]	Total Loss: 1.08285	Main MSE (x10^-2): 108.2845	LR: 3.63e-04	EMPP_Raw: 1.54437
2025-07-17 22:55:05,757 - logger.py:50 - Epoch 100 Training Summary: Avg Total Loss: 1.08285, Avg Main MSE: 1.08285, Time: 17.32s
2025-07-17 22:55:24,154 - logger.py:50 - Epoch 100 Summary | Train MSE (x10^-2): 108.2845 | Val MSE (x10^-2): 32.4159 | Time: 35.72s
2025-07-17 22:55:27,352 - logger.py:50 - Epoch: [101][0/6]	Total Loss: 1.12325	Main MSE (x10^-2): 112.3251	LR: 3.62e-04	EMPP_Raw: 1.59940
2025-07-17 22:55:41,321 - logger.py:50 - Epoch: [101][5/6]	Total Loss: 1.08161	Main MSE (x10^-2): 108.1605	LR: 3.62e-04	EMPP_Raw: 1.55645
2025-07-17 22:55:41,365 - logger.py:50 - Epoch 101 Training Summary: Avg Total Loss: 1.08161, Avg Main MSE: 1.08161, Time: 17.20s
2025-07-17 22:55:59,811 - logger.py:50 - Epoch 101 Summary | Train MSE (x10^-2): 108.1605 | Val MSE (x10^-2): 31.3113 | Time: 35.65s
2025-07-17 22:56:02,874 - logger.py:50 - Epoch: [102][0/6]	Total Loss: 1.13684	Main MSE (x10^-2): 113.6840	LR: 3.61e-04	EMPP_Raw: 1.65899
2025-07-17 22:56:17,062 - logger.py:50 - Epoch: [102][5/6]	Total Loss: 1.07013	Main MSE (x10^-2): 107.0126	LR: 3.61e-04	EMPP_Raw: 1.56478
2025-07-17 22:56:17,100 - logger.py:50 - Epoch 102 Training Summary: Avg Total Loss: 1.07013, Avg Main MSE: 1.07013, Time: 17.28s
2025-07-17 22:56:35,531 - logger.py:50 - Epoch 102 Summary | Train MSE (x10^-2): 107.0126 | Val MSE (x10^-2): 30.0927 | Time: 35.71s
2025-07-17 22:56:38,571 - logger.py:50 - Epoch: [103][0/6]	Total Loss: 1.09716	Main MSE (x10^-2): 109.7158	LR: 3.60e-04	EMPP_Raw: 1.61017
2025-07-17 22:56:52,611 - logger.py:50 - Epoch: [103][5/6]	Total Loss: 1.06638	Main MSE (x10^-2): 106.6380	LR: 3.60e-04	EMPP_Raw: 1.57822
2025-07-17 22:56:52,652 - logger.py:50 - Epoch 103 Training Summary: Avg Total Loss: 1.06638, Avg Main MSE: 1.06638, Time: 17.11s
2025-07-17 22:57:11,249 - logger.py:50 - Epoch 103 Summary | Train MSE (x10^-2): 106.6380 | Val MSE (x10^-2): 29.8309 | Time: 35.71s
2025-07-17 22:57:14,320 - logger.py:50 - Epoch: [104][0/6]	Total Loss: 1.04440	Main MSE (x10^-2): 104.4398	LR: 3.60e-04	EMPP_Raw: 1.59616
2025-07-17 22:57:28,445 - logger.py:50 - Epoch: [104][5/6]	Total Loss: 1.03480	Main MSE (x10^-2): 103.4800	LR: 3.60e-04	EMPP_Raw: 1.55094
2025-07-17 22:57:28,488 - logger.py:50 - Epoch 104 Training Summary: Avg Total Loss: 1.03480, Avg Main MSE: 1.03480, Time: 17.23s
2025-07-17 22:58:05,482 - logger.py:50 - *** New Best Val MSE (x10^-2): 25.0356, Corresponding Test MSE (x10^-2): 25.9015 at Epoch 104 ***
2025-07-17 22:58:05,533 - logger.py:50 - Epoch 104 Summary | Train MSE (x10^-2): 103.4800 | Val MSE (x10^-2): 25.0356 | Time: 54.28s
2025-07-17 22:58:08,549 - logger.py:50 - Epoch: [105][0/6]	Total Loss: 1.09070	Main MSE (x10^-2): 109.0703	LR: 3.59e-04	EMPP_Raw: 1.72585
2025-07-17 22:58:22,729 - logger.py:50 - Epoch: [105][5/6]	Total Loss: 1.06471	Main MSE (x10^-2): 106.4714	LR: 3.59e-04	EMPP_Raw: 1.62562
2025-07-17 22:58:22,767 - logger.py:50 - Epoch 105 Training Summary: Avg Total Loss: 1.06471, Avg Main MSE: 1.06471, Time: 17.23s
2025-07-17 22:58:41,126 - logger.py:50 - Epoch 105 Summary | Train MSE (x10^-2): 106.4714 | Val MSE (x10^-2): 27.4136 | Time: 35.59s
2025-07-17 22:58:44,218 - logger.py:50 - Epoch: [106][0/6]	Total Loss: 1.02050	Main MSE (x10^-2): 102.0496	LR: 3.58e-04	EMPP_Raw: 1.54936
2025-07-17 22:58:58,247 - logger.py:50 - Epoch: [106][5/6]	Total Loss: 1.04248	Main MSE (x10^-2): 104.2483	LR: 3.58e-04	EMPP_Raw: 1.57383
2025-07-17 22:58:58,291 - logger.py:50 - Epoch 106 Training Summary: Avg Total Loss: 1.04248, Avg Main MSE: 1.04248, Time: 17.16s
2025-07-17 22:59:16,837 - logger.py:50 - Epoch 106 Summary | Train MSE (x10^-2): 104.2483 | Val MSE (x10^-2): 29.0586 | Time: 35.71s
2025-07-17 22:59:19,949 - logger.py:50 - Epoch: [107][0/6]	Total Loss: 1.00085	Main MSE (x10^-2): 100.0852	LR: 3.57e-04	EMPP_Raw: 1.47137
2025-07-17 22:59:33,992 - logger.py:50 - Epoch: [107][5/6]	Total Loss: 1.01560	Main MSE (x10^-2): 101.5595	LR: 3.57e-04	EMPP_Raw: 1.52356
2025-07-17 22:59:34,037 - logger.py:50 - Epoch 107 Training Summary: Avg Total Loss: 1.01560, Avg Main MSE: 1.01560, Time: 17.19s
2025-07-17 22:59:52,467 - logger.py:50 - Epoch 107 Summary | Train MSE (x10^-2): 101.5595 | Val MSE (x10^-2): 25.2764 | Time: 35.62s
2025-07-17 22:59:55,681 - logger.py:50 - Epoch: [108][0/6]	Total Loss: 0.97800	Main MSE (x10^-2): 97.8001	LR: 3.57e-04	EMPP_Raw: 1.51444
2025-07-17 23:00:09,661 - logger.py:50 - Epoch: [108][5/6]	Total Loss: 1.03802	Main MSE (x10^-2): 103.8019	LR: 3.57e-04	EMPP_Raw: 1.58300
2025-07-17 23:00:09,707 - logger.py:50 - Epoch 108 Training Summary: Avg Total Loss: 1.03802, Avg Main MSE: 1.03802, Time: 17.23s
2025-07-17 23:00:28,007 - logger.py:50 - Epoch 108 Summary | Train MSE (x10^-2): 103.8019 | Val MSE (x10^-2): 26.6575 | Time: 35.54s
2025-07-17 23:00:31,197 - logger.py:50 - Epoch: [109][0/6]	Total Loss: 1.07430	Main MSE (x10^-2): 107.4297	LR: 3.56e-04	EMPP_Raw: 1.59708
2025-07-17 23:00:45,181 - logger.py:50 - Epoch: [109][5/6]	Total Loss: 1.03879	Main MSE (x10^-2): 103.8793	LR: 3.56e-04	EMPP_Raw: 1.57917
2025-07-17 23:00:45,224 - logger.py:50 - Epoch 109 Training Summary: Avg Total Loss: 1.03879, Avg Main MSE: 1.03879, Time: 17.21s
2025-07-17 23:01:03,615 - logger.py:50 - Epoch 109 Summary | Train MSE (x10^-2): 103.8793 | Val MSE (x10^-2): 27.1191 | Time: 35.60s
2025-07-17 23:01:06,878 - logger.py:50 - Epoch: [110][0/6]	Total Loss: 1.00393	Main MSE (x10^-2): 100.3925	LR: 3.55e-04	EMPP_Raw: 1.54309
2025-07-17 23:01:20,940 - logger.py:50 - Epoch: [110][5/6]	Total Loss: 1.03609	Main MSE (x10^-2): 103.6088	LR: 3.55e-04	EMPP_Raw: 1.57472
2025-07-17 23:01:20,983 - logger.py:50 - Epoch 110 Training Summary: Avg Total Loss: 1.03609, Avg Main MSE: 1.03609, Time: 17.36s
2025-07-17 23:01:39,422 - logger.py:50 - Epoch 110 Summary | Train MSE (x10^-2): 103.6088 | Val MSE (x10^-2): 25.0545 | Time: 35.80s
2025-07-17 23:01:42,505 - logger.py:50 - Epoch: [111][0/6]	Total Loss: 1.07420	Main MSE (x10^-2): 107.4200	LR: 3.54e-04	EMPP_Raw: 1.72738
2025-07-17 23:01:56,843 - logger.py:50 - Epoch: [111][5/6]	Total Loss: 1.02173	Main MSE (x10^-2): 102.1733	LR: 3.54e-04	EMPP_Raw: 1.57456
2025-07-17 23:01:56,893 - logger.py:50 - Epoch 111 Training Summary: Avg Total Loss: 1.02173, Avg Main MSE: 1.02173, Time: 17.47s
2025-07-17 23:02:15,414 - logger.py:50 - Epoch 111 Summary | Train MSE (x10^-2): 102.1733 | Val MSE (x10^-2): 26.9497 | Time: 35.99s
2025-07-17 23:02:18,457 - logger.py:50 - Epoch: [112][0/6]	Total Loss: 1.00720	Main MSE (x10^-2): 100.7197	LR: 3.53e-04	EMPP_Raw: 1.49121
2025-07-17 23:02:32,517 - logger.py:50 - Epoch: [112][5/6]	Total Loss: 1.02034	Main MSE (x10^-2): 102.0342	LR: 3.53e-04	EMPP_Raw: 1.56568
2025-07-17 23:02:32,566 - logger.py:50 - Epoch 112 Training Summary: Avg Total Loss: 1.02034, Avg Main MSE: 1.02034, Time: 17.14s
2025-07-17 23:02:51,084 - logger.py:50 - Epoch 112 Summary | Train MSE (x10^-2): 102.0342 | Val MSE (x10^-2): 26.4949 | Time: 35.66s
2025-07-17 23:02:54,142 - logger.py:50 - Epoch: [113][0/6]	Total Loss: 0.94584	Main MSE (x10^-2): 94.5836	LR: 3.53e-04	EMPP_Raw: 1.45020
2025-07-17 23:03:08,221 - logger.py:50 - Epoch: [113][5/6]	Total Loss: 1.01113	Main MSE (x10^-2): 101.1129	LR: 3.53e-04	EMPP_Raw: 1.55623
2025-07-17 23:03:08,283 - logger.py:50 - Epoch 113 Training Summary: Avg Total Loss: 1.01113, Avg Main MSE: 1.01113, Time: 17.19s
2025-07-17 23:03:26,754 - logger.py:50 - Epoch 113 Summary | Train MSE (x10^-2): 101.1129 | Val MSE (x10^-2): 25.8488 | Time: 35.66s
2025-07-17 23:03:29,796 - logger.py:50 - Epoch: [114][0/6]	Total Loss: 1.08962	Main MSE (x10^-2): 108.9623	LR: 3.52e-04	EMPP_Raw: 1.68778
2025-07-17 23:03:43,897 - logger.py:50 - Epoch: [114][5/6]	Total Loss: 1.02653	Main MSE (x10^-2): 102.6529	LR: 3.52e-04	EMPP_Raw: 1.58997
2025-07-17 23:03:43,945 - logger.py:50 - Epoch 114 Training Summary: Avg Total Loss: 1.02653, Avg Main MSE: 1.02653, Time: 17.18s
2025-07-17 23:04:20,653 - logger.py:50 - *** New Best Val MSE (x10^-2): 24.9527, Corresponding Test MSE (x10^-2): 25.5468 at Epoch 114 ***
2025-07-17 23:04:20,700 - logger.py:50 - Epoch 114 Summary | Train MSE (x10^-2): 102.6529 | Val MSE (x10^-2): 24.9527 | Time: 53.94s
2025-07-17 23:04:23,752 - logger.py:50 - Epoch: [115][0/6]	Total Loss: 1.00148	Main MSE (x10^-2): 100.1479	LR: 3.51e-04	EMPP_Raw: 1.49648
2025-07-17 23:04:37,805 - logger.py:50 - Epoch: [115][5/6]	Total Loss: 1.00822	Main MSE (x10^-2): 100.8219	LR: 3.51e-04	EMPP_Raw: 1.55117
2025-07-17 23:04:37,843 - logger.py:50 - Epoch 115 Training Summary: Avg Total Loss: 1.00822, Avg Main MSE: 1.00822, Time: 17.14s
2025-07-17 23:04:56,397 - logger.py:50 - Epoch 115 Summary | Train MSE (x10^-2): 100.8219 | Val MSE (x10^-2): 25.0351 | Time: 35.70s
2025-07-17 23:04:59,441 - logger.py:50 - Epoch: [116][0/6]	Total Loss: 1.00326	Main MSE (x10^-2): 100.3262	LR: 3.50e-04	EMPP_Raw: 1.59563
2025-07-17 23:05:13,476 - logger.py:50 - Epoch: [116][5/6]	Total Loss: 1.01208	Main MSE (x10^-2): 101.2080	LR: 3.50e-04	EMPP_Raw: 1.53202
2025-07-17 23:05:13,531 - logger.py:50 - Epoch 116 Training Summary: Avg Total Loss: 1.01208, Avg Main MSE: 1.01208, Time: 17.13s
2025-07-17 23:05:32,025 - logger.py:50 - Epoch 116 Summary | Train MSE (x10^-2): 101.2080 | Val MSE (x10^-2): 27.3188 | Time: 35.62s
2025-07-17 23:05:35,102 - logger.py:50 - Epoch: [117][0/6]	Total Loss: 0.96228	Main MSE (x10^-2): 96.2281	LR: 3.49e-04	EMPP_Raw: 1.46934
2025-07-17 23:05:49,262 - logger.py:50 - Epoch: [117][5/6]	Total Loss: 0.96722	Main MSE (x10^-2): 96.7224	LR: 3.49e-04	EMPP_Raw: 1.47314
2025-07-17 23:05:49,305 - logger.py:50 - Epoch 117 Training Summary: Avg Total Loss: 0.96722, Avg Main MSE: 0.96722, Time: 17.27s
2025-07-17 23:06:26,220 - logger.py:50 - *** New Best Val MSE (x10^-2): 24.7447, Corresponding Test MSE (x10^-2): 25.4114 at Epoch 117 ***
2025-07-17 23:06:26,267 - logger.py:50 - Epoch 117 Summary | Train MSE (x10^-2): 96.7224 | Val MSE (x10^-2): 24.7447 | Time: 54.24s
2025-07-17 23:06:29,318 - logger.py:50 - Epoch: [118][0/6]	Total Loss: 0.96302	Main MSE (x10^-2): 96.3018	LR: 3.48e-04	EMPP_Raw: 1.50086
2025-07-17 23:06:43,429 - logger.py:50 - Epoch: [118][5/6]	Total Loss: 1.00501	Main MSE (x10^-2): 100.5012	LR: 3.48e-04	EMPP_Raw: 1.55685
2025-07-17 23:06:43,466 - logger.py:50 - Epoch 118 Training Summary: Avg Total Loss: 1.00501, Avg Main MSE: 1.00501, Time: 17.19s
2025-07-17 23:07:20,404 - logger.py:50 - *** New Best Val MSE (x10^-2): 24.6929, Corresponding Test MSE (x10^-2): 25.1811 at Epoch 118 ***
2025-07-17 23:07:20,451 - logger.py:50 - Epoch 118 Summary | Train MSE (x10^-2): 100.5012 | Val MSE (x10^-2): 24.6929 | Time: 54.18s
2025-07-17 23:07:23,496 - logger.py:50 - Epoch: [119][0/6]	Total Loss: 1.00231	Main MSE (x10^-2): 100.2306	LR: 3.48e-04	EMPP_Raw: 1.56531
2025-07-17 23:07:37,679 - logger.py:50 - Epoch: [119][5/6]	Total Loss: 1.02601	Main MSE (x10^-2): 102.6008	LR: 3.48e-04	EMPP_Raw: 1.58161
2025-07-17 23:07:37,719 - logger.py:50 - Epoch 119 Training Summary: Avg Total Loss: 1.02601, Avg Main MSE: 1.02601, Time: 17.26s
2025-07-17 23:07:56,171 - logger.py:50 - Epoch 119 Summary | Train MSE (x10^-2): 102.6008 | Val MSE (x10^-2): 28.1344 | Time: 35.72s
2025-07-17 23:07:59,280 - logger.py:50 - Epoch: [120][0/6]	Total Loss: 1.04094	Main MSE (x10^-2): 104.0943	LR: 3.47e-04	EMPP_Raw: 1.56682
2025-07-17 23:08:13,334 - logger.py:50 - Epoch: [120][5/6]	Total Loss: 0.97979	Main MSE (x10^-2): 97.9785	LR: 3.47e-04	EMPP_Raw: 1.50609
2025-07-17 23:08:13,379 - logger.py:50 - Epoch 120 Training Summary: Avg Total Loss: 0.97979, Avg Main MSE: 0.97979, Time: 17.20s
2025-07-17 23:08:31,867 - logger.py:50 - Epoch 120 Summary | Train MSE (x10^-2): 97.9785 | Val MSE (x10^-2): 26.2517 | Time: 35.69s
2025-07-17 23:08:35,097 - logger.py:50 - Epoch: [121][0/6]	Total Loss: 1.08885	Main MSE (x10^-2): 108.8849	LR: 3.46e-04	EMPP_Raw: 1.64293
2025-07-17 23:08:49,125 - logger.py:50 - Epoch: [121][5/6]	Total Loss: 0.99709	Main MSE (x10^-2): 99.7092	LR: 3.46e-04	EMPP_Raw: 1.53209
2025-07-17 23:08:49,169 - logger.py:50 - Epoch 121 Training Summary: Avg Total Loss: 0.99709, Avg Main MSE: 0.99709, Time: 17.29s
2025-07-17 23:09:07,588 - logger.py:50 - Epoch 121 Summary | Train MSE (x10^-2): 99.7092 | Val MSE (x10^-2): 25.2458 | Time: 35.71s
2025-07-17 23:09:10,836 - logger.py:50 - Epoch: [122][0/6]	Total Loss: 0.95088	Main MSE (x10^-2): 95.0877	LR: 3.45e-04	EMPP_Raw: 1.46116
2025-07-17 23:09:24,948 - logger.py:50 - Epoch: [122][5/6]	Total Loss: 0.99800	Main MSE (x10^-2): 99.7997	LR: 3.45e-04	EMPP_Raw: 1.55245
2025-07-17 23:09:24,989 - logger.py:50 - Epoch 122 Training Summary: Avg Total Loss: 0.99800, Avg Main MSE: 0.99800, Time: 17.39s
2025-07-17 23:09:43,299 - logger.py:50 - Epoch 122 Summary | Train MSE (x10^-2): 99.7997 | Val MSE (x10^-2): 24.7439 | Time: 35.71s
2025-07-17 23:09:46,507 - logger.py:50 - Epoch: [123][0/6]	Total Loss: 0.95313	Main MSE (x10^-2): 95.3127	LR: 3.44e-04	EMPP_Raw: 1.49729
2025-07-17 23:10:00,535 - logger.py:50 - Epoch: [123][5/6]	Total Loss: 0.96105	Main MSE (x10^-2): 96.1050	LR: 3.44e-04	EMPP_Raw: 1.50364
2025-07-17 23:10:00,578 - logger.py:50 - Epoch 123 Training Summary: Avg Total Loss: 0.96105, Avg Main MSE: 0.96105, Time: 17.27s
2025-07-17 23:10:37,350 - logger.py:50 - *** New Best Val MSE (x10^-2): 24.6721, Corresponding Test MSE (x10^-2): 25.1047 at Epoch 123 ***
2025-07-17 23:10:37,397 - logger.py:50 - Epoch 123 Summary | Train MSE (x10^-2): 96.1050 | Val MSE (x10^-2): 24.6721 | Time: 54.09s
2025-07-17 23:10:40,501 - logger.py:50 - Epoch: [124][0/6]	Total Loss: 1.07456	Main MSE (x10^-2): 107.4559	LR: 3.43e-04	EMPP_Raw: 1.71055
2025-07-17 23:10:54,703 - logger.py:50 - Epoch: [124][5/6]	Total Loss: 0.99372	Main MSE (x10^-2): 99.3724	LR: 3.43e-04	EMPP_Raw: 1.56616
2025-07-17 23:10:54,748 - logger.py:50 - Epoch 124 Training Summary: Avg Total Loss: 0.99372, Avg Main MSE: 0.99372, Time: 17.35s
2025-07-17 23:11:13,038 - logger.py:50 - Epoch 124 Summary | Train MSE (x10^-2): 99.3724 | Val MSE (x10^-2): 24.6910 | Time: 35.64s
2025-07-17 23:11:16,238 - logger.py:50 - Epoch: [125][0/6]	Total Loss: 0.95075	Main MSE (x10^-2): 95.0750	LR: 3.42e-04	EMPP_Raw: 1.49136
2025-07-17 23:11:30,250 - logger.py:50 - Epoch: [125][5/6]	Total Loss: 0.97683	Main MSE (x10^-2): 97.6827	LR: 3.42e-04	EMPP_Raw: 1.51903
2025-07-17 23:11:30,301 - logger.py:50 - Epoch 125 Training Summary: Avg Total Loss: 0.97683, Avg Main MSE: 0.97683, Time: 17.25s
2025-07-17 23:11:48,638 - logger.py:50 - Epoch 125 Summary | Train MSE (x10^-2): 97.6827 | Val MSE (x10^-2): 25.6847 | Time: 35.59s
2025-07-17 23:11:51,907 - logger.py:50 - Epoch: [126][0/6]	Total Loss: 0.98980	Main MSE (x10^-2): 98.9801	LR: 3.42e-04	EMPP_Raw: 1.48435
2025-07-17 23:12:05,948 - logger.py:50 - Epoch: [126][5/6]	Total Loss: 0.96542	Main MSE (x10^-2): 96.5424	LR: 3.42e-04	EMPP_Raw: 1.50504
2025-07-17 23:12:05,991 - logger.py:50 - Epoch 126 Training Summary: Avg Total Loss: 0.96542, Avg Main MSE: 0.96542, Time: 17.34s
2025-07-17 23:12:43,115 - logger.py:50 - *** New Best Val MSE (x10^-2): 24.1224, Corresponding Test MSE (x10^-2): 24.7245 at Epoch 126 ***
2025-07-17 23:12:43,163 - logger.py:50 - Epoch 126 Summary | Train MSE (x10^-2): 96.5424 | Val MSE (x10^-2): 24.1224 | Time: 54.52s
2025-07-17 23:12:46,359 - logger.py:50 - Epoch: [127][0/6]	Total Loss: 0.93700	Main MSE (x10^-2): 93.7001	LR: 3.41e-04	EMPP_Raw: 1.44429
2025-07-17 23:13:00,648 - logger.py:50 - Epoch: [127][5/6]	Total Loss: 0.95249	Main MSE (x10^-2): 95.2488	LR: 3.41e-04	EMPP_Raw: 1.48636
2025-07-17 23:13:00,685 - logger.py:50 - Epoch 127 Training Summary: Avg Total Loss: 0.95249, Avg Main MSE: 0.95249, Time: 17.52s
2025-07-17 23:13:19,181 - logger.py:50 - Epoch 127 Summary | Train MSE (x10^-2): 95.2488 | Val MSE (x10^-2): 26.1580 | Time: 36.02s
2025-07-17 23:13:22,506 - logger.py:50 - Epoch: [128][0/6]	Total Loss: 0.88510	Main MSE (x10^-2): 88.5095	LR: 3.40e-04	EMPP_Raw: 1.43027
2025-07-17 23:13:36,601 - logger.py:50 - Epoch: [128][5/6]	Total Loss: 0.97904	Main MSE (x10^-2): 97.9035	LR: 3.40e-04	EMPP_Raw: 1.54112
2025-07-17 23:13:36,644 - logger.py:50 - Epoch 128 Training Summary: Avg Total Loss: 0.97904, Avg Main MSE: 0.97904, Time: 17.45s
2025-07-17 23:13:55,135 - logger.py:50 - Epoch 128 Summary | Train MSE (x10^-2): 97.9035 | Val MSE (x10^-2): 25.4583 | Time: 35.95s
2025-07-17 23:13:58,424 - logger.py:50 - Epoch: [129][0/6]	Total Loss: 0.98173	Main MSE (x10^-2): 98.1734	LR: 3.39e-04	EMPP_Raw: 1.58403
2025-07-17 23:14:12,447 - logger.py:50 - Epoch: [129][5/6]	Total Loss: 0.96810	Main MSE (x10^-2): 96.8102	LR: 3.39e-04	EMPP_Raw: 1.50610
2025-07-17 23:14:12,490 - logger.py:50 - Epoch 129 Training Summary: Avg Total Loss: 0.96810, Avg Main MSE: 0.96810, Time: 17.35s
2025-07-17 23:14:30,888 - logger.py:50 - Epoch 129 Summary | Train MSE (x10^-2): 96.8102 | Val MSE (x10^-2): 25.8786 | Time: 35.75s
2025-07-17 23:14:33,939 - logger.py:50 - Epoch: [130][0/6]	Total Loss: 1.01567	Main MSE (x10^-2): 101.5667	LR: 3.38e-04	EMPP_Raw: 1.64875
2025-07-17 23:14:48,261 - logger.py:50 - Epoch: [130][5/6]	Total Loss: 0.99006	Main MSE (x10^-2): 99.0063	LR: 3.38e-04	EMPP_Raw: 1.57168
2025-07-17 23:14:48,302 - logger.py:50 - Epoch 130 Training Summary: Avg Total Loss: 0.99006, Avg Main MSE: 0.99006, Time: 17.40s
2025-07-17 23:15:06,659 - logger.py:50 - Epoch 130 Summary | Train MSE (x10^-2): 99.0063 | Val MSE (x10^-2): 24.1998 | Time: 35.76s
2025-07-17 23:15:09,726 - logger.py:50 - Epoch: [131][0/6]	Total Loss: 0.91908	Main MSE (x10^-2): 91.9079	LR: 3.37e-04	EMPP_Raw: 1.41454
2025-07-17 23:15:23,816 - logger.py:50 - Epoch: [131][5/6]	Total Loss: 0.94298	Main MSE (x10^-2): 94.2976	LR: 3.37e-04	EMPP_Raw: 1.48878
2025-07-17 23:15:23,860 - logger.py:50 - Epoch 131 Training Summary: Avg Total Loss: 0.94298, Avg Main MSE: 0.94298, Time: 17.19s
2025-07-17 23:15:42,377 - logger.py:50 - Epoch 131 Summary | Train MSE (x10^-2): 94.2976 | Val MSE (x10^-2): 24.5093 | Time: 35.71s
2025-07-17 23:15:45,484 - logger.py:50 - Epoch: [132][0/6]	Total Loss: 0.91478	Main MSE (x10^-2): 91.4778	LR: 3.36e-04	EMPP_Raw: 1.49174
2025-07-17 23:15:59,590 - logger.py:50 - Epoch: [132][5/6]	Total Loss: 0.99455	Main MSE (x10^-2): 99.4554	LR: 3.36e-04	EMPP_Raw: 1.58169
2025-07-17 23:15:59,649 - logger.py:50 - Epoch 132 Training Summary: Avg Total Loss: 0.99455, Avg Main MSE: 0.99455, Time: 17.26s
2025-07-17 23:16:18,169 - logger.py:50 - Epoch 132 Summary | Train MSE (x10^-2): 99.4554 | Val MSE (x10^-2): 24.8045 | Time: 35.79s
2025-07-17 23:16:21,218 - logger.py:50 - Epoch: [133][0/6]	Total Loss: 0.95369	Main MSE (x10^-2): 95.3687	LR: 3.35e-04	EMPP_Raw: 1.45207
2025-07-17 23:16:35,342 - logger.py:50 - Epoch: [133][5/6]	Total Loss: 0.94875	Main MSE (x10^-2): 94.8752	LR: 3.35e-04	EMPP_Raw: 1.50334
2025-07-17 23:16:35,384 - logger.py:50 - Epoch 133 Training Summary: Avg Total Loss: 0.94875, Avg Main MSE: 0.94875, Time: 17.21s
2025-07-17 23:16:53,785 - logger.py:50 - Epoch 133 Summary | Train MSE (x10^-2): 94.8752 | Val MSE (x10^-2): 25.0333 | Time: 35.61s
2025-07-17 23:16:56,969 - logger.py:50 - Epoch: [134][0/6]	Total Loss: 0.91810	Main MSE (x10^-2): 91.8096	LR: 3.34e-04	EMPP_Raw: 1.42959
2025-07-17 23:17:11,044 - logger.py:50 - Epoch: [134][5/6]	Total Loss: 0.95659	Main MSE (x10^-2): 95.6590	LR: 3.34e-04	EMPP_Raw: 1.52101
2025-07-17 23:17:11,087 - logger.py:50 - Epoch 134 Training Summary: Avg Total Loss: 0.95659, Avg Main MSE: 0.95659, Time: 17.29s
2025-07-17 23:17:29,586 - logger.py:50 - Epoch 134 Summary | Train MSE (x10^-2): 95.6590 | Val MSE (x10^-2): 25.0001 | Time: 35.79s
2025-07-17 23:17:32,801 - logger.py:50 - Epoch: [135][0/6]	Total Loss: 0.98049	Main MSE (x10^-2): 98.0491	LR: 3.33e-04	EMPP_Raw: 1.56263
2025-07-17 23:17:46,916 - logger.py:50 - Epoch: [135][5/6]	Total Loss: 0.98900	Main MSE (x10^-2): 98.9004	LR: 3.33e-04	EMPP_Raw: 1.56992
2025-07-17 23:17:46,958 - logger.py:50 - Epoch 135 Training Summary: Avg Total Loss: 0.98900, Avg Main MSE: 0.98900, Time: 17.36s
2025-07-17 23:18:05,233 - logger.py:50 - Epoch 135 Summary | Train MSE (x10^-2): 98.9004 | Val MSE (x10^-2): 25.6449 | Time: 35.64s
2025-07-17 23:18:08,471 - logger.py:50 - Epoch: [136][0/6]	Total Loss: 1.03091	Main MSE (x10^-2): 103.0914	LR: 3.32e-04	EMPP_Raw: 1.72319
2025-07-17 23:18:22,446 - logger.py:50 - Epoch: [136][5/6]	Total Loss: 0.96784	Main MSE (x10^-2): 96.7841	LR: 3.32e-04	EMPP_Raw: 1.54774
2025-07-17 23:18:22,488 - logger.py:50 - Epoch 136 Training Summary: Avg Total Loss: 0.96784, Avg Main MSE: 0.96784, Time: 17.25s
2025-07-17 23:18:40,856 - logger.py:50 - Epoch 136 Summary | Train MSE (x10^-2): 96.7841 | Val MSE (x10^-2): 25.5746 | Time: 35.62s
2025-07-17 23:18:43,983 - logger.py:50 - Epoch: [137][0/6]	Total Loss: 0.98101	Main MSE (x10^-2): 98.1013	LR: 3.31e-04	EMPP_Raw: 1.60925
2025-07-17 23:18:58,579 - logger.py:50 - Epoch: [137][5/6]	Total Loss: 0.99538	Main MSE (x10^-2): 99.5378	LR: 3.31e-04	EMPP_Raw: 1.58343
2025-07-17 23:18:58,630 - logger.py:50 - Epoch 137 Training Summary: Avg Total Loss: 0.99538, Avg Main MSE: 0.99538, Time: 17.76s
2025-07-17 23:19:17,296 - logger.py:50 - Epoch 137 Summary | Train MSE (x10^-2): 99.5378 | Val MSE (x10^-2): 27.3148 | Time: 36.43s
2025-07-17 23:19:20,372 - logger.py:50 - Epoch: [138][0/6]	Total Loss: 1.07152	Main MSE (x10^-2): 107.1520	LR: 3.31e-04	EMPP_Raw: 1.69282
2025-07-17 23:19:34,751 - logger.py:50 - Epoch: [138][5/6]	Total Loss: 1.01533	Main MSE (x10^-2): 101.5335	LR: 3.31e-04	EMPP_Raw: 1.60315
2025-07-17 23:19:34,808 - logger.py:50 - Epoch 138 Training Summary: Avg Total Loss: 1.01533, Avg Main MSE: 1.01533, Time: 17.50s
2025-07-17 23:19:53,396 - logger.py:50 - Epoch 138 Summary | Train MSE (x10^-2): 101.5335 | Val MSE (x10^-2): 25.4690 | Time: 36.10s
2025-07-17 23:19:56,433 - logger.py:50 - Epoch: [139][0/6]	Total Loss: 0.97572	Main MSE (x10^-2): 97.5724	LR: 3.30e-04	EMPP_Raw: 1.48886
2025-07-17 23:20:10,477 - logger.py:50 - Epoch: [139][5/6]	Total Loss: 0.95984	Main MSE (x10^-2): 95.9840	LR: 3.30e-04	EMPP_Raw: 1.52554
2025-07-17 23:20:10,518 - logger.py:50 - Epoch 139 Training Summary: Avg Total Loss: 0.95984, Avg Main MSE: 0.95984, Time: 17.11s
2025-07-17 23:20:29,010 - logger.py:50 - Epoch 139 Summary | Train MSE (x10^-2): 95.9840 | Val MSE (x10^-2): 24.6145 | Time: 35.61s
2025-07-17 23:20:32,082 - logger.py:50 - Epoch: [140][0/6]	Total Loss: 0.95749	Main MSE (x10^-2): 95.7487	LR: 3.29e-04	EMPP_Raw: 1.54086
2025-07-17 23:20:46,203 - logger.py:50 - Epoch: [140][5/6]	Total Loss: 0.97823	Main MSE (x10^-2): 97.8229	LR: 3.29e-04	EMPP_Raw: 1.54050
2025-07-17 23:20:46,246 - logger.py:50 - Epoch 140 Training Summary: Avg Total Loss: 0.97823, Avg Main MSE: 0.97823, Time: 17.23s
2025-07-17 23:21:04,791 - logger.py:50 - Epoch 140 Summary | Train MSE (x10^-2): 97.8229 | Val MSE (x10^-2): 28.6345 | Time: 35.78s
2025-07-17 23:21:07,832 - logger.py:50 - Epoch: [141][0/6]	Total Loss: 0.97406	Main MSE (x10^-2): 97.4060	LR: 3.28e-04	EMPP_Raw: 1.52062
2025-07-17 23:21:21,873 - logger.py:50 - Epoch: [141][5/6]	Total Loss: 0.97337	Main MSE (x10^-2): 97.3367	LR: 3.28e-04	EMPP_Raw: 1.53508
2025-07-17 23:21:21,915 - logger.py:50 - Epoch 141 Training Summary: Avg Total Loss: 0.97337, Avg Main MSE: 0.97337, Time: 17.11s
2025-07-17 23:21:40,258 - logger.py:50 - Epoch 141 Summary | Train MSE (x10^-2): 97.3367 | Val MSE (x10^-2): 25.4278 | Time: 35.46s
2025-07-17 23:21:43,729 - logger.py:50 - Epoch: [142][0/6]	Total Loss: 0.90786	Main MSE (x10^-2): 90.7860	LR: 3.27e-04	EMPP_Raw: 1.46122
2025-07-17 23:21:57,788 - logger.py:50 - Epoch: [142][5/6]	Total Loss: 0.95628	Main MSE (x10^-2): 95.6278	LR: 3.27e-04	EMPP_Raw: 1.52359
2025-07-17 23:21:57,839 - logger.py:50 - Epoch 142 Training Summary: Avg Total Loss: 0.95628, Avg Main MSE: 0.95628, Time: 17.57s
2025-07-17 23:22:16,269 - logger.py:50 - Epoch 142 Summary | Train MSE (x10^-2): 95.6278 | Val MSE (x10^-2): 24.4756 | Time: 36.01s
2025-07-17 23:22:19,305 - logger.py:50 - Epoch: [143][0/6]	Total Loss: 0.92954	Main MSE (x10^-2): 92.9545	LR: 3.26e-04	EMPP_Raw: 1.46413
2025-07-17 23:22:33,397 - logger.py:50 - Epoch: [143][5/6]	Total Loss: 0.94844	Main MSE (x10^-2): 94.8445	LR: 3.26e-04	EMPP_Raw: 1.50494
2025-07-17 23:22:33,447 - logger.py:50 - Epoch 143 Training Summary: Avg Total Loss: 0.94844, Avg Main MSE: 0.94844, Time: 17.17s
2025-07-17 23:22:51,810 - logger.py:50 - Epoch 143 Summary | Train MSE (x10^-2): 94.8445 | Val MSE (x10^-2): 24.7425 | Time: 35.53s
2025-07-17 23:22:55,067 - logger.py:50 - Epoch: [144][0/6]	Total Loss: 0.90341	Main MSE (x10^-2): 90.3407	LR: 3.25e-04	EMPP_Raw: 1.47422
2025-07-17 23:23:09,169 - logger.py:50 - Epoch: [144][5/6]	Total Loss: 0.94004	Main MSE (x10^-2): 94.0038	LR: 3.25e-04	EMPP_Raw: 1.49476
2025-07-17 23:23:09,214 - logger.py:50 - Epoch 144 Training Summary: Avg Total Loss: 0.94004, Avg Main MSE: 0.94004, Time: 17.39s
2025-07-17 23:23:27,956 - logger.py:50 - Epoch 144 Summary | Train MSE (x10^-2): 94.0038 | Val MSE (x10^-2): 24.3011 | Time: 36.14s
2025-07-17 23:23:30,994 - logger.py:50 - Epoch: [145][0/6]	Total Loss: 0.89176	Main MSE (x10^-2): 89.1761	LR: 3.24e-04	EMPP_Raw: 1.46556
2025-07-17 23:23:45,266 - logger.py:50 - Epoch: [145][5/6]	Total Loss: 1.00605	Main MSE (x10^-2): 100.6048	LR: 3.24e-04	EMPP_Raw: 1.62755
2025-07-17 23:23:45,312 - logger.py:50 - Epoch 145 Training Summary: Avg Total Loss: 1.00605, Avg Main MSE: 1.00605, Time: 17.35s
2025-07-17 23:24:03,684 - logger.py:50 - Epoch 145 Summary | Train MSE (x10^-2): 100.6048 | Val MSE (x10^-2): 24.4312 | Time: 35.72s
2025-07-17 23:24:06,745 - logger.py:50 - Epoch: [146][0/6]	Total Loss: 0.99676	Main MSE (x10^-2): 99.6764	LR: 3.23e-04	EMPP_Raw: 1.62728
2025-07-17 23:24:20,986 - logger.py:50 - Epoch: [146][5/6]	Total Loss: 0.96279	Main MSE (x10^-2): 96.2785	LR: 3.23e-04	EMPP_Raw: 1.54055
2025-07-17 23:24:21,030 - logger.py:50 - Epoch 146 Training Summary: Avg Total Loss: 0.96279, Avg Main MSE: 0.96279, Time: 17.34s
2025-07-17 23:24:39,405 - logger.py:50 - Epoch 146 Summary | Train MSE (x10^-2): 96.2785 | Val MSE (x10^-2): 25.8736 | Time: 35.72s
2025-07-17 23:24:42,477 - logger.py:50 - Epoch: [147][0/6]	Total Loss: 1.02606	Main MSE (x10^-2): 102.6059	LR: 3.22e-04	EMPP_Raw: 1.67349
2025-07-17 23:24:56,610 - logger.py:50 - Epoch: [147][5/6]	Total Loss: 0.94517	Main MSE (x10^-2): 94.5174	LR: 3.22e-04	EMPP_Raw: 1.52459
2025-07-17 23:24:56,654 - logger.py:50 - Epoch 147 Training Summary: Avg Total Loss: 0.94517, Avg Main MSE: 0.94517, Time: 17.24s
2025-07-17 23:25:15,372 - logger.py:50 - Epoch 147 Summary | Train MSE (x10^-2): 94.5174 | Val MSE (x10^-2): 25.4194 | Time: 35.96s
2025-07-17 23:25:18,454 - logger.py:50 - Epoch: [148][0/6]	Total Loss: 0.94219	Main MSE (x10^-2): 94.2194	LR: 3.21e-04	EMPP_Raw: 1.51769
2025-07-17 23:25:32,854 - logger.py:50 - Epoch: [148][5/6]	Total Loss: 0.94945	Main MSE (x10^-2): 94.9448	LR: 3.21e-04	EMPP_Raw: 1.53257
2025-07-17 23:25:32,905 - logger.py:50 - Epoch 148 Training Summary: Avg Total Loss: 0.94945, Avg Main MSE: 0.94945, Time: 17.52s
2025-07-17 23:25:51,495 - logger.py:50 - Epoch 148 Summary | Train MSE (x10^-2): 94.9448 | Val MSE (x10^-2): 25.4436 | Time: 36.12s
2025-07-17 23:25:54,568 - logger.py:50 - Epoch: [149][0/6]	Total Loss: 1.01167	Main MSE (x10^-2): 101.1674	LR: 3.20e-04	EMPP_Raw: 1.63880
2025-07-17 23:26:08,710 - logger.py:50 - Epoch: [149][5/6]	Total Loss: 0.95881	Main MSE (x10^-2): 95.8812	LR: 3.20e-04	EMPP_Raw: 1.55851
2025-07-17 23:26:08,753 - logger.py:50 - Epoch 149 Training Summary: Avg Total Loss: 0.95881, Avg Main MSE: 0.95881, Time: 17.25s
2025-07-17 23:26:27,227 - logger.py:50 - Epoch 149 Summary | Train MSE (x10^-2): 95.8812 | Val MSE (x10^-2): 24.7635 | Time: 35.73s
2025-07-17 23:26:30,434 - logger.py:50 - Epoch: [150][0/6]	Total Loss: 0.94877	Main MSE (x10^-2): 94.8775	LR: 3.19e-04	EMPP_Raw: 1.52015
2025-07-17 23:26:44,505 - logger.py:50 - Epoch: [150][5/6]	Total Loss: 0.95258	Main MSE (x10^-2): 95.2580	LR: 3.19e-04	EMPP_Raw: 1.55400
2025-07-17 23:26:44,547 - logger.py:50 - Epoch 150 Training Summary: Avg Total Loss: 0.95258, Avg Main MSE: 0.95258, Time: 17.31s
2025-07-17 23:27:02,991 - logger.py:50 - Epoch 150 Summary | Train MSE (x10^-2): 95.2580 | Val MSE (x10^-2): 25.2315 | Time: 35.76s
2025-07-17 23:27:06,044 - logger.py:50 - Epoch: [151][0/6]	Total Loss: 0.90900	Main MSE (x10^-2): 90.9001	LR: 3.18e-04	EMPP_Raw: 1.49701
2025-07-17 23:27:20,376 - logger.py:50 - Epoch: [151][5/6]	Total Loss: 0.94810	Main MSE (x10^-2): 94.8096	LR: 3.18e-04	EMPP_Raw: 1.55184
2025-07-17 23:27:20,440 - logger.py:50 - Epoch 151 Training Summary: Avg Total Loss: 0.94810, Avg Main MSE: 0.94810, Time: 17.44s
2025-07-17 23:27:38,868 - logger.py:50 - Epoch 151 Summary | Train MSE (x10^-2): 94.8096 | Val MSE (x10^-2): 25.9869 | Time: 35.88s
2025-07-17 23:27:41,983 - logger.py:50 - Epoch: [152][0/6]	Total Loss: 0.92913	Main MSE (x10^-2): 92.9131	LR: 3.17e-04	EMPP_Raw: 1.52086
2025-07-17 23:27:56,277 - logger.py:50 - Epoch: [152][5/6]	Total Loss: 0.94075	Main MSE (x10^-2): 94.0747	LR: 3.17e-04	EMPP_Raw: 1.53459
2025-07-17 23:27:56,338 - logger.py:50 - Epoch 152 Training Summary: Avg Total Loss: 0.94075, Avg Main MSE: 0.94075, Time: 17.46s
2025-07-17 23:28:15,001 - logger.py:50 - Epoch 152 Summary | Train MSE (x10^-2): 94.0747 | Val MSE (x10^-2): 24.8450 | Time: 36.13s
2025-07-17 23:28:18,072 - logger.py:50 - Epoch: [153][0/6]	Total Loss: 0.91324	Main MSE (x10^-2): 91.3245	LR: 3.16e-04	EMPP_Raw: 1.49481
2025-07-17 23:28:32,181 - logger.py:50 - Epoch: [153][5/6]	Total Loss: 0.93493	Main MSE (x10^-2): 93.4928	LR: 3.16e-04	EMPP_Raw: 1.52122
2025-07-17 23:28:32,232 - logger.py:50 - Epoch 153 Training Summary: Avg Total Loss: 0.93493, Avg Main MSE: 0.93493, Time: 17.22s
2025-07-17 23:28:50,811 - logger.py:50 - Epoch 153 Summary | Train MSE (x10^-2): 93.4928 | Val MSE (x10^-2): 25.9957 | Time: 35.80s
2025-07-17 23:28:53,896 - logger.py:50 - Epoch: [154][0/6]	Total Loss: 0.95202	Main MSE (x10^-2): 95.2016	LR: 3.15e-04	EMPP_Raw: 1.54686
2025-07-17 23:29:08,075 - logger.py:50 - Epoch: [154][5/6]	Total Loss: 0.95416	Main MSE (x10^-2): 95.4158	LR: 3.15e-04	EMPP_Raw: 1.55709
2025-07-17 23:29:08,118 - logger.py:50 - Epoch 154 Training Summary: Avg Total Loss: 0.95416, Avg Main MSE: 0.95416, Time: 17.30s
2025-07-17 23:29:26,752 - logger.py:50 - Epoch 154 Summary | Train MSE (x10^-2): 95.4158 | Val MSE (x10^-2): 24.6959 | Time: 35.94s
2025-07-17 23:29:29,827 - logger.py:50 - Epoch: [155][0/6]	Total Loss: 0.86974	Main MSE (x10^-2): 86.9742	LR: 3.14e-04	EMPP_Raw: 1.38784
2025-07-17 23:29:43,967 - logger.py:50 - Epoch: [155][5/6]	Total Loss: 0.94340	Main MSE (x10^-2): 94.3401	LR: 3.14e-04	EMPP_Raw: 1.53386
2025-07-17 23:29:44,009 - logger.py:50 - Epoch 155 Training Summary: Avg Total Loss: 0.94340, Avg Main MSE: 0.94340, Time: 17.25s
2025-07-17 23:30:02,336 - logger.py:50 - Epoch 155 Summary | Train MSE (x10^-2): 94.3401 | Val MSE (x10^-2): 25.3759 | Time: 35.58s
2025-07-17 23:30:05,638 - logger.py:50 - Epoch: [156][0/6]	Total Loss: 0.94376	Main MSE (x10^-2): 94.3756	LR: 3.13e-04	EMPP_Raw: 1.54054
2025-07-17 23:30:19,758 - logger.py:50 - Epoch: [156][5/6]	Total Loss: 0.94675	Main MSE (x10^-2): 94.6747	LR: 3.13e-04	EMPP_Raw: 1.53328
2025-07-17 23:30:19,799 - logger.py:50 - Epoch 156 Training Summary: Avg Total Loss: 0.94675, Avg Main MSE: 0.94675, Time: 17.45s
2025-07-17 23:30:38,127 - logger.py:50 - Epoch 156 Summary | Train MSE (x10^-2): 94.6747 | Val MSE (x10^-2): 25.4667 | Time: 35.78s
2025-07-17 23:30:41,249 - logger.py:50 - Epoch: [157][0/6]	Total Loss: 0.96578	Main MSE (x10^-2): 96.5775	LR: 3.12e-04	EMPP_Raw: 1.60513
2025-07-17 23:30:55,423 - logger.py:50 - Epoch: [157][5/6]	Total Loss: 0.91326	Main MSE (x10^-2): 91.3264	LR: 3.12e-04	EMPP_Raw: 1.49527
2025-07-17 23:30:55,468 - logger.py:50 - Epoch 157 Training Summary: Avg Total Loss: 0.91326, Avg Main MSE: 0.91326, Time: 17.33s
2025-07-17 23:31:13,696 - logger.py:50 - Epoch 157 Summary | Train MSE (x10^-2): 91.3264 | Val MSE (x10^-2): 24.1709 | Time: 35.56s
2025-07-17 23:31:16,741 - logger.py:50 - Epoch: [158][0/6]	Total Loss: 0.86508	Main MSE (x10^-2): 86.5076	LR: 3.11e-04	EMPP_Raw: 1.43737
2025-07-17 23:31:30,985 - logger.py:50 - Epoch: [158][5/6]	Total Loss: 0.93567	Main MSE (x10^-2): 93.5669	LR: 3.11e-04	EMPP_Raw: 1.53785
2025-07-17 23:31:31,026 - logger.py:50 - Epoch 158 Training Summary: Avg Total Loss: 0.93567, Avg Main MSE: 0.93567, Time: 17.32s
2025-07-17 23:31:49,352 - logger.py:50 - Epoch 158 Summary | Train MSE (x10^-2): 93.5669 | Val MSE (x10^-2): 24.8358 | Time: 35.65s
2025-07-17 23:31:52,399 - logger.py:50 - Epoch: [159][0/6]	Total Loss: 0.83770	Main MSE (x10^-2): 83.7704	LR: 3.10e-04	EMPP_Raw: 1.36558
2025-07-17 23:32:06,449 - logger.py:50 - Epoch: [159][5/6]	Total Loss: 0.90960	Main MSE (x10^-2): 90.9598	LR: 3.10e-04	EMPP_Raw: 1.50063
2025-07-17 23:32:06,493 - logger.py:50 - Epoch 159 Training Summary: Avg Total Loss: 0.90960, Avg Main MSE: 0.90960, Time: 17.13s
2025-07-17 23:32:24,948 - logger.py:50 - Epoch 159 Summary | Train MSE (x10^-2): 90.9598 | Val MSE (x10^-2): 25.3733 | Time: 35.59s
2025-07-17 23:32:28,028 - logger.py:50 - Epoch: [160][0/6]	Total Loss: 0.84026	Main MSE (x10^-2): 84.0259	LR: 3.08e-04	EMPP_Raw: 1.37141
2025-07-17 23:32:42,141 - logger.py:50 - Epoch: [160][5/6]	Total Loss: 0.92755	Main MSE (x10^-2): 92.7550	LR: 3.08e-04	EMPP_Raw: 1.52808
2025-07-17 23:32:42,180 - logger.py:50 - Epoch 160 Training Summary: Avg Total Loss: 0.92755, Avg Main MSE: 0.92755, Time: 17.22s
2025-07-17 23:33:00,594 - logger.py:50 - Epoch 160 Summary | Train MSE (x10^-2): 92.7550 | Val MSE (x10^-2): 25.4594 | Time: 35.64s
2025-07-17 23:33:03,793 - logger.py:50 - Epoch: [161][0/6]	Total Loss: 0.86761	Main MSE (x10^-2): 86.7614	LR: 3.07e-04	EMPP_Raw: 1.44001
2025-07-17 23:33:17,827 - logger.py:50 - Epoch: [161][5/6]	Total Loss: 0.88866	Main MSE (x10^-2): 88.8656	LR: 3.07e-04	EMPP_Raw: 1.46605
2025-07-17 23:33:17,865 - logger.py:50 - Epoch 161 Training Summary: Avg Total Loss: 0.88866, Avg Main MSE: 0.88866, Time: 17.26s
2025-07-17 23:33:36,515 - logger.py:50 - Epoch 161 Summary | Train MSE (x10^-2): 88.8656 | Val MSE (x10^-2): 25.1829 | Time: 35.92s
2025-07-17 23:33:39,832 - logger.py:50 - Epoch: [162][0/6]	Total Loss: 0.95273	Main MSE (x10^-2): 95.2729	LR: 3.06e-04	EMPP_Raw: 1.56746
2025-07-17 23:33:54,066 - logger.py:50 - Epoch: [162][5/6]	Total Loss: 0.93060	Main MSE (x10^-2): 93.0597	LR: 3.06e-04	EMPP_Raw: 1.54364
2025-07-17 23:33:54,128 - logger.py:50 - Epoch 162 Training Summary: Avg Total Loss: 0.93060, Avg Main MSE: 0.93060, Time: 17.60s
2025-07-17 23:34:12,537 - logger.py:50 - Epoch 162 Summary | Train MSE (x10^-2): 93.0597 | Val MSE (x10^-2): 25.7905 | Time: 36.02s
2025-07-17 23:34:15,580 - logger.py:50 - Epoch: [163][0/6]	Total Loss: 0.94217	Main MSE (x10^-2): 94.2168	LR: 3.05e-04	EMPP_Raw: 1.55267
2025-07-17 23:34:29,766 - logger.py:50 - Epoch: [163][5/6]	Total Loss: 0.92919	Main MSE (x10^-2): 92.9189	LR: 3.05e-04	EMPP_Raw: 1.54451
2025-07-17 23:34:29,812 - logger.py:50 - Epoch 163 Training Summary: Avg Total Loss: 0.92919, Avg Main MSE: 0.92919, Time: 17.27s
2025-07-17 23:34:48,300 - logger.py:50 - Epoch 163 Summary | Train MSE (x10^-2): 92.9189 | Val MSE (x10^-2): 35.1001 | Time: 35.76s
2025-07-17 23:34:51,425 - logger.py:50 - Epoch: [164][0/6]	Total Loss: 0.93699	Main MSE (x10^-2): 93.6986	LR: 3.04e-04	EMPP_Raw: 1.44043
2025-07-17 23:35:05,709 - logger.py:50 - Epoch: [164][5/6]	Total Loss: 0.95070	Main MSE (x10^-2): 95.0704	LR: 3.04e-04	EMPP_Raw: 1.52043
2025-07-17 23:35:05,764 - logger.py:50 - Epoch 164 Training Summary: Avg Total Loss: 0.95070, Avg Main MSE: 0.95070, Time: 17.45s
2025-07-17 23:35:24,146 - logger.py:50 - Epoch 164 Summary | Train MSE (x10^-2): 95.0704 | Val MSE (x10^-2): 25.9128 | Time: 35.84s
2025-07-17 23:35:27,187 - logger.py:50 - Epoch: [165][0/6]	Total Loss: 0.94043	Main MSE (x10^-2): 94.0430	LR: 3.03e-04	EMPP_Raw: 1.56709
2025-07-17 23:35:41,237 - logger.py:50 - Epoch: [165][5/6]	Total Loss: 0.91543	Main MSE (x10^-2): 91.5427	LR: 3.03e-04	EMPP_Raw: 1.49916
2025-07-17 23:35:41,287 - logger.py:50 - Epoch 165 Training Summary: Avg Total Loss: 0.91543, Avg Main MSE: 0.91543, Time: 17.13s
2025-07-17 23:35:59,820 - logger.py:50 - Epoch 165 Summary | Train MSE (x10^-2): 91.5427 | Val MSE (x10^-2): 25.6061 | Time: 35.67s
2025-07-17 23:36:02,849 - logger.py:50 - Epoch: [166][0/6]	Total Loss: 1.00385	Main MSE (x10^-2): 100.3850	LR: 3.02e-04	EMPP_Raw: 1.71105
2025-07-17 23:36:16,979 - logger.py:50 - Epoch: [166][5/6]	Total Loss: 0.94399	Main MSE (x10^-2): 94.3995	LR: 3.02e-04	EMPP_Raw: 1.59057
2025-07-17 23:36:17,034 - logger.py:50 - Epoch 166 Training Summary: Avg Total Loss: 0.94399, Avg Main MSE: 0.94399, Time: 17.20s
2025-07-17 23:36:35,527 - logger.py:50 - Epoch 166 Summary | Train MSE (x10^-2): 94.3995 | Val MSE (x10^-2): 25.4298 | Time: 35.70s
2025-07-17 23:36:38,554 - logger.py:50 - Epoch: [167][0/6]	Total Loss: 1.03261	Main MSE (x10^-2): 103.2610	LR: 3.01e-04	EMPP_Raw: 1.71613
2025-07-17 23:36:52,691 - logger.py:50 - Epoch: [167][5/6]	Total Loss: 0.94979	Main MSE (x10^-2): 94.9792	LR: 3.01e-04	EMPP_Raw: 1.59233
2025-07-17 23:36:52,745 - logger.py:50 - Epoch 167 Training Summary: Avg Total Loss: 0.94979, Avg Main MSE: 0.94979, Time: 17.21s
2025-07-17 23:37:11,134 - logger.py:50 - Epoch 167 Summary | Train MSE (x10^-2): 94.9792 | Val MSE (x10^-2): 24.9508 | Time: 35.60s
2025-07-17 23:37:14,554 - logger.py:50 - Epoch: [168][0/6]	Total Loss: 0.86496	Main MSE (x10^-2): 86.4956	LR: 3.00e-04	EMPP_Raw: 1.39762
2025-07-17 23:37:28,618 - logger.py:50 - Epoch: [168][5/6]	Total Loss: 0.91038	Main MSE (x10^-2): 91.0378	LR: 3.00e-04	EMPP_Raw: 1.53448
2025-07-17 23:37:28,691 - logger.py:50 - Epoch 168 Training Summary: Avg Total Loss: 0.91038, Avg Main MSE: 0.91038, Time: 17.55s
2025-07-17 23:37:47,296 - logger.py:50 - Epoch 168 Summary | Train MSE (x10^-2): 91.0378 | Val MSE (x10^-2): 24.7630 | Time: 36.16s
2025-07-17 23:37:50,438 - logger.py:50 - Epoch: [169][0/6]	Total Loss: 0.98289	Main MSE (x10^-2): 98.2889	LR: 2.99e-04	EMPP_Raw: 1.66409
2025-07-17 23:38:04,462 - logger.py:50 - Epoch: [169][5/6]	Total Loss: 0.92666	Main MSE (x10^-2): 92.6663	LR: 2.99e-04	EMPP_Raw: 1.56990
2025-07-17 23:38:04,508 - logger.py:50 - Epoch 169 Training Summary: Avg Total Loss: 0.92666, Avg Main MSE: 0.92666, Time: 17.20s
2025-07-17 23:38:22,864 - logger.py:50 - Epoch 169 Summary | Train MSE (x10^-2): 92.6663 | Val MSE (x10^-2): 24.5795 | Time: 35.56s
2025-07-17 23:38:26,045 - logger.py:50 - Epoch: [170][0/6]	Total Loss: 0.86751	Main MSE (x10^-2): 86.7513	LR: 2.98e-04	EMPP_Raw: 1.47607
2025-07-17 23:38:40,051 - logger.py:50 - Epoch: [170][5/6]	Total Loss: 0.88441	Main MSE (x10^-2): 88.4408	LR: 2.98e-04	EMPP_Raw: 1.49401
2025-07-17 23:38:40,094 - logger.py:50 - Epoch 170 Training Summary: Avg Total Loss: 0.88441, Avg Main MSE: 0.88441, Time: 17.22s
2025-07-17 23:38:58,393 - logger.py:50 - Epoch 170 Summary | Train MSE (x10^-2): 88.4408 | Val MSE (x10^-2): 24.4132 | Time: 35.52s
2025-07-17 23:39:01,484 - logger.py:50 - Epoch: [171][0/6]	Total Loss: 0.88640	Main MSE (x10^-2): 88.6399	LR: 2.97e-04	EMPP_Raw: 1.49374
2025-07-17 23:39:15,763 - logger.py:50 - Epoch: [171][5/6]	Total Loss: 0.90718	Main MSE (x10^-2): 90.7180	LR: 2.97e-04	EMPP_Raw: 1.54601
2025-07-17 23:39:15,804 - logger.py:50 - Epoch 171 Training Summary: Avg Total Loss: 0.90718, Avg Main MSE: 0.90718, Time: 17.40s
2025-07-17 23:39:34,391 - logger.py:50 - Epoch 171 Summary | Train MSE (x10^-2): 90.7180 | Val MSE (x10^-2): 25.1315 | Time: 35.99s
2025-07-17 23:39:37,466 - logger.py:50 - Epoch: [172][0/6]	Total Loss: 0.88124	Main MSE (x10^-2): 88.1237	LR: 2.96e-04	EMPP_Raw: 1.51174
2025-07-17 23:39:51,712 - logger.py:50 - Epoch: [172][5/6]	Total Loss: 0.89340	Main MSE (x10^-2): 89.3404	LR: 2.96e-04	EMPP_Raw: 1.50961
2025-07-17 23:39:51,754 - logger.py:50 - Epoch 172 Training Summary: Avg Total Loss: 0.89340, Avg Main MSE: 0.89340, Time: 17.35s
2025-07-17 23:40:10,098 - logger.py:50 - Epoch 172 Summary | Train MSE (x10^-2): 89.3404 | Val MSE (x10^-2): 25.8059 | Time: 35.70s
2025-07-17 23:40:13,247 - logger.py:50 - Epoch: [173][0/6]	Total Loss: 0.92091	Main MSE (x10^-2): 92.0912	LR: 2.94e-04	EMPP_Raw: 1.57753
2025-07-17 23:40:27,303 - logger.py:50 - Epoch: [173][5/6]	Total Loss: 0.90337	Main MSE (x10^-2): 90.3374	LR: 2.94e-04	EMPP_Raw: 1.52182
2025-07-17 23:40:27,347 - logger.py:50 - Epoch 173 Training Summary: Avg Total Loss: 0.90337, Avg Main MSE: 0.90337, Time: 17.24s
2025-07-17 23:40:45,785 - logger.py:50 - Epoch 173 Summary | Train MSE (x10^-2): 90.3374 | Val MSE (x10^-2): 26.4537 | Time: 35.69s
2025-07-17 23:40:48,827 - logger.py:50 - Epoch: [174][0/6]	Total Loss: 1.02617	Main MSE (x10^-2): 102.6168	LR: 2.93e-04	EMPP_Raw: 1.73590
2025-07-17 23:41:02,879 - logger.py:50 - Epoch: [174][5/6]	Total Loss: 0.92879	Main MSE (x10^-2): 92.8786	LR: 2.93e-04	EMPP_Raw: 1.56647
2025-07-17 23:41:02,921 - logger.py:50 - Epoch 174 Training Summary: Avg Total Loss: 0.92879, Avg Main MSE: 0.92879, Time: 17.13s
2025-07-17 23:41:21,483 - logger.py:50 - Epoch 174 Summary | Train MSE (x10^-2): 92.8786 | Val MSE (x10^-2): 24.9532 | Time: 35.69s
2025-07-17 23:41:24,539 - logger.py:50 - Epoch: [175][0/6]	Total Loss: 0.89635	Main MSE (x10^-2): 89.6349	LR: 2.92e-04	EMPP_Raw: 1.53699
2025-07-17 23:41:38,602 - logger.py:50 - Epoch: [175][5/6]	Total Loss: 0.90553	Main MSE (x10^-2): 90.5529	LR: 2.92e-04	EMPP_Raw: 1.54963
2025-07-17 23:41:38,644 - logger.py:50 - Epoch 175 Training Summary: Avg Total Loss: 0.90553, Avg Main MSE: 0.90553, Time: 17.15s
2025-07-17 23:41:57,071 - logger.py:50 - Epoch 175 Summary | Train MSE (x10^-2): 90.5529 | Val MSE (x10^-2): 25.1957 | Time: 35.58s
2025-07-17 23:42:00,330 - logger.py:50 - Epoch: [176][0/6]	Total Loss: 1.02585	Main MSE (x10^-2): 102.5848	LR: 2.91e-04	EMPP_Raw: 1.72914
2025-07-17 23:42:14,413 - logger.py:50 - Epoch: [176][5/6]	Total Loss: 0.91789	Main MSE (x10^-2): 91.7886	LR: 2.91e-04	EMPP_Raw: 1.55633
2025-07-17 23:42:14,453 - logger.py:50 - Epoch 176 Training Summary: Avg Total Loss: 0.91789, Avg Main MSE: 0.91789, Time: 17.37s
2025-07-17 23:42:32,843 - logger.py:50 - Epoch 176 Summary | Train MSE (x10^-2): 91.7886 | Val MSE (x10^-2): 25.1618 | Time: 35.77s
2025-07-17 23:42:35,936 - logger.py:50 - Epoch: [177][0/6]	Total Loss: 0.90772	Main MSE (x10^-2): 90.7722	LR: 2.90e-04	EMPP_Raw: 1.55957
2025-07-17 23:42:50,148 - logger.py:50 - Epoch: [177][5/6]	Total Loss: 0.88569	Main MSE (x10^-2): 88.5690	LR: 2.90e-04	EMPP_Raw: 1.50958
2025-07-17 23:42:50,191 - logger.py:50 - Epoch 177 Training Summary: Avg Total Loss: 0.88569, Avg Main MSE: 0.88569, Time: 17.34s
2025-07-17 23:43:08,603 - logger.py:50 - Epoch 177 Summary | Train MSE (x10^-2): 88.5690 | Val MSE (x10^-2): 25.9282 | Time: 35.76s
2025-07-17 23:43:11,692 - logger.py:50 - Epoch: [178][0/6]	Total Loss: 0.86621	Main MSE (x10^-2): 86.6212	LR: 2.89e-04	EMPP_Raw: 1.46327
2025-07-17 23:43:25,894 - logger.py:50 - Epoch: [178][5/6]	Total Loss: 0.89622	Main MSE (x10^-2): 89.6222	LR: 2.89e-04	EMPP_Raw: 1.53596
2025-07-17 23:43:25,937 - logger.py:50 - Epoch 178 Training Summary: Avg Total Loss: 0.89622, Avg Main MSE: 0.89622, Time: 17.33s
2025-07-17 23:43:44,294 - logger.py:50 - Epoch 178 Summary | Train MSE (x10^-2): 89.6222 | Val MSE (x10^-2): 25.2597 | Time: 35.69s
2025-07-17 23:43:47,323 - logger.py:50 - Epoch: [179][0/6]	Total Loss: 0.90993	Main MSE (x10^-2): 90.9929	LR: 2.88e-04	EMPP_Raw: 1.57234
2025-07-17 23:44:01,392 - logger.py:50 - Epoch: [179][5/6]	Total Loss: 0.91029	Main MSE (x10^-2): 91.0286	LR: 2.88e-04	EMPP_Raw: 1.54766
2025-07-17 23:44:01,438 - logger.py:50 - Epoch 179 Training Summary: Avg Total Loss: 0.91029, Avg Main MSE: 0.91029, Time: 17.13s
2025-07-17 23:44:19,959 - logger.py:50 - Epoch 179 Summary | Train MSE (x10^-2): 91.0286 | Val MSE (x10^-2): 25.0439 | Time: 35.66s
2025-07-17 23:44:22,997 - logger.py:50 - Epoch: [180][0/6]	Total Loss: 0.96952	Main MSE (x10^-2): 96.9518	LR: 2.87e-04	EMPP_Raw: 1.70069
2025-07-17 23:44:37,089 - logger.py:50 - Epoch: [180][5/6]	Total Loss: 0.91707	Main MSE (x10^-2): 91.7068	LR: 2.87e-04	EMPP_Raw: 1.57812
2025-07-17 23:44:37,131 - logger.py:50 - Epoch 180 Training Summary: Avg Total Loss: 0.91707, Avg Main MSE: 0.91707, Time: 17.16s
2025-07-17 23:44:55,625 - logger.py:50 - Epoch 180 Summary | Train MSE (x10^-2): 91.7068 | Val MSE (x10^-2): 25.5510 | Time: 35.66s
2025-07-17 23:44:58,675 - logger.py:50 - Epoch: [181][0/6]	Total Loss: 0.89351	Main MSE (x10^-2): 89.3513	LR: 2.85e-04	EMPP_Raw: 1.54562
2025-07-17 23:45:12,716 - logger.py:50 - Epoch: [181][5/6]	Total Loss: 0.86568	Main MSE (x10^-2): 86.5677	LR: 2.85e-04	EMPP_Raw: 1.48819
2025-07-17 23:45:12,761 - logger.py:50 - Epoch 181 Training Summary: Avg Total Loss: 0.86568, Avg Main MSE: 0.86568, Time: 17.13s
2025-07-17 23:45:31,100 - logger.py:50 - Epoch 181 Summary | Train MSE (x10^-2): 86.5677 | Val MSE (x10^-2): 26.7875 | Time: 35.47s
2025-07-17 23:45:34,334 - logger.py:50 - Epoch: [182][0/6]	Total Loss: 0.79527	Main MSE (x10^-2): 79.5272	LR: 2.84e-04	EMPP_Raw: 1.36587
2025-07-17 23:45:48,346 - logger.py:50 - Epoch: [182][5/6]	Total Loss: 0.89029	Main MSE (x10^-2): 89.0288	LR: 2.84e-04	EMPP_Raw: 1.53292
2025-07-17 23:45:48,388 - logger.py:50 - Epoch 182 Training Summary: Avg Total Loss: 0.89029, Avg Main MSE: 0.89029, Time: 17.28s
2025-07-17 23:46:06,883 - logger.py:50 - Epoch 182 Summary | Train MSE (x10^-2): 89.0288 | Val MSE (x10^-2): 27.0756 | Time: 35.78s
2025-07-17 23:46:09,958 - logger.py:50 - Epoch: [183][0/6]	Total Loss: 0.85365	Main MSE (x10^-2): 85.3645	LR: 2.83e-04	EMPP_Raw: 1.47139
2025-07-17 23:46:24,159 - logger.py:50 - Epoch: [183][5/6]	Total Loss: 0.89011	Main MSE (x10^-2): 89.0108	LR: 2.83e-04	EMPP_Raw: 1.54293
2025-07-17 23:46:24,202 - logger.py:50 - Epoch 183 Training Summary: Avg Total Loss: 0.89011, Avg Main MSE: 0.89011, Time: 17.31s
2025-07-17 23:46:42,741 - logger.py:50 - Epoch 183 Summary | Train MSE (x10^-2): 89.0108 | Val MSE (x10^-2): 26.1000 | Time: 35.85s
2025-07-17 23:46:45,772 - logger.py:50 - Epoch: [184][0/6]	Total Loss: 0.89393	Main MSE (x10^-2): 89.3928	LR: 2.82e-04	EMPP_Raw: 1.57647
2025-07-17 23:47:00,000 - logger.py:50 - Epoch: [184][5/6]	Total Loss: 0.91246	Main MSE (x10^-2): 91.2457	LR: 2.82e-04	EMPP_Raw: 1.58869
2025-07-17 23:47:00,041 - logger.py:50 - Epoch 184 Training Summary: Avg Total Loss: 0.91246, Avg Main MSE: 0.91246, Time: 17.29s
2025-07-17 23:47:18,378 - logger.py:50 - Epoch 184 Summary | Train MSE (x10^-2): 91.2457 | Val MSE (x10^-2): 25.5820 | Time: 35.63s
2025-07-17 23:47:21,437 - logger.py:50 - Epoch: [185][0/6]	Total Loss: 0.91069	Main MSE (x10^-2): 91.0689	LR: 2.81e-04	EMPP_Raw: 1.57072
2025-07-17 23:47:35,548 - logger.py:50 - Epoch: [185][5/6]	Total Loss: 0.86763	Main MSE (x10^-2): 86.7633	LR: 2.81e-04	EMPP_Raw: 1.49841
2025-07-17 23:47:35,590 - logger.py:50 - Epoch 185 Training Summary: Avg Total Loss: 0.86763, Avg Main MSE: 0.86763, Time: 17.20s
2025-07-17 23:47:54,095 - logger.py:50 - Epoch 185 Summary | Train MSE (x10^-2): 86.7633 | Val MSE (x10^-2): 25.8769 | Time: 35.71s
2025-07-17 23:47:57,159 - logger.py:50 - Epoch: [186][0/6]	Total Loss: 0.95797	Main MSE (x10^-2): 95.7971	LR: 2.80e-04	EMPP_Raw: 1.66030
2025-07-17 23:48:11,252 - logger.py:50 - Epoch: [186][5/6]	Total Loss: 0.89778	Main MSE (x10^-2): 89.7784	LR: 2.80e-04	EMPP_Raw: 1.56461
2025-07-17 23:48:11,309 - logger.py:50 - Epoch 186 Training Summary: Avg Total Loss: 0.89778, Avg Main MSE: 0.89778, Time: 17.20s
2025-07-17 23:48:29,788 - logger.py:50 - Epoch 186 Summary | Train MSE (x10^-2): 89.7784 | Val MSE (x10^-2): 25.8542 | Time: 35.69s
2025-07-17 23:48:33,005 - logger.py:50 - Epoch: [187][0/6]	Total Loss: 0.87832	Main MSE (x10^-2): 87.8316	LR: 2.79e-04	EMPP_Raw: 1.52755
2025-07-17 23:48:47,076 - logger.py:50 - Epoch: [187][5/6]	Total Loss: 0.86328	Main MSE (x10^-2): 86.3280	LR: 2.79e-04	EMPP_Raw: 1.49930
2025-07-17 23:48:47,121 - logger.py:50 - Epoch 187 Training Summary: Avg Total Loss: 0.86328, Avg Main MSE: 0.86328, Time: 17.32s
2025-07-17 23:49:05,466 - logger.py:50 - Epoch 187 Summary | Train MSE (x10^-2): 86.3280 | Val MSE (x10^-2): 25.5440 | Time: 35.67s
2025-07-17 23:49:08,652 - logger.py:50 - Epoch: [188][0/6]	Total Loss: 0.97043	Main MSE (x10^-2): 97.0434	LR: 2.77e-04	EMPP_Raw: 1.69161
2025-07-17 23:49:22,621 - logger.py:50 - Epoch: [188][5/6]	Total Loss: 0.89727	Main MSE (x10^-2): 89.7271	LR: 2.77e-04	EMPP_Raw: 1.56727
2025-07-17 23:49:22,664 - logger.py:50 - Epoch 188 Training Summary: Avg Total Loss: 0.89727, Avg Main MSE: 0.89727, Time: 17.19s
2025-07-17 23:49:41,135 - logger.py:50 - Epoch 188 Summary | Train MSE (x10^-2): 89.7271 | Val MSE (x10^-2): 25.7294 | Time: 35.66s
2025-07-17 23:49:44,191 - logger.py:50 - Epoch: [189][0/6]	Total Loss: 0.86883	Main MSE (x10^-2): 86.8834	LR: 2.76e-04	EMPP_Raw: 1.51493
2025-07-17 23:49:58,420 - logger.py:50 - Epoch: [189][5/6]	Total Loss: 0.88496	Main MSE (x10^-2): 88.4957	LR: 2.76e-04	EMPP_Raw: 1.56158
2025-07-17 23:49:58,466 - logger.py:50 - Epoch 189 Training Summary: Avg Total Loss: 0.88496, Avg Main MSE: 0.88496, Time: 17.32s
2025-07-17 23:50:16,846 - logger.py:50 - Epoch 189 Summary | Train MSE (x10^-2): 88.4957 | Val MSE (x10^-2): 27.1010 | Time: 35.71s
2025-07-17 23:50:19,880 - logger.py:50 - Epoch: [190][0/6]	Total Loss: 0.90004	Main MSE (x10^-2): 90.0037	LR: 2.75e-04	EMPP_Raw: 1.60333
2025-07-17 23:50:34,055 - logger.py:50 - Epoch: [190][5/6]	Total Loss: 0.86820	Main MSE (x10^-2): 86.8201	LR: 2.75e-04	EMPP_Raw: 1.51258
2025-07-17 23:50:34,101 - logger.py:50 - Epoch 190 Training Summary: Avg Total Loss: 0.86820, Avg Main MSE: 0.86820, Time: 17.25s
2025-07-17 23:50:52,452 - logger.py:50 - Epoch 190 Summary | Train MSE (x10^-2): 86.8201 | Val MSE (x10^-2): 27.3466 | Time: 35.60s
2025-07-17 23:50:55,527 - logger.py:50 - Epoch: [191][0/6]	Total Loss: 0.89940	Main MSE (x10^-2): 89.9404	LR: 2.74e-04	EMPP_Raw: 1.57023
2025-07-17 23:51:09,596 - logger.py:50 - Epoch: [191][5/6]	Total Loss: 0.85090	Main MSE (x10^-2): 85.0899	LR: 2.74e-04	EMPP_Raw: 1.49355
2025-07-17 23:51:09,639 - logger.py:50 - Epoch 191 Training Summary: Avg Total Loss: 0.85090, Avg Main MSE: 0.85090, Time: 17.18s
2025-07-17 23:51:28,167 - logger.py:50 - Epoch 191 Summary | Train MSE (x10^-2): 85.0899 | Val MSE (x10^-2): 25.9478 | Time: 35.71s
2025-07-17 23:51:31,234 - logger.py:50 - Epoch: [192][0/6]	Total Loss: 0.89713	Main MSE (x10^-2): 89.7129	LR: 2.73e-04	EMPP_Raw: 1.61057
2025-07-17 23:51:45,355 - logger.py:50 - Epoch: [192][5/6]	Total Loss: 0.88410	Main MSE (x10^-2): 88.4097	LR: 2.73e-04	EMPP_Raw: 1.56997
2025-07-17 23:51:45,402 - logger.py:50 - Epoch 192 Training Summary: Avg Total Loss: 0.88410, Avg Main MSE: 0.88410, Time: 17.23s
2025-07-17 23:52:03,903 - logger.py:50 - Epoch 192 Summary | Train MSE (x10^-2): 88.4097 | Val MSE (x10^-2): 25.3610 | Time: 35.73s
2025-07-17 23:52:06,989 - logger.py:50 - Epoch: [193][0/6]	Total Loss: 0.85879	Main MSE (x10^-2): 85.8792	LR: 2.72e-04	EMPP_Raw: 1.52515
2025-07-17 23:52:21,124 - logger.py:50 - Epoch: [193][5/6]	Total Loss: 0.86088	Main MSE (x10^-2): 86.0883	LR: 2.72e-04	EMPP_Raw: 1.52058
2025-07-17 23:52:21,166 - logger.py:50 - Epoch 193 Training Summary: Avg Total Loss: 0.86088, Avg Main MSE: 0.86088, Time: 17.25s
2025-07-17 23:52:39,675 - logger.py:50 - Epoch 193 Summary | Train MSE (x10^-2): 86.0883 | Val MSE (x10^-2): 26.7288 | Time: 35.77s
2025-07-17 23:52:43,164 - logger.py:50 - Epoch: [194][0/6]	Total Loss: 0.87389	Main MSE (x10^-2): 87.3890	LR: 2.70e-04	EMPP_Raw: 1.54680
2025-07-17 23:52:57,355 - logger.py:50 - Epoch: [194][5/6]	Total Loss: 0.87151	Main MSE (x10^-2): 87.1508	LR: 2.70e-04	EMPP_Raw: 1.53798
2025-07-17 23:52:57,406 - logger.py:50 - Epoch 194 Training Summary: Avg Total Loss: 0.87151, Avg Main MSE: 0.87151, Time: 17.72s
2025-07-17 23:53:15,968 - logger.py:50 - Epoch 194 Summary | Train MSE (x10^-2): 87.1508 | Val MSE (x10^-2): 26.0141 | Time: 36.29s
2025-07-17 23:53:19,035 - logger.py:50 - Epoch: [195][0/6]	Total Loss: 0.86429	Main MSE (x10^-2): 86.4294	LR: 2.69e-04	EMPP_Raw: 1.53099
2025-07-17 23:53:33,096 - logger.py:50 - Epoch: [195][5/6]	Total Loss: 0.86991	Main MSE (x10^-2): 86.9905	LR: 2.69e-04	EMPP_Raw: 1.54454
2025-07-17 23:53:33,141 - logger.py:50 - Epoch 195 Training Summary: Avg Total Loss: 0.86991, Avg Main MSE: 0.86991, Time: 17.16s
2025-07-17 23:53:51,641 - logger.py:50 - Epoch 195 Summary | Train MSE (x10^-2): 86.9905 | Val MSE (x10^-2): 25.6572 | Time: 35.67s
2025-07-17 23:53:54,858 - logger.py:50 - Epoch: [196][0/6]	Total Loss: 0.87509	Main MSE (x10^-2): 87.5094	LR: 2.68e-04	EMPP_Raw: 1.55420
2025-07-17 23:54:08,886 - logger.py:50 - Epoch: [196][5/6]	Total Loss: 0.89128	Main MSE (x10^-2): 89.1280	LR: 2.68e-04	EMPP_Raw: 1.57523
2025-07-17 23:54:08,933 - logger.py:50 - Epoch 196 Training Summary: Avg Total Loss: 0.89128, Avg Main MSE: 0.89128, Time: 17.28s
2025-07-17 23:54:27,295 - logger.py:50 - Epoch 196 Summary | Train MSE (x10^-2): 89.1280 | Val MSE (x10^-2): 25.8354 | Time: 35.65s
2025-07-17 23:54:30,336 - logger.py:50 - Epoch: [197][0/6]	Total Loss: 0.88890	Main MSE (x10^-2): 88.8903	LR: 2.67e-04	EMPP_Raw: 1.54166
2025-07-17 23:54:44,561 - logger.py:50 - Epoch: [197][5/6]	Total Loss: 0.85306	Main MSE (x10^-2): 85.3061	LR: 2.67e-04	EMPP_Raw: 1.50622
2025-07-17 23:54:44,605 - logger.py:50 - Epoch 197 Training Summary: Avg Total Loss: 0.85306, Avg Main MSE: 0.85306, Time: 17.30s
2025-07-17 23:55:02,944 - logger.py:50 - Epoch 197 Summary | Train MSE (x10^-2): 85.3061 | Val MSE (x10^-2): 25.5499 | Time: 35.64s
2025-07-17 23:55:05,987 - logger.py:50 - Epoch: [198][0/6]	Total Loss: 0.81335	Main MSE (x10^-2): 81.3346	LR: 2.66e-04	EMPP_Raw: 1.43455
2025-07-17 23:55:20,202 - logger.py:50 - Epoch: [198][5/6]	Total Loss: 0.84329	Main MSE (x10^-2): 84.3289	LR: 2.66e-04	EMPP_Raw: 1.48851
2025-07-17 23:55:20,248 - logger.py:50 - Epoch 198 Training Summary: Avg Total Loss: 0.84329, Avg Main MSE: 0.84329, Time: 17.30s
2025-07-17 23:55:38,751 - logger.py:50 - Epoch 198 Summary | Train MSE (x10^-2): 84.3289 | Val MSE (x10^-2): 26.2433 | Time: 35.80s
2025-07-17 23:55:41,791 - logger.py:50 - Epoch: [199][0/6]	Total Loss: 0.84348	Main MSE (x10^-2): 84.3479	LR: 2.65e-04	EMPP_Raw: 1.48693
2025-07-17 23:55:55,954 - logger.py:50 - Epoch: [199][5/6]	Total Loss: 0.86658	Main MSE (x10^-2): 86.6578	LR: 2.65e-04	EMPP_Raw: 1.53008
2025-07-17 23:55:56,004 - logger.py:50 - Epoch 199 Training Summary: Avg Total Loss: 0.86658, Avg Main MSE: 0.86658, Time: 17.24s
2025-07-17 23:56:14,617 - logger.py:50 - Epoch 199 Summary | Train MSE (x10^-2): 86.6578 | Val MSE (x10^-2): 25.5913 | Time: 35.86s
2025-07-17 23:56:17,671 - logger.py:50 - Epoch: [200][0/6]	Total Loss: 0.85887	Main MSE (x10^-2): 85.8872	LR: 2.63e-04	EMPP_Raw: 1.53937
2025-07-17 23:56:31,709 - logger.py:50 - Epoch: [200][5/6]	Total Loss: 0.86683	Main MSE (x10^-2): 86.6830	LR: 2.63e-04	EMPP_Raw: 1.52967
2025-07-17 23:56:31,755 - logger.py:50 - Epoch 200 Training Summary: Avg Total Loss: 0.86683, Avg Main MSE: 0.86683, Time: 17.13s
2025-07-17 23:56:50,280 - logger.py:50 - Epoch 200 Summary | Train MSE (x10^-2): 86.6830 | Val MSE (x10^-2): 25.8382 | Time: 35.66s
2025-07-17 23:56:53,320 - logger.py:50 - Epoch: [201][0/6]	Total Loss: 0.89214	Main MSE (x10^-2): 89.2138	LR: 2.62e-04	EMPP_Raw: 1.60116
2025-07-17 23:57:07,403 - logger.py:50 - Epoch: [201][5/6]	Total Loss: 0.86271	Main MSE (x10^-2): 86.2705	LR: 2.62e-04	EMPP_Raw: 1.49395
2025-07-17 23:57:07,446 - logger.py:50 - Epoch 201 Training Summary: Avg Total Loss: 0.86271, Avg Main MSE: 0.86271, Time: 17.16s
2025-07-17 23:57:25,852 - logger.py:50 - Epoch 201 Summary | Train MSE (x10^-2): 86.2705 | Val MSE (x10^-2): 30.7780 | Time: 35.57s
2025-07-17 23:57:29,039 - logger.py:50 - Epoch: [202][0/6]	Total Loss: 0.91026	Main MSE (x10^-2): 91.0257	LR: 2.61e-04	EMPP_Raw: 1.58670
2025-07-17 23:57:43,059 - logger.py:50 - Epoch: [202][5/6]	Total Loss: 0.87220	Main MSE (x10^-2): 87.2203	LR: 2.61e-04	EMPP_Raw: 1.51890
2025-07-17 23:57:43,110 - logger.py:50 - Epoch 202 Training Summary: Avg Total Loss: 0.87220, Avg Main MSE: 0.87220, Time: 17.25s
2025-07-17 23:58:01,502 - logger.py:50 - Epoch 202 Summary | Train MSE (x10^-2): 87.2203 | Val MSE (x10^-2): 26.3258 | Time: 35.64s
2025-07-17 23:58:04,556 - logger.py:50 - Epoch: [203][0/6]	Total Loss: 0.81701	Main MSE (x10^-2): 81.7012	LR: 2.60e-04	EMPP_Raw: 1.42605
2025-07-17 23:58:18,796 - logger.py:50 - Epoch: [203][5/6]	Total Loss: 0.84207	Main MSE (x10^-2): 84.2074	LR: 2.60e-04	EMPP_Raw: 1.49034
2025-07-17 23:58:18,839 - logger.py:50 - Epoch 203 Training Summary: Avg Total Loss: 0.84207, Avg Main MSE: 0.84207, Time: 17.33s
2025-07-17 23:58:37,242 - logger.py:50 - Epoch 203 Summary | Train MSE (x10^-2): 84.2074 | Val MSE (x10^-2): 25.5515 | Time: 35.73s
2025-07-17 23:58:40,269 - logger.py:50 - Epoch: [204][0/6]	Total Loss: 0.85771	Main MSE (x10^-2): 85.7709	LR: 2.59e-04	EMPP_Raw: 1.53460
2025-07-17 23:58:54,477 - logger.py:50 - Epoch: [204][5/6]	Total Loss: 0.87068	Main MSE (x10^-2): 87.0677	LR: 2.59e-04	EMPP_Raw: 1.56422
2025-07-17 23:58:54,519 - logger.py:50 - Epoch 204 Training Summary: Avg Total Loss: 0.87068, Avg Main MSE: 0.87068, Time: 17.27s
2025-07-17 23:59:12,829 - logger.py:50 - Epoch 204 Summary | Train MSE (x10^-2): 87.0677 | Val MSE (x10^-2): 26.7107 | Time: 35.58s
2025-07-17 23:59:15,872 - logger.py:50 - Epoch: [205][0/6]	Total Loss: 0.81017	Main MSE (x10^-2): 81.0165	LR: 2.57e-04	EMPP_Raw: 1.44853
2025-07-17 23:59:29,989 - logger.py:50 - Epoch: [205][5/6]	Total Loss: 0.86263	Main MSE (x10^-2): 86.2633	LR: 2.57e-04	EMPP_Raw: 1.54809
2025-07-17 23:59:30,035 - logger.py:50 - Epoch 205 Training Summary: Avg Total Loss: 0.86263, Avg Main MSE: 0.86263, Time: 17.20s
2025-07-17 23:59:48,442 - logger.py:50 - Epoch 205 Summary | Train MSE (x10^-2): 86.2633 | Val MSE (x10^-2): 25.4824 | Time: 35.61s
2025-07-17 23:59:51,490 - logger.py:50 - Epoch: [206][0/6]	Total Loss: 0.78969	Main MSE (x10^-2): 78.9686	LR: 2.56e-04	EMPP_Raw: 1.42568
2025-07-18 00:00:05,547 - logger.py:50 - Epoch: [206][5/6]	Total Loss: 0.85014	Main MSE (x10^-2): 85.0144	LR: 2.56e-04	EMPP_Raw: 1.52879
2025-07-18 00:00:05,594 - logger.py:50 - Epoch 206 Training Summary: Avg Total Loss: 0.85014, Avg Main MSE: 0.85014, Time: 17.14s
2025-07-18 00:00:24,046 - logger.py:50 - Epoch 206 Summary | Train MSE (x10^-2): 85.0144 | Val MSE (x10^-2): 25.6224 | Time: 35.60s
2025-07-18 00:00:27,106 - logger.py:50 - Epoch: [207][0/6]	Total Loss: 0.95128	Main MSE (x10^-2): 95.1282	LR: 2.55e-04	EMPP_Raw: 1.71028
2025-07-18 00:00:41,237 - logger.py:50 - Epoch: [207][5/6]	Total Loss: 0.88566	Main MSE (x10^-2): 88.5661	LR: 2.55e-04	EMPP_Raw: 1.58570
2025-07-18 00:00:41,300 - logger.py:50 - Epoch 207 Training Summary: Avg Total Loss: 0.88566, Avg Main MSE: 0.88566, Time: 17.24s
2025-07-18 00:00:59,649 - logger.py:50 - Epoch 207 Summary | Train MSE (x10^-2): 88.5661 | Val MSE (x10^-2): 26.1420 | Time: 35.60s
2025-07-18 00:01:02,879 - logger.py:50 - Epoch: [208][0/6]	Total Loss: 0.88820	Main MSE (x10^-2): 88.8196	LR: 2.54e-04	EMPP_Raw: 1.59549
2025-07-18 00:01:16,916 - logger.py:50 - Epoch: [208][5/6]	Total Loss: 0.84048	Main MSE (x10^-2): 84.0483	LR: 2.54e-04	EMPP_Raw: 1.52185
2025-07-18 00:01:16,960 - logger.py:50 - Epoch 208 Training Summary: Avg Total Loss: 0.84048, Avg Main MSE: 0.84048, Time: 17.30s
2025-07-18 00:01:35,283 - logger.py:50 - Epoch 208 Summary | Train MSE (x10^-2): 84.0483 | Val MSE (x10^-2): 26.3020 | Time: 35.63s
2025-07-18 00:01:38,379 - logger.py:50 - Epoch: [209][0/6]	Total Loss: 0.77278	Main MSE (x10^-2): 77.2779	LR: 2.53e-04	EMPP_Raw: 1.38204
2025-07-18 00:01:52,578 - logger.py:50 - Epoch: [209][5/6]	Total Loss: 0.85843	Main MSE (x10^-2): 85.8426	LR: 2.53e-04	EMPP_Raw: 1.54837
2025-07-18 00:01:52,619 - logger.py:50 - Epoch 209 Training Summary: Avg Total Loss: 0.85843, Avg Main MSE: 0.85843, Time: 17.33s
2025-07-18 00:02:10,908 - logger.py:50 - Epoch 209 Summary | Train MSE (x10^-2): 85.8426 | Val MSE (x10^-2): 25.9990 | Time: 35.62s
2025-07-18 00:02:14,000 - logger.py:50 - Epoch: [210][0/6]	Total Loss: 0.91451	Main MSE (x10^-2): 91.4505	LR: 2.51e-04	EMPP_Raw: 1.66734
2025-07-18 00:02:28,271 - logger.py:50 - Epoch: [210][5/6]	Total Loss: 0.83916	Main MSE (x10^-2): 83.9165	LR: 2.51e-04	EMPP_Raw: 1.51180
2025-07-18 00:02:28,315 - logger.py:50 - Epoch 210 Training Summary: Avg Total Loss: 0.83916, Avg Main MSE: 0.83916, Time: 17.40s
2025-07-18 00:02:46,789 - logger.py:50 - Epoch 210 Summary | Train MSE (x10^-2): 83.9165 | Val MSE (x10^-2): 27.0657 | Time: 35.88s
2025-07-18 00:02:49,869 - logger.py:50 - Epoch: [211][0/6]	Total Loss: 0.83670	Main MSE (x10^-2): 83.6700	LR: 2.50e-04	EMPP_Raw: 1.49722
2025-07-18 00:03:04,007 - logger.py:50 - Epoch: [211][5/6]	Total Loss: 0.79936	Main MSE (x10^-2): 79.9355	LR: 2.50e-04	EMPP_Raw: 1.42608
2025-07-18 00:03:04,049 - logger.py:50 - Epoch 211 Training Summary: Avg Total Loss: 0.79936, Avg Main MSE: 0.79936, Time: 17.25s
2025-07-18 00:03:22,647 - logger.py:50 - Epoch 211 Summary | Train MSE (x10^-2): 79.9355 | Val MSE (x10^-2): 27.1550 | Time: 35.85s
2025-07-18 00:03:25,781 - logger.py:50 - Epoch: [212][0/6]	Total Loss: 0.79204	Main MSE (x10^-2): 79.2041	LR: 2.49e-04	EMPP_Raw: 1.41686
2025-07-18 00:03:40,100 - logger.py:50 - Epoch: [212][5/6]	Total Loss: 0.85080	Main MSE (x10^-2): 85.0798	LR: 2.49e-04	EMPP_Raw: 1.52293
2025-07-18 00:03:40,149 - logger.py:50 - Epoch 212 Training Summary: Avg Total Loss: 0.85080, Avg Main MSE: 0.85080, Time: 17.49s
2025-07-18 00:03:58,466 - logger.py:50 - Epoch 212 Summary | Train MSE (x10^-2): 85.0798 | Val MSE (x10^-2): 26.3069 | Time: 35.81s
2025-07-18 00:04:01,689 - logger.py:50 - Epoch: [213][0/6]	Total Loss: 0.84008	Main MSE (x10^-2): 84.0075	LR: 2.48e-04	EMPP_Raw: 1.52303
2025-07-18 00:04:15,772 - logger.py:50 - Epoch: [213][5/6]	Total Loss: 0.83616	Main MSE (x10^-2): 83.6156	LR: 2.48e-04	EMPP_Raw: 1.50633
2025-07-18 00:04:15,816 - logger.py:50 - Epoch 213 Training Summary: Avg Total Loss: 0.83616, Avg Main MSE: 0.83616, Time: 17.34s
2025-07-18 00:04:34,104 - logger.py:50 - Epoch 213 Summary | Train MSE (x10^-2): 83.6156 | Val MSE (x10^-2): 26.6250 | Time: 35.63s
2025-07-18 00:04:37,371 - logger.py:50 - Epoch: [214][0/6]	Total Loss: 0.82840	Main MSE (x10^-2): 82.8399	LR: 2.46e-04	EMPP_Raw: 1.48267
2025-07-18 00:04:51,466 - logger.py:50 - Epoch: [214][5/6]	Total Loss: 0.85384	Main MSE (x10^-2): 85.3839	LR: 2.46e-04	EMPP_Raw: 1.54655
2025-07-18 00:04:51,514 - logger.py:50 - Epoch 214 Training Summary: Avg Total Loss: 0.85384, Avg Main MSE: 0.85384, Time: 17.40s
2025-07-18 00:05:09,776 - logger.py:50 - Epoch 214 Summary | Train MSE (x10^-2): 85.3839 | Val MSE (x10^-2): 26.1601 | Time: 35.67s
2025-07-18 00:05:12,914 - logger.py:50 - Epoch: [215][0/6]	Total Loss: 0.91322	Main MSE (x10^-2): 91.3223	LR: 2.45e-04	EMPP_Raw: 1.67614
2025-07-18 00:05:27,091 - logger.py:50 - Epoch: [215][5/6]	Total Loss: 0.84998	Main MSE (x10^-2): 84.9980	LR: 2.45e-04	EMPP_Raw: 1.54052
2025-07-18 00:05:27,145 - logger.py:50 - Epoch 215 Training Summary: Avg Total Loss: 0.84998, Avg Main MSE: 0.84998, Time: 17.36s
2025-07-18 00:05:45,420 - logger.py:50 - Epoch 215 Summary | Train MSE (x10^-2): 84.9980 | Val MSE (x10^-2): 25.5288 | Time: 35.64s
2025-07-18 00:05:48,535 - logger.py:50 - Epoch: [216][0/6]	Total Loss: 0.84420	Main MSE (x10^-2): 84.4198	LR: 2.44e-04	EMPP_Raw: 1.51919
2025-07-18 00:06:02,746 - logger.py:50 - Epoch: [216][5/6]	Total Loss: 0.83969	Main MSE (x10^-2): 83.9691	LR: 2.44e-04	EMPP_Raw: 1.51388
2025-07-18 00:06:02,790 - logger.py:50 - Epoch 216 Training Summary: Avg Total Loss: 0.83969, Avg Main MSE: 0.83969, Time: 17.36s
2025-07-18 00:06:21,198 - logger.py:50 - Epoch 216 Summary | Train MSE (x10^-2): 83.9691 | Val MSE (x10^-2): 25.6094 | Time: 35.77s
2025-07-18 00:06:24,239 - logger.py:50 - Epoch: [217][0/6]	Total Loss: 0.89264	Main MSE (x10^-2): 89.2635	LR: 2.43e-04	EMPP_Raw: 1.61739
2025-07-18 00:06:38,306 - logger.py:50 - Epoch: [217][5/6]	Total Loss: 0.86629	Main MSE (x10^-2): 86.6289	LR: 2.43e-04	EMPP_Raw: 1.56056
2025-07-18 00:06:38,346 - logger.py:50 - Epoch 217 Training Summary: Avg Total Loss: 0.86629, Avg Main MSE: 0.86629, Time: 17.14s
2025-07-18 00:06:56,794 - logger.py:50 - Epoch 217 Summary | Train MSE (x10^-2): 86.6289 | Val MSE (x10^-2): 25.9974 | Time: 35.59s
2025-07-18 00:06:59,877 - logger.py:50 - Epoch: [218][0/6]	Total Loss: 0.83227	Main MSE (x10^-2): 83.2267	LR: 2.42e-04	EMPP_Raw: 1.50984
2025-07-18 00:07:13,974 - logger.py:50 - Epoch: [218][5/6]	Total Loss: 0.85187	Main MSE (x10^-2): 85.1867	LR: 2.42e-04	EMPP_Raw: 1.54104
2025-07-18 00:07:14,015 - logger.py:50 - Epoch 218 Training Summary: Avg Total Loss: 0.85187, Avg Main MSE: 0.85187, Time: 17.21s
2025-07-18 00:07:32,500 - logger.py:50 - Epoch 218 Summary | Train MSE (x10^-2): 85.1867 | Val MSE (x10^-2): 25.1557 | Time: 35.70s
2025-07-18 00:07:35,546 - logger.py:50 - Epoch: [219][0/6]	Total Loss: 0.85282	Main MSE (x10^-2): 85.2819	LR: 2.40e-04	EMPP_Raw: 1.54908
2025-07-18 00:07:49,651 - logger.py:50 - Epoch: [219][5/6]	Total Loss: 0.84491	Main MSE (x10^-2): 84.4913	LR: 2.40e-04	EMPP_Raw: 1.52352
2025-07-18 00:07:49,695 - logger.py:50 - Epoch 219 Training Summary: Avg Total Loss: 0.84491, Avg Main MSE: 0.84491, Time: 17.19s
2025-07-18 00:08:08,192 - logger.py:50 - Epoch 219 Summary | Train MSE (x10^-2): 84.4913 | Val MSE (x10^-2): 25.2408 | Time: 35.69s
2025-07-18 00:08:11,568 - logger.py:50 - Epoch: [220][0/6]	Total Loss: 0.81971	Main MSE (x10^-2): 81.9705	LR: 2.39e-04	EMPP_Raw: 1.48801
2025-07-18 00:08:25,601 - logger.py:50 - Epoch: [220][5/6]	Total Loss: 0.81660	Main MSE (x10^-2): 81.6596	LR: 2.39e-04	EMPP_Raw: 1.47732
2025-07-18 00:08:25,655 - logger.py:50 - Epoch 220 Training Summary: Avg Total Loss: 0.81660, Avg Main MSE: 0.81660, Time: 17.45s
2025-07-18 00:08:44,366 - logger.py:50 - Epoch 220 Summary | Train MSE (x10^-2): 81.6596 | Val MSE (x10^-2): 26.3960 | Time: 36.17s
2025-07-18 00:08:47,458 - logger.py:50 - Epoch: [221][0/6]	Total Loss: 0.84429	Main MSE (x10^-2): 84.4287	LR: 2.38e-04	EMPP_Raw: 1.54347
2025-07-18 00:09:01,633 - logger.py:50 - Epoch: [221][5/6]	Total Loss: 0.81794	Main MSE (x10^-2): 81.7943	LR: 2.38e-04	EMPP_Raw: 1.48320
2025-07-18 00:09:01,681 - logger.py:50 - Epoch 221 Training Summary: Avg Total Loss: 0.81794, Avg Main MSE: 0.81794, Time: 17.31s
2025-07-18 00:09:20,024 - logger.py:50 - Epoch 221 Summary | Train MSE (x10^-2): 81.7943 | Val MSE (x10^-2): 24.8840 | Time: 35.65s
2025-07-18 00:09:23,234 - logger.py:50 - Epoch: [222][0/6]	Total Loss: 0.84355	Main MSE (x10^-2): 84.3553	LR: 2.37e-04	EMPP_Raw: 1.52863
2025-07-18 00:09:37,300 - logger.py:50 - Epoch: [222][5/6]	Total Loss: 0.83099	Main MSE (x10^-2): 83.0985	LR: 2.37e-04	EMPP_Raw: 1.51553
2025-07-18 00:09:37,346 - logger.py:50 - Epoch 222 Training Summary: Avg Total Loss: 0.83099, Avg Main MSE: 0.83099, Time: 17.31s
2025-07-18 00:09:55,677 - logger.py:50 - Epoch 222 Summary | Train MSE (x10^-2): 83.0985 | Val MSE (x10^-2): 25.2240 | Time: 35.65s
2025-07-18 00:09:58,735 - logger.py:50 - Epoch: [223][0/6]	Total Loss: 0.77653	Main MSE (x10^-2): 77.6532	LR: 2.35e-04	EMPP_Raw: 1.41488
2025-07-18 00:10:13,011 - logger.py:50 - Epoch: [223][5/6]	Total Loss: 0.83415	Main MSE (x10^-2): 83.4152	LR: 2.35e-04	EMPP_Raw: 1.51009
2025-07-18 00:10:13,053 - logger.py:50 - Epoch 223 Training Summary: Avg Total Loss: 0.83415, Avg Main MSE: 0.83415, Time: 17.37s
2025-07-18 00:10:31,305 - logger.py:50 - Epoch 223 Summary | Train MSE (x10^-2): 83.4152 | Val MSE (x10^-2): 26.8732 | Time: 35.62s
2025-07-18 00:10:34,402 - logger.py:50 - Epoch: [224][0/6]	Total Loss: 0.83990	Main MSE (x10^-2): 83.9903	LR: 2.34e-04	EMPP_Raw: 1.50790
2025-07-18 00:10:48,736 - logger.py:50 - Epoch: [224][5/6]	Total Loss: 0.84971	Main MSE (x10^-2): 84.9708	LR: 2.34e-04	EMPP_Raw: 1.53921
2025-07-18 00:10:48,802 - logger.py:50 - Epoch 224 Training Summary: Avg Total Loss: 0.84971, Avg Main MSE: 0.84971, Time: 17.49s
2025-07-18 00:11:07,084 - logger.py:50 - Epoch 224 Summary | Train MSE (x10^-2): 84.9708 | Val MSE (x10^-2): 26.1581 | Time: 35.77s
2025-07-18 00:11:10,176 - logger.py:50 - Epoch: [225][0/6]	Total Loss: 0.83572	Main MSE (x10^-2): 83.5725	LR: 2.33e-04	EMPP_Raw: 1.51326
2025-07-18 00:11:24,338 - logger.py:50 - Epoch: [225][5/6]	Total Loss: 0.84891	Main MSE (x10^-2): 84.8909	LR: 2.33e-04	EMPP_Raw: 1.54747
2025-07-18 00:11:24,384 - logger.py:50 - Epoch 225 Training Summary: Avg Total Loss: 0.84891, Avg Main MSE: 0.84891, Time: 17.29s
2025-07-18 00:11:42,795 - logger.py:50 - Epoch 225 Summary | Train MSE (x10^-2): 84.8909 | Val MSE (x10^-2): 25.6646 | Time: 35.70s
2025-07-18 00:11:45,831 - logger.py:50 - Epoch: [226][0/6]	Total Loss: 0.78635	Main MSE (x10^-2): 78.6355	LR: 2.32e-04	EMPP_Raw: 1.44372
2025-07-18 00:11:59,960 - logger.py:50 - Epoch: [226][5/6]	Total Loss: 0.81762	Main MSE (x10^-2): 81.7619	LR: 2.32e-04	EMPP_Raw: 1.49241
2025-07-18 00:12:00,006 - logger.py:50 - Epoch 226 Training Summary: Avg Total Loss: 0.81762, Avg Main MSE: 0.81762, Time: 17.20s
2025-07-18 00:12:18,514 - logger.py:50 - Epoch 226 Summary | Train MSE (x10^-2): 81.7619 | Val MSE (x10^-2): 25.4963 | Time: 35.71s
2025-07-18 00:12:21,586 - logger.py:50 - Epoch: [227][0/6]	Total Loss: 0.82467	Main MSE (x10^-2): 82.4670	LR: 2.30e-04	EMPP_Raw: 1.50964
2025-07-18 00:12:35,752 - logger.py:50 - Epoch: [227][5/6]	Total Loss: 0.84281	Main MSE (x10^-2): 84.2813	LR: 2.30e-04	EMPP_Raw: 1.54478
2025-07-18 00:12:35,792 - logger.py:50 - Epoch 227 Training Summary: Avg Total Loss: 0.84281, Avg Main MSE: 0.84281, Time: 17.27s
2025-07-18 00:12:54,116 - logger.py:50 - Epoch 227 Summary | Train MSE (x10^-2): 84.2813 | Val MSE (x10^-2): 25.6658 | Time: 35.60s
2025-07-18 00:12:57,360 - logger.py:50 - Epoch: [228][0/6]	Total Loss: 0.89641	Main MSE (x10^-2): 89.6412	LR: 2.29e-04	EMPP_Raw: 1.64759
2025-07-18 00:13:11,427 - logger.py:50 - Epoch: [228][5/6]	Total Loss: 0.84191	Main MSE (x10^-2): 84.1905	LR: 2.29e-04	EMPP_Raw: 1.54348
2025-07-18 00:13:11,492 - logger.py:50 - Epoch 228 Training Summary: Avg Total Loss: 0.84191, Avg Main MSE: 0.84191, Time: 17.37s
2025-07-18 00:13:29,911 - logger.py:50 - Epoch 228 Summary | Train MSE (x10^-2): 84.1905 | Val MSE (x10^-2): 25.5654 | Time: 35.79s
2025-07-18 00:13:33,013 - logger.py:50 - Epoch: [229][0/6]	Total Loss: 0.82445	Main MSE (x10^-2): 82.4453	LR: 2.28e-04	EMPP_Raw: 1.52205
2025-07-18 00:13:47,339 - logger.py:50 - Epoch: [229][5/6]	Total Loss: 0.84110	Main MSE (x10^-2): 84.1098	LR: 2.28e-04	EMPP_Raw: 1.53894
2025-07-18 00:13:47,382 - logger.py:50 - Epoch 229 Training Summary: Avg Total Loss: 0.84110, Avg Main MSE: 0.84110, Time: 17.46s
2025-07-18 00:14:05,760 - logger.py:50 - Epoch 229 Summary | Train MSE (x10^-2): 84.1098 | Val MSE (x10^-2): 25.2212 | Time: 35.84s
2025-07-18 00:14:08,794 - logger.py:50 - Epoch: [230][0/6]	Total Loss: 0.84145	Main MSE (x10^-2): 84.1446	LR: 2.27e-04	EMPP_Raw: 1.53863
2025-07-18 00:14:23,030 - logger.py:50 - Epoch: [230][5/6]	Total Loss: 0.82484	Main MSE (x10^-2): 82.4836	LR: 2.27e-04	EMPP_Raw: 1.51136
2025-07-18 00:14:23,075 - logger.py:50 - Epoch 230 Training Summary: Avg Total Loss: 0.82484, Avg Main MSE: 0.82484, Time: 17.30s
2025-07-18 00:14:41,540 - logger.py:50 - Epoch 230 Summary | Train MSE (x10^-2): 82.4836 | Val MSE (x10^-2): 25.6460 | Time: 35.77s
2025-07-18 00:14:44,603 - logger.py:50 - Epoch: [231][0/6]	Total Loss: 0.78280	Main MSE (x10^-2): 78.2796	LR: 2.26e-04	EMPP_Raw: 1.43461
2025-07-18 00:14:58,701 - logger.py:50 - Epoch: [231][5/6]	Total Loss: 0.79838	Main MSE (x10^-2): 79.8383	LR: 2.26e-04	EMPP_Raw: 1.45902
2025-07-18 00:14:58,745 - logger.py:50 - Epoch 231 Training Summary: Avg Total Loss: 0.79838, Avg Main MSE: 0.79838, Time: 17.20s
2025-07-18 00:15:17,265 - logger.py:50 - Epoch 231 Summary | Train MSE (x10^-2): 79.8383 | Val MSE (x10^-2): 26.0826 | Time: 35.72s
2025-07-18 00:15:20,328 - logger.py:50 - Epoch: [232][0/6]	Total Loss: 0.83330	Main MSE (x10^-2): 83.3295	LR: 2.24e-04	EMPP_Raw: 1.53066
2025-07-18 00:15:34,458 - logger.py:50 - Epoch: [232][5/6]	Total Loss: 0.82253	Main MSE (x10^-2): 82.2533	LR: 2.24e-04	EMPP_Raw: 1.51439
2025-07-18 00:15:34,505 - logger.py:50 - Epoch 232 Training Summary: Avg Total Loss: 0.82253, Avg Main MSE: 0.82253, Time: 17.23s
2025-07-18 00:15:53,270 - logger.py:50 - Epoch 232 Summary | Train MSE (x10^-2): 82.2533 | Val MSE (x10^-2): 26.3120 | Time: 36.00s
2025-07-18 00:15:56,305 - logger.py:50 - Epoch: [233][0/6]	Total Loss: 0.74012	Main MSE (x10^-2): 74.0120	LR: 2.23e-04	EMPP_Raw: 1.33820
2025-07-18 00:16:10,359 - logger.py:50 - Epoch: [233][5/6]	Total Loss: 0.80716	Main MSE (x10^-2): 80.7165	LR: 2.23e-04	EMPP_Raw: 1.48108
2025-07-18 00:16:10,405 - logger.py:50 - Epoch 233 Training Summary: Avg Total Loss: 0.80716, Avg Main MSE: 0.80716, Time: 17.13s
2025-07-18 00:16:28,772 - logger.py:50 - Epoch 233 Summary | Train MSE (x10^-2): 80.7165 | Val MSE (x10^-2): 25.5613 | Time: 35.50s
2025-07-18 00:16:31,958 - logger.py:50 - Epoch: [234][0/6]	Total Loss: 0.85632	Main MSE (x10^-2): 85.6317	LR: 2.22e-04	EMPP_Raw: 1.58071
2025-07-18 00:16:45,984 - logger.py:50 - Epoch: [234][5/6]	Total Loss: 0.83367	Main MSE (x10^-2): 83.3666	LR: 2.22e-04	EMPP_Raw: 1.53271
2025-07-18 00:16:46,030 - logger.py:50 - Epoch 234 Training Summary: Avg Total Loss: 0.83367, Avg Main MSE: 0.83367, Time: 17.25s
2025-07-18 00:17:04,301 - logger.py:50 - Epoch 234 Summary | Train MSE (x10^-2): 83.3666 | Val MSE (x10^-2): 26.0345 | Time: 35.52s
2025-07-18 00:17:07,388 - logger.py:50 - Epoch: [235][0/6]	Total Loss: 0.78991	Main MSE (x10^-2): 78.9914	LR: 2.21e-04	EMPP_Raw: 1.44986
2025-07-18 00:17:21,581 - logger.py:50 - Epoch: [235][5/6]	Total Loss: 0.83181	Main MSE (x10^-2): 83.1808	LR: 2.21e-04	EMPP_Raw: 1.52985
2025-07-18 00:17:21,624 - logger.py:50 - Epoch 235 Training Summary: Avg Total Loss: 0.83181, Avg Main MSE: 0.83181, Time: 17.31s
2025-07-18 00:17:39,991 - logger.py:50 - Epoch 235 Summary | Train MSE (x10^-2): 83.1808 | Val MSE (x10^-2): 26.2481 | Time: 35.68s
2025-07-18 00:17:43,091 - logger.py:50 - Epoch: [236][0/6]	Total Loss: 0.81390	Main MSE (x10^-2): 81.3898	LR: 2.19e-04	EMPP_Raw: 1.48632
2025-07-18 00:17:57,252 - logger.py:50 - Epoch: [236][5/6]	Total Loss: 0.84681	Main MSE (x10^-2): 84.6807	LR: 2.19e-04	EMPP_Raw: 1.56010
2025-07-18 00:17:57,301 - logger.py:50 - Epoch 236 Training Summary: Avg Total Loss: 0.84681, Avg Main MSE: 0.84681, Time: 17.30s
2025-07-18 00:18:15,707 - logger.py:50 - Epoch 236 Summary | Train MSE (x10^-2): 84.6807 | Val MSE (x10^-2): 26.5293 | Time: 35.71s
2025-07-18 00:18:18,849 - logger.py:50 - Epoch: [237][0/6]	Total Loss: 0.81594	Main MSE (x10^-2): 81.5935	LR: 2.18e-04	EMPP_Raw: 1.49438
2025-07-18 00:18:33,013 - logger.py:50 - Epoch: [237][5/6]	Total Loss: 0.83638	Main MSE (x10^-2): 83.6384	LR: 2.18e-04	EMPP_Raw: 1.54040
2025-07-18 00:18:33,055 - logger.py:50 - Epoch 237 Training Summary: Avg Total Loss: 0.83638, Avg Main MSE: 0.83638, Time: 17.34s
2025-07-18 00:18:51,572 - logger.py:50 - Epoch 237 Summary | Train MSE (x10^-2): 83.6384 | Val MSE (x10^-2): 26.4060 | Time: 35.86s
2025-07-18 00:18:54,628 - logger.py:50 - Epoch: [238][0/6]	Total Loss: 0.83622	Main MSE (x10^-2): 83.6221	LR: 2.17e-04	EMPP_Raw: 1.54772
2025-07-18 00:19:08,668 - logger.py:50 - Epoch: [238][5/6]	Total Loss: 0.81000	Main MSE (x10^-2): 81.0003	LR: 2.17e-04	EMPP_Raw: 1.49196
2025-07-18 00:19:08,708 - logger.py:50 - Epoch 238 Training Summary: Avg Total Loss: 0.81000, Avg Main MSE: 0.81000, Time: 17.13s
2025-07-18 00:19:27,132 - logger.py:50 - Epoch 238 Summary | Train MSE (x10^-2): 81.0003 | Val MSE (x10^-2): 25.9099 | Time: 35.55s
2025-07-18 00:19:30,328 - logger.py:50 - Epoch: [239][0/6]	Total Loss: 0.84650	Main MSE (x10^-2): 84.6499	LR: 2.16e-04	EMPP_Raw: 1.57282
2025-07-18 00:19:44,351 - logger.py:50 - Epoch: [239][5/6]	Total Loss: 0.84254	Main MSE (x10^-2): 84.2541	LR: 2.16e-04	EMPP_Raw: 1.56196
2025-07-18 00:19:44,401 - logger.py:50 - Epoch 239 Training Summary: Avg Total Loss: 0.84254, Avg Main MSE: 0.84254, Time: 17.26s
2025-07-18 00:20:02,886 - logger.py:50 - Epoch 239 Summary | Train MSE (x10^-2): 84.2541 | Val MSE (x10^-2): 25.3654 | Time: 35.75s
2025-07-18 00:20:06,095 - logger.py:50 - Epoch: [240][0/6]	Total Loss: 0.80236	Main MSE (x10^-2): 80.2359	LR: 2.14e-04	EMPP_Raw: 1.48303
2025-07-18 00:20:20,170 - logger.py:50 - Epoch: [240][5/6]	Total Loss: 0.82361	Main MSE (x10^-2): 82.3612	LR: 2.14e-04	EMPP_Raw: 1.53288
2025-07-18 00:20:20,217 - logger.py:50 - Epoch 240 Training Summary: Avg Total Loss: 0.82361, Avg Main MSE: 0.82361, Time: 17.32s
2025-07-18 00:20:38,515 - logger.py:50 - Epoch 240 Summary | Train MSE (x10^-2): 82.3612 | Val MSE (x10^-2): 24.8684 | Time: 35.62s
2025-07-18 00:20:41,635 - logger.py:50 - Epoch: [241][0/6]	Total Loss: 0.84748	Main MSE (x10^-2): 84.7484	LR: 2.13e-04	EMPP_Raw: 1.57141
2025-07-18 00:20:55,847 - logger.py:50 - Epoch: [241][5/6]	Total Loss: 0.81043	Main MSE (x10^-2): 81.0435	LR: 2.13e-04	EMPP_Raw: 1.48907
2025-07-18 00:20:55,892 - logger.py:50 - Epoch 241 Training Summary: Avg Total Loss: 0.81043, Avg Main MSE: 0.81043, Time: 17.37s
2025-07-18 00:21:14,268 - logger.py:50 - Epoch 241 Summary | Train MSE (x10^-2): 81.0435 | Val MSE (x10^-2): 25.6782 | Time: 35.75s
2025-07-18 00:21:17,338 - logger.py:50 - Epoch: [242][0/6]	Total Loss: 0.84782	Main MSE (x10^-2): 84.7820	LR: 2.12e-04	EMPP_Raw: 1.57294
2025-07-18 00:21:31,517 - logger.py:50 - Epoch: [242][5/6]	Total Loss: 0.83492	Main MSE (x10^-2): 83.4917	LR: 2.12e-04	EMPP_Raw: 1.54201
2025-07-18 00:21:31,589 - logger.py:50 - Epoch 242 Training Summary: Avg Total Loss: 0.83492, Avg Main MSE: 0.83492, Time: 17.31s
2025-07-18 00:21:49,913 - logger.py:50 - Epoch 242 Summary | Train MSE (x10^-2): 83.4917 | Val MSE (x10^-2): 25.1253 | Time: 35.64s
2025-07-18 00:21:53,014 - logger.py:50 - Epoch: [243][0/6]	Total Loss: 0.77962	Main MSE (x10^-2): 77.9620	LR: 2.11e-04	EMPP_Raw: 1.44702
2025-07-18 00:22:07,127 - logger.py:50 - Epoch: [243][5/6]	Total Loss: 0.81670	Main MSE (x10^-2): 81.6705	LR: 2.11e-04	EMPP_Raw: 1.50671
2025-07-18 00:22:07,171 - logger.py:50 - Epoch 243 Training Summary: Avg Total Loss: 0.81670, Avg Main MSE: 0.81670, Time: 17.25s
2025-07-18 00:22:25,599 - logger.py:50 - Epoch 243 Summary | Train MSE (x10^-2): 81.6705 | Val MSE (x10^-2): 25.4324 | Time: 35.68s
2025-07-18 00:22:28,624 - logger.py:50 - Epoch: [244][0/6]	Total Loss: 0.78947	Main MSE (x10^-2): 78.9469	LR: 2.09e-04	EMPP_Raw: 1.45018
2025-07-18 00:22:42,637 - logger.py:50 - Epoch: [244][5/6]	Total Loss: 0.80091	Main MSE (x10^-2): 80.0906	LR: 2.09e-04	EMPP_Raw: 1.48315
2025-07-18 00:22:42,677 - logger.py:50 - Epoch 244 Training Summary: Avg Total Loss: 0.80091, Avg Main MSE: 0.80091, Time: 17.07s
2025-07-18 00:23:01,112 - logger.py:50 - Epoch 244 Summary | Train MSE (x10^-2): 80.0906 | Val MSE (x10^-2): 26.3644 | Time: 35.51s
2025-07-18 00:23:04,162 - logger.py:50 - Epoch: [245][0/6]	Total Loss: 0.73578	Main MSE (x10^-2): 73.5785	LR: 2.08e-04	EMPP_Raw: 1.34571
2025-07-18 00:23:18,259 - logger.py:50 - Epoch: [245][5/6]	Total Loss: 0.78519	Main MSE (x10^-2): 78.5193	LR: 2.08e-04	EMPP_Raw: 1.44695
2025-07-18 00:23:18,310 - logger.py:50 - Epoch 245 Training Summary: Avg Total Loss: 0.78519, Avg Main MSE: 0.78519, Time: 17.19s
2025-07-18 00:23:36,587 - logger.py:50 - Epoch 245 Summary | Train MSE (x10^-2): 78.5193 | Val MSE (x10^-2): 26.1806 | Time: 35.47s
2025-07-18 00:23:39,997 - logger.py:50 - Epoch: [246][0/6]	Total Loss: 0.77607	Main MSE (x10^-2): 77.6070	LR: 2.07e-04	EMPP_Raw: 1.44117
2025-07-18 00:23:54,072 - logger.py:50 - Epoch: [246][5/6]	Total Loss: 0.79540	Main MSE (x10^-2): 79.5398	LR: 2.07e-04	EMPP_Raw: 1.46708
2025-07-18 00:23:54,130 - logger.py:50 - Epoch 246 Training Summary: Avg Total Loss: 0.79540, Avg Main MSE: 0.79540, Time: 17.53s
2025-07-18 00:24:12,587 - logger.py:50 - Epoch 246 Summary | Train MSE (x10^-2): 79.5398 | Val MSE (x10^-2): 26.0903 | Time: 35.99s
2025-07-18 00:24:15,646 - logger.py:50 - Epoch: [247][0/6]	Total Loss: 0.85145	Main MSE (x10^-2): 85.1453	LR: 2.06e-04	EMPP_Raw: 1.57955
2025-07-18 00:24:29,662 - logger.py:50 - Epoch: [247][5/6]	Total Loss: 0.82549	Main MSE (x10^-2): 82.5485	LR: 2.06e-04	EMPP_Raw: 1.53036
2025-07-18 00:24:29,705 - logger.py:50 - Epoch 247 Training Summary: Avg Total Loss: 0.82549, Avg Main MSE: 0.82549, Time: 17.11s
2025-07-18 00:24:48,196 - logger.py:50 - Epoch 247 Summary | Train MSE (x10^-2): 82.5485 | Val MSE (x10^-2): 25.0744 | Time: 35.60s
2025-07-18 00:24:51,461 - logger.py:50 - Epoch: [248][0/6]	Total Loss: 0.77122	Main MSE (x10^-2): 77.1215	LR: 2.04e-04	EMPP_Raw: 1.43472
2025-07-18 00:25:05,479 - logger.py:50 - Epoch: [248][5/6]	Total Loss: 0.81813	Main MSE (x10^-2): 81.8132	LR: 2.04e-04	EMPP_Raw: 1.50571
2025-07-18 00:25:05,523 - logger.py:50 - Epoch 248 Training Summary: Avg Total Loss: 0.81813, Avg Main MSE: 0.81813, Time: 17.32s
2025-07-18 00:25:23,784 - logger.py:50 - Epoch 248 Summary | Train MSE (x10^-2): 81.8132 | Val MSE (x10^-2): 30.8547 | Time: 35.58s
2025-07-18 00:25:26,871 - logger.py:50 - Epoch: [249][0/6]	Total Loss: 0.87993	Main MSE (x10^-2): 87.9926	LR: 2.03e-04	EMPP_Raw: 1.56483
2025-07-18 00:25:41,182 - logger.py:50 - Epoch: [249][5/6]	Total Loss: 0.82976	Main MSE (x10^-2): 82.9763	LR: 2.03e-04	EMPP_Raw: 1.50964
2025-07-18 00:25:41,238 - logger.py:50 - Epoch 249 Training Summary: Avg Total Loss: 0.82976, Avg Main MSE: 0.82976, Time: 17.44s
2025-07-18 00:25:59,606 - logger.py:50 - Epoch 249 Summary | Train MSE (x10^-2): 82.9763 | Val MSE (x10^-2): 25.7901 | Time: 35.82s
2025-07-18 00:26:02,733 - logger.py:50 - Epoch: [250][0/6]	Total Loss: 0.92836	Main MSE (x10^-2): 92.8357	LR: 2.02e-04	EMPP_Raw: 1.73322
2025-07-18 00:26:16,936 - logger.py:50 - Epoch: [250][5/6]	Total Loss: 0.83197	Main MSE (x10^-2): 83.1965	LR: 2.02e-04	EMPP_Raw: 1.53921
2025-07-18 00:26:16,980 - logger.py:50 - Epoch 250 Training Summary: Avg Total Loss: 0.83197, Avg Main MSE: 0.83197, Time: 17.36s
2025-07-18 00:26:35,472 - logger.py:50 - Epoch 250 Summary | Train MSE (x10^-2): 83.1965 | Val MSE (x10^-2): 25.7385 | Time: 35.86s
2025-07-18 00:26:38,563 - logger.py:50 - Epoch: [251][0/6]	Total Loss: 0.78059	Main MSE (x10^-2): 78.0588	LR: 2.00e-04	EMPP_Raw: 1.44167
2025-07-18 00:26:52,816 - logger.py:50 - Epoch: [251][5/6]	Total Loss: 0.79309	Main MSE (x10^-2): 79.3091	LR: 2.00e-04	EMPP_Raw: 1.46956
2025-07-18 00:26:52,876 - logger.py:50 - Epoch 251 Training Summary: Avg Total Loss: 0.79309, Avg Main MSE: 0.79309, Time: 17.39s
2025-07-18 00:27:11,602 - logger.py:50 - Epoch 251 Summary | Train MSE (x10^-2): 79.3091 | Val MSE (x10^-2): 25.1912 | Time: 36.12s
2025-07-18 00:27:14,691 - logger.py:50 - Epoch: [252][0/6]	Total Loss: 0.72332	Main MSE (x10^-2): 72.3323	LR: 1.99e-04	EMPP_Raw: 1.33990
2025-07-18 00:27:28,737 - logger.py:50 - Epoch: [252][5/6]	Total Loss: 0.79302	Main MSE (x10^-2): 79.3018	LR: 1.99e-04	EMPP_Raw: 1.47651
2025-07-18 00:27:28,780 - logger.py:50 - Epoch 252 Training Summary: Avg Total Loss: 0.79302, Avg Main MSE: 0.79302, Time: 17.17s
2025-07-18 00:27:47,435 - logger.py:50 - Epoch 252 Summary | Train MSE (x10^-2): 79.3018 | Val MSE (x10^-2): 25.3599 | Time: 35.83s
2025-07-18 00:27:50,470 - logger.py:50 - Epoch: [253][0/6]	Total Loss: 0.80536	Main MSE (x10^-2): 80.5363	LR: 1.98e-04	EMPP_Raw: 1.48320
2025-07-18 00:28:04,566 - logger.py:50 - Epoch: [253][5/6]	Total Loss: 0.81003	Main MSE (x10^-2): 81.0030	LR: 1.98e-04	EMPP_Raw: 1.50848
2025-07-18 00:28:04,609 - logger.py:50 - Epoch 253 Training Summary: Avg Total Loss: 0.81003, Avg Main MSE: 0.81003, Time: 17.16s
2025-07-18 00:28:23,003 - logger.py:50 - Epoch 253 Summary | Train MSE (x10^-2): 81.0030 | Val MSE (x10^-2): 25.2101 | Time: 35.56s
2025-07-18 00:28:26,217 - logger.py:50 - Epoch: [254][0/6]	Total Loss: 0.76716	Main MSE (x10^-2): 76.7164	LR: 1.97e-04	EMPP_Raw: 1.43081
2025-07-18 00:28:40,321 - logger.py:50 - Epoch: [254][5/6]	Total Loss: 0.78025	Main MSE (x10^-2): 78.0252	LR: 1.97e-04	EMPP_Raw: 1.44865
2025-07-18 00:28:40,365 - logger.py:50 - Epoch 254 Training Summary: Avg Total Loss: 0.78025, Avg Main MSE: 0.78025, Time: 17.35s
2025-07-18 00:28:58,835 - logger.py:50 - Epoch 254 Summary | Train MSE (x10^-2): 78.0252 | Val MSE (x10^-2): 25.6332 | Time: 35.83s
2025-07-18 00:29:01,867 - logger.py:50 - Epoch: [255][0/6]	Total Loss: 0.84807	Main MSE (x10^-2): 84.8071	LR: 1.95e-04	EMPP_Raw: 1.58821
2025-07-18 00:29:16,162 - logger.py:50 - Epoch: [255][5/6]	Total Loss: 0.81552	Main MSE (x10^-2): 81.5516	LR: 1.95e-04	EMPP_Raw: 1.51635
2025-07-18 00:29:16,209 - logger.py:50 - Epoch 255 Training Summary: Avg Total Loss: 0.81552, Avg Main MSE: 0.81552, Time: 17.37s
2025-07-18 00:29:34,613 - logger.py:50 - Epoch 255 Summary | Train MSE (x10^-2): 81.5516 | Val MSE (x10^-2): 24.9105 | Time: 35.77s
2025-07-18 00:29:37,713 - logger.py:50 - Epoch: [256][0/6]	Total Loss: 0.74156	Main MSE (x10^-2): 74.1564	LR: 1.94e-04	EMPP_Raw: 1.37162
2025-07-18 00:29:51,935 - logger.py:50 - Epoch: [256][5/6]	Total Loss: 0.79231	Main MSE (x10^-2): 79.2311	LR: 1.94e-04	EMPP_Raw: 1.47126
2025-07-18 00:29:51,980 - logger.py:50 - Epoch 256 Training Summary: Avg Total Loss: 0.79231, Avg Main MSE: 0.79231, Time: 17.36s
2025-07-18 00:30:10,460 - logger.py:50 - Epoch 256 Summary | Train MSE (x10^-2): 79.2311 | Val MSE (x10^-2): 25.5550 | Time: 35.84s
2025-07-18 00:30:13,505 - logger.py:50 - Epoch: [257][0/6]	Total Loss: 0.84261	Main MSE (x10^-2): 84.2608	LR: 1.93e-04	EMPP_Raw: 1.57999
2025-07-18 00:30:27,599 - logger.py:50 - Epoch: [257][5/6]	Total Loss: 0.82249	Main MSE (x10^-2): 82.2493	LR: 1.93e-04	EMPP_Raw: 1.53636
2025-07-18 00:30:27,639 - logger.py:50 - Epoch 257 Training Summary: Avg Total Loss: 0.82249, Avg Main MSE: 0.82249, Time: 17.17s
2025-07-18 00:30:46,067 - logger.py:50 - Epoch 257 Summary | Train MSE (x10^-2): 82.2493 | Val MSE (x10^-2): 24.8433 | Time: 35.60s
2025-07-18 00:30:49,128 - logger.py:50 - Epoch: [258][0/6]	Total Loss: 0.76267	Main MSE (x10^-2): 76.2670	LR: 1.92e-04	EMPP_Raw: 1.41579
2025-07-18 00:31:03,260 - logger.py:50 - Epoch: [258][5/6]	Total Loss: 0.82787	Main MSE (x10^-2): 82.7871	LR: 1.92e-04	EMPP_Raw: 1.54431
2025-07-18 00:31:03,302 - logger.py:50 - Epoch 258 Training Summary: Avg Total Loss: 0.82787, Avg Main MSE: 0.82787, Time: 17.23s
2025-07-18 00:31:21,908 - logger.py:50 - Epoch 258 Summary | Train MSE (x10^-2): 82.7871 | Val MSE (x10^-2): 25.4624 | Time: 35.84s
2025-07-18 00:31:25,005 - logger.py:50 - Epoch: [259][0/6]	Total Loss: 0.84634	Main MSE (x10^-2): 84.6342	LR: 1.90e-04	EMPP_Raw: 1.57477
2025-07-18 00:31:39,164 - logger.py:50 - Epoch: [259][5/6]	Total Loss: 0.81211	Main MSE (x10^-2): 81.2110	LR: 1.90e-04	EMPP_Raw: 1.50737
2025-07-18 00:31:39,212 - logger.py:50 - Epoch 259 Training Summary: Avg Total Loss: 0.81211, Avg Main MSE: 0.81211, Time: 17.29s
2025-07-18 00:31:57,745 - logger.py:50 - Epoch 259 Summary | Train MSE (x10^-2): 81.2110 | Val MSE (x10^-2): 28.4826 | Time: 35.83s
2025-07-18 00:32:00,965 - logger.py:50 - Epoch: [260][0/6]	Total Loss: 0.86380	Main MSE (x10^-2): 86.3800	LR: 1.89e-04	EMPP_Raw: 1.59480
2025-07-18 00:32:15,131 - logger.py:50 - Epoch: [260][5/6]	Total Loss: 0.81509	Main MSE (x10^-2): 81.5087	LR: 1.89e-04	EMPP_Raw: 1.50825
2025-07-18 00:32:15,175 - logger.py:50 - Epoch 260 Training Summary: Avg Total Loss: 0.81509, Avg Main MSE: 0.81509, Time: 17.42s
2025-07-18 00:32:33,564 - logger.py:50 - Epoch 260 Summary | Train MSE (x10^-2): 81.5087 | Val MSE (x10^-2): 25.3696 | Time: 35.81s
2025-07-18 00:32:36,634 - logger.py:50 - Epoch: [261][0/6]	Total Loss: 0.86821	Main MSE (x10^-2): 86.8205	LR: 1.88e-04	EMPP_Raw: 1.64211
2025-07-18 00:32:50,839 - logger.py:50 - Epoch: [261][5/6]	Total Loss: 0.81338	Main MSE (x10^-2): 81.3384	LR: 1.88e-04	EMPP_Raw: 1.52831
2025-07-18 00:32:50,881 - logger.py:50 - Epoch 261 Training Summary: Avg Total Loss: 0.81338, Avg Main MSE: 0.81338, Time: 17.31s
2025-07-18 00:33:09,145 - logger.py:50 - Epoch 261 Summary | Train MSE (x10^-2): 81.3384 | Val MSE (x10^-2): 25.0944 | Time: 35.58s
2025-07-18 00:33:12,203 - logger.py:50 - Epoch: [262][0/6]	Total Loss: 0.80618	Main MSE (x10^-2): 80.6182	LR: 1.87e-04	EMPP_Raw: 1.52139
2025-07-18 00:33:26,398 - logger.py:50 - Epoch: [262][5/6]	Total Loss: 0.80905	Main MSE (x10^-2): 80.9051	LR: 1.87e-04	EMPP_Raw: 1.51591
2025-07-18 00:33:26,447 - logger.py:50 - Epoch 262 Training Summary: Avg Total Loss: 0.80905, Avg Main MSE: 0.80905, Time: 17.29s
2025-07-18 00:33:45,121 - logger.py:50 - Epoch 262 Summary | Train MSE (x10^-2): 80.9051 | Val MSE (x10^-2): 25.2433 | Time: 35.97s
2025-07-18 00:33:48,197 - logger.py:50 - Epoch: [263][0/6]	Total Loss: 0.82457	Main MSE (x10^-2): 82.4568	LR: 1.85e-04	EMPP_Raw: 1.54782
2025-07-18 00:34:02,286 - logger.py:50 - Epoch: [263][5/6]	Total Loss: 0.84537	Main MSE (x10^-2): 84.5365	LR: 1.85e-04	EMPP_Raw: 1.58634
2025-07-18 00:34:02,328 - logger.py:50 - Epoch 263 Training Summary: Avg Total Loss: 0.84537, Avg Main MSE: 0.84537, Time: 17.20s
2025-07-18 00:34:21,320 - logger.py:50 - Epoch 263 Summary | Train MSE (x10^-2): 84.5365 | Val MSE (x10^-2): 25.0383 | Time: 36.20s
2025-07-18 00:34:24,432 - logger.py:50 - Epoch: [264][0/6]	Total Loss: 0.85772	Main MSE (x10^-2): 85.7716	LR: 1.84e-04	EMPP_Raw: 1.61161
2025-07-18 00:34:38,784 - logger.py:50 - Epoch: [264][5/6]	Total Loss: 0.81833	Main MSE (x10^-2): 81.8325	LR: 1.84e-04	EMPP_Raw: 1.53844
2025-07-18 00:34:38,834 - logger.py:50 - Epoch 264 Training Summary: Avg Total Loss: 0.81833, Avg Main MSE: 0.81833, Time: 17.50s
2025-07-18 00:34:57,233 - logger.py:50 - Epoch 264 Summary | Train MSE (x10^-2): 81.8325 | Val MSE (x10^-2): 25.0001 | Time: 35.91s
2025-07-18 00:35:00,444 - logger.py:50 - Epoch: [265][0/6]	Total Loss: 0.78205	Main MSE (x10^-2): 78.2054	LR: 1.83e-04	EMPP_Raw: 1.45924
2025-07-18 00:35:14,560 - logger.py:50 - Epoch: [265][5/6]	Total Loss: 0.81859	Main MSE (x10^-2): 81.8591	LR: 1.83e-04	EMPP_Raw: 1.53308
2025-07-18 00:35:14,604 - logger.py:50 - Epoch 265 Training Summary: Avg Total Loss: 0.81859, Avg Main MSE: 0.81859, Time: 17.36s
2025-07-18 00:35:33,088 - logger.py:50 - Epoch 265 Summary | Train MSE (x10^-2): 81.8591 | Val MSE (x10^-2): 25.4103 | Time: 35.85s
2025-07-18 00:35:36,285 - logger.py:50 - Epoch: [266][0/6]	Total Loss: 0.85004	Main MSE (x10^-2): 85.0038	LR: 1.82e-04	EMPP_Raw: 1.59637
2025-07-18 00:35:50,306 - logger.py:50 - Epoch: [266][5/6]	Total Loss: 0.81306	Main MSE (x10^-2): 81.3062	LR: 1.82e-04	EMPP_Raw: 1.52261
2025-07-18 00:35:50,348 - logger.py:50 - Epoch 266 Training Summary: Avg Total Loss: 0.81306, Avg Main MSE: 0.81306, Time: 17.25s
2025-07-18 00:36:08,745 - logger.py:50 - Epoch 266 Summary | Train MSE (x10^-2): 81.3062 | Val MSE (x10^-2): 25.7938 | Time: 35.65s
2025-07-18 00:36:11,790 - logger.py:50 - Epoch: [267][0/6]	Total Loss: 0.83259	Main MSE (x10^-2): 83.2592	LR: 1.80e-04	EMPP_Raw: 1.56470
2025-07-18 00:36:26,075 - logger.py:50 - Epoch: [267][5/6]	Total Loss: 0.81164	Main MSE (x10^-2): 81.1640	LR: 1.80e-04	EMPP_Raw: 1.52041
2025-07-18 00:36:26,121 - logger.py:50 - Epoch 267 Training Summary: Avg Total Loss: 0.81164, Avg Main MSE: 0.81164, Time: 17.37s
2025-07-18 00:36:44,841 - logger.py:50 - Epoch 267 Summary | Train MSE (x10^-2): 81.1640 | Val MSE (x10^-2): 25.4717 | Time: 36.09s
2025-07-18 00:36:47,890 - logger.py:50 - Epoch: [268][0/6]	Total Loss: 0.76556	Main MSE (x10^-2): 76.5562	LR: 1.79e-04	EMPP_Raw: 1.42253
2025-07-18 00:37:02,143 - logger.py:50 - Epoch: [268][5/6]	Total Loss: 0.82089	Main MSE (x10^-2): 82.0890	LR: 1.79e-04	EMPP_Raw: 1.53846
2025-07-18 00:37:02,187 - logger.py:50 - Epoch 268 Training Summary: Avg Total Loss: 0.82089, Avg Main MSE: 0.82089, Time: 17.34s
2025-07-18 00:37:20,765 - logger.py:50 - Epoch 268 Summary | Train MSE (x10^-2): 82.0890 | Val MSE (x10^-2): 25.4670 | Time: 35.92s
2025-07-18 00:37:23,951 - logger.py:50 - Epoch: [269][0/6]	Total Loss: 0.83002	Main MSE (x10^-2): 83.0015	LR: 1.78e-04	EMPP_Raw: 1.54817
2025-07-18 00:37:38,037 - logger.py:50 - Epoch: [269][5/6]	Total Loss: 0.81382	Main MSE (x10^-2): 81.3825	LR: 1.78e-04	EMPP_Raw: 1.52815
2025-07-18 00:37:38,085 - logger.py:50 - Epoch 269 Training Summary: Avg Total Loss: 0.81382, Avg Main MSE: 0.81382, Time: 17.31s
2025-07-18 00:37:56,672 - logger.py:50 - Epoch 269 Summary | Train MSE (x10^-2): 81.3825 | Val MSE (x10^-2): 25.3628 | Time: 35.90s
2025-07-18 00:37:59,718 - logger.py:50 - Epoch: [270][0/6]	Total Loss: 0.78742	Main MSE (x10^-2): 78.7423	LR: 1.77e-04	EMPP_Raw: 1.47547
2025-07-18 00:38:13,930 - logger.py:50 - Epoch: [270][5/6]	Total Loss: 0.80116	Main MSE (x10^-2): 80.1163	LR: 1.77e-04	EMPP_Raw: 1.50381
2025-07-18 00:38:13,971 - logger.py:50 - Epoch 270 Training Summary: Avg Total Loss: 0.80116, Avg Main MSE: 0.80116, Time: 17.29s
2025-07-18 00:38:32,635 - logger.py:50 - Epoch 270 Summary | Train MSE (x10^-2): 80.1163 | Val MSE (x10^-2): 24.8138 | Time: 35.96s
2025-07-18 00:38:35,679 - logger.py:50 - Epoch: [271][0/6]	Total Loss: 0.86248	Main MSE (x10^-2): 86.2480	LR: 1.75e-04	EMPP_Raw: 1.63242
2025-07-18 00:38:49,810 - logger.py:50 - Epoch: [271][5/6]	Total Loss: 0.83289	Main MSE (x10^-2): 83.2894	LR: 1.75e-04	EMPP_Raw: 1.56595
2025-07-18 00:38:49,855 - logger.py:50 - Epoch 271 Training Summary: Avg Total Loss: 0.83289, Avg Main MSE: 0.83289, Time: 17.21s
2025-07-18 00:39:08,346 - logger.py:50 - Epoch 271 Summary | Train MSE (x10^-2): 83.2894 | Val MSE (x10^-2): 24.8018 | Time: 35.70s
2025-07-18 00:39:11,734 - logger.py:50 - Epoch: [272][0/6]	Total Loss: 0.79734	Main MSE (x10^-2): 79.7337	LR: 1.74e-04	EMPP_Raw: 1.49525
2025-07-18 00:39:25,825 - logger.py:50 - Epoch: [272][5/6]	Total Loss: 0.81533	Main MSE (x10^-2): 81.5332	LR: 1.74e-04	EMPP_Raw: 1.53263
2025-07-18 00:39:25,873 - logger.py:50 - Epoch 272 Training Summary: Avg Total Loss: 0.81533, Avg Main MSE: 0.81533, Time: 17.52s
2025-07-18 00:39:44,542 - logger.py:50 - Epoch 272 Summary | Train MSE (x10^-2): 81.5332 | Val MSE (x10^-2): 24.7967 | Time: 36.19s
2025-07-18 00:39:47,634 - logger.py:50 - Epoch: [273][0/6]	Total Loss: 0.80549	Main MSE (x10^-2): 80.5490	LR: 1.73e-04	EMPP_Raw: 1.52307
2025-07-18 00:40:01,696 - logger.py:50 - Epoch: [273][5/6]	Total Loss: 0.79796	Main MSE (x10^-2): 79.7959	LR: 1.73e-04	EMPP_Raw: 1.49961
2025-07-18 00:40:01,737 - logger.py:50 - Epoch 273 Training Summary: Avg Total Loss: 0.79796, Avg Main MSE: 0.79796, Time: 17.18s
2025-07-18 00:40:19,995 - logger.py:50 - Epoch 273 Summary | Train MSE (x10^-2): 79.7959 | Val MSE (x10^-2): 24.9857 | Time: 35.45s
2025-07-18 00:40:23,187 - logger.py:50 - Epoch: [274][0/6]	Total Loss: 0.79594	Main MSE (x10^-2): 79.5943	LR: 1.72e-04	EMPP_Raw: 1.49041
2025-07-18 00:40:37,194 - logger.py:50 - Epoch: [274][5/6]	Total Loss: 0.81254	Main MSE (x10^-2): 81.2544	LR: 1.72e-04	EMPP_Raw: 1.53017
2025-07-18 00:40:37,234 - logger.py:50 - Epoch 274 Training Summary: Avg Total Loss: 0.81254, Avg Main MSE: 0.81254, Time: 17.23s
2025-07-18 00:40:55,529 - logger.py:50 - Epoch 274 Summary | Train MSE (x10^-2): 81.2544 | Val MSE (x10^-2): 25.1052 | Time: 35.53s
2025-07-18 00:40:58,608 - logger.py:50 - Epoch: [275][0/6]	Total Loss: 0.81103	Main MSE (x10^-2): 81.1029	LR: 1.71e-04	EMPP_Raw: 1.52567
2025-07-18 00:41:12,785 - logger.py:50 - Epoch: [275][5/6]	Total Loss: 0.82954	Main MSE (x10^-2): 82.9543	LR: 1.71e-04	EMPP_Raw: 1.56207
2025-07-18 00:41:12,830 - logger.py:50 - Epoch 275 Training Summary: Avg Total Loss: 0.82954, Avg Main MSE: 0.82954, Time: 17.29s
2025-07-18 00:41:31,330 - logger.py:50 - Epoch 275 Summary | Train MSE (x10^-2): 82.9543 | Val MSE (x10^-2): 25.5624 | Time: 35.80s
2025-07-18 00:41:34,384 - logger.py:50 - Epoch: [276][0/6]	Total Loss: 0.79738	Main MSE (x10^-2): 79.7382	LR: 1.69e-04	EMPP_Raw: 1.51238
2025-07-18 00:41:48,630 - logger.py:50 - Epoch: [276][5/6]	Total Loss: 0.81503	Main MSE (x10^-2): 81.5029	LR: 1.69e-04	EMPP_Raw: 1.53827
2025-07-18 00:41:48,674 - logger.py:50 - Epoch 276 Training Summary: Avg Total Loss: 0.81503, Avg Main MSE: 0.81503, Time: 17.33s
2025-07-18 00:42:07,205 - logger.py:50 - Epoch 276 Summary | Train MSE (x10^-2): 81.5029 | Val MSE (x10^-2): 24.9072 | Time: 35.87s
2025-07-18 00:42:10,346 - logger.py:50 - Epoch: [277][0/6]	Total Loss: 0.82015	Main MSE (x10^-2): 82.0149	LR: 1.68e-04	EMPP_Raw: 1.54873
2025-07-18 00:42:24,463 - logger.py:50 - Epoch: [277][5/6]	Total Loss: 0.84208	Main MSE (x10^-2): 84.2080	LR: 1.68e-04	EMPP_Raw: 1.58996
2025-07-18 00:42:24,515 - logger.py:50 - Epoch 277 Training Summary: Avg Total Loss: 0.84208, Avg Main MSE: 0.84208, Time: 17.30s
2025-07-18 00:42:43,011 - logger.py:50 - Epoch 277 Summary | Train MSE (x10^-2): 84.2080 | Val MSE (x10^-2): 25.4700 | Time: 35.80s
2025-07-18 00:42:46,092 - logger.py:50 - Epoch: [278][0/6]	Total Loss: 0.84884	Main MSE (x10^-2): 84.8835	LR: 1.67e-04	EMPP_Raw: 1.61874
2025-07-18 00:43:00,150 - logger.py:50 - Epoch: [278][5/6]	Total Loss: 0.79616	Main MSE (x10^-2): 79.6158	LR: 1.67e-04	EMPP_Raw: 1.50461
2025-07-18 00:43:00,199 - logger.py:50 - Epoch 278 Training Summary: Avg Total Loss: 0.79616, Avg Main MSE: 0.79616, Time: 17.18s
2025-07-18 00:43:18,723 - logger.py:50 - Epoch 278 Summary | Train MSE (x10^-2): 79.6158 | Val MSE (x10^-2): 25.3046 | Time: 35.71s
2025-07-18 00:43:21,770 - logger.py:50 - Epoch: [279][0/6]	Total Loss: 0.87118	Main MSE (x10^-2): 87.1176	LR: 1.66e-04	EMPP_Raw: 1.66109
2025-07-18 00:43:35,918 - logger.py:50 - Epoch: [279][5/6]	Total Loss: 0.83173	Main MSE (x10^-2): 83.1729	LR: 1.66e-04	EMPP_Raw: 1.57323
2025-07-18 00:43:35,967 - logger.py:50 - Epoch 279 Training Summary: Avg Total Loss: 0.83173, Avg Main MSE: 0.83173, Time: 17.23s
2025-07-18 00:43:54,243 - logger.py:50 - Epoch 279 Summary | Train MSE (x10^-2): 83.1729 | Val MSE (x10^-2): 24.9380 | Time: 35.51s
2025-07-18 00:43:57,442 - logger.py:50 - Epoch: [280][0/6]	Total Loss: 0.86975	Main MSE (x10^-2): 86.9751	LR: 1.64e-04	EMPP_Raw: 1.64761
2025-07-18 00:44:11,486 - logger.py:50 - Epoch: [280][5/6]	Total Loss: 0.83632	Main MSE (x10^-2): 83.6320	LR: 1.64e-04	EMPP_Raw: 1.58027
2025-07-18 00:44:11,531 - logger.py:50 - Epoch 280 Training Summary: Avg Total Loss: 0.83632, Avg Main MSE: 0.83632, Time: 17.28s
2025-07-18 00:44:29,929 - logger.py:50 - Epoch 280 Summary | Train MSE (x10^-2): 83.6320 | Val MSE (x10^-2): 26.3774 | Time: 35.68s
2025-07-18 00:44:33,022 - logger.py:50 - Epoch: [281][0/6]	Total Loss: 0.84663	Main MSE (x10^-2): 84.6627	LR: 1.63e-04	EMPP_Raw: 1.59733
2025-07-18 00:44:47,180 - logger.py:50 - Epoch: [281][5/6]	Total Loss: 0.82126	Main MSE (x10^-2): 82.1261	LR: 1.63e-04	EMPP_Raw: 1.54787
2025-07-18 00:44:47,224 - logger.py:50 - Epoch 281 Training Summary: Avg Total Loss: 0.82126, Avg Main MSE: 0.82126, Time: 17.28s
2025-07-18 00:45:05,606 - logger.py:50 - Epoch 281 Summary | Train MSE (x10^-2): 82.1261 | Val MSE (x10^-2): 24.9747 | Time: 35.67s
2025-07-18 00:45:08,637 - logger.py:50 - Epoch: [282][0/6]	Total Loss: 0.81349	Main MSE (x10^-2): 81.3486	LR: 1.62e-04	EMPP_Raw: 1.53456
2025-07-18 00:45:22,824 - logger.py:50 - Epoch: [282][5/6]	Total Loss: 0.80798	Main MSE (x10^-2): 80.7984	LR: 1.62e-04	EMPP_Raw: 1.52013
2025-07-18 00:45:22,867 - logger.py:50 - Epoch 282 Training Summary: Avg Total Loss: 0.80798, Avg Main MSE: 0.80798, Time: 17.25s
2025-07-18 00:45:41,257 - logger.py:50 - Epoch 282 Summary | Train MSE (x10^-2): 80.7984 | Val MSE (x10^-2): 24.8007 | Time: 35.65s
2025-07-18 00:45:44,366 - logger.py:50 - Epoch: [283][0/6]	Total Loss: 0.70835	Main MSE (x10^-2): 70.8355	LR: 1.61e-04	EMPP_Raw: 1.31673
2025-07-18 00:45:58,374 - logger.py:50 - Epoch: [283][5/6]	Total Loss: 0.77951	Main MSE (x10^-2): 77.9510	LR: 1.61e-04	EMPP_Raw: 1.46643
2025-07-18 00:45:58,419 - logger.py:50 - Epoch 283 Training Summary: Avg Total Loss: 0.77951, Avg Main MSE: 0.77951, Time: 17.15s
2025-07-18 00:46:17,272 - logger.py:50 - Epoch 283 Summary | Train MSE (x10^-2): 77.9510 | Val MSE (x10^-2): 25.4786 | Time: 36.01s
2025-07-18 00:46:20,338 - logger.py:50 - Epoch: [284][0/6]	Total Loss: 0.78873	Main MSE (x10^-2): 78.8734	LR: 1.59e-04	EMPP_Raw: 1.48203
2025-07-18 00:46:34,687 - logger.py:50 - Epoch: [284][5/6]	Total Loss: 0.79596	Main MSE (x10^-2): 79.5957	LR: 1.59e-04	EMPP_Raw: 1.49914
2025-07-18 00:46:34,728 - logger.py:50 - Epoch 284 Training Summary: Avg Total Loss: 0.79596, Avg Main MSE: 0.79596, Time: 17.44s
2025-07-18 00:46:53,370 - logger.py:50 - Epoch 284 Summary | Train MSE (x10^-2): 79.5957 | Val MSE (x10^-2): 25.9311 | Time: 36.09s
2025-07-18 00:46:56,481 - logger.py:50 - Epoch: [285][0/6]	Total Loss: 0.79281	Main MSE (x10^-2): 79.2807	LR: 1.58e-04	EMPP_Raw: 1.50011
2025-07-18 00:47:10,744 - logger.py:50 - Epoch: [285][5/6]	Total Loss: 0.80882	Main MSE (x10^-2): 80.8816	LR: 1.58e-04	EMPP_Raw: 1.52894
2025-07-18 00:47:10,789 - logger.py:50 - Epoch 285 Training Summary: Avg Total Loss: 0.80882, Avg Main MSE: 0.80882, Time: 17.41s
2025-07-18 00:47:29,152 - logger.py:50 - Epoch 285 Summary | Train MSE (x10^-2): 80.8816 | Val MSE (x10^-2): 25.3198 | Time: 35.78s
2025-07-18 00:47:32,350 - logger.py:50 - Epoch: [286][0/6]	Total Loss: 0.78336	Main MSE (x10^-2): 78.3359	LR: 1.57e-04	EMPP_Raw: 1.46635
2025-07-18 00:47:46,420 - logger.py:50 - Epoch: [286][5/6]	Total Loss: 0.80215	Main MSE (x10^-2): 80.2146	LR: 1.57e-04	EMPP_Raw: 1.51451
2025-07-18 00:47:46,461 - logger.py:50 - Epoch 286 Training Summary: Avg Total Loss: 0.80215, Avg Main MSE: 0.80215, Time: 17.30s
2025-07-18 00:48:04,857 - logger.py:50 - Epoch 286 Summary | Train MSE (x10^-2): 80.2146 | Val MSE (x10^-2): 25.0562 | Time: 35.70s
2025-07-18 00:48:07,987 - logger.py:50 - Epoch: [287][0/6]	Total Loss: 0.82760	Main MSE (x10^-2): 82.7604	LR: 1.56e-04	EMPP_Raw: 1.55780
2025-07-18 00:48:22,215 - logger.py:50 - Epoch: [287][5/6]	Total Loss: 0.79163	Main MSE (x10^-2): 79.1634	LR: 1.56e-04	EMPP_Raw: 1.48844
2025-07-18 00:48:22,260 - logger.py:50 - Epoch 287 Training Summary: Avg Total Loss: 0.79163, Avg Main MSE: 0.79163, Time: 17.39s
2025-07-18 00:48:40,757 - logger.py:50 - Epoch 287 Summary | Train MSE (x10^-2): 79.1634 | Val MSE (x10^-2): 25.0581 | Time: 35.89s
2025-07-18 00:48:43,800 - logger.py:50 - Epoch: [288][0/6]	Total Loss: 0.77023	Main MSE (x10^-2): 77.0229	LR: 1.55e-04	EMPP_Raw: 1.44993
2025-07-18 00:48:58,022 - logger.py:50 - Epoch: [288][5/6]	Total Loss: 0.81255	Main MSE (x10^-2): 81.2553	LR: 1.55e-04	EMPP_Raw: 1.53389
2025-07-18 00:48:58,060 - logger.py:50 - Epoch 288 Training Summary: Avg Total Loss: 0.81255, Avg Main MSE: 0.81255, Time: 17.29s
2025-07-18 00:49:16,521 - logger.py:50 - Epoch 288 Summary | Train MSE (x10^-2): 81.2553 | Val MSE (x10^-2): 24.9660 | Time: 35.76s
2025-07-18 00:49:19,559 - logger.py:50 - Epoch: [289][0/6]	Total Loss: 0.77501	Main MSE (x10^-2): 77.5008	LR: 1.53e-04	EMPP_Raw: 1.45993
2025-07-18 00:49:33,773 - logger.py:50 - Epoch: [289][5/6]	Total Loss: 0.79159	Main MSE (x10^-2): 79.1586	LR: 1.53e-04	EMPP_Raw: 1.48634
2025-07-18 00:49:33,817 - logger.py:50 - Epoch 289 Training Summary: Avg Total Loss: 0.79159, Avg Main MSE: 0.79159, Time: 17.29s
2025-07-18 00:49:52,238 - logger.py:50 - Epoch 289 Summary | Train MSE (x10^-2): 79.1586 | Val MSE (x10^-2): 25.0957 | Time: 35.71s
2025-07-18 00:49:55,275 - logger.py:50 - Epoch: [290][0/6]	Total Loss: 0.75950	Main MSE (x10^-2): 75.9504	LR: 1.52e-04	EMPP_Raw: 1.43510
2025-07-18 00:50:09,332 - logger.py:50 - Epoch: [290][5/6]	Total Loss: 0.78761	Main MSE (x10^-2): 78.7608	LR: 1.52e-04	EMPP_Raw: 1.49114
2025-07-18 00:50:09,375 - logger.py:50 - Epoch 290 Training Summary: Avg Total Loss: 0.78761, Avg Main MSE: 0.78761, Time: 17.13s
2025-07-18 00:50:27,985 - logger.py:50 - Epoch 290 Summary | Train MSE (x10^-2): 78.7608 | Val MSE (x10^-2): 25.3240 | Time: 35.74s
2025-07-18 00:50:31,219 - logger.py:50 - Epoch: [291][0/6]	Total Loss: 0.84330	Main MSE (x10^-2): 84.3301	LR: 1.51e-04	EMPP_Raw: 1.60895
2025-07-18 00:50:45,250 - logger.py:50 - Epoch: [291][5/6]	Total Loss: 0.80790	Main MSE (x10^-2): 80.7897	LR: 1.51e-04	EMPP_Raw: 1.53255
2025-07-18 00:50:45,294 - logger.py:50 - Epoch 291 Training Summary: Avg Total Loss: 0.80790, Avg Main MSE: 0.80790, Time: 17.30s
2025-07-18 00:51:03,840 - logger.py:50 - Epoch 291 Summary | Train MSE (x10^-2): 80.7897 | Val MSE (x10^-2): 24.8416 | Time: 35.85s
2025-07-18 00:51:07,048 - logger.py:50 - Epoch: [292][0/6]	Total Loss: 0.82926	Main MSE (x10^-2): 82.9265	LR: 1.50e-04	EMPP_Raw: 1.57005
2025-07-18 00:51:21,202 - logger.py:50 - Epoch: [292][5/6]	Total Loss: 0.80151	Main MSE (x10^-2): 80.1511	LR: 1.50e-04	EMPP_Raw: 1.51512
2025-07-18 00:51:21,245 - logger.py:50 - Epoch 292 Training Summary: Avg Total Loss: 0.80151, Avg Main MSE: 0.80151, Time: 17.40s
2025-07-18 00:51:39,561 - logger.py:50 - Epoch 292 Summary | Train MSE (x10^-2): 80.1511 | Val MSE (x10^-2): 25.7913 | Time: 35.72s
2025-07-18 00:51:42,602 - logger.py:50 - Epoch: [293][0/6]	Total Loss: 0.80520	Main MSE (x10^-2): 80.5197	LR: 1.48e-04	EMPP_Raw: 1.52070
2025-07-18 00:51:56,824 - logger.py:50 - Epoch: [293][5/6]	Total Loss: 0.81410	Main MSE (x10^-2): 81.4100	LR: 1.48e-04	EMPP_Raw: 1.54185
2025-07-18 00:51:56,865 - logger.py:50 - Epoch 293 Training Summary: Avg Total Loss: 0.81410, Avg Main MSE: 0.81410, Time: 17.29s
2025-07-18 00:52:15,228 - logger.py:50 - Epoch 293 Summary | Train MSE (x10^-2): 81.4100 | Val MSE (x10^-2): 25.4628 | Time: 35.66s
2025-07-18 00:52:18,254 - logger.py:50 - Epoch: [294][0/6]	Total Loss: 0.74357	Main MSE (x10^-2): 74.3569	LR: 1.47e-04	EMPP_Raw: 1.39712
2025-07-18 00:52:32,516 - logger.py:50 - Epoch: [294][5/6]	Total Loss: 0.79844	Main MSE (x10^-2): 79.8436	LR: 1.47e-04	EMPP_Raw: 1.50835
2025-07-18 00:52:32,559 - logger.py:50 - Epoch 294 Training Summary: Avg Total Loss: 0.79844, Avg Main MSE: 0.79844, Time: 17.32s
2025-07-18 00:52:50,857 - logger.py:50 - Epoch 294 Summary | Train MSE (x10^-2): 79.8436 | Val MSE (x10^-2): 25.3016 | Time: 35.62s
2025-07-18 00:52:53,886 - logger.py:50 - Epoch: [295][0/6]	Total Loss: 0.79078	Main MSE (x10^-2): 79.0783	LR: 1.46e-04	EMPP_Raw: 1.49352
2025-07-18 00:53:07,913 - logger.py:50 - Epoch: [295][5/6]	Total Loss: 0.80129	Main MSE (x10^-2): 80.1287	LR: 1.46e-04	EMPP_Raw: 1.51644
2025-07-18 00:53:07,957 - logger.py:50 - Epoch 295 Training Summary: Avg Total Loss: 0.80129, Avg Main MSE: 0.80129, Time: 17.09s
2025-07-18 00:53:26,518 - logger.py:50 - Epoch 295 Summary | Train MSE (x10^-2): 80.1287 | Val MSE (x10^-2): 24.9985 | Time: 35.66s
2025-07-18 00:53:29,567 - logger.py:50 - Epoch: [296][0/6]	Total Loss: 0.88139	Main MSE (x10^-2): 88.1392	LR: 1.45e-04	EMPP_Raw: 1.66986
2025-07-18 00:53:43,596 - logger.py:50 - Epoch: [296][5/6]	Total Loss: 0.84133	Main MSE (x10^-2): 84.1335	LR: 1.45e-04	EMPP_Raw: 1.59703
2025-07-18 00:53:43,638 - logger.py:50 - Epoch 296 Training Summary: Avg Total Loss: 0.84133, Avg Main MSE: 0.84133, Time: 17.11s
2025-07-18 00:54:02,122 - logger.py:50 - Epoch 296 Summary | Train MSE (x10^-2): 84.1335 | Val MSE (x10^-2): 24.8307 | Time: 35.60s
2025-07-18 00:54:05,195 - logger.py:50 - Epoch: [297][0/6]	Total Loss: 0.84738	Main MSE (x10^-2): 84.7379	LR: 1.44e-04	EMPP_Raw: 1.61067
2025-07-18 00:54:19,222 - logger.py:50 - Epoch: [297][5/6]	Total Loss: 0.77057	Main MSE (x10^-2): 77.0567	LR: 1.44e-04	EMPP_Raw: 1.45663
2025-07-18 00:54:19,263 - logger.py:50 - Epoch 297 Training Summary: Avg Total Loss: 0.77057, Avg Main MSE: 0.77057, Time: 17.13s
2025-07-18 00:54:37,589 - logger.py:50 - Epoch 297 Summary | Train MSE (x10^-2): 77.0567 | Val MSE (x10^-2): 25.0581 | Time: 35.46s
2025-07-18 00:54:40,965 - logger.py:50 - Epoch: [298][0/6]	Total Loss: 0.78081	Main MSE (x10^-2): 78.0807	LR: 1.42e-04	EMPP_Raw: 1.47541
2025-07-18 00:54:55,032 - logger.py:50 - Epoch: [298][5/6]	Total Loss: 0.78105	Main MSE (x10^-2): 78.1054	LR: 1.42e-04	EMPP_Raw: 1.47999
2025-07-18 00:54:55,094 - logger.py:50 - Epoch 298 Training Summary: Avg Total Loss: 0.78105, Avg Main MSE: 0.78105, Time: 17.50s
2025-07-18 00:55:13,523 - logger.py:50 - Epoch 298 Summary | Train MSE (x10^-2): 78.1054 | Val MSE (x10^-2): 25.3198 | Time: 35.93s
2025-07-18 00:55:16,555 - logger.py:50 - Epoch: [299][0/6]	Total Loss: 0.76586	Main MSE (x10^-2): 76.5862	LR: 1.41e-04	EMPP_Raw: 1.43798
2025-07-18 00:55:30,549 - logger.py:50 - Epoch: [299][5/6]	Total Loss: 0.77666	Main MSE (x10^-2): 77.6658	LR: 1.41e-04	EMPP_Raw: 1.46867
2025-07-18 00:55:30,593 - logger.py:50 - Epoch 299 Training Summary: Avg Total Loss: 0.77666, Avg Main MSE: 0.77666, Time: 17.06s
2025-07-18 00:55:48,981 - logger.py:50 - Epoch 299 Summary | Train MSE (x10^-2): 77.6658 | Val MSE (x10^-2): 25.6127 | Time: 35.45s
2025-07-18 00:55:52,216 - logger.py:50 - Epoch: [300][0/6]	Total Loss: 0.86297	Main MSE (x10^-2): 86.2972	LR: 1.40e-04	EMPP_Raw: 1.63728
2025-07-18 00:56:06,408 - logger.py:50 - Epoch: [300][5/6]	Total Loss: 0.80390	Main MSE (x10^-2): 80.3896	LR: 1.40e-04	EMPP_Raw: 1.52565
2025-07-18 00:56:06,454 - logger.py:50 - Epoch 300 Training Summary: Avg Total Loss: 0.80390, Avg Main MSE: 0.80390, Time: 17.46s
2025-07-18 00:56:24,879 - logger.py:50 - Epoch 300 Summary | Train MSE (x10^-2): 80.3896 | Val MSE (x10^-2): 25.3848 | Time: 35.89s
2025-07-18 00:56:27,906 - logger.py:50 - Epoch: [301][0/6]	Total Loss: 0.72298	Main MSE (x10^-2): 72.2975	LR: 1.39e-04	EMPP_Raw: 1.35712
2025-07-18 00:56:42,101 - logger.py:50 - Epoch: [301][5/6]	Total Loss: 0.76605	Main MSE (x10^-2): 76.6051	LR: 1.39e-04	EMPP_Raw: 1.44993
2025-07-18 00:56:42,142 - logger.py:50 - Epoch 301 Training Summary: Avg Total Loss: 0.76605, Avg Main MSE: 0.76605, Time: 17.25s
2025-07-18 00:57:00,471 - logger.py:50 - Epoch 301 Summary | Train MSE (x10^-2): 76.6051 | Val MSE (x10^-2): 25.2444 | Time: 35.59s
2025-07-18 00:57:03,640 - logger.py:50 - Epoch: [302][0/6]	Total Loss: 0.75835	Main MSE (x10^-2): 75.8349	LR: 1.38e-04	EMPP_Raw: 1.43418
2025-07-18 00:57:17,919 - logger.py:50 - Epoch: [302][5/6]	Total Loss: 0.78121	Main MSE (x10^-2): 78.1209	LR: 1.38e-04	EMPP_Raw: 1.48250
2025-07-18 00:57:17,965 - logger.py:50 - Epoch 302 Training Summary: Avg Total Loss: 0.78121, Avg Main MSE: 0.78121, Time: 17.49s
2025-07-18 00:57:36,318 - logger.py:50 - Epoch 302 Summary | Train MSE (x10^-2): 78.1209 | Val MSE (x10^-2): 24.7308 | Time: 35.84s
2025-07-18 00:57:39,374 - logger.py:50 - Epoch: [303][0/6]	Total Loss: 0.81600	Main MSE (x10^-2): 81.5998	LR: 1.36e-04	EMPP_Raw: 1.55008
2025-07-18 00:57:53,405 - logger.py:50 - Epoch: [303][5/6]	Total Loss: 0.80659	Main MSE (x10^-2): 80.6592	LR: 1.36e-04	EMPP_Raw: 1.53520
2025-07-18 00:57:53,450 - logger.py:50 - Epoch 303 Training Summary: Avg Total Loss: 0.80659, Avg Main MSE: 0.80659, Time: 17.12s
2025-07-18 00:58:11,961 - logger.py:50 - Epoch 303 Summary | Train MSE (x10^-2): 80.6592 | Val MSE (x10^-2): 24.9628 | Time: 35.64s
2025-07-18 00:58:14,987 - logger.py:50 - Epoch: [304][0/6]	Total Loss: 0.81038	Main MSE (x10^-2): 81.0376	LR: 1.35e-04	EMPP_Raw: 1.55212
2025-07-18 00:58:29,098 - logger.py:50 - Epoch: [304][5/6]	Total Loss: 0.81252	Main MSE (x10^-2): 81.2521	LR: 1.35e-04	EMPP_Raw: 1.54702
2025-07-18 00:58:29,143 - logger.py:50 - Epoch 304 Training Summary: Avg Total Loss: 0.81252, Avg Main MSE: 0.81252, Time: 17.17s
2025-07-18 00:58:47,524 - logger.py:50 - Epoch 304 Summary | Train MSE (x10^-2): 81.2521 | Val MSE (x10^-2): 24.7503 | Time: 35.56s
2025-07-18 00:58:50,565 - logger.py:50 - Epoch: [305][0/6]	Total Loss: 0.83265	Main MSE (x10^-2): 83.2654	LR: 1.34e-04	EMPP_Raw: 1.58416
2025-07-18 00:59:04,582 - logger.py:50 - Epoch: [305][5/6]	Total Loss: 0.81148	Main MSE (x10^-2): 81.1478	LR: 1.34e-04	EMPP_Raw: 1.54402
2025-07-18 00:59:04,622 - logger.py:50 - Epoch 305 Training Summary: Avg Total Loss: 0.81148, Avg Main MSE: 0.81148, Time: 17.09s
2025-07-18 00:59:23,038 - logger.py:50 - Epoch 305 Summary | Train MSE (x10^-2): 81.1478 | Val MSE (x10^-2): 25.1405 | Time: 35.51s
2025-07-18 00:59:26,219 - logger.py:50 - Epoch: [306][0/6]	Total Loss: 0.80426	Main MSE (x10^-2): 80.4259	LR: 1.33e-04	EMPP_Raw: 1.53033
2025-07-18 00:59:40,219 - logger.py:50 - Epoch: [306][5/6]	Total Loss: 0.78912	Main MSE (x10^-2): 78.9117	LR: 1.33e-04	EMPP_Raw: 1.49563
2025-07-18 00:59:40,259 - logger.py:50 - Epoch 306 Training Summary: Avg Total Loss: 0.78912, Avg Main MSE: 0.78912, Time: 17.21s
2025-07-18 00:59:58,553 - logger.py:50 - Epoch 306 Summary | Train MSE (x10^-2): 78.9117 | Val MSE (x10^-2): 25.1934 | Time: 35.51s
2025-07-18 01:00:01,618 - logger.py:50 - Epoch: [307][0/6]	Total Loss: 0.82094	Main MSE (x10^-2): 82.0936	LR: 1.32e-04	EMPP_Raw: 1.55692
2025-07-18 01:00:15,823 - logger.py:50 - Epoch: [307][5/6]	Total Loss: 0.80216	Main MSE (x10^-2): 80.2160	LR: 1.32e-04	EMPP_Raw: 1.51899
2025-07-18 01:00:15,872 - logger.py:50 - Epoch 307 Training Summary: Avg Total Loss: 0.80216, Avg Main MSE: 0.80216, Time: 17.31s
2025-07-18 01:00:34,175 - logger.py:50 - Epoch 307 Summary | Train MSE (x10^-2): 80.2160 | Val MSE (x10^-2): 24.8226 | Time: 35.62s
2025-07-18 01:00:37,227 - logger.py:50 - Epoch: [308][0/6]	Total Loss: 0.79329	Main MSE (x10^-2): 79.3289	LR: 1.31e-04	EMPP_Raw: 1.49844
2025-07-18 01:00:51,423 - logger.py:50 - Epoch: [308][5/6]	Total Loss: 0.80675	Main MSE (x10^-2): 80.6745	LR: 1.31e-04	EMPP_Raw: 1.53146
2025-07-18 01:00:51,468 - logger.py:50 - Epoch 308 Training Summary: Avg Total Loss: 0.80675, Avg Main MSE: 0.80675, Time: 17.28s
2025-07-18 01:01:09,845 - logger.py:50 - Epoch 308 Summary | Train MSE (x10^-2): 80.6745 | Val MSE (x10^-2): 24.8977 | Time: 35.66s
2025-07-18 01:01:12,926 - logger.py:50 - Epoch: [309][0/6]	Total Loss: 0.72042	Main MSE (x10^-2): 72.0422	LR: 1.29e-04	EMPP_Raw: 1.35966
2025-07-18 01:01:27,051 - logger.py:50 - Epoch: [309][5/6]	Total Loss: 0.75064	Main MSE (x10^-2): 75.0642	LR: 1.29e-04	EMPP_Raw: 1.42044
2025-07-18 01:01:27,096 - logger.py:50 - Epoch 309 Training Summary: Avg Total Loss: 0.75064, Avg Main MSE: 0.75064, Time: 17.24s
2025-07-18 01:01:45,556 - logger.py:50 - Epoch 309 Summary | Train MSE (x10^-2): 75.0642 | Val MSE (x10^-2): 24.9450 | Time: 35.71s
2025-07-18 01:01:48,616 - logger.py:50 - Epoch: [310][0/6]	Total Loss: 0.83649	Main MSE (x10^-2): 83.6488	LR: 1.28e-04	EMPP_Raw: 1.59983
2025-07-18 01:02:02,676 - logger.py:50 - Epoch: [310][5/6]	Total Loss: 0.80086	Main MSE (x10^-2): 80.0861	LR: 1.28e-04	EMPP_Raw: 1.52393
2025-07-18 01:02:02,721 - logger.py:50 - Epoch 310 Training Summary: Avg Total Loss: 0.80086, Avg Main MSE: 0.80086, Time: 17.16s
2025-07-18 01:02:21,296 - logger.py:50 - Epoch 310 Summary | Train MSE (x10^-2): 80.0861 | Val MSE (x10^-2): 24.6381 | Time: 35.73s
2025-07-18 01:02:24,436 - logger.py:50 - Epoch: [311][0/6]	Total Loss: 0.78768	Main MSE (x10^-2): 78.7684	LR: 1.27e-04	EMPP_Raw: 1.49896
2025-07-18 01:02:38,699 - logger.py:50 - Epoch: [311][5/6]	Total Loss: 0.82106	Main MSE (x10^-2): 82.1063	LR: 1.27e-04	EMPP_Raw: 1.56539
2025-07-18 01:02:38,748 - logger.py:50 - Epoch 311 Training Summary: Avg Total Loss: 0.82106, Avg Main MSE: 0.82106, Time: 17.44s
2025-07-18 01:02:57,136 - logger.py:50 - Epoch 311 Summary | Train MSE (x10^-2): 82.1063 | Val MSE (x10^-2): 25.6189 | Time: 35.83s
2025-07-18 01:03:00,324 - logger.py:50 - Epoch: [312][0/6]	Total Loss: 0.76078	Main MSE (x10^-2): 76.0777	LR: 1.26e-04	EMPP_Raw: 1.44481
2025-07-18 01:03:14,325 - logger.py:50 - Epoch: [312][5/6]	Total Loss: 0.82249	Main MSE (x10^-2): 82.2485	LR: 1.26e-04	EMPP_Raw: 1.56643
2025-07-18 01:03:14,367 - logger.py:50 - Epoch 312 Training Summary: Avg Total Loss: 0.82249, Avg Main MSE: 0.82249, Time: 17.22s
2025-07-18 01:03:32,680 - logger.py:50 - Epoch 312 Summary | Train MSE (x10^-2): 82.2485 | Val MSE (x10^-2): 25.3245 | Time: 35.54s
2025-07-18 01:03:35,714 - logger.py:50 - Epoch: [313][0/6]	Total Loss: 0.85498	Main MSE (x10^-2): 85.4980	LR: 1.25e-04	EMPP_Raw: 1.62883
2025-07-18 01:03:49,920 - logger.py:50 - Epoch: [313][5/6]	Total Loss: 0.81510	Main MSE (x10^-2): 81.5097	LR: 1.25e-04	EMPP_Raw: 1.55220
2025-07-18 01:03:49,966 - logger.py:50 - Epoch 313 Training Summary: Avg Total Loss: 0.81510, Avg Main MSE: 0.81510, Time: 17.28s
2025-07-18 01:04:08,298 - logger.py:50 - Epoch 313 Summary | Train MSE (x10^-2): 81.5097 | Val MSE (x10^-2): 24.8567 | Time: 35.61s
2025-07-18 01:04:11,330 - logger.py:50 - Epoch: [314][0/6]	Total Loss: 0.75296	Main MSE (x10^-2): 75.2957	LR: 1.24e-04	EMPP_Raw: 1.43498
2025-07-18 01:04:25,571 - logger.py:50 - Epoch: [314][5/6]	Total Loss: 0.77789	Main MSE (x10^-2): 77.7885	LR: 1.24e-04	EMPP_Raw: 1.47945
2025-07-18 01:04:25,615 - logger.py:50 - Epoch 314 Training Summary: Avg Total Loss: 0.77789, Avg Main MSE: 0.77789, Time: 17.31s
2025-07-18 01:04:43,897 - logger.py:50 - Epoch 314 Summary | Train MSE (x10^-2): 77.7885 | Val MSE (x10^-2): 25.2759 | Time: 35.59s
2025-07-18 01:04:46,973 - logger.py:50 - Epoch: [315][0/6]	Total Loss: 0.79023	Main MSE (x10^-2): 79.0232	LR: 1.22e-04	EMPP_Raw: 1.49804
2025-07-18 01:05:01,133 - logger.py:50 - Epoch: [315][5/6]	Total Loss: 0.76903	Main MSE (x10^-2): 76.9030	LR: 1.22e-04	EMPP_Raw: 1.46198
2025-07-18 01:05:01,177 - logger.py:50 - Epoch 315 Training Summary: Avg Total Loss: 0.76903, Avg Main MSE: 0.76903, Time: 17.27s
2025-07-18 01:05:19,643 - logger.py:50 - Epoch 315 Summary | Train MSE (x10^-2): 76.9030 | Val MSE (x10^-2): 24.6683 | Time: 35.74s
2025-07-18 01:05:22,728 - logger.py:50 - Epoch: [316][0/6]	Total Loss: 0.80037	Main MSE (x10^-2): 80.0366	LR: 1.21e-04	EMPP_Raw: 1.52883
2025-07-18 01:05:36,792 - logger.py:50 - Epoch: [316][5/6]	Total Loss: 0.78965	Main MSE (x10^-2): 78.9653	LR: 1.21e-04	EMPP_Raw: 1.50637
2025-07-18 01:05:36,837 - logger.py:50 - Epoch 316 Training Summary: Avg Total Loss: 0.78965, Avg Main MSE: 0.78965, Time: 17.18s
2025-07-18 01:05:55,192 - logger.py:50 - Epoch 316 Summary | Train MSE (x10^-2): 78.9653 | Val MSE (x10^-2): 25.1550 | Time: 35.54s
2025-07-18 01:05:58,361 - logger.py:50 - Epoch: [317][0/6]	Total Loss: 0.76687	Main MSE (x10^-2): 76.6873	LR: 1.20e-04	EMPP_Raw: 1.46399
2025-07-18 01:06:12,366 - logger.py:50 - Epoch: [317][5/6]	Total Loss: 0.77196	Main MSE (x10^-2): 77.1963	LR: 1.20e-04	EMPP_Raw: 1.47169
2025-07-18 01:06:12,414 - logger.py:50 - Epoch 317 Training Summary: Avg Total Loss: 0.77196, Avg Main MSE: 0.77196, Time: 17.22s
2025-07-18 01:06:30,704 - logger.py:50 - Epoch 317 Summary | Train MSE (x10^-2): 77.1963 | Val MSE (x10^-2): 24.9274 | Time: 35.51s
2025-07-18 01:06:33,895 - logger.py:50 - Epoch: [318][0/6]	Total Loss: 0.82614	Main MSE (x10^-2): 82.6142	LR: 1.19e-04	EMPP_Raw: 1.58343
2025-07-18 01:06:47,914 - logger.py:50 - Epoch: [318][5/6]	Total Loss: 0.79352	Main MSE (x10^-2): 79.3517	LR: 1.19e-04	EMPP_Raw: 1.51511
2025-07-18 01:06:47,957 - logger.py:50 - Epoch 318 Training Summary: Avg Total Loss: 0.79352, Avg Main MSE: 0.79352, Time: 17.24s
2025-07-18 01:07:06,259 - logger.py:50 - Epoch 318 Summary | Train MSE (x10^-2): 79.3517 | Val MSE (x10^-2): 25.2221 | Time: 35.55s
2025-07-18 01:07:09,299 - logger.py:50 - Epoch: [319][0/6]	Total Loss: 0.78600	Main MSE (x10^-2): 78.6005	LR: 1.18e-04	EMPP_Raw: 1.50336
2025-07-18 01:07:23,509 - logger.py:50 - Epoch: [319][5/6]	Total Loss: 0.78454	Main MSE (x10^-2): 78.4535	LR: 1.18e-04	EMPP_Raw: 1.49252
2025-07-18 01:07:23,550 - logger.py:50 - Epoch 319 Training Summary: Avg Total Loss: 0.78454, Avg Main MSE: 0.78454, Time: 17.28s
2025-07-18 01:07:41,959 - logger.py:50 - Epoch 319 Summary | Train MSE (x10^-2): 78.4535 | Val MSE (x10^-2): 24.5958 | Time: 35.69s
2025-07-18 01:07:45,086 - logger.py:50 - Epoch: [320][0/6]	Total Loss: 0.76900	Main MSE (x10^-2): 76.9002	LR: 1.17e-04	EMPP_Raw: 1.46375
2025-07-18 01:07:59,307 - logger.py:50 - Epoch: [320][5/6]	Total Loss: 0.77224	Main MSE (x10^-2): 77.2236	LR: 1.17e-04	EMPP_Raw: 1.47134
2025-07-18 01:07:59,351 - logger.py:50 - Epoch 320 Training Summary: Avg Total Loss: 0.77224, Avg Main MSE: 0.77224, Time: 17.39s
2025-07-18 01:08:17,749 - logger.py:50 - Epoch 320 Summary | Train MSE (x10^-2): 77.2236 | Val MSE (x10^-2): 25.2794 | Time: 35.79s
2025-07-18 01:08:20,819 - logger.py:50 - Epoch: [321][0/6]	Total Loss: 0.82368	Main MSE (x10^-2): 82.3675	LR: 1.16e-04	EMPP_Raw: 1.57312
2025-07-18 01:08:34,882 - logger.py:50 - Epoch: [321][5/6]	Total Loss: 0.74936	Main MSE (x10^-2): 74.9363	LR: 1.16e-04	EMPP_Raw: 1.42099
2025-07-18 01:08:34,927 - logger.py:50 - Epoch 321 Training Summary: Avg Total Loss: 0.74936, Avg Main MSE: 0.74936, Time: 17.17s
2025-07-18 01:08:53,504 - logger.py:50 - Epoch 321 Summary | Train MSE (x10^-2): 74.9363 | Val MSE (x10^-2): 25.3679 | Time: 35.75s
2025-07-18 01:08:56,593 - logger.py:50 - Epoch: [322][0/6]	Total Loss: 0.77186	Main MSE (x10^-2): 77.1857	LR: 1.14e-04	EMPP_Raw: 1.47000
2025-07-18 01:09:10,793 - logger.py:50 - Epoch: [322][5/6]	Total Loss: 0.79695	Main MSE (x10^-2): 79.6945	LR: 1.14e-04	EMPP_Raw: 1.51497
2025-07-18 01:09:10,837 - logger.py:50 - Epoch 322 Training Summary: Avg Total Loss: 0.79695, Avg Main MSE: 0.79695, Time: 17.32s
2025-07-18 01:09:29,224 - logger.py:50 - Epoch 322 Summary | Train MSE (x10^-2): 79.6945 | Val MSE (x10^-2): 24.8992 | Time: 35.71s
2025-07-18 01:09:32,335 - logger.py:50 - Epoch: [323][0/6]	Total Loss: 0.81445	Main MSE (x10^-2): 81.4451	LR: 1.13e-04	EMPP_Raw: 1.55109
2025-07-18 01:09:46,557 - logger.py:50 - Epoch: [323][5/6]	Total Loss: 0.81579	Main MSE (x10^-2): 81.5793	LR: 1.13e-04	EMPP_Raw: 1.55602
2025-07-18 01:09:46,600 - logger.py:50 - Epoch 323 Training Summary: Avg Total Loss: 0.81579, Avg Main MSE: 0.81579, Time: 17.37s
2025-07-18 01:10:05,004 - logger.py:50 - Epoch 323 Summary | Train MSE (x10^-2): 81.5793 | Val MSE (x10^-2): 24.4124 | Time: 35.77s
2025-07-18 01:10:08,458 - logger.py:50 - Epoch: [324][0/6]	Total Loss: 0.85016	Main MSE (x10^-2): 85.0163	LR: 1.12e-04	EMPP_Raw: 1.62520
2025-07-18 01:10:22,490 - logger.py:50 - Epoch: [324][5/6]	Total Loss: 0.79428	Main MSE (x10^-2): 79.4283	LR: 1.12e-04	EMPP_Raw: 1.51045
2025-07-18 01:10:22,546 - logger.py:50 - Epoch 324 Training Summary: Avg Total Loss: 0.79428, Avg Main MSE: 0.79428, Time: 17.53s
2025-07-18 01:10:40,922 - logger.py:50 - Epoch 324 Summary | Train MSE (x10^-2): 79.4283 | Val MSE (x10^-2): 24.8493 | Time: 35.91s
2025-07-18 01:10:44,009 - logger.py:50 - Epoch: [325][0/6]	Total Loss: 0.76187	Main MSE (x10^-2): 76.1873	LR: 1.11e-04	EMPP_Raw: 1.43783
2025-07-18 01:10:58,155 - logger.py:50 - Epoch: [325][5/6]	Total Loss: 0.78534	Main MSE (x10^-2): 78.5339	LR: 1.11e-04	EMPP_Raw: 1.49205
2025-07-18 01:10:58,196 - logger.py:50 - Epoch 325 Training Summary: Avg Total Loss: 0.78534, Avg Main MSE: 0.78534, Time: 17.26s
2025-07-18 01:11:16,502 - logger.py:50 - Epoch 325 Summary | Train MSE (x10^-2): 78.5339 | Val MSE (x10^-2): 24.4329 | Time: 35.57s
2025-07-18 01:11:19,758 - logger.py:50 - Epoch: [326][0/6]	Total Loss: 0.81324	Main MSE (x10^-2): 81.3242	LR: 1.10e-04	EMPP_Raw: 1.55120
2025-07-18 01:11:33,829 - logger.py:50 - Epoch: [326][5/6]	Total Loss: 0.80253	Main MSE (x10^-2): 80.2530	LR: 1.10e-04	EMPP_Raw: 1.52856
2025-07-18 01:11:33,873 - logger.py:50 - Epoch 326 Training Summary: Avg Total Loss: 0.80253, Avg Main MSE: 0.80253, Time: 17.36s
2025-07-18 01:11:52,266 - logger.py:50 - Epoch 326 Summary | Train MSE (x10^-2): 80.2530 | Val MSE (x10^-2): 24.8272 | Time: 35.76s
2025-07-18 01:11:55,329 - logger.py:50 - Epoch: [327][0/6]	Total Loss: 0.77013	Main MSE (x10^-2): 77.0128	LR: 1.09e-04	EMPP_Raw: 1.47298
2025-07-18 01:12:09,601 - logger.py:50 - Epoch: [327][5/6]	Total Loss: 0.79338	Main MSE (x10^-2): 79.3383	LR: 1.09e-04	EMPP_Raw: 1.50532
2025-07-18 01:12:09,644 - logger.py:50 - Epoch 327 Training Summary: Avg Total Loss: 0.79338, Avg Main MSE: 0.79338, Time: 17.37s
2025-07-18 01:12:28,011 - logger.py:50 - Epoch 327 Summary | Train MSE (x10^-2): 79.3383 | Val MSE (x10^-2): 25.5924 | Time: 35.74s
2025-07-18 01:12:31,061 - logger.py:50 - Epoch: [328][0/6]	Total Loss: 0.76898	Main MSE (x10^-2): 76.8980	LR: 1.08e-04	EMPP_Raw: 1.45704
2025-07-18 01:12:45,219 - logger.py:50 - Epoch: [328][5/6]	Total Loss: 0.78566	Main MSE (x10^-2): 78.5658	LR: 1.08e-04	EMPP_Raw: 1.49619
2025-07-18 01:12:45,259 - logger.py:50 - Epoch 328 Training Summary: Avg Total Loss: 0.78566, Avg Main MSE: 0.78566, Time: 17.24s
2025-07-18 01:13:03,603 - logger.py:50 - Epoch 328 Summary | Train MSE (x10^-2): 78.5658 | Val MSE (x10^-2): 24.5579 | Time: 35.59s
2025-07-18 01:13:06,648 - logger.py:50 - Epoch: [329][0/6]	Total Loss: 0.81592	Main MSE (x10^-2): 81.5917	LR: 1.07e-04	EMPP_Raw: 1.56566
2025-07-18 01:13:20,754 - logger.py:50 - Epoch: [329][5/6]	Total Loss: 0.76713	Main MSE (x10^-2): 76.7126	LR: 1.07e-04	EMPP_Raw: 1.46696
2025-07-18 01:13:20,797 - logger.py:50 - Epoch 329 Training Summary: Avg Total Loss: 0.76713, Avg Main MSE: 0.76713, Time: 17.19s
2025-07-18 01:13:39,250 - logger.py:50 - Epoch 329 Summary | Train MSE (x10^-2): 76.7126 | Val MSE (x10^-2): 24.5004 | Time: 35.64s
2025-07-18 01:13:42,304 - logger.py:50 - Epoch: [330][0/6]	Total Loss: 0.73566	Main MSE (x10^-2): 73.5656	LR: 1.05e-04	EMPP_Raw: 1.40074
2025-07-18 01:13:56,417 - logger.py:50 - Epoch: [330][5/6]	Total Loss: 0.79247	Main MSE (x10^-2): 79.2471	LR: 1.05e-04	EMPP_Raw: 1.51268
2025-07-18 01:13:56,460 - logger.py:50 - Epoch 330 Training Summary: Avg Total Loss: 0.79247, Avg Main MSE: 0.79247, Time: 17.20s
2025-07-18 01:14:15,039 - logger.py:50 - Epoch 330 Summary | Train MSE (x10^-2): 79.2471 | Val MSE (x10^-2): 24.6775 | Time: 35.78s
2025-07-18 01:14:18,121 - logger.py:50 - Epoch: [331][0/6]	Total Loss: 0.73372	Main MSE (x10^-2): 73.3723	LR: 1.04e-04	EMPP_Raw: 1.39787
2025-07-18 01:14:32,351 - logger.py:50 - Epoch: [331][5/6]	Total Loss: 0.80204	Main MSE (x10^-2): 80.2042	LR: 1.04e-04	EMPP_Raw: 1.53424
2025-07-18 01:14:32,400 - logger.py:50 - Epoch 331 Training Summary: Avg Total Loss: 0.80204, Avg Main MSE: 0.80204, Time: 17.35s
2025-07-18 01:14:50,699 - logger.py:50 - Epoch 331 Summary | Train MSE (x10^-2): 80.2042 | Val MSE (x10^-2): 24.6380 | Time: 35.65s
2025-07-18 01:14:53,903 - logger.py:50 - Epoch: [332][0/6]	Total Loss: 0.78143	Main MSE (x10^-2): 78.1431	LR: 1.03e-04	EMPP_Raw: 1.48549
2025-07-18 01:15:07,938 - logger.py:50 - Epoch: [332][5/6]	Total Loss: 0.81245	Main MSE (x10^-2): 81.2450	LR: 1.03e-04	EMPP_Raw: 1.55145
2025-07-18 01:15:07,999 - logger.py:50 - Epoch 332 Training Summary: Avg Total Loss: 0.81245, Avg Main MSE: 0.81245, Time: 17.29s
2025-07-18 01:15:26,412 - logger.py:50 - Epoch 332 Summary | Train MSE (x10^-2): 81.2450 | Val MSE (x10^-2): 24.7151 | Time: 35.71s
2025-07-18 01:15:29,459 - logger.py:50 - Epoch: [333][0/6]	Total Loss: 0.80953	Main MSE (x10^-2): 80.9530	LR: 1.02e-04	EMPP_Raw: 1.55164
2025-07-18 01:15:43,657 - logger.py:50 - Epoch: [333][5/6]	Total Loss: 0.80035	Main MSE (x10^-2): 80.0345	LR: 1.02e-04	EMPP_Raw: 1.53032
2025-07-18 01:15:43,708 - logger.py:50 - Epoch 333 Training Summary: Avg Total Loss: 0.80035, Avg Main MSE: 0.80035, Time: 17.29s
2025-07-18 01:16:01,987 - logger.py:50 - Epoch 333 Summary | Train MSE (x10^-2): 80.0345 | Val MSE (x10^-2): 25.1683 | Time: 35.57s
2025-07-18 01:16:05,085 - logger.py:50 - Epoch: [334][0/6]	Total Loss: 0.77869	Main MSE (x10^-2): 77.8688	LR: 1.01e-04	EMPP_Raw: 1.49004
2025-07-18 01:16:19,292 - logger.py:50 - Epoch: [334][5/6]	Total Loss: 0.78078	Main MSE (x10^-2): 78.0785	LR: 1.01e-04	EMPP_Raw: 1.49217
2025-07-18 01:16:19,335 - logger.py:50 - Epoch 334 Training Summary: Avg Total Loss: 0.78078, Avg Main MSE: 0.78078, Time: 17.34s
2025-07-18 01:16:37,585 - logger.py:50 - Epoch 334 Summary | Train MSE (x10^-2): 78.0785 | Val MSE (x10^-2): 24.9484 | Time: 35.59s
2025-07-18 01:16:40,621 - logger.py:50 - Epoch: [335][0/6]	Total Loss: 0.73043	Main MSE (x10^-2): 73.0434	LR: 1.00e-04	EMPP_Raw: 1.39117
2025-07-18 01:16:54,658 - logger.py:50 - Epoch: [335][5/6]	Total Loss: 0.78669	Main MSE (x10^-2): 78.6694	LR: 1.00e-04	EMPP_Raw: 1.50279
2025-07-18 01:16:54,703 - logger.py:50 - Epoch 335 Training Summary: Avg Total Loss: 0.78669, Avg Main MSE: 0.78669, Time: 17.11s
2025-07-18 01:17:13,236 - logger.py:50 - Epoch 335 Summary | Train MSE (x10^-2): 78.6694 | Val MSE (x10^-2): 25.1779 | Time: 35.65s
2025-07-18 01:17:16,272 - logger.py:50 - Epoch: [336][0/6]	Total Loss: 0.78818	Main MSE (x10^-2): 78.8176	LR: 9.89e-05	EMPP_Raw: 1.51567
2025-07-18 01:17:30,379 - logger.py:50 - Epoch: [336][5/6]	Total Loss: 0.78790	Main MSE (x10^-2): 78.7904	LR: 9.89e-05	EMPP_Raw: 1.50803
2025-07-18 01:17:30,421 - logger.py:50 - Epoch 336 Training Summary: Avg Total Loss: 0.78790, Avg Main MSE: 0.78790, Time: 17.18s
2025-07-18 01:17:48,776 - logger.py:50 - Epoch 336 Summary | Train MSE (x10^-2): 78.7904 | Val MSE (x10^-2): 25.0885 | Time: 35.53s
2025-07-18 01:17:51,843 - logger.py:50 - Epoch: [337][0/6]	Total Loss: 0.76663	Main MSE (x10^-2): 76.6634	LR: 9.79e-05	EMPP_Raw: 1.46103
2025-07-18 01:18:05,938 - logger.py:50 - Epoch: [337][5/6]	Total Loss: 0.80059	Main MSE (x10^-2): 80.0592	LR: 9.79e-05	EMPP_Raw: 1.53232
2025-07-18 01:18:05,978 - logger.py:50 - Epoch 337 Training Summary: Avg Total Loss: 0.80059, Avg Main MSE: 0.80059, Time: 17.19s
2025-07-18 01:18:24,227 - logger.py:50 - Epoch 337 Summary | Train MSE (x10^-2): 80.0592 | Val MSE (x10^-2): 25.2031 | Time: 35.44s
2025-07-18 01:18:27,448 - logger.py:50 - Epoch: [338][0/6]	Total Loss: 0.75197	Main MSE (x10^-2): 75.1967	LR: 9.68e-05	EMPP_Raw: 1.44276
2025-07-18 01:18:41,545 - logger.py:50 - Epoch: [338][5/6]	Total Loss: 0.77827	Main MSE (x10^-2): 77.8266	LR: 9.68e-05	EMPP_Raw: 1.49063
2025-07-18 01:18:41,593 - logger.py:50 - Epoch 338 Training Summary: Avg Total Loss: 0.77827, Avg Main MSE: 0.77827, Time: 17.36s
2025-07-18 01:18:59,999 - logger.py:50 - Epoch 338 Summary | Train MSE (x10^-2): 77.8266 | Val MSE (x10^-2): 24.9165 | Time: 35.77s
2025-07-18 01:19:03,040 - logger.py:50 - Epoch: [339][0/6]	Total Loss: 0.75327	Main MSE (x10^-2): 75.3274	LR: 9.57e-05	EMPP_Raw: 1.44581
2025-07-18 01:19:17,218 - logger.py:50 - Epoch: [339][5/6]	Total Loss: 0.78924	Main MSE (x10^-2): 78.9241	LR: 9.57e-05	EMPP_Raw: 1.51024
2025-07-18 01:19:17,260 - logger.py:50 - Epoch 339 Training Summary: Avg Total Loss: 0.78924, Avg Main MSE: 0.78924, Time: 17.25s
2025-07-18 01:19:35,599 - logger.py:50 - Epoch 339 Summary | Train MSE (x10^-2): 78.9241 | Val MSE (x10^-2): 24.6124 | Time: 35.59s
2025-07-18 01:19:38,643 - logger.py:50 - Epoch: [340][0/6]	Total Loss: 0.73698	Main MSE (x10^-2): 73.6984	LR: 9.47e-05	EMPP_Raw: 1.41489
2025-07-18 01:19:52,851 - logger.py:50 - Epoch: [340][5/6]	Total Loss: 0.76981	Main MSE (x10^-2): 76.9809	LR: 9.47e-05	EMPP_Raw: 1.47479
2025-07-18 01:19:52,892 - logger.py:50 - Epoch 340 Training Summary: Avg Total Loss: 0.76981, Avg Main MSE: 0.76981, Time: 17.28s
2025-07-18 01:20:11,254 - logger.py:50 - Epoch 340 Summary | Train MSE (x10^-2): 76.9809 | Val MSE (x10^-2): 24.5544 | Time: 35.65s
2025-07-18 01:20:14,313 - logger.py:50 - Epoch: [341][0/6]	Total Loss: 0.79766	Main MSE (x10^-2): 79.7662	LR: 9.36e-05	EMPP_Raw: 1.53207
2025-07-18 01:20:28,373 - logger.py:50 - Epoch: [341][5/6]	Total Loss: 0.78977	Main MSE (x10^-2): 78.9770	LR: 9.36e-05	EMPP_Raw: 1.51200
2025-07-18 01:20:28,413 - logger.py:50 - Epoch 341 Training Summary: Avg Total Loss: 0.78977, Avg Main MSE: 0.78977, Time: 17.15s
2025-07-18 01:20:46,798 - logger.py:50 - Epoch 341 Summary | Train MSE (x10^-2): 78.9770 | Val MSE (x10^-2): 24.4876 | Time: 35.54s
2025-07-18 01:20:49,848 - logger.py:50 - Epoch: [342][0/6]	Total Loss: 0.92152	Main MSE (x10^-2): 92.1524	LR: 9.25e-05	EMPP_Raw: 1.77404
2025-07-18 01:21:03,841 - logger.py:50 - Epoch: [342][5/6]	Total Loss: 0.82861	Main MSE (x10^-2): 82.8607	LR: 9.25e-05	EMPP_Raw: 1.58992
2025-07-18 01:21:03,885 - logger.py:50 - Epoch 342 Training Summary: Avg Total Loss: 0.82861, Avg Main MSE: 0.82861, Time: 17.08s
2025-07-18 01:21:22,150 - logger.py:50 - Epoch 342 Summary | Train MSE (x10^-2): 82.8607 | Val MSE (x10^-2): 24.6834 | Time: 35.35s
2025-07-18 01:21:25,353 - logger.py:50 - Epoch: [343][0/6]	Total Loss: 0.77431	Main MSE (x10^-2): 77.4307	LR: 9.15e-05	EMPP_Raw: 1.48433
2025-07-18 01:21:39,366 - logger.py:50 - Epoch: [343][5/6]	Total Loss: 0.78817	Main MSE (x10^-2): 78.8172	LR: 9.15e-05	EMPP_Raw: 1.50810
2025-07-18 01:21:39,407 - logger.py:50 - Epoch 343 Training Summary: Avg Total Loss: 0.78817, Avg Main MSE: 0.78817, Time: 17.25s
2025-07-18 01:21:57,847 - logger.py:50 - Epoch 343 Summary | Train MSE (x10^-2): 78.8172 | Val MSE (x10^-2): 24.9905 | Time: 35.69s
2025-07-18 01:22:01,088 - logger.py:50 - Epoch: [344][0/6]	Total Loss: 0.80554	Main MSE (x10^-2): 80.5541	LR: 9.04e-05	EMPP_Raw: 1.54408
2025-07-18 01:22:15,230 - logger.py:50 - Epoch: [344][5/6]	Total Loss: 0.76255	Main MSE (x10^-2): 76.2546	LR: 9.04e-05	EMPP_Raw: 1.45950
2025-07-18 01:22:15,274 - logger.py:50 - Epoch 344 Training Summary: Avg Total Loss: 0.76255, Avg Main MSE: 0.76255, Time: 17.42s
2025-07-18 01:22:33,581 - logger.py:50 - Epoch 344 Summary | Train MSE (x10^-2): 76.2546 | Val MSE (x10^-2): 24.7710 | Time: 35.73s
2025-07-18 01:22:36,630 - logger.py:50 - Epoch: [345][0/6]	Total Loss: 0.71375	Main MSE (x10^-2): 71.3749	LR: 8.94e-05	EMPP_Raw: 1.35494
2025-07-18 01:22:50,852 - logger.py:50 - Epoch: [345][5/6]	Total Loss: 0.80570	Main MSE (x10^-2): 80.5701	LR: 8.94e-05	EMPP_Raw: 1.54432
2025-07-18 01:22:50,896 - logger.py:50 - Epoch 345 Training Summary: Avg Total Loss: 0.80570, Avg Main MSE: 0.80570, Time: 17.31s
2025-07-18 01:23:09,244 - logger.py:50 - Epoch 345 Summary | Train MSE (x10^-2): 80.5701 | Val MSE (x10^-2): 24.5144 | Time: 35.66s
2025-07-18 01:23:12,297 - logger.py:50 - Epoch: [346][0/6]	Total Loss: 0.80638	Main MSE (x10^-2): 80.6385	LR: 8.84e-05	EMPP_Raw: 1.53462
2025-07-18 01:23:26,452 - logger.py:50 - Epoch: [346][5/6]	Total Loss: 0.80524	Main MSE (x10^-2): 80.5241	LR: 8.84e-05	EMPP_Raw: 1.53682
2025-07-18 01:23:26,489 - logger.py:50 - Epoch 346 Training Summary: Avg Total Loss: 0.80524, Avg Main MSE: 0.80524, Time: 17.24s
2025-07-18 01:23:44,923 - logger.py:50 - Epoch 346 Summary | Train MSE (x10^-2): 80.5241 | Val MSE (x10^-2): 25.6392 | Time: 35.67s
2025-07-18 01:23:48,002 - logger.py:50 - Epoch: [347][0/6]	Total Loss: 0.73083	Main MSE (x10^-2): 73.0835	LR: 8.73e-05	EMPP_Raw: 1.38469
2025-07-18 01:24:02,072 - logger.py:50 - Epoch: [347][5/6]	Total Loss: 0.79418	Main MSE (x10^-2): 79.4176	LR: 8.73e-05	EMPP_Raw: 1.52010
2025-07-18 01:24:02,119 - logger.py:50 - Epoch 347 Training Summary: Avg Total Loss: 0.79418, Avg Main MSE: 0.79418, Time: 17.19s
2025-07-18 01:24:20,474 - logger.py:50 - Epoch 347 Summary | Train MSE (x10^-2): 79.4176 | Val MSE (x10^-2): 24.5387 | Time: 35.55s
2025-07-18 01:24:23,573 - logger.py:50 - Epoch: [348][0/6]	Total Loss: 0.82764	Main MSE (x10^-2): 82.7641	LR: 8.63e-05	EMPP_Raw: 1.59592
2025-07-18 01:24:37,666 - logger.py:50 - Epoch: [348][5/6]	Total Loss: 0.79310	Main MSE (x10^-2): 79.3103	LR: 8.63e-05	EMPP_Raw: 1.52258
2025-07-18 01:24:37,710 - logger.py:50 - Epoch 348 Training Summary: Avg Total Loss: 0.79310, Avg Main MSE: 0.79310, Time: 17.23s
2025-07-18 01:24:56,219 - logger.py:50 - Epoch 348 Summary | Train MSE (x10^-2): 79.3103 | Val MSE (x10^-2): 24.3737 | Time: 35.74s
2025-07-18 01:24:59,275 - logger.py:50 - Epoch: [349][0/6]	Total Loss: 0.85178	Main MSE (x10^-2): 85.1780	LR: 8.53e-05	EMPP_Raw: 1.64100
2025-07-18 01:25:13,409 - logger.py:50 - Epoch: [349][5/6]	Total Loss: 0.79605	Main MSE (x10^-2): 79.6045	LR: 8.53e-05	EMPP_Raw: 1.53061
2025-07-18 01:25:13,456 - logger.py:50 - Epoch 349 Training Summary: Avg Total Loss: 0.79605, Avg Main MSE: 0.79605, Time: 17.23s
2025-07-18 01:25:32,016 - logger.py:50 - Epoch 349 Summary | Train MSE (x10^-2): 79.6045 | Val MSE (x10^-2): 24.5981 | Time: 35.79s
2025-07-18 01:25:35,454 - logger.py:50 - Epoch: [350][0/6]	Total Loss: 0.83711	Main MSE (x10^-2): 83.7107	LR: 8.43e-05	EMPP_Raw: 1.60868
2025-07-18 01:25:49,510 - logger.py:50 - Epoch: [350][5/6]	Total Loss: 0.79702	Main MSE (x10^-2): 79.7017	LR: 8.43e-05	EMPP_Raw: 1.52704
2025-07-18 01:25:49,571 - logger.py:50 - Epoch 350 Training Summary: Avg Total Loss: 0.79702, Avg Main MSE: 0.79702, Time: 17.54s
2025-07-18 01:26:08,045 - logger.py:50 - Epoch 350 Summary | Train MSE (x10^-2): 79.7017 | Val MSE (x10^-2): 24.6489 | Time: 36.02s
2025-07-18 01:26:11,123 - logger.py:50 - Epoch: [351][0/6]	Total Loss: 0.83739	Main MSE (x10^-2): 83.7394	LR: 8.32e-05	EMPP_Raw: 1.60812
2025-07-18 01:26:25,275 - logger.py:50 - Epoch: [351][5/6]	Total Loss: 0.79583	Main MSE (x10^-2): 79.5834	LR: 8.32e-05	EMPP_Raw: 1.52362
2025-07-18 01:26:25,345 - logger.py:50 - Epoch 351 Training Summary: Avg Total Loss: 0.79583, Avg Main MSE: 0.79583, Time: 17.29s
2025-07-18 01:26:43,700 - logger.py:50 - Epoch 351 Summary | Train MSE (x10^-2): 79.5834 | Val MSE (x10^-2): 24.8247 | Time: 35.65s
2025-07-18 01:26:46,901 - logger.py:50 - Epoch: [352][0/6]	Total Loss: 0.80582	Main MSE (x10^-2): 80.5818	LR: 8.22e-05	EMPP_Raw: 1.53510
2025-07-18 01:27:00,957 - logger.py:50 - Epoch: [352][5/6]	Total Loss: 0.81505	Main MSE (x10^-2): 81.5048	LR: 8.22e-05	EMPP_Raw: 1.55710
2025-07-18 01:27:01,004 - logger.py:50 - Epoch 352 Training Summary: Avg Total Loss: 0.81505, Avg Main MSE: 0.81505, Time: 17.29s
2025-07-18 01:27:19,408 - logger.py:50 - Epoch 352 Summary | Train MSE (x10^-2): 81.5048 | Val MSE (x10^-2): 25.2511 | Time: 35.70s
2025-07-18 01:27:22,454 - logger.py:50 - Epoch: [353][0/6]	Total Loss: 0.80828	Main MSE (x10^-2): 80.8275	LR: 8.12e-05	EMPP_Raw: 1.54207
2025-07-18 01:27:36,676 - logger.py:50 - Epoch: [353][5/6]	Total Loss: 0.79300	Main MSE (x10^-2): 79.3003	LR: 8.12e-05	EMPP_Raw: 1.51754
2025-07-18 01:27:36,722 - logger.py:50 - Epoch 353 Training Summary: Avg Total Loss: 0.79300, Avg Main MSE: 0.79300, Time: 17.30s
2025-07-18 01:27:55,042 - logger.py:50 - Epoch 353 Summary | Train MSE (x10^-2): 79.3003 | Val MSE (x10^-2): 24.5572 | Time: 35.63s
2025-07-18 01:27:58,087 - logger.py:50 - Epoch: [354][0/6]	Total Loss: 0.72684	Main MSE (x10^-2): 72.6844	LR: 8.02e-05	EMPP_Raw: 1.39080
2025-07-18 01:28:12,301 - logger.py:50 - Epoch: [354][5/6]	Total Loss: 0.79519	Main MSE (x10^-2): 79.5194	LR: 8.02e-05	EMPP_Raw: 1.52575
2025-07-18 01:28:12,352 - logger.py:50 - Epoch 354 Training Summary: Avg Total Loss: 0.79519, Avg Main MSE: 0.79519, Time: 17.30s
2025-07-18 01:28:30,680 - logger.py:50 - Epoch 354 Summary | Train MSE (x10^-2): 79.5194 | Val MSE (x10^-2): 24.3619 | Time: 35.63s
2025-07-18 01:28:33,781 - logger.py:50 - Epoch: [355][0/6]	Total Loss: 0.80046	Main MSE (x10^-2): 80.0461	LR: 7.92e-05	EMPP_Raw: 1.53886
2025-07-18 01:28:47,882 - logger.py:50 - Epoch: [355][5/6]	Total Loss: 0.77943	Main MSE (x10^-2): 77.9434	LR: 7.92e-05	EMPP_Raw: 1.49336
2025-07-18 01:28:47,950 - logger.py:50 - Epoch 355 Training Summary: Avg Total Loss: 0.77943, Avg Main MSE: 0.77943, Time: 17.26s
2025-07-18 01:29:06,531 - logger.py:50 - Epoch 355 Summary | Train MSE (x10^-2): 77.9434 | Val MSE (x10^-2): 24.5982 | Time: 35.85s
2025-07-18 01:29:09,605 - logger.py:50 - Epoch: [356][0/6]	Total Loss: 0.81528	Main MSE (x10^-2): 81.5280	LR: 7.82e-05	EMPP_Raw: 1.56403
2025-07-18 01:29:23,646 - logger.py:50 - Epoch: [356][5/6]	Total Loss: 0.78946	Main MSE (x10^-2): 78.9455	LR: 7.82e-05	EMPP_Raw: 1.51653
2025-07-18 01:29:23,688 - logger.py:50 - Epoch 356 Training Summary: Avg Total Loss: 0.78946, Avg Main MSE: 0.78946, Time: 17.15s
2025-07-18 01:29:42,153 - logger.py:50 - Epoch 356 Summary | Train MSE (x10^-2): 78.9455 | Val MSE (x10^-2): 24.5047 | Time: 35.62s
2025-07-18 01:29:45,248 - logger.py:50 - Epoch: [357][0/6]	Total Loss: 0.79021	Main MSE (x10^-2): 79.0207	LR: 7.72e-05	EMPP_Raw: 1.51204
2025-07-18 01:29:59,343 - logger.py:50 - Epoch: [357][5/6]	Total Loss: 0.78009	Main MSE (x10^-2): 78.0091	LR: 7.72e-05	EMPP_Raw: 1.49624
2025-07-18 01:29:59,398 - logger.py:50 - Epoch 357 Training Summary: Avg Total Loss: 0.78009, Avg Main MSE: 0.78009, Time: 17.24s
2025-07-18 01:30:17,882 - logger.py:50 - Epoch 357 Summary | Train MSE (x10^-2): 78.0091 | Val MSE (x10^-2): 25.2494 | Time: 35.72s
2025-07-18 01:30:21,074 - logger.py:50 - Epoch: [358][0/6]	Total Loss: 0.80448	Main MSE (x10^-2): 80.4478	LR: 7.63e-05	EMPP_Raw: 1.54505
2025-07-18 01:30:35,115 - logger.py:50 - Epoch: [358][5/6]	Total Loss: 0.80609	Main MSE (x10^-2): 80.6089	LR: 7.63e-05	EMPP_Raw: 1.54559
2025-07-18 01:30:35,158 - logger.py:50 - Epoch 358 Training Summary: Avg Total Loss: 0.80609, Avg Main MSE: 0.80609, Time: 17.27s
2025-07-18 01:30:53,386 - logger.py:50 - Epoch 358 Summary | Train MSE (x10^-2): 80.6089 | Val MSE (x10^-2): 24.7077 | Time: 35.50s
2025-07-18 01:30:56,425 - logger.py:50 - Epoch: [359][0/6]	Total Loss: 0.76393	Main MSE (x10^-2): 76.3934	LR: 7.53e-05	EMPP_Raw: 1.47132
2025-07-18 01:31:10,637 - logger.py:50 - Epoch: [359][5/6]	Total Loss: 0.77213	Main MSE (x10^-2): 77.2130	LR: 7.53e-05	EMPP_Raw: 1.47855
2025-07-18 01:31:10,678 - logger.py:50 - Epoch 359 Training Summary: Avg Total Loss: 0.77213, Avg Main MSE: 0.77213, Time: 17.28s
2025-07-18 01:31:28,998 - logger.py:50 - Epoch 359 Summary | Train MSE (x10^-2): 77.2130 | Val MSE (x10^-2): 24.9311 | Time: 35.61s
2025-07-18 01:31:32,076 - logger.py:50 - Epoch: [360][0/6]	Total Loss: 0.81318	Main MSE (x10^-2): 81.3185	LR: 7.43e-05	EMPP_Raw: 1.54596
2025-07-18 01:31:46,278 - logger.py:50 - Epoch: [360][5/6]	Total Loss: 0.80589	Main MSE (x10^-2): 80.5889	LR: 7.43e-05	EMPP_Raw: 1.54682
2025-07-18 01:31:46,318 - logger.py:50 - Epoch 360 Training Summary: Avg Total Loss: 0.80589, Avg Main MSE: 0.80589, Time: 17.31s
2025-07-18 01:32:04,600 - logger.py:50 - Epoch 360 Summary | Train MSE (x10^-2): 80.5889 | Val MSE (x10^-2): 24.8292 | Time: 35.60s
2025-07-18 01:32:07,642 - logger.py:50 - Epoch: [361][0/6]	Total Loss: 0.71873	Main MSE (x10^-2): 71.8732	LR: 7.33e-05	EMPP_Raw: 1.37832
2025-07-18 01:32:21,723 - logger.py:50 - Epoch: [361][5/6]	Total Loss: 0.79440	Main MSE (x10^-2): 79.4403	LR: 7.33e-05	EMPP_Raw: 1.52498
2025-07-18 01:32:21,763 - logger.py:50 - Epoch 361 Training Summary: Avg Total Loss: 0.79440, Avg Main MSE: 0.79440, Time: 17.15s
2025-07-18 01:32:40,125 - logger.py:50 - Epoch 361 Summary | Train MSE (x10^-2): 79.4403 | Val MSE (x10^-2): 24.5336 | Time: 35.52s
2025-07-18 01:32:43,158 - logger.py:50 - Epoch: [362][0/6]	Total Loss: 0.75711	Main MSE (x10^-2): 75.7109	LR: 7.24e-05	EMPP_Raw: 1.44217
2025-07-18 01:32:57,239 - logger.py:50 - Epoch: [362][5/6]	Total Loss: 0.79554	Main MSE (x10^-2): 79.5543	LR: 7.24e-05	EMPP_Raw: 1.52506
2025-07-18 01:32:57,284 - logger.py:50 - Epoch 362 Training Summary: Avg Total Loss: 0.79554, Avg Main MSE: 0.79554, Time: 17.15s
2025-07-18 01:33:15,731 - logger.py:50 - Epoch 362 Summary | Train MSE (x10^-2): 79.5543 | Val MSE (x10^-2): 24.5261 | Time: 35.60s
2025-07-18 01:33:18,764 - logger.py:50 - Epoch: [363][0/6]	Total Loss: 0.67778	Main MSE (x10^-2): 67.7780	LR: 7.14e-05	EMPP_Raw: 1.29552
2025-07-18 01:33:32,795 - logger.py:50 - Epoch: [363][5/6]	Total Loss: 0.75792	Main MSE (x10^-2): 75.7915	LR: 7.14e-05	EMPP_Raw: 1.45562
2025-07-18 01:33:32,834 - logger.py:50 - Epoch 363 Training Summary: Avg Total Loss: 0.75792, Avg Main MSE: 0.75792, Time: 17.09s
2025-07-18 01:33:51,180 - logger.py:50 - Epoch 363 Summary | Train MSE (x10^-2): 75.7915 | Val MSE (x10^-2): 24.4420 | Time: 35.44s
2025-07-18 01:33:54,399 - logger.py:50 - Epoch: [364][0/6]	Total Loss: 0.80207	Main MSE (x10^-2): 80.2067	LR: 7.05e-05	EMPP_Raw: 1.53848
2025-07-18 01:34:08,450 - logger.py:50 - Epoch: [364][5/6]	Total Loss: 0.79445	Main MSE (x10^-2): 79.4445	LR: 7.05e-05	EMPP_Raw: 1.52554
2025-07-18 01:34:08,493 - logger.py:50 - Epoch 364 Training Summary: Avg Total Loss: 0.79445, Avg Main MSE: 0.79445, Time: 17.30s
2025-07-18 01:34:27,109 - logger.py:50 - Epoch 364 Summary | Train MSE (x10^-2): 79.4445 | Val MSE (x10^-2): 24.6962 | Time: 35.92s
2025-07-18 01:34:30,179 - logger.py:50 - Epoch: [365][0/6]	Total Loss: 0.82768	Main MSE (x10^-2): 82.7680	LR: 6.95e-05	EMPP_Raw: 1.59591
2025-07-18 01:34:44,424 - logger.py:50 - Epoch: [365][5/6]	Total Loss: 0.79052	Main MSE (x10^-2): 79.0516	LR: 6.95e-05	EMPP_Raw: 1.51496
2025-07-18 01:34:44,469 - logger.py:50 - Epoch 365 Training Summary: Avg Total Loss: 0.79052, Avg Main MSE: 0.79052, Time: 17.35s
2025-07-18 01:35:02,930 - logger.py:50 - Epoch 365 Summary | Train MSE (x10^-2): 79.0516 | Val MSE (x10^-2): 24.2655 | Time: 35.81s
2025-07-18 01:35:06,034 - logger.py:50 - Epoch: [366][0/6]	Total Loss: 0.80388	Main MSE (x10^-2): 80.3880	LR: 6.86e-05	EMPP_Raw: 1.54688
2025-07-18 01:35:20,270 - logger.py:50 - Epoch: [366][5/6]	Total Loss: 0.78474	Main MSE (x10^-2): 78.4737	LR: 6.86e-05	EMPP_Raw: 1.51007
2025-07-18 01:35:20,314 - logger.py:50 - Epoch 366 Training Summary: Avg Total Loss: 0.78474, Avg Main MSE: 0.78474, Time: 17.37s
2025-07-18 01:35:38,658 - logger.py:50 - Epoch 366 Summary | Train MSE (x10^-2): 78.4737 | Val MSE (x10^-2): 24.7692 | Time: 35.72s
2025-07-18 01:35:41,750 - logger.py:50 - Epoch: [367][0/6]	Total Loss: 0.78222	Main MSE (x10^-2): 78.2218	LR: 6.76e-05	EMPP_Raw: 1.50322
2025-07-18 01:35:55,837 - logger.py:50 - Epoch: [367][5/6]	Total Loss: 0.76974	Main MSE (x10^-2): 76.9742	LR: 6.76e-05	EMPP_Raw: 1.47752
2025-07-18 01:35:55,879 - logger.py:50 - Epoch 367 Training Summary: Avg Total Loss: 0.76974, Avg Main MSE: 0.76974, Time: 17.21s
2025-07-18 01:36:14,283 - logger.py:50 - Epoch 367 Summary | Train MSE (x10^-2): 76.9742 | Val MSE (x10^-2): 24.1844 | Time: 35.62s
2025-07-18 01:36:17,354 - logger.py:50 - Epoch: [368][0/6]	Total Loss: 0.80709	Main MSE (x10^-2): 80.7095	LR: 6.67e-05	EMPP_Raw: 1.55429
2025-07-18 01:36:31,376 - logger.py:50 - Epoch: [368][5/6]	Total Loss: 0.80361	Main MSE (x10^-2): 80.3607	LR: 6.67e-05	EMPP_Raw: 1.54459
2025-07-18 01:36:31,419 - logger.py:50 - Epoch 368 Training Summary: Avg Total Loss: 0.80361, Avg Main MSE: 0.80361, Time: 17.13s
2025-07-18 01:36:49,905 - logger.py:50 - Epoch 368 Summary | Train MSE (x10^-2): 80.3607 | Val MSE (x10^-2): 24.6535 | Time: 35.62s
2025-07-18 01:36:53,157 - logger.py:50 - Epoch: [369][0/6]	Total Loss: 0.78377	Main MSE (x10^-2): 78.3766	LR: 6.58e-05	EMPP_Raw: 1.49992
2025-07-18 01:37:07,331 - logger.py:50 - Epoch: [369][5/6]	Total Loss: 0.79457	Main MSE (x10^-2): 79.4573	LR: 6.58e-05	EMPP_Raw: 1.52556
2025-07-18 01:37:07,374 - logger.py:50 - Epoch 369 Training Summary: Avg Total Loss: 0.79457, Avg Main MSE: 0.79457, Time: 17.46s
2025-07-18 01:37:25,699 - logger.py:50 - Epoch 369 Summary | Train MSE (x10^-2): 79.4573 | Val MSE (x10^-2): 24.5406 | Time: 35.79s
2025-07-18 01:37:28,918 - logger.py:50 - Epoch: [370][0/6]	Total Loss: 0.82075	Main MSE (x10^-2): 82.0750	LR: 6.48e-05	EMPP_Raw: 1.57921
2025-07-18 01:37:42,929 - logger.py:50 - Epoch: [370][5/6]	Total Loss: 0.77741	Main MSE (x10^-2): 77.7414	LR: 6.48e-05	EMPP_Raw: 1.49331
2025-07-18 01:37:42,972 - logger.py:50 - Epoch 370 Training Summary: Avg Total Loss: 0.77741, Avg Main MSE: 0.77741, Time: 17.26s
2025-07-18 01:38:01,318 - logger.py:50 - Epoch 370 Summary | Train MSE (x10^-2): 77.7414 | Val MSE (x10^-2): 24.4226 | Time: 35.61s
2025-07-18 01:38:04,367 - logger.py:50 - Epoch: [371][0/6]	Total Loss: 0.77866	Main MSE (x10^-2): 77.8664	LR: 6.39e-05	EMPP_Raw: 1.49310
2025-07-18 01:38:18,562 - logger.py:50 - Epoch: [371][5/6]	Total Loss: 0.77730	Main MSE (x10^-2): 77.7301	LR: 6.39e-05	EMPP_Raw: 1.49168
2025-07-18 01:38:18,607 - logger.py:50 - Epoch 371 Training Summary: Avg Total Loss: 0.77730, Avg Main MSE: 0.77730, Time: 17.28s
2025-07-18 01:38:37,016 - logger.py:50 - Epoch 371 Summary | Train MSE (x10^-2): 77.7301 | Val MSE (x10^-2): 24.5365 | Time: 35.69s
2025-07-18 01:38:40,062 - logger.py:50 - Epoch: [372][0/6]	Total Loss: 0.78450	Main MSE (x10^-2): 78.4497	LR: 6.30e-05	EMPP_Raw: 1.50754
2025-07-18 01:38:54,231 - logger.py:50 - Epoch: [372][5/6]	Total Loss: 0.76646	Main MSE (x10^-2): 76.6462	LR: 6.30e-05	EMPP_Raw: 1.47210
2025-07-18 01:38:54,275 - logger.py:50 - Epoch 372 Training Summary: Avg Total Loss: 0.76646, Avg Main MSE: 0.76646, Time: 17.25s
2025-07-18 01:39:12,528 - logger.py:50 - Epoch 372 Summary | Train MSE (x10^-2): 76.6462 | Val MSE (x10^-2): 24.5153 | Time: 35.51s
2025-07-18 01:39:15,594 - logger.py:50 - Epoch: [373][0/6]	Total Loss: 0.76630	Main MSE (x10^-2): 76.6300	LR: 6.21e-05	EMPP_Raw: 1.46623
2025-07-18 01:39:29,654 - logger.py:50 - Epoch: [373][5/6]	Total Loss: 0.75567	Main MSE (x10^-2): 75.5672	LR: 6.21e-05	EMPP_Raw: 1.44984
2025-07-18 01:39:29,697 - logger.py:50 - Epoch 373 Training Summary: Avg Total Loss: 0.75567, Avg Main MSE: 0.75567, Time: 17.16s
2025-07-18 01:39:48,061 - logger.py:50 - Epoch 373 Summary | Train MSE (x10^-2): 75.5672 | Val MSE (x10^-2): 24.2954 | Time: 35.53s
2025-07-18 01:39:51,096 - logger.py:50 - Epoch: [374][0/6]	Total Loss: 0.84366	Main MSE (x10^-2): 84.3661	LR: 6.12e-05	EMPP_Raw: 1.63484
2025-07-18 01:40:05,208 - logger.py:50 - Epoch: [374][5/6]	Total Loss: 0.79514	Main MSE (x10^-2): 79.5139	LR: 6.12e-05	EMPP_Raw: 1.52965
2025-07-18 01:40:05,253 - logger.py:50 - Epoch 374 Training Summary: Avg Total Loss: 0.79514, Avg Main MSE: 0.79514, Time: 17.18s
2025-07-18 01:40:23,657 - logger.py:50 - Epoch 374 Summary | Train MSE (x10^-2): 79.5139 | Val MSE (x10^-2): 24.3912 | Time: 35.59s
2025-07-18 01:40:26,697 - logger.py:50 - Epoch: [375][0/6]	Total Loss: 0.76403	Main MSE (x10^-2): 76.4032	LR: 6.03e-05	EMPP_Raw: 1.46548
2025-07-18 01:40:40,717 - logger.py:50 - Epoch: [375][5/6]	Total Loss: 0.78103	Main MSE (x10^-2): 78.1028	LR: 6.03e-05	EMPP_Raw: 1.50294
2025-07-18 01:40:40,762 - logger.py:50 - Epoch 375 Training Summary: Avg Total Loss: 0.78103, Avg Main MSE: 0.78103, Time: 17.10s
2025-07-18 01:40:59,139 - logger.py:50 - Epoch 375 Summary | Train MSE (x10^-2): 78.1028 | Val MSE (x10^-2): 24.4821 | Time: 35.48s
2025-07-18 01:41:02,512 - logger.py:50 - Epoch: [376][0/6]	Total Loss: 0.82472	Main MSE (x10^-2): 82.4724	LR: 5.94e-05	EMPP_Raw: 1.59169
2025-07-18 01:41:16,574 - logger.py:50 - Epoch: [376][5/6]	Total Loss: 0.77836	Main MSE (x10^-2): 77.8361	LR: 5.94e-05	EMPP_Raw: 1.49587
2025-07-18 01:41:16,628 - logger.py:50 - Epoch 376 Training Summary: Avg Total Loss: 0.77836, Avg Main MSE: 0.77836, Time: 17.48s
2025-07-18 01:41:35,016 - logger.py:50 - Epoch 376 Summary | Train MSE (x10^-2): 77.8361 | Val MSE (x10^-2): 24.6325 | Time: 35.87s
2025-07-18 01:41:38,064 - logger.py:50 - Epoch: [377][0/6]	Total Loss: 0.76357	Main MSE (x10^-2): 76.3571	LR: 5.85e-05	EMPP_Raw: 1.46087
2025-07-18 01:41:52,195 - logger.py:50 - Epoch: [377][5/6]	Total Loss: 0.75590	Main MSE (x10^-2): 75.5904	LR: 5.85e-05	EMPP_Raw: 1.44801
2025-07-18 01:41:52,236 - logger.py:50 - Epoch 377 Training Summary: Avg Total Loss: 0.75590, Avg Main MSE: 0.75590, Time: 17.22s
2025-07-18 01:42:10,591 - logger.py:50 - Epoch 377 Summary | Train MSE (x10^-2): 75.5904 | Val MSE (x10^-2): 24.6861 | Time: 35.57s
2025-07-18 01:42:13,811 - logger.py:50 - Epoch: [378][0/6]	Total Loss: 0.79489	Main MSE (x10^-2): 79.4891	LR: 5.77e-05	EMPP_Raw: 1.52237
2025-07-18 01:42:27,813 - logger.py:50 - Epoch: [378][5/6]	Total Loss: 0.78998	Main MSE (x10^-2): 78.9976	LR: 5.77e-05	EMPP_Raw: 1.51740
2025-07-18 01:42:27,864 - logger.py:50 - Epoch 378 Training Summary: Avg Total Loss: 0.78998, Avg Main MSE: 0.78998, Time: 17.26s
2025-07-18 01:42:46,366 - logger.py:50 - Epoch 378 Summary | Train MSE (x10^-2): 78.9976 | Val MSE (x10^-2): 24.7335 | Time: 35.77s
2025-07-18 01:42:49,406 - logger.py:50 - Epoch: [379][0/6]	Total Loss: 0.82247	Main MSE (x10^-2): 82.2472	LR: 5.68e-05	EMPP_Raw: 1.58674
2025-07-18 01:43:03,650 - logger.py:50 - Epoch: [379][5/6]	Total Loss: 0.79800	Main MSE (x10^-2): 79.8003	LR: 5.68e-05	EMPP_Raw: 1.53694
2025-07-18 01:43:03,693 - logger.py:50 - Epoch 379 Training Summary: Avg Total Loss: 0.79800, Avg Main MSE: 0.79800, Time: 17.32s
2025-07-18 01:43:22,116 - logger.py:50 - Epoch 379 Summary | Train MSE (x10^-2): 79.8003 | Val MSE (x10^-2): 24.4359 | Time: 35.74s
2025-07-18 01:43:25,187 - logger.py:50 - Epoch: [380][0/6]	Total Loss: 0.84565	Main MSE (x10^-2): 84.5650	LR: 5.59e-05	EMPP_Raw: 1.63523
2025-07-18 01:43:39,430 - logger.py:50 - Epoch: [380][5/6]	Total Loss: 0.78728	Main MSE (x10^-2): 78.7280	LR: 5.59e-05	EMPP_Raw: 1.51425
2025-07-18 01:43:39,475 - logger.py:50 - Epoch 380 Training Summary: Avg Total Loss: 0.78728, Avg Main MSE: 0.78728, Time: 17.35s
2025-07-18 01:43:57,912 - logger.py:50 - Epoch 380 Summary | Train MSE (x10^-2): 78.7280 | Val MSE (x10^-2): 24.4463 | Time: 35.79s
2025-07-18 01:44:00,964 - logger.py:50 - Epoch: [381][0/6]	Total Loss: 0.77901	Main MSE (x10^-2): 77.9010	LR: 5.51e-05	EMPP_Raw: 1.49824
2025-07-18 01:44:15,079 - logger.py:50 - Epoch: [381][5/6]	Total Loss: 0.79379	Main MSE (x10^-2): 79.3786	LR: 5.51e-05	EMPP_Raw: 1.52967
2025-07-18 01:44:15,123 - logger.py:50 - Epoch 381 Training Summary: Avg Total Loss: 0.79379, Avg Main MSE: 0.79379, Time: 17.20s
2025-07-18 01:44:33,610 - logger.py:50 - Epoch 381 Summary | Train MSE (x10^-2): 79.3786 | Val MSE (x10^-2): 24.2842 | Time: 35.69s
2025-07-18 01:44:36,686 - logger.py:50 - Epoch: [382][0/6]	Total Loss: 0.79189	Main MSE (x10^-2): 79.1894	LR: 5.42e-05	EMPP_Raw: 1.52458
2025-07-18 01:44:50,796 - logger.py:50 - Epoch: [382][5/6]	Total Loss: 0.79770	Main MSE (x10^-2): 79.7704	LR: 5.42e-05	EMPP_Raw: 1.53468
2025-07-18 01:44:50,847 - logger.py:50 - Epoch 382 Training Summary: Avg Total Loss: 0.79770, Avg Main MSE: 0.79770, Time: 17.23s
2025-07-18 01:45:09,312 - logger.py:50 - Epoch 382 Summary | Train MSE (x10^-2): 79.7704 | Val MSE (x10^-2): 24.5211 | Time: 35.70s
2025-07-18 01:45:12,366 - logger.py:50 - Epoch: [383][0/6]	Total Loss: 0.80290	Main MSE (x10^-2): 80.2896	LR: 5.34e-05	EMPP_Raw: 1.54180
2025-07-18 01:45:26,467 - logger.py:50 - Epoch: [383][5/6]	Total Loss: 0.77762	Main MSE (x10^-2): 77.7618	LR: 5.34e-05	EMPP_Raw: 1.49690
2025-07-18 01:45:26,531 - logger.py:50 - Epoch 383 Training Summary: Avg Total Loss: 0.77762, Avg Main MSE: 0.77762, Time: 17.21s
2025-07-18 01:45:44,967 - logger.py:50 - Epoch 383 Summary | Train MSE (x10^-2): 77.7618 | Val MSE (x10^-2): 24.5466 | Time: 35.65s
2025-07-18 01:45:48,165 - logger.py:50 - Epoch: [384][0/6]	Total Loss: 0.78042	Main MSE (x10^-2): 78.0418	LR: 5.25e-05	EMPP_Raw: 1.50352
2025-07-18 01:46:02,206 - logger.py:50 - Epoch: [384][5/6]	Total Loss: 0.76693	Main MSE (x10^-2): 76.6934	LR: 5.25e-05	EMPP_Raw: 1.47634
2025-07-18 01:46:02,249 - logger.py:50 - Epoch 384 Training Summary: Avg Total Loss: 0.76693, Avg Main MSE: 0.76693, Time: 17.28s
2025-07-18 01:46:20,547 - logger.py:50 - Epoch 384 Summary | Train MSE (x10^-2): 76.6934 | Val MSE (x10^-2): 24.3646 | Time: 35.58s
2025-07-18 01:46:23,631 - logger.py:50 - Epoch: [385][0/6]	Total Loss: 0.83376	Main MSE (x10^-2): 83.3758	LR: 5.17e-05	EMPP_Raw: 1.61020
2025-07-18 01:46:37,832 - logger.py:50 - Epoch: [385][5/6]	Total Loss: 0.79946	Main MSE (x10^-2): 79.9463	LR: 5.17e-05	EMPP_Raw: 1.53737
2025-07-18 01:46:37,875 - logger.py:50 - Epoch 385 Training Summary: Avg Total Loss: 0.79946, Avg Main MSE: 0.79946, Time: 17.32s
2025-07-18 01:46:56,249 - logger.py:50 - Epoch 385 Summary | Train MSE (x10^-2): 79.9463 | Val MSE (x10^-2): 25.0205 | Time: 35.70s
2025-07-18 01:46:59,292 - logger.py:50 - Epoch: [386][0/6]	Total Loss: 0.74476	Main MSE (x10^-2): 74.4758	LR: 5.09e-05	EMPP_Raw: 1.43207
2025-07-18 01:47:13,468 - logger.py:50 - Epoch: [386][5/6]	Total Loss: 0.79267	Main MSE (x10^-2): 79.2668	LR: 5.09e-05	EMPP_Raw: 1.52658
2025-07-18 01:47:13,518 - logger.py:50 - Epoch 386 Training Summary: Avg Total Loss: 0.79267, Avg Main MSE: 0.79267, Time: 17.26s
2025-07-18 01:47:31,797 - logger.py:50 - Epoch 386 Summary | Train MSE (x10^-2): 79.2668 | Val MSE (x10^-2): 24.6389 | Time: 35.54s
2025-07-18 01:47:34,905 - logger.py:50 - Epoch: [387][0/6]	Total Loss: 0.78595	Main MSE (x10^-2): 78.5946	LR: 5.00e-05	EMPP_Raw: 1.51565
2025-07-18 01:47:49,017 - logger.py:50 - Epoch: [387][5/6]	Total Loss: 0.78015	Main MSE (x10^-2): 78.0149	LR: 5.00e-05	EMPP_Raw: 1.50081
2025-07-18 01:47:49,061 - logger.py:50 - Epoch 387 Training Summary: Avg Total Loss: 0.78015, Avg Main MSE: 0.78015, Time: 17.26s
2025-07-18 01:48:07,491 - logger.py:50 - Epoch 387 Summary | Train MSE (x10^-2): 78.0149 | Val MSE (x10^-2): 24.4654 | Time: 35.69s
2025-07-18 01:48:10,546 - logger.py:50 - Epoch: [388][0/6]	Total Loss: 0.76877	Main MSE (x10^-2): 76.8772	LR: 4.92e-05	EMPP_Raw: 1.47767
2025-07-18 01:48:24,593 - logger.py:50 - Epoch: [388][5/6]	Total Loss: 0.79155	Main MSE (x10^-2): 79.1549	LR: 4.92e-05	EMPP_Raw: 1.52519
2025-07-18 01:48:24,639 - logger.py:50 - Epoch 388 Training Summary: Avg Total Loss: 0.79155, Avg Main MSE: 0.79155, Time: 17.14s
2025-07-18 01:48:43,076 - logger.py:50 - Epoch 388 Summary | Train MSE (x10^-2): 79.1549 | Val MSE (x10^-2): 24.4530 | Time: 35.58s
2025-07-18 01:48:46,123 - logger.py:50 - Epoch: [389][0/6]	Total Loss: 0.74434	Main MSE (x10^-2): 74.4335	LR: 4.84e-05	EMPP_Raw: 1.43249
2025-07-18 01:49:00,159 - logger.py:50 - Epoch: [389][5/6]	Total Loss: 0.79150	Main MSE (x10^-2): 79.1503	LR: 4.84e-05	EMPP_Raw: 1.52666
2025-07-18 01:49:00,204 - logger.py:50 - Epoch 389 Training Summary: Avg Total Loss: 0.79150, Avg Main MSE: 0.79150, Time: 17.12s
2025-07-18 01:49:18,510 - logger.py:50 - Epoch 389 Summary | Train MSE (x10^-2): 79.1503 | Val MSE (x10^-2): 24.8895 | Time: 35.43s
2025-07-18 01:49:21,740 - logger.py:50 - Epoch: [390][0/6]	Total Loss: 0.84566	Main MSE (x10^-2): 84.5663	LR: 4.76e-05	EMPP_Raw: 1.63257
2025-07-18 01:49:35,880 - logger.py:50 - Epoch: [390][5/6]	Total Loss: 0.79548	Main MSE (x10^-2): 79.5481	LR: 4.76e-05	EMPP_Raw: 1.53210
2025-07-18 01:49:35,923 - logger.py:50 - Epoch 390 Training Summary: Avg Total Loss: 0.79548, Avg Main MSE: 0.79548, Time: 17.40s
2025-07-18 01:49:54,247 - logger.py:50 - Epoch 390 Summary | Train MSE (x10^-2): 79.5481 | Val MSE (x10^-2): 24.4246 | Time: 35.73s
2025-07-18 01:49:57,304 - logger.py:50 - Epoch: [391][0/6]	Total Loss: 0.83083	Main MSE (x10^-2): 83.0828	LR: 4.68e-05	EMPP_Raw: 1.59792
2025-07-18 01:50:11,471 - logger.py:50 - Epoch: [391][5/6]	Total Loss: 0.78569	Main MSE (x10^-2): 78.5690	LR: 4.68e-05	EMPP_Raw: 1.51190
2025-07-18 01:50:11,518 - logger.py:50 - Epoch 391 Training Summary: Avg Total Loss: 0.78569, Avg Main MSE: 0.78569, Time: 17.26s
2025-07-18 01:50:29,780 - logger.py:50 - Epoch 391 Summary | Train MSE (x10^-2): 78.5690 | Val MSE (x10^-2): 24.4023 | Time: 35.53s
2025-07-18 01:50:32,859 - logger.py:50 - Epoch: [392][0/6]	Total Loss: 0.80455	Main MSE (x10^-2): 80.4551	LR: 4.60e-05	EMPP_Raw: 1.55066
2025-07-18 01:50:47,269 - logger.py:50 - Epoch: [392][5/6]	Total Loss: 0.76792	Main MSE (x10^-2): 76.7925	LR: 4.60e-05	EMPP_Raw: 1.48029
2025-07-18 01:50:47,314 - logger.py:50 - Epoch 392 Training Summary: Avg Total Loss: 0.76792, Avg Main MSE: 0.76792, Time: 17.52s
2025-07-18 01:51:05,593 - logger.py:50 - Epoch 392 Summary | Train MSE (x10^-2): 76.7925 | Val MSE (x10^-2): 24.4311 | Time: 35.81s
2025-07-18 01:51:08,640 - logger.py:50 - Epoch: [393][0/6]	Total Loss: 0.74846	Main MSE (x10^-2): 74.8457	LR: 4.52e-05	EMPP_Raw: 1.43830
2025-07-18 01:51:22,666 - logger.py:50 - Epoch: [393][5/6]	Total Loss: 0.77930	Main MSE (x10^-2): 77.9298	LR: 4.52e-05	EMPP_Raw: 1.50018
2025-07-18 01:51:22,715 - logger.py:50 - Epoch 393 Training Summary: Avg Total Loss: 0.77930, Avg Main MSE: 0.77930, Time: 17.11s
2025-07-18 01:51:41,169 - logger.py:50 - Epoch 393 Summary | Train MSE (x10^-2): 77.9298 | Val MSE (x10^-2): 24.3479 | Time: 35.57s
2025-07-18 01:51:44,199 - logger.py:50 - Epoch: [394][0/6]	Total Loss: 0.76159	Main MSE (x10^-2): 76.1593	LR: 4.44e-05	EMPP_Raw: 1.46623
2025-07-18 01:51:58,207 - logger.py:50 - Epoch: [394][5/6]	Total Loss: 0.79450	Main MSE (x10^-2): 79.4504	LR: 4.44e-05	EMPP_Raw: 1.53289
2025-07-18 01:51:58,251 - logger.py:50 - Epoch 394 Training Summary: Avg Total Loss: 0.79450, Avg Main MSE: 0.79450, Time: 17.07s
2025-07-18 01:52:16,562 - logger.py:50 - Epoch 394 Summary | Train MSE (x10^-2): 79.4504 | Val MSE (x10^-2): 24.6657 | Time: 35.39s
2025-07-18 01:52:19,783 - logger.py:50 - Epoch: [395][0/6]	Total Loss: 0.82141	Main MSE (x10^-2): 82.1412	LR: 4.36e-05	EMPP_Raw: 1.59170
2025-07-18 01:52:33,793 - logger.py:50 - Epoch: [395][5/6]	Total Loss: 0.78521	Main MSE (x10^-2): 78.5208	LR: 4.36e-05	EMPP_Raw: 1.51658
2025-07-18 01:52:33,835 - logger.py:50 - Epoch 395 Training Summary: Avg Total Loss: 0.78521, Avg Main MSE: 0.78521, Time: 17.26s
2025-07-18 01:52:52,217 - logger.py:50 - Epoch 395 Summary | Train MSE (x10^-2): 78.5208 | Val MSE (x10^-2): 24.5350 | Time: 35.65s
2025-07-18 01:52:55,410 - logger.py:50 - Epoch: [396][0/6]	Total Loss: 0.83153	Main MSE (x10^-2): 83.1533	LR: 4.29e-05	EMPP_Raw: 1.59588
2025-07-18 01:53:09,570 - logger.py:50 - Epoch: [396][5/6]	Total Loss: 0.77981	Main MSE (x10^-2): 77.9811	LR: 4.29e-05	EMPP_Raw: 1.50093
2025-07-18 01:53:09,614 - logger.py:50 - Epoch 396 Training Summary: Avg Total Loss: 0.77981, Avg Main MSE: 0.77981, Time: 17.39s
2025-07-18 01:53:27,953 - logger.py:50 - Epoch 396 Summary | Train MSE (x10^-2): 77.9811 | Val MSE (x10^-2): 24.4357 | Time: 35.73s
2025-07-18 01:53:31,033 - logger.py:50 - Epoch: [397][0/6]	Total Loss: 0.76630	Main MSE (x10^-2): 76.6302	LR: 4.21e-05	EMPP_Raw: 1.48302
2025-07-18 01:53:45,188 - logger.py:50 - Epoch: [397][5/6]	Total Loss: 0.79128	Main MSE (x10^-2): 79.1281	LR: 4.21e-05	EMPP_Raw: 1.52890
2025-07-18 01:53:45,229 - logger.py:50 - Epoch 397 Training Summary: Avg Total Loss: 0.79128, Avg Main MSE: 0.79128, Time: 17.27s
2025-07-18 01:54:03,540 - logger.py:50 - Epoch 397 Summary | Train MSE (x10^-2): 79.1281 | Val MSE (x10^-2): 24.2618 | Time: 35.58s
2025-07-18 01:54:06,615 - logger.py:50 - Epoch: [398][0/6]	Total Loss: 0.81362	Main MSE (x10^-2): 81.3624	LR: 4.13e-05	EMPP_Raw: 1.57405
2025-07-18 01:54:20,782 - logger.py:50 - Epoch: [398][5/6]	Total Loss: 0.78649	Main MSE (x10^-2): 78.6491	LR: 4.13e-05	EMPP_Raw: 1.51636
2025-07-18 01:54:20,825 - logger.py:50 - Epoch 398 Training Summary: Avg Total Loss: 0.78649, Avg Main MSE: 0.78649, Time: 17.27s
2025-07-18 01:54:39,092 - logger.py:50 - Epoch 398 Summary | Train MSE (x10^-2): 78.6491 | Val MSE (x10^-2): 24.4027 | Time: 35.55s
2025-07-18 01:54:42,125 - logger.py:50 - Epoch: [399][0/6]	Total Loss: 0.79370	Main MSE (x10^-2): 79.3704	LR: 4.06e-05	EMPP_Raw: 1.53250
2025-07-18 01:54:56,242 - logger.py:50 - Epoch: [399][5/6]	Total Loss: 0.75732	Main MSE (x10^-2): 75.7321	LR: 4.06e-05	EMPP_Raw: 1.45764
2025-07-18 01:54:56,287 - logger.py:50 - Epoch 399 Training Summary: Avg Total Loss: 0.75732, Avg Main MSE: 0.75732, Time: 17.19s
2025-07-18 01:55:14,783 - logger.py:50 - Epoch 399 Summary | Train MSE (x10^-2): 75.7321 | Val MSE (x10^-2): 24.5235 | Time: 35.69s
2025-07-18 01:55:17,856 - logger.py:50 - Epoch: [400][0/6]	Total Loss: 0.72295	Main MSE (x10^-2): 72.2955	LR: 3.98e-05	EMPP_Raw: 1.39210
2025-07-18 01:55:31,930 - logger.py:50 - Epoch: [400][5/6]	Total Loss: 0.76829	Main MSE (x10^-2): 76.8288	LR: 3.98e-05	EMPP_Raw: 1.48008
2025-07-18 01:55:31,974 - logger.py:50 - Epoch 400 Training Summary: Avg Total Loss: 0.76829, Avg Main MSE: 0.76829, Time: 17.18s
2025-07-18 01:55:50,526 - logger.py:50 - Epoch 400 Summary | Train MSE (x10^-2): 76.8288 | Val MSE (x10^-2): 24.4078 | Time: 35.74s
2025-07-18 01:55:53,630 - logger.py:50 - Epoch: [401][0/6]	Total Loss: 0.75780	Main MSE (x10^-2): 75.7799	LR: 3.91e-05	EMPP_Raw: 1.46079
2025-07-18 01:56:07,713 - logger.py:50 - Epoch: [401][5/6]	Total Loss: 0.79498	Main MSE (x10^-2): 79.4982	LR: 3.91e-05	EMPP_Raw: 1.53242
2025-07-18 01:56:07,760 - logger.py:50 - Epoch 401 Training Summary: Avg Total Loss: 0.79498, Avg Main MSE: 0.79498, Time: 17.23s
2025-07-18 01:56:26,092 - logger.py:50 - Epoch 401 Summary | Train MSE (x10^-2): 79.4982 | Val MSE (x10^-2): 24.2541 | Time: 35.57s
2025-07-18 01:56:29,496 - logger.py:50 - Epoch: [402][0/6]	Total Loss: 0.77074	Main MSE (x10^-2): 77.0740	LR: 3.84e-05	EMPP_Raw: 1.48852
2025-07-18 01:56:43,608 - logger.py:50 - Epoch: [402][5/6]	Total Loss: 0.80976	Main MSE (x10^-2): 80.9764	LR: 3.84e-05	EMPP_Raw: 1.56363
2025-07-18 01:56:43,684 - logger.py:50 - Epoch 402 Training Summary: Avg Total Loss: 0.80976, Avg Main MSE: 0.80976, Time: 17.58s
2025-07-18 01:57:02,202 - logger.py:50 - Epoch 402 Summary | Train MSE (x10^-2): 80.9764 | Val MSE (x10^-2): 24.5593 | Time: 36.11s
2025-07-18 01:57:05,245 - logger.py:50 - Epoch: [403][0/6]	Total Loss: 0.79980	Main MSE (x10^-2): 79.9800	LR: 3.76e-05	EMPP_Raw: 1.54227
2025-07-18 01:57:19,360 - logger.py:50 - Epoch: [403][5/6]	Total Loss: 0.81805	Main MSE (x10^-2): 81.8049	LR: 3.76e-05	EMPP_Raw: 1.57970
2025-07-18 01:57:19,402 - logger.py:50 - Epoch 403 Training Summary: Avg Total Loss: 0.81805, Avg Main MSE: 0.81805, Time: 17.19s
2025-07-18 01:57:37,653 - logger.py:50 - Epoch 403 Summary | Train MSE (x10^-2): 81.8049 | Val MSE (x10^-2): 24.4483 | Time: 35.44s
2025-07-18 01:57:40,873 - logger.py:50 - Epoch: [404][0/6]	Total Loss: 0.78902	Main MSE (x10^-2): 78.9020	LR: 3.69e-05	EMPP_Raw: 1.52210
2025-07-18 01:57:54,903 - logger.py:50 - Epoch: [404][5/6]	Total Loss: 0.78370	Main MSE (x10^-2): 78.3701	LR: 3.69e-05	EMPP_Raw: 1.50988
2025-07-18 01:57:54,943 - logger.py:50 - Epoch 404 Training Summary: Avg Total Loss: 0.78370, Avg Main MSE: 0.78370, Time: 17.28s
2025-07-18 01:58:13,280 - logger.py:50 - Epoch 404 Summary | Train MSE (x10^-2): 78.3701 | Val MSE (x10^-2): 24.3860 | Time: 35.62s
2025-07-18 01:58:16,319 - logger.py:50 - Epoch: [405][0/6]	Total Loss: 0.82916	Main MSE (x10^-2): 82.9160	LR: 3.62e-05	EMPP_Raw: 1.59745
2025-07-18 01:58:30,544 - logger.py:50 - Epoch: [405][5/6]	Total Loss: 0.79165	Main MSE (x10^-2): 79.1652	LR: 3.62e-05	EMPP_Raw: 1.52721
2025-07-18 01:58:30,589 - logger.py:50 - Epoch 405 Training Summary: Avg Total Loss: 0.79165, Avg Main MSE: 0.79165, Time: 17.30s
2025-07-18 01:58:48,883 - logger.py:50 - Epoch 405 Summary | Train MSE (x10^-2): 79.1652 | Val MSE (x10^-2): 24.4023 | Time: 35.60s
2025-07-18 01:58:51,922 - logger.py:50 - Epoch: [406][0/6]	Total Loss: 0.84230	Main MSE (x10^-2): 84.2295	LR: 3.55e-05	EMPP_Raw: 1.62883
2025-07-18 01:59:06,178 - logger.py:50 - Epoch: [406][5/6]	Total Loss: 0.79338	Main MSE (x10^-2): 79.3380	LR: 3.55e-05	EMPP_Raw: 1.52892
2025-07-18 01:59:06,222 - logger.py:50 - Epoch 406 Training Summary: Avg Total Loss: 0.79338, Avg Main MSE: 0.79338, Time: 17.33s
2025-07-18 01:59:24,591 - logger.py:50 - Epoch 406 Summary | Train MSE (x10^-2): 79.3380 | Val MSE (x10^-2): 24.2886 | Time: 35.70s
2025-07-18 01:59:27,652 - logger.py:50 - Epoch: [407][0/6]	Total Loss: 0.73231	Main MSE (x10^-2): 73.2313	LR: 3.48e-05	EMPP_Raw: 1.40694
2025-07-18 01:59:41,719 - logger.py:50 - Epoch: [407][5/6]	Total Loss: 0.75630	Main MSE (x10^-2): 75.6301	LR: 3.48e-05	EMPP_Raw: 1.45651
2025-07-18 01:59:41,764 - logger.py:50 - Epoch 407 Training Summary: Avg Total Loss: 0.75630, Avg Main MSE: 0.75630, Time: 17.16s
2025-07-18 02:00:00,410 - logger.py:50 - Epoch 407 Summary | Train MSE (x10^-2): 75.6301 | Val MSE (x10^-2): 24.6029 | Time: 35.81s
2025-07-18 02:00:03,467 - logger.py:50 - Epoch: [408][0/6]	Total Loss: 0.79045	Main MSE (x10^-2): 79.0448	LR: 3.41e-05	EMPP_Raw: 1.51765
2025-07-18 02:00:17,539 - logger.py:50 - Epoch: [408][5/6]	Total Loss: 0.78873	Main MSE (x10^-2): 78.8728	LR: 3.41e-05	EMPP_Raw: 1.52106
2025-07-18 02:00:17,581 - logger.py:50 - Epoch 408 Training Summary: Avg Total Loss: 0.78873, Avg Main MSE: 0.78873, Time: 17.16s
2025-07-18 02:00:36,029 - logger.py:50 - Epoch 408 Summary | Train MSE (x10^-2): 78.8728 | Val MSE (x10^-2): 24.1801 | Time: 35.61s
2025-07-18 02:00:39,076 - logger.py:50 - Epoch: [409][0/6]	Total Loss: 0.71069	Main MSE (x10^-2): 71.0687	LR: 3.34e-05	EMPP_Raw: 1.36782
2025-07-18 02:00:53,121 - logger.py:50 - Epoch: [409][5/6]	Total Loss: 0.73882	Main MSE (x10^-2): 73.8824	LR: 3.34e-05	EMPP_Raw: 1.42251
2025-07-18 02:00:53,167 - logger.py:50 - Epoch 409 Training Summary: Avg Total Loss: 0.73882, Avg Main MSE: 0.73882, Time: 17.13s
2025-07-18 02:01:11,532 - logger.py:50 - Epoch 409 Summary | Train MSE (x10^-2): 73.8824 | Val MSE (x10^-2): 24.4400 | Time: 35.50s
2025-07-18 02:01:14,725 - logger.py:50 - Epoch: [410][0/6]	Total Loss: 0.78772	Main MSE (x10^-2): 78.7724	LR: 3.27e-05	EMPP_Raw: 1.52337
2025-07-18 02:01:28,789 - logger.py:50 - Epoch: [410][5/6]	Total Loss: 0.79415	Main MSE (x10^-2): 79.4151	LR: 3.27e-05	EMPP_Raw: 1.53306
2025-07-18 02:01:28,833 - logger.py:50 - Epoch 410 Training Summary: Avg Total Loss: 0.79415, Avg Main MSE: 0.79415, Time: 17.29s
2025-07-18 02:01:47,132 - logger.py:50 - Epoch 410 Summary | Train MSE (x10^-2): 79.4151 | Val MSE (x10^-2): 24.4101 | Time: 35.59s
2025-07-18 02:01:50,167 - logger.py:50 - Epoch: [411][0/6]	Total Loss: 0.71009	Main MSE (x10^-2): 71.0094	LR: 3.21e-05	EMPP_Raw: 1.36712
2025-07-18 02:02:04,363 - logger.py:50 - Epoch: [411][5/6]	Total Loss: 0.76324	Main MSE (x10^-2): 76.3242	LR: 3.21e-05	EMPP_Raw: 1.47235
2025-07-18 02:02:04,406 - logger.py:50 - Epoch 411 Training Summary: Avg Total Loss: 0.76324, Avg Main MSE: 0.76324, Time: 17.26s
2025-07-18 02:02:22,765 - logger.py:50 - Epoch 411 Summary | Train MSE (x10^-2): 76.3242 | Val MSE (x10^-2): 24.3092 | Time: 35.63s
2025-07-18 02:02:25,809 - logger.py:50 - Epoch: [412][0/6]	Total Loss: 0.77274	Main MSE (x10^-2): 77.2737	LR: 3.14e-05	EMPP_Raw: 1.49454
2025-07-18 02:02:39,963 - logger.py:50 - Epoch: [412][5/6]	Total Loss: 0.79244	Main MSE (x10^-2): 79.2440	LR: 3.14e-05	EMPP_Raw: 1.53236
2025-07-18 02:02:40,019 - logger.py:50 - Epoch 412 Training Summary: Avg Total Loss: 0.79244, Avg Main MSE: 0.79244, Time: 17.25s
2025-07-18 02:02:58,308 - logger.py:50 - Epoch 412 Summary | Train MSE (x10^-2): 79.2440 | Val MSE (x10^-2): 24.4324 | Time: 35.54s
2025-07-18 02:03:01,355 - logger.py:50 - Epoch: [413][0/6]	Total Loss: 0.88049	Main MSE (x10^-2): 88.0494	LR: 3.07e-05	EMPP_Raw: 1.70899
2025-07-18 02:03:15,443 - logger.py:50 - Epoch: [413][5/6]	Total Loss: 0.82373	Main MSE (x10^-2): 82.3730	LR: 3.07e-05	EMPP_Raw: 1.59184
2025-07-18 02:03:15,483 - logger.py:50 - Epoch 413 Training Summary: Avg Total Loss: 0.82373, Avg Main MSE: 0.82373, Time: 17.17s
2025-07-18 02:03:34,218 - logger.py:50 - Epoch 413 Summary | Train MSE (x10^-2): 82.3730 | Val MSE (x10^-2): 24.3430 | Time: 35.90s
2025-07-18 02:03:37,316 - logger.py:50 - Epoch: [414][0/6]	Total Loss: 0.79812	Main MSE (x10^-2): 79.8120	LR: 3.01e-05	EMPP_Raw: 1.54461
2025-07-18 02:03:51,444 - logger.py:50 - Epoch: [414][5/6]	Total Loss: 0.75675	Main MSE (x10^-2): 75.6747	LR: 3.01e-05	EMPP_Raw: 1.46082
2025-07-18 02:03:51,483 - logger.py:50 - Epoch 414 Training Summary: Avg Total Loss: 0.75675, Avg Main MSE: 0.75675, Time: 17.26s
2025-07-18 02:04:10,051 - logger.py:50 - Epoch 414 Summary | Train MSE (x10^-2): 75.6747 | Val MSE (x10^-2): 24.2188 | Time: 35.83s
2025-07-18 02:04:13,092 - logger.py:50 - Epoch: [415][0/6]	Total Loss: 0.81090	Main MSE (x10^-2): 81.0899	LR: 2.94e-05	EMPP_Raw: 1.56982
2025-07-18 02:04:27,173 - logger.py:50 - Epoch: [415][5/6]	Total Loss: 0.78717	Main MSE (x10^-2): 78.7169	LR: 2.94e-05	EMPP_Raw: 1.51767
2025-07-18 02:04:27,218 - logger.py:50 - Epoch 415 Training Summary: Avg Total Loss: 0.78717, Avg Main MSE: 0.78717, Time: 17.16s
2025-07-18 02:04:45,438 - logger.py:50 - Epoch 415 Summary | Train MSE (x10^-2): 78.7169 | Val MSE (x10^-2): 24.3469 | Time: 35.38s
2025-07-18 02:04:48,668 - logger.py:50 - Epoch: [416][0/6]	Total Loss: 0.75590	Main MSE (x10^-2): 75.5896	LR: 2.88e-05	EMPP_Raw: 1.45564
2025-07-18 02:05:02,656 - logger.py:50 - Epoch: [416][5/6]	Total Loss: 0.75948	Main MSE (x10^-2): 75.9482	LR: 2.88e-05	EMPP_Raw: 1.46380
2025-07-18 02:05:02,700 - logger.py:50 - Epoch 416 Training Summary: Avg Total Loss: 0.75948, Avg Main MSE: 0.75948, Time: 17.25s
2025-07-18 02:05:21,008 - logger.py:50 - Epoch 416 Summary | Train MSE (x10^-2): 75.9482 | Val MSE (x10^-2): 24.2334 | Time: 35.56s
2025-07-18 02:05:24,065 - logger.py:50 - Epoch: [417][0/6]	Total Loss: 0.83941	Main MSE (x10^-2): 83.9409	LR: 2.81e-05	EMPP_Raw: 1.62452
2025-07-18 02:05:38,320 - logger.py:50 - Epoch: [417][5/6]	Total Loss: 0.77522	Main MSE (x10^-2): 77.5222	LR: 2.81e-05	EMPP_Raw: 1.49594
2025-07-18 02:05:38,366 - logger.py:50 - Epoch 417 Training Summary: Avg Total Loss: 0.77522, Avg Main MSE: 0.77522, Time: 17.35s
2025-07-18 02:05:56,665 - logger.py:50 - Epoch 417 Summary | Train MSE (x10^-2): 77.5222 | Val MSE (x10^-2): 24.2592 | Time: 35.65s
2025-07-18 02:05:59,737 - logger.py:50 - Epoch: [418][0/6]	Total Loss: 0.77224	Main MSE (x10^-2): 77.2239	LR: 2.75e-05	EMPP_Raw: 1.49524
2025-07-18 02:06:13,914 - logger.py:50 - Epoch: [418][5/6]	Total Loss: 0.76316	Main MSE (x10^-2): 76.3157	LR: 2.75e-05	EMPP_Raw: 1.47307
2025-07-18 02:06:13,958 - logger.py:50 - Epoch 418 Training Summary: Avg Total Loss: 0.76316, Avg Main MSE: 0.76316, Time: 17.28s
2025-07-18 02:06:32,332 - logger.py:50 - Epoch 418 Summary | Train MSE (x10^-2): 76.3157 | Val MSE (x10^-2): 24.4470 | Time: 35.66s
2025-07-18 02:06:35,420 - logger.py:50 - Epoch: [419][0/6]	Total Loss: 0.72831	Main MSE (x10^-2): 72.8308	LR: 2.69e-05	EMPP_Raw: 1.40632
2025-07-18 02:06:49,482 - logger.py:50 - Epoch: [419][5/6]	Total Loss: 0.76204	Main MSE (x10^-2): 76.2039	LR: 2.69e-05	EMPP_Raw: 1.46997
2025-07-18 02:06:49,522 - logger.py:50 - Epoch 419 Training Summary: Avg Total Loss: 0.76204, Avg Main MSE: 0.76204, Time: 17.18s
2025-07-18 02:07:07,956 - logger.py:50 - Epoch 419 Summary | Train MSE (x10^-2): 76.2039 | Val MSE (x10^-2): 24.4371 | Time: 35.62s
2025-07-18 02:07:10,992 - logger.py:50 - Epoch: [420][0/6]	Total Loss: 0.72808	Main MSE (x10^-2): 72.8085	LR: 2.63e-05	EMPP_Raw: 1.40495
2025-07-18 02:07:25,025 - logger.py:50 - Epoch: [420][5/6]	Total Loss: 0.78916	Main MSE (x10^-2): 78.9156	LR: 2.63e-05	EMPP_Raw: 1.52391
2025-07-18 02:07:25,066 - logger.py:50 - Epoch 420 Training Summary: Avg Total Loss: 0.78916, Avg Main MSE: 0.78916, Time: 17.10s
2025-07-18 02:07:43,446 - logger.py:50 - Epoch 420 Summary | Train MSE (x10^-2): 78.9156 | Val MSE (x10^-2): 24.3937 | Time: 35.48s
2025-07-18 02:07:46,639 - logger.py:50 - Epoch: [421][0/6]	Total Loss: 0.81499	Main MSE (x10^-2): 81.4992	LR: 2.57e-05	EMPP_Raw: 1.57694
2025-07-18 02:08:00,726 - logger.py:50 - Epoch: [421][5/6]	Total Loss: 0.78364	Main MSE (x10^-2): 78.3642	LR: 2.57e-05	EMPP_Raw: 1.51432
2025-07-18 02:08:00,772 - logger.py:50 - Epoch 421 Training Summary: Avg Total Loss: 0.78364, Avg Main MSE: 0.78364, Time: 17.32s
2025-07-18 02:08:19,128 - logger.py:50 - Epoch 421 Summary | Train MSE (x10^-2): 78.3642 | Val MSE (x10^-2): 24.3597 | Time: 35.68s
2025-07-18 02:08:22,345 - logger.py:50 - Epoch: [422][0/6]	Total Loss: 0.81468	Main MSE (x10^-2): 81.4683	LR: 2.51e-05	EMPP_Raw: 1.57070
2025-07-18 02:08:36,389 - logger.py:50 - Epoch: [422][5/6]	Total Loss: 0.79232	Main MSE (x10^-2): 79.2319	LR: 2.51e-05	EMPP_Raw: 1.53144
2025-07-18 02:08:36,435 - logger.py:50 - Epoch 422 Training Summary: Avg Total Loss: 0.79232, Avg Main MSE: 0.79232, Time: 17.30s
2025-07-18 02:08:55,007 - logger.py:50 - Epoch 422 Summary | Train MSE (x10^-2): 79.2319 | Val MSE (x10^-2): 24.1937 | Time: 35.87s
2025-07-18 02:08:58,040 - logger.py:50 - Epoch: [423][0/6]	Total Loss: 0.81124	Main MSE (x10^-2): 81.1236	LR: 2.45e-05	EMPP_Raw: 1.56581
2025-07-18 02:09:12,268 - logger.py:50 - Epoch: [423][5/6]	Total Loss: 0.78569	Main MSE (x10^-2): 78.5687	LR: 2.45e-05	EMPP_Raw: 1.51947
2025-07-18 02:09:12,312 - logger.py:50 - Epoch 423 Training Summary: Avg Total Loss: 0.78569, Avg Main MSE: 0.78569, Time: 17.29s
2025-07-18 02:09:30,538 - logger.py:50 - Epoch 423 Summary | Train MSE (x10^-2): 78.5687 | Val MSE (x10^-2): 24.2203 | Time: 35.52s
2025-07-18 02:09:33,587 - logger.py:50 - Epoch: [424][0/6]	Total Loss: 0.73185	Main MSE (x10^-2): 73.1853	LR: 2.39e-05	EMPP_Raw: 1.41369
2025-07-18 02:09:47,831 - logger.py:50 - Epoch: [424][5/6]	Total Loss: 0.77231	Main MSE (x10^-2): 77.2310	LR: 2.39e-05	EMPP_Raw: 1.49283
2025-07-18 02:09:47,876 - logger.py:50 - Epoch 424 Training Summary: Avg Total Loss: 0.77231, Avg Main MSE: 0.77231, Time: 17.33s
2025-07-18 02:10:06,284 - logger.py:50 - Epoch 424 Summary | Train MSE (x10^-2): 77.2310 | Val MSE (x10^-2): 24.3582 | Time: 35.74s
2025-07-18 02:10:09,387 - logger.py:50 - Epoch: [425][0/6]	Total Loss: 0.76714	Main MSE (x10^-2): 76.7144	LR: 2.33e-05	EMPP_Raw: 1.48054
2025-07-18 02:10:23,426 - logger.py:50 - Epoch: [425][5/6]	Total Loss: 0.78572	Main MSE (x10^-2): 78.5722	LR: 2.33e-05	EMPP_Raw: 1.51820
2025-07-18 02:10:23,466 - logger.py:50 - Epoch 425 Training Summary: Avg Total Loss: 0.78572, Avg Main MSE: 0.78572, Time: 17.17s
2025-07-18 02:10:42,004 - logger.py:50 - Epoch 425 Summary | Train MSE (x10^-2): 78.5722 | Val MSE (x10^-2): 24.3335 | Time: 35.71s
2025-07-18 02:10:45,071 - logger.py:50 - Epoch: [426][0/6]	Total Loss: 0.73531	Main MSE (x10^-2): 73.5311	LR: 2.27e-05	EMPP_Raw: 1.41798
2025-07-18 02:10:59,079 - logger.py:50 - Epoch: [426][5/6]	Total Loss: 0.76036	Main MSE (x10^-2): 76.0359	LR: 2.27e-05	EMPP_Raw: 1.46592
2025-07-18 02:10:59,121 - logger.py:50 - Epoch 426 Training Summary: Avg Total Loss: 0.76036, Avg Main MSE: 0.76036, Time: 17.11s
2025-07-18 02:11:17,653 - logger.py:50 - Epoch 426 Summary | Train MSE (x10^-2): 76.0359 | Val MSE (x10^-2): 24.3704 | Time: 35.64s
2025-07-18 02:11:20,729 - logger.py:50 - Epoch: [427][0/6]	Total Loss: 0.79612	Main MSE (x10^-2): 79.6122	LR: 2.22e-05	EMPP_Raw: 1.54247
2025-07-18 02:11:34,789 - logger.py:50 - Epoch: [427][5/6]	Total Loss: 0.77509	Main MSE (x10^-2): 77.5086	LR: 2.22e-05	EMPP_Raw: 1.49648
2025-07-18 02:11:34,834 - logger.py:50 - Epoch 427 Training Summary: Avg Total Loss: 0.77509, Avg Main MSE: 0.77509, Time: 17.17s
2025-07-18 02:11:53,296 - logger.py:50 - Epoch 427 Summary | Train MSE (x10^-2): 77.5086 | Val MSE (x10^-2): 24.3908 | Time: 35.64s
2025-07-18 02:11:56,709 - logger.py:50 - Epoch: [428][0/6]	Total Loss: 0.83425	Main MSE (x10^-2): 83.4253	LR: 2.16e-05	EMPP_Raw: 1.62119
2025-07-18 02:12:10,792 - logger.py:50 - Epoch: [428][5/6]	Total Loss: 0.77050	Main MSE (x10^-2): 77.0501	LR: 2.16e-05	EMPP_Raw: 1.48862
2025-07-18 02:12:10,845 - logger.py:50 - Epoch 428 Training Summary: Avg Total Loss: 0.77050, Avg Main MSE: 0.77050, Time: 17.54s
2025-07-18 02:12:29,273 - logger.py:50 - Epoch 428 Summary | Train MSE (x10^-2): 77.0501 | Val MSE (x10^-2): 24.3981 | Time: 35.97s
2025-07-18 02:12:32,358 - logger.py:50 - Epoch: [429][0/6]	Total Loss: 0.81535	Main MSE (x10^-2): 81.5353	LR: 2.11e-05	EMPP_Raw: 1.57780
2025-07-18 02:12:46,490 - logger.py:50 - Epoch: [429][5/6]	Total Loss: 0.78095	Main MSE (x10^-2): 78.0948	LR: 2.11e-05	EMPP_Raw: 1.50749
2025-07-18 02:12:46,532 - logger.py:50 - Epoch 429 Training Summary: Avg Total Loss: 0.78095, Avg Main MSE: 0.78095, Time: 17.25s
2025-07-18 02:13:04,800 - logger.py:50 - Epoch 429 Summary | Train MSE (x10^-2): 78.0948 | Val MSE (x10^-2): 24.2116 | Time: 35.52s
2025-07-18 02:13:07,994 - logger.py:50 - Epoch: [430][0/6]	Total Loss: 0.78823	Main MSE (x10^-2): 78.8234	LR: 2.05e-05	EMPP_Raw: 1.52836
2025-07-18 02:13:22,008 - logger.py:50 - Epoch: [430][5/6]	Total Loss: 0.75246	Main MSE (x10^-2): 75.2462	LR: 2.05e-05	EMPP_Raw: 1.45298
2025-07-18 02:13:22,052 - logger.py:50 - Epoch 430 Training Summary: Avg Total Loss: 0.75246, Avg Main MSE: 0.75246, Time: 17.24s
2025-07-18 02:13:40,354 - logger.py:50 - Epoch 430 Summary | Train MSE (x10^-2): 75.2462 | Val MSE (x10^-2): 24.3300 | Time: 35.55s
2025-07-18 02:13:43,414 - logger.py:50 - Epoch: [431][0/6]	Total Loss: 0.74959	Main MSE (x10^-2): 74.9588	LR: 2.00e-05	EMPP_Raw: 1.44467
2025-07-18 02:13:57,653 - logger.py:50 - Epoch: [431][5/6]	Total Loss: 0.77789	Main MSE (x10^-2): 77.7886	LR: 2.00e-05	EMPP_Raw: 1.50342
2025-07-18 02:13:57,712 - logger.py:50 - Epoch 431 Training Summary: Avg Total Loss: 0.77789, Avg Main MSE: 0.77789, Time: 17.35s
2025-07-18 02:14:16,339 - logger.py:50 - Epoch 431 Summary | Train MSE (x10^-2): 77.7886 | Val MSE (x10^-2): 24.2204 | Time: 35.98s
2025-07-18 02:14:19,425 - logger.py:50 - Epoch: [432][0/6]	Total Loss: 0.71709	Main MSE (x10^-2): 71.7093	LR: 1.95e-05	EMPP_Raw: 1.38443
2025-07-18 02:14:33,633 - logger.py:50 - Epoch: [432][5/6]	Total Loss: 0.74549	Main MSE (x10^-2): 74.5491	LR: 1.95e-05	EMPP_Raw: 1.43951
2025-07-18 02:14:33,673 - logger.py:50 - Epoch 432 Training Summary: Avg Total Loss: 0.74549, Avg Main MSE: 0.74549, Time: 17.32s
2025-07-18 02:14:52,084 - logger.py:50 - Epoch 432 Summary | Train MSE (x10^-2): 74.5491 | Val MSE (x10^-2): 24.1713 | Time: 35.74s
2025-07-18 02:14:55,164 - logger.py:50 - Epoch: [433][0/6]	Total Loss: 0.77566	Main MSE (x10^-2): 77.5656	LR: 1.89e-05	EMPP_Raw: 1.49614
2025-07-18 02:15:09,225 - logger.py:50 - Epoch: [433][5/6]	Total Loss: 0.78258	Main MSE (x10^-2): 78.2585	LR: 1.89e-05	EMPP_Raw: 1.51190
2025-07-18 02:15:09,270 - logger.py:50 - Epoch 433 Training Summary: Avg Total Loss: 0.78258, Avg Main MSE: 0.78258, Time: 17.18s
2025-07-18 02:15:27,817 - logger.py:50 - Epoch 433 Summary | Train MSE (x10^-2): 78.2585 | Val MSE (x10^-2): 24.2193 | Time: 35.73s
2025-07-18 02:15:30,887 - logger.py:50 - Epoch: [434][0/6]	Total Loss: 0.82956	Main MSE (x10^-2): 82.9562	LR: 1.84e-05	EMPP_Raw: 1.60311
2025-07-18 02:15:44,959 - logger.py:50 - Epoch: [434][5/6]	Total Loss: 0.78813	Main MSE (x10^-2): 78.8128	LR: 1.84e-05	EMPP_Raw: 1.52352
2025-07-18 02:15:45,004 - logger.py:50 - Epoch 434 Training Summary: Avg Total Loss: 0.78813, Avg Main MSE: 0.78813, Time: 17.18s
2025-07-18 02:16:03,616 - logger.py:50 - Epoch 434 Summary | Train MSE (x10^-2): 78.8128 | Val MSE (x10^-2): 24.3079 | Time: 35.80s
2025-07-18 02:16:06,667 - logger.py:50 - Epoch: [435][0/6]	Total Loss: 0.79870	Main MSE (x10^-2): 79.8696	LR: 1.79e-05	EMPP_Raw: 1.55086
2025-07-18 02:16:20,828 - logger.py:50 - Epoch: [435][5/6]	Total Loss: 0.78101	Main MSE (x10^-2): 78.1012	LR: 1.79e-05	EMPP_Raw: 1.50929
2025-07-18 02:16:20,870 - logger.py:50 - Epoch 435 Training Summary: Avg Total Loss: 0.78101, Avg Main MSE: 0.78101, Time: 17.24s
2025-07-18 02:16:39,354 - logger.py:50 - Epoch 435 Summary | Train MSE (x10^-2): 78.1012 | Val MSE (x10^-2): 24.1854 | Time: 35.73s
2025-07-18 02:16:42,537 - logger.py:50 - Epoch: [436][0/6]	Total Loss: 0.82145	Main MSE (x10^-2): 82.1448	LR: 1.74e-05	EMPP_Raw: 1.59152
2025-07-18 02:16:56,531 - logger.py:50 - Epoch: [436][5/6]	Total Loss: 0.77914	Main MSE (x10^-2): 77.9142	LR: 1.74e-05	EMPP_Raw: 1.50652
2025-07-18 02:16:56,573 - logger.py:50 - Epoch 436 Training Summary: Avg Total Loss: 0.77914, Avg Main MSE: 0.77914, Time: 17.21s
2025-07-18 02:17:14,867 - logger.py:50 - Epoch 436 Summary | Train MSE (x10^-2): 77.9142 | Val MSE (x10^-2): 24.2834 | Time: 35.51s
2025-07-18 02:17:17,905 - logger.py:50 - Epoch: [437][0/6]	Total Loss: 0.79549	Main MSE (x10^-2): 79.5491	LR: 1.69e-05	EMPP_Raw: 1.53947
2025-07-18 02:17:32,168 - logger.py:50 - Epoch: [437][5/6]	Total Loss: 0.76999	Main MSE (x10^-2): 76.9989	LR: 1.69e-05	EMPP_Raw: 1.48834
2025-07-18 02:17:32,213 - logger.py:50 - Epoch 437 Training Summary: Avg Total Loss: 0.76999, Avg Main MSE: 0.76999, Time: 17.34s
2025-07-18 02:17:50,624 - logger.py:50 - Epoch 437 Summary | Train MSE (x10^-2): 76.9989 | Val MSE (x10^-2): 24.2294 | Time: 35.75s
2025-07-18 02:17:53,669 - logger.py:50 - Epoch: [438][0/6]	Total Loss: 0.70834	Main MSE (x10^-2): 70.8336	LR: 1.64e-05	EMPP_Raw: 1.35855
2025-07-18 02:18:07,831 - logger.py:50 - Epoch: [438][5/6]	Total Loss: 0.76385	Main MSE (x10^-2): 76.3845	LR: 1.64e-05	EMPP_Raw: 1.47198
2025-07-18 02:18:07,879 - logger.py:50 - Epoch 438 Training Summary: Avg Total Loss: 0.76385, Avg Main MSE: 0.76385, Time: 17.25s
2025-07-18 02:18:26,110 - logger.py:50 - Epoch 438 Summary | Train MSE (x10^-2): 76.3845 | Val MSE (x10^-2): 24.2099 | Time: 35.48s
2025-07-18 02:18:29,154 - logger.py:50 - Epoch: [439][0/6]	Total Loss: 0.77697	Main MSE (x10^-2): 77.6970	LR: 1.59e-05	EMPP_Raw: 1.49727
2025-07-18 02:18:43,238 - logger.py:50 - Epoch: [439][5/6]	Total Loss: 0.78567	Main MSE (x10^-2): 78.5671	LR: 1.59e-05	EMPP_Raw: 1.51891
2025-07-18 02:18:43,278 - logger.py:50 - Epoch 439 Training Summary: Avg Total Loss: 0.78567, Avg Main MSE: 0.78567, Time: 17.16s
2025-07-18 02:19:01,740 - logger.py:50 - Epoch 439 Summary | Train MSE (x10^-2): 78.5671 | Val MSE (x10^-2): 24.3482 | Time: 35.62s
2025-07-18 02:19:04,774 - logger.py:50 - Epoch: [440][0/6]	Total Loss: 0.85032	Main MSE (x10^-2): 85.0321	LR: 1.55e-05	EMPP_Raw: 1.64459
2025-07-18 02:19:18,775 - logger.py:50 - Epoch: [440][5/6]	Total Loss: 0.76648	Main MSE (x10^-2): 76.6478	LR: 1.55e-05	EMPP_Raw: 1.47967
2025-07-18 02:19:18,818 - logger.py:50 - Epoch 440 Training Summary: Avg Total Loss: 0.76648, Avg Main MSE: 0.76648, Time: 17.07s
2025-07-18 02:19:37,168 - logger.py:50 - Epoch 440 Summary | Train MSE (x10^-2): 76.6478 | Val MSE (x10^-2): 24.3042 | Time: 35.42s
2025-07-18 02:19:40,275 - logger.py:50 - Epoch: [441][0/6]	Total Loss: 0.72491	Main MSE (x10^-2): 72.4912	LR: 1.50e-05	EMPP_Raw: 1.40175
2025-07-18 02:19:54,534 - logger.py:50 - Epoch: [441][5/6]	Total Loss: 0.74746	Main MSE (x10^-2): 74.7460	LR: 1.50e-05	EMPP_Raw: 1.44383
2025-07-18 02:19:54,580 - logger.py:50 - Epoch 441 Training Summary: Avg Total Loss: 0.74746, Avg Main MSE: 0.74746, Time: 17.40s
2025-07-18 02:20:13,064 - logger.py:50 - Epoch 441 Summary | Train MSE (x10^-2): 74.7460 | Val MSE (x10^-2): 24.2603 | Time: 35.89s
2025-07-18 02:20:16,293 - logger.py:50 - Epoch: [442][0/6]	Total Loss: 0.82105	Main MSE (x10^-2): 82.1047	LR: 1.46e-05	EMPP_Raw: 1.58727
2025-07-18 02:20:30,362 - logger.py:50 - Epoch: [442][5/6]	Total Loss: 0.76189	Main MSE (x10^-2): 76.1889	LR: 1.46e-05	EMPP_Raw: 1.47205
2025-07-18 02:20:30,406 - logger.py:50 - Epoch 442 Training Summary: Avg Total Loss: 0.76189, Avg Main MSE: 0.76189, Time: 17.33s
2025-07-18 02:20:48,735 - logger.py:50 - Epoch 442 Summary | Train MSE (x10^-2): 76.1889 | Val MSE (x10^-2): 24.2392 | Time: 35.66s
2025-07-18 02:20:51,880 - logger.py:50 - Epoch: [443][0/6]	Total Loss: 0.76145	Main MSE (x10^-2): 76.1446	LR: 1.41e-05	EMPP_Raw: 1.47467
2025-07-18 02:21:06,112 - logger.py:50 - Epoch: [443][5/6]	Total Loss: 0.76456	Main MSE (x10^-2): 76.4561	LR: 1.41e-05	EMPP_Raw: 1.47889
2025-07-18 02:21:06,158 - logger.py:50 - Epoch 443 Training Summary: Avg Total Loss: 0.76456, Avg Main MSE: 0.76456, Time: 17.41s
2025-07-18 02:21:24,674 - logger.py:50 - Epoch 443 Summary | Train MSE (x10^-2): 76.4561 | Val MSE (x10^-2): 24.1645 | Time: 35.93s
2025-07-18 02:21:27,797 - logger.py:50 - Epoch: [444][0/6]	Total Loss: 0.81598	Main MSE (x10^-2): 81.5977	LR: 1.37e-05	EMPP_Raw: 1.57867
2025-07-18 02:21:42,177 - logger.py:50 - Epoch: [444][5/6]	Total Loss: 0.78987	Main MSE (x10^-2): 78.9869	LR: 1.37e-05	EMPP_Raw: 1.52769
2025-07-18 02:21:42,220 - logger.py:50 - Epoch 444 Training Summary: Avg Total Loss: 0.78987, Avg Main MSE: 0.78987, Time: 17.54s
2025-07-18 02:22:00,887 - logger.py:50 - Epoch 444 Summary | Train MSE (x10^-2): 78.9869 | Val MSE (x10^-2): 24.1562 | Time: 36.21s
2025-07-18 02:22:03,990 - logger.py:50 - Epoch: [445][0/6]	Total Loss: 0.77120	Main MSE (x10^-2): 77.1197	LR: 1.32e-05	EMPP_Raw: 1.48433
2025-07-18 02:22:18,026 - logger.py:50 - Epoch: [445][5/6]	Total Loss: 0.76966	Main MSE (x10^-2): 76.9662	LR: 1.32e-05	EMPP_Raw: 1.48455
2025-07-18 02:22:18,070 - logger.py:50 - Epoch 445 Training Summary: Avg Total Loss: 0.76966, Avg Main MSE: 0.76966, Time: 17.17s
2025-07-18 02:22:36,530 - logger.py:50 - Epoch 445 Summary | Train MSE (x10^-2): 76.9662 | Val MSE (x10^-2): 24.2732 | Time: 35.64s
2025-07-18 02:22:39,650 - logger.py:50 - Epoch: [446][0/6]	Total Loss: 0.72044	Main MSE (x10^-2): 72.0436	LR: 1.28e-05	EMPP_Raw: 1.38401
2025-07-18 02:22:53,795 - logger.py:50 - Epoch: [446][5/6]	Total Loss: 0.77025	Main MSE (x10^-2): 77.0251	LR: 1.28e-05	EMPP_Raw: 1.48940
2025-07-18 02:22:53,839 - logger.py:50 - Epoch 446 Training Summary: Avg Total Loss: 0.77025, Avg Main MSE: 0.77025, Time: 17.30s
2025-07-18 02:23:12,219 - logger.py:50 - Epoch 446 Summary | Train MSE (x10^-2): 77.0251 | Val MSE (x10^-2): 24.2198 | Time: 35.68s
2025-07-18 02:23:15,451 - logger.py:50 - Epoch: [447][0/6]	Total Loss: 0.86527	Main MSE (x10^-2): 86.5268	LR: 1.24e-05	EMPP_Raw: 1.67953
2025-07-18 02:23:29,462 - logger.py:50 - Epoch: [447][5/6]	Total Loss: 0.77578	Main MSE (x10^-2): 77.5778	LR: 1.24e-05	EMPP_Raw: 1.50089
2025-07-18 02:23:29,525 - logger.py:50 - Epoch 447 Training Summary: Avg Total Loss: 0.77578, Avg Main MSE: 0.77578, Time: 17.30s
2025-07-18 02:23:47,795 - logger.py:50 - Epoch 447 Summary | Train MSE (x10^-2): 77.5778 | Val MSE (x10^-2): 24.2661 | Time: 35.57s
2025-07-18 02:23:51,004 - logger.py:50 - Epoch: [448][0/6]	Total Loss: 0.78237	Main MSE (x10^-2): 78.2370	LR: 1.20e-05	EMPP_Raw: 1.51286
2025-07-18 02:24:05,001 - logger.py:50 - Epoch: [448][5/6]	Total Loss: 0.74854	Main MSE (x10^-2): 74.8545	LR: 1.20e-05	EMPP_Raw: 1.44354
2025-07-18 02:24:05,048 - logger.py:50 - Epoch 448 Training Summary: Avg Total Loss: 0.74854, Avg Main MSE: 0.74854, Time: 17.24s
2025-07-18 02:24:41,684 - logger.py:50 - *** New Best Val MSE (x10^-2): 24.1197, Corresponding Test MSE (x10^-2): 25.0317 at Epoch 448 ***
2025-07-18 02:24:41,731 - logger.py:50 - Epoch 448 Summary | Train MSE (x10^-2): 74.8545 | Val MSE (x10^-2): 24.1197 | Time: 53.93s
2025-07-18 02:24:44,913 - logger.py:50 - Epoch: [449][0/6]	Total Loss: 0.73504	Main MSE (x10^-2): 73.5044	LR: 1.16e-05	EMPP_Raw: 1.42332
2025-07-18 02:24:59,130 - logger.py:50 - Epoch: [449][5/6]	Total Loss: 0.77324	Main MSE (x10^-2): 77.3243	LR: 1.16e-05	EMPP_Raw: 1.49742
2025-07-18 02:24:59,169 - logger.py:50 - Epoch 449 Training Summary: Avg Total Loss: 0.77324, Avg Main MSE: 0.77324, Time: 17.43s
2025-07-18 02:25:17,767 - logger.py:50 - Epoch 449 Summary | Train MSE (x10^-2): 77.3243 | Val MSE (x10^-2): 24.1863 | Time: 36.04s
2025-07-18 02:25:20,951 - logger.py:50 - Epoch: [450][0/6]	Total Loss: 0.76851	Main MSE (x10^-2): 76.8506	LR: 1.12e-05	EMPP_Raw: 1.48667
2025-07-18 02:25:34,989 - logger.py:50 - Epoch: [450][5/6]	Total Loss: 0.80180	Main MSE (x10^-2): 80.1798	LR: 1.12e-05	EMPP_Raw: 1.55159
2025-07-18 02:25:35,032 - logger.py:50 - Epoch 450 Training Summary: Avg Total Loss: 0.80180, Avg Main MSE: 0.80180, Time: 17.26s
2025-07-18 02:25:53,310 - logger.py:50 - Epoch 450 Summary | Train MSE (x10^-2): 80.1798 | Val MSE (x10^-2): 24.3286 | Time: 35.54s
2025-07-18 02:25:56,544 - logger.py:50 - Epoch: [451][0/6]	Total Loss: 0.78924	Main MSE (x10^-2): 78.9240	LR: 1.08e-05	EMPP_Raw: 1.52849
2025-07-18 02:26:10,761 - logger.py:50 - Epoch: [451][5/6]	Total Loss: 0.79142	Main MSE (x10^-2): 79.1418	LR: 1.08e-05	EMPP_Raw: 1.53180
2025-07-18 02:26:10,806 - logger.py:50 - Epoch 451 Training Summary: Avg Total Loss: 0.79142, Avg Main MSE: 0.79142, Time: 17.49s
2025-07-18 02:26:29,196 - logger.py:50 - Epoch 451 Summary | Train MSE (x10^-2): 79.1418 | Val MSE (x10^-2): 24.2875 | Time: 35.88s
2025-07-18 02:26:32,305 - logger.py:50 - Epoch: [452][0/6]	Total Loss: 0.80776	Main MSE (x10^-2): 80.7756	LR: 1.04e-05	EMPP_Raw: 1.56655
2025-07-18 02:26:46,617 - logger.py:50 - Epoch: [452][5/6]	Total Loss: 0.77487	Main MSE (x10^-2): 77.4865	LR: 1.04e-05	EMPP_Raw: 1.50027
2025-07-18 02:26:46,663 - logger.py:50 - Epoch 452 Training Summary: Avg Total Loss: 0.77487, Avg Main MSE: 0.77487, Time: 17.46s
2025-07-18 02:27:05,072 - logger.py:50 - Epoch 452 Summary | Train MSE (x10^-2): 77.4865 | Val MSE (x10^-2): 24.3232 | Time: 35.87s
2025-07-18 02:27:08,104 - logger.py:50 - Epoch: [453][0/6]	Total Loss: 0.79139	Main MSE (x10^-2): 79.1391	LR: 1.00e-05	EMPP_Raw: 1.53916
2025-07-18 02:27:22,458 - logger.py:50 - Epoch: [453][5/6]	Total Loss: 0.79763	Main MSE (x10^-2): 79.7631	LR: 1.00e-05	EMPP_Raw: 1.54355
2025-07-18 02:27:22,505 - logger.py:50 - Epoch 453 Training Summary: Avg Total Loss: 0.79763, Avg Main MSE: 0.79763, Time: 17.42s
2025-07-18 02:27:40,850 - logger.py:50 - Epoch 453 Summary | Train MSE (x10^-2): 79.7631 | Val MSE (x10^-2): 24.3158 | Time: 35.77s
2025-07-18 02:27:43,877 - logger.py:50 - Epoch: [454][0/6]	Total Loss: 0.80667	Main MSE (x10^-2): 80.6667	LR: 9.64e-06	EMPP_Raw: 1.56535
2025-07-18 02:27:57,877 - logger.py:50 - Epoch: [454][5/6]	Total Loss: 0.76923	Main MSE (x10^-2): 76.9229	LR: 9.64e-06	EMPP_Raw: 1.48762
2025-07-18 02:27:57,925 - logger.py:50 - Epoch 454 Training Summary: Avg Total Loss: 0.76923, Avg Main MSE: 0.76923, Time: 17.07s
2025-07-18 02:28:16,325 - logger.py:50 - Epoch 454 Summary | Train MSE (x10^-2): 76.9229 | Val MSE (x10^-2): 24.2674 | Time: 35.47s
2025-07-18 02:28:19,373 - logger.py:50 - Epoch: [455][0/6]	Total Loss: 0.81545	Main MSE (x10^-2): 81.5453	LR: 9.27e-06	EMPP_Raw: 1.57902
2025-07-18 02:28:33,460 - logger.py:50 - Epoch: [455][5/6]	Total Loss: 0.78122	Main MSE (x10^-2): 78.1216	LR: 9.27e-06	EMPP_Raw: 1.51099
2025-07-18 02:28:33,503 - logger.py:50 - Epoch 455 Training Summary: Avg Total Loss: 0.78122, Avg Main MSE: 0.78122, Time: 17.17s
2025-07-18 02:28:51,797 - logger.py:50 - Epoch 455 Summary | Train MSE (x10^-2): 78.1216 | Val MSE (x10^-2): 24.2748 | Time: 35.47s
2025-07-18 02:28:55,095 - logger.py:50 - Epoch: [456][0/6]	Total Loss: 0.76679	Main MSE (x10^-2): 76.6787	LR: 8.92e-06	EMPP_Raw: 1.48426
2025-07-18 02:29:09,185 - logger.py:50 - Epoch: [456][5/6]	Total Loss: 0.75442	Main MSE (x10^-2): 75.4416	LR: 8.92e-06	EMPP_Raw: 1.45965
2025-07-18 02:29:09,233 - logger.py:50 - Epoch 456 Training Summary: Avg Total Loss: 0.75442, Avg Main MSE: 0.75442, Time: 17.43s
2025-07-18 02:29:27,715 - logger.py:50 - Epoch 456 Summary | Train MSE (x10^-2): 75.4416 | Val MSE (x10^-2): 24.2183 | Time: 35.91s
2025-07-18 02:29:30,923 - logger.py:50 - Epoch: [457][0/6]	Total Loss: 0.88774	Main MSE (x10^-2): 88.7742	LR: 8.58e-06	EMPP_Raw: 1.72207
2025-07-18 02:29:44,979 - logger.py:50 - Epoch: [457][5/6]	Total Loss: 0.76811	Main MSE (x10^-2): 76.8113	LR: 8.58e-06	EMPP_Raw: 1.48606
2025-07-18 02:29:45,022 - logger.py:50 - Epoch 457 Training Summary: Avg Total Loss: 0.76811, Avg Main MSE: 0.76811, Time: 17.30s
2025-07-18 02:30:03,315 - logger.py:50 - Epoch 457 Summary | Train MSE (x10^-2): 76.8113 | Val MSE (x10^-2): 24.1802 | Time: 35.59s
2025-07-18 02:30:06,354 - logger.py:50 - Epoch: [458][0/6]	Total Loss: 0.81858	Main MSE (x10^-2): 81.8584	LR: 8.24e-06	EMPP_Raw: 1.58388
2025-07-18 02:30:20,675 - logger.py:50 - Epoch: [458][5/6]	Total Loss: 0.79455	Main MSE (x10^-2): 79.4549	LR: 8.24e-06	EMPP_Raw: 1.53852
2025-07-18 02:30:20,714 - logger.py:50 - Epoch 458 Training Summary: Avg Total Loss: 0.79455, Avg Main MSE: 0.79455, Time: 17.39s
2025-07-18 02:30:39,082 - logger.py:50 - Epoch 458 Summary | Train MSE (x10^-2): 79.4549 | Val MSE (x10^-2): 24.1932 | Time: 35.76s
2025-07-18 02:30:42,218 - logger.py:50 - Epoch: [459][0/6]	Total Loss: 0.80154	Main MSE (x10^-2): 80.1537	LR: 7.91e-06	EMPP_Raw: 1.55399
2025-07-18 02:30:56,644 - logger.py:50 - Epoch: [459][5/6]	Total Loss: 0.79978	Main MSE (x10^-2): 79.9776	LR: 7.91e-06	EMPP_Raw: 1.55109
2025-07-18 02:30:56,689 - logger.py:50 - Epoch 459 Training Summary: Avg Total Loss: 0.79978, Avg Main MSE: 0.79978, Time: 17.60s
2025-07-18 02:31:15,094 - logger.py:50 - Epoch 459 Summary | Train MSE (x10^-2): 79.9776 | Val MSE (x10^-2): 24.1624 | Time: 36.01s
2025-07-18 02:31:18,188 - logger.py:50 - Epoch: [460][0/6]	Total Loss: 0.74928	Main MSE (x10^-2): 74.9282	LR: 7.58e-06	EMPP_Raw: 1.44362
2025-07-18 02:31:32,282 - logger.py:50 - Epoch: [460][5/6]	Total Loss: 0.78672	Main MSE (x10^-2): 78.6721	LR: 7.58e-06	EMPP_Raw: 1.52372
2025-07-18 02:31:32,326 - logger.py:50 - Epoch 460 Training Summary: Avg Total Loss: 0.78672, Avg Main MSE: 0.78672, Time: 17.22s
2025-07-18 02:31:50,858 - logger.py:50 - Epoch 460 Summary | Train MSE (x10^-2): 78.6721 | Val MSE (x10^-2): 24.2716 | Time: 35.76s
2025-07-18 02:31:53,929 - logger.py:50 - Epoch: [461][0/6]	Total Loss: 0.79826	Main MSE (x10^-2): 79.8262	LR: 7.27e-06	EMPP_Raw: 1.54541
2025-07-18 02:32:08,085 - logger.py:50 - Epoch: [461][5/6]	Total Loss: 0.76651	Main MSE (x10^-2): 76.6510	LR: 7.27e-06	EMPP_Raw: 1.48200
2025-07-18 02:32:08,131 - logger.py:50 - Epoch 461 Training Summary: Avg Total Loss: 0.76651, Avg Main MSE: 0.76651, Time: 17.26s
2025-07-18 02:32:26,493 - logger.py:50 - Epoch 461 Summary | Train MSE (x10^-2): 76.6510 | Val MSE (x10^-2): 24.2503 | Time: 35.63s
2025-07-18 02:32:29,554 - logger.py:50 - Epoch: [462][0/6]	Total Loss: 0.81018	Main MSE (x10^-2): 81.0176	LR: 6.96e-06	EMPP_Raw: 1.56931
2025-07-18 02:32:43,637 - logger.py:50 - Epoch: [462][5/6]	Total Loss: 0.78614	Main MSE (x10^-2): 78.6143	LR: 6.96e-06	EMPP_Raw: 1.52195
2025-07-18 02:32:43,681 - logger.py:50 - Epoch 462 Training Summary: Avg Total Loss: 0.78614, Avg Main MSE: 0.78614, Time: 17.18s
2025-07-18 02:33:02,021 - logger.py:50 - Epoch 462 Summary | Train MSE (x10^-2): 78.6143 | Val MSE (x10^-2): 24.1516 | Time: 35.52s
2025-07-18 02:33:05,431 - logger.py:50 - Epoch: [463][0/6]	Total Loss: 0.70833	Main MSE (x10^-2): 70.8325	LR: 6.66e-06	EMPP_Raw: 1.36468
2025-07-18 02:33:19,564 - logger.py:50 - Epoch: [463][5/6]	Total Loss: 0.76994	Main MSE (x10^-2): 76.9942	LR: 6.66e-06	EMPP_Raw: 1.49064
2025-07-18 02:33:19,621 - logger.py:50 - Epoch 463 Training Summary: Avg Total Loss: 0.76994, Avg Main MSE: 0.76994, Time: 17.59s
2025-07-18 02:33:38,095 - logger.py:50 - Epoch 463 Summary | Train MSE (x10^-2): 76.9942 | Val MSE (x10^-2): 24.1613 | Time: 36.07s
2025-07-18 02:33:41,136 - logger.py:50 - Epoch: [464][0/6]	Total Loss: 0.78449	Main MSE (x10^-2): 78.4490	LR: 6.37e-06	EMPP_Raw: 1.51624
2025-07-18 02:33:55,181 - logger.py:50 - Epoch: [464][5/6]	Total Loss: 0.79136	Main MSE (x10^-2): 79.1356	LR: 6.37e-06	EMPP_Raw: 1.53116
2025-07-18 02:33:55,234 - logger.py:50 - Epoch 464 Training Summary: Avg Total Loss: 0.79136, Avg Main MSE: 0.79136, Time: 17.13s
2025-07-18 02:34:13,552 - logger.py:50 - Epoch 464 Summary | Train MSE (x10^-2): 79.1356 | Val MSE (x10^-2): 24.2140 | Time: 35.46s
2025-07-18 02:34:16,778 - logger.py:50 - Epoch: [465][0/6]	Total Loss: 0.81599	Main MSE (x10^-2): 81.5989	LR: 6.08e-06	EMPP_Raw: 1.58642
2025-07-18 02:34:30,897 - logger.py:50 - Epoch: [465][5/6]	Total Loss: 0.80359	Main MSE (x10^-2): 80.3594	LR: 6.08e-06	EMPP_Raw: 1.55593
2025-07-18 02:34:30,938 - logger.py:50 - Epoch 465 Training Summary: Avg Total Loss: 0.80359, Avg Main MSE: 0.80359, Time: 17.38s
2025-07-18 02:34:49,344 - logger.py:50 - Epoch 465 Summary | Train MSE (x10^-2): 80.3594 | Val MSE (x10^-2): 24.2155 | Time: 35.79s
2025-07-18 02:34:52,395 - logger.py:50 - Epoch: [466][0/6]	Total Loss: 0.75910	Main MSE (x10^-2): 75.9102	LR: 5.80e-06	EMPP_Raw: 1.46844
2025-07-18 02:35:07,020 - logger.py:50 - Epoch: [466][5/6]	Total Loss: 0.76757	Main MSE (x10^-2): 76.7573	LR: 5.80e-06	EMPP_Raw: 1.48499
2025-07-18 02:35:07,068 - logger.py:50 - Epoch 466 Training Summary: Avg Total Loss: 0.76757, Avg Main MSE: 0.76757, Time: 17.71s
2025-07-18 02:35:25,661 - logger.py:50 - Epoch 466 Summary | Train MSE (x10^-2): 76.7573 | Val MSE (x10^-2): 24.1505 | Time: 36.31s
2025-07-18 02:35:28,715 - logger.py:50 - Epoch: [467][0/6]	Total Loss: 0.73438	Main MSE (x10^-2): 73.4379	LR: 5.54e-06	EMPP_Raw: 1.42095
2025-07-18 02:35:43,011 - logger.py:50 - Epoch: [467][5/6]	Total Loss: 0.77814	Main MSE (x10^-2): 77.8135	LR: 5.54e-06	EMPP_Raw: 1.50749
2025-07-18 02:35:43,060 - logger.py:50 - Epoch 467 Training Summary: Avg Total Loss: 0.77814, Avg Main MSE: 0.77814, Time: 17.39s
2025-07-18 02:36:01,355 - logger.py:50 - Epoch 467 Summary | Train MSE (x10^-2): 77.8135 | Val MSE (x10^-2): 24.1781 | Time: 35.69s
2025-07-18 02:36:04,417 - logger.py:50 - Epoch: [468][0/6]	Total Loss: 0.73713	Main MSE (x10^-2): 73.7132	LR: 5.27e-06	EMPP_Raw: 1.42720
2025-07-18 02:36:18,453 - logger.py:50 - Epoch: [468][5/6]	Total Loss: 0.77951	Main MSE (x10^-2): 77.9513	LR: 5.27e-06	EMPP_Raw: 1.50922
2025-07-18 02:36:18,498 - logger.py:50 - Epoch 468 Training Summary: Avg Total Loss: 0.77951, Avg Main MSE: 0.77951, Time: 17.13s
2025-07-18 02:36:36,946 - logger.py:50 - Epoch 468 Summary | Train MSE (x10^-2): 77.9513 | Val MSE (x10^-2): 24.2431 | Time: 35.59s
2025-07-18 02:36:39,985 - logger.py:50 - Epoch: [469][0/6]	Total Loss: 0.72945	Main MSE (x10^-2): 72.9450	LR: 5.02e-06	EMPP_Raw: 1.41100
2025-07-18 02:36:54,033 - logger.py:50 - Epoch: [469][5/6]	Total Loss: 0.78561	Main MSE (x10^-2): 78.5610	LR: 5.02e-06	EMPP_Raw: 1.51931
2025-07-18 02:36:54,078 - logger.py:50 - Epoch 469 Training Summary: Avg Total Loss: 0.78561, Avg Main MSE: 0.78561, Time: 17.12s
2025-07-18 02:37:12,582 - logger.py:50 - Epoch 469 Summary | Train MSE (x10^-2): 78.5610 | Val MSE (x10^-2): 24.2143 | Time: 35.63s
2025-07-18 02:37:15,620 - logger.py:50 - Epoch: [470][0/6]	Total Loss: 0.84739	Main MSE (x10^-2): 84.7394	LR: 4.77e-06	EMPP_Raw: 1.64580
2025-07-18 02:37:29,764 - logger.py:50 - Epoch: [470][5/6]	Total Loss: 0.77975	Main MSE (x10^-2): 77.9753	LR: 4.77e-06	EMPP_Raw: 1.50842
2025-07-18 02:37:29,816 - logger.py:50 - Epoch 470 Training Summary: Avg Total Loss: 0.77975, Avg Main MSE: 0.77975, Time: 17.22s
2025-07-18 02:37:48,149 - logger.py:50 - Epoch 470 Summary | Train MSE (x10^-2): 77.9753 | Val MSE (x10^-2): 24.1367 | Time: 35.56s
2025-07-18 02:37:51,341 - logger.py:50 - Epoch: [471][0/6]	Total Loss: 0.81967	Main MSE (x10^-2): 81.9673	LR: 4.53e-06	EMPP_Raw: 1.58818
2025-07-18 02:38:05,484 - logger.py:50 - Epoch: [471][5/6]	Total Loss: 0.75428	Main MSE (x10^-2): 75.4284	LR: 4.53e-06	EMPP_Raw: 1.45977
2025-07-18 02:38:05,529 - logger.py:50 - Epoch 471 Training Summary: Avg Total Loss: 0.75428, Avg Main MSE: 0.75428, Time: 17.37s
2025-07-18 02:38:42,351 - logger.py:50 - *** New Best Val MSE (x10^-2): 24.1088, Corresponding Test MSE (x10^-2): 24.9808 at Epoch 471 ***
2025-07-18 02:38:42,403 - logger.py:50 - Epoch 471 Summary | Train MSE (x10^-2): 75.4284 | Val MSE (x10^-2): 24.1088 | Time: 54.25s
2025-07-18 02:38:45,840 - logger.py:50 - Epoch: [472][0/6]	Total Loss: 0.73008	Main MSE (x10^-2): 73.0082	LR: 4.30e-06	EMPP_Raw: 1.41299
2025-07-18 02:38:59,931 - logger.py:50 - Epoch: [472][5/6]	Total Loss: 0.76315	Main MSE (x10^-2): 76.3147	LR: 4.30e-06	EMPP_Raw: 1.47688
2025-07-18 02:38:59,983 - logger.py:50 - Epoch 472 Training Summary: Avg Total Loss: 0.76315, Avg Main MSE: 0.76315, Time: 17.58s
2025-07-18 02:39:18,793 - logger.py:50 - Epoch 472 Summary | Train MSE (x10^-2): 76.3147 | Val MSE (x10^-2): 24.1667 | Time: 36.39s
2025-07-18 02:39:21,830 - logger.py:50 - Epoch: [473][0/6]	Total Loss: 0.73135	Main MSE (x10^-2): 73.1345	LR: 4.08e-06	EMPP_Raw: 1.40953
2025-07-18 02:39:35,899 - logger.py:50 - Epoch: [473][5/6]	Total Loss: 0.76102	Main MSE (x10^-2): 76.1019	LR: 4.08e-06	EMPP_Raw: 1.47210
2025-07-18 02:39:35,940 - logger.py:50 - Epoch 473 Training Summary: Avg Total Loss: 0.76102, Avg Main MSE: 0.76102, Time: 17.14s
2025-07-18 02:39:54,367 - logger.py:50 - Epoch 473 Summary | Train MSE (x10^-2): 76.1019 | Val MSE (x10^-2): 24.2273 | Time: 35.57s
2025-07-18 02:39:57,559 - logger.py:50 - Epoch: [474][0/6]	Total Loss: 0.81367	Main MSE (x10^-2): 81.3672	LR: 3.86e-06	EMPP_Raw: 1.57977
2025-07-18 02:40:11,595 - logger.py:50 - Epoch: [474][5/6]	Total Loss: 0.76726	Main MSE (x10^-2): 76.7261	LR: 3.86e-06	EMPP_Raw: 1.48442
2025-07-18 02:40:11,640 - logger.py:50 - Epoch 474 Training Summary: Avg Total Loss: 0.76726, Avg Main MSE: 0.76726, Time: 17.26s
2025-07-18 02:40:30,083 - logger.py:50 - Epoch 474 Summary | Train MSE (x10^-2): 76.7261 | Val MSE (x10^-2): 24.2199 | Time: 35.71s
2025-07-18 02:40:33,148 - logger.py:50 - Epoch: [475][0/6]	Total Loss: 0.77182	Main MSE (x10^-2): 77.1825	LR: 3.66e-06	EMPP_Raw: 1.49285
2025-07-18 02:40:47,612 - logger.py:50 - Epoch: [475][5/6]	Total Loss: 0.77163	Main MSE (x10^-2): 77.1632	LR: 3.66e-06	EMPP_Raw: 1.49453
2025-07-18 02:40:47,658 - logger.py:50 - Epoch 475 Training Summary: Avg Total Loss: 0.77163, Avg Main MSE: 0.77163, Time: 17.57s
2025-07-18 02:41:05,989 - logger.py:50 - Epoch 475 Summary | Train MSE (x10^-2): 77.1632 | Val MSE (x10^-2): 24.1928 | Time: 35.90s
2025-07-18 02:41:09,068 - logger.py:50 - Epoch: [476][0/6]	Total Loss: 0.79254	Main MSE (x10^-2): 79.2537	LR: 3.46e-06	EMPP_Raw: 1.53434
2025-07-18 02:41:23,271 - logger.py:50 - Epoch: [476][5/6]	Total Loss: 0.78279	Main MSE (x10^-2): 78.2793	LR: 3.46e-06	EMPP_Raw: 1.51586
2025-07-18 02:41:23,315 - logger.py:50 - Epoch 476 Training Summary: Avg Total Loss: 0.78279, Avg Main MSE: 0.78279, Time: 17.32s
2025-07-18 02:41:41,665 - logger.py:50 - Epoch 476 Summary | Train MSE (x10^-2): 78.2793 | Val MSE (x10^-2): 24.1738 | Time: 35.67s
2025-07-18 02:41:44,714 - logger.py:50 - Epoch: [477][0/6]	Total Loss: 0.77629	Main MSE (x10^-2): 77.6293	LR: 3.26e-06	EMPP_Raw: 1.49954
2025-07-18 02:41:58,828 - logger.py:50 - Epoch: [477][5/6]	Total Loss: 0.75870	Main MSE (x10^-2): 75.8700	LR: 3.26e-06	EMPP_Raw: 1.46859
2025-07-18 02:41:58,871 - logger.py:50 - Epoch 477 Training Summary: Avg Total Loss: 0.75870, Avg Main MSE: 0.75870, Time: 17.20s
2025-07-18 02:42:17,421 - logger.py:50 - Epoch 477 Summary | Train MSE (x10^-2): 75.8700 | Val MSE (x10^-2): 24.1710 | Time: 35.75s
2025-07-18 02:42:20,463 - logger.py:50 - Epoch: [478][0/6]	Total Loss: 0.70042	Main MSE (x10^-2): 70.0418	LR: 3.08e-06	EMPP_Raw: 1.35201
2025-07-18 02:42:34,519 - logger.py:50 - Epoch: [478][5/6]	Total Loss: 0.76674	Main MSE (x10^-2): 76.6738	LR: 3.08e-06	EMPP_Raw: 1.48264
2025-07-18 02:42:34,558 - logger.py:50 - Epoch 478 Training Summary: Avg Total Loss: 0.76674, Avg Main MSE: 0.76674, Time: 17.13s
2025-07-18 02:42:53,027 - logger.py:50 - Epoch 478 Summary | Train MSE (x10^-2): 76.6738 | Val MSE (x10^-2): 24.2142 | Time: 35.60s
2025-07-18 02:42:56,145 - logger.py:50 - Epoch: [479][0/6]	Total Loss: 0.86069	Main MSE (x10^-2): 86.0691	LR: 2.90e-06	EMPP_Raw: 1.67025
2025-07-18 02:43:10,284 - logger.py:50 - Epoch: [479][5/6]	Total Loss: 0.77866	Main MSE (x10^-2): 77.8662	LR: 2.90e-06	EMPP_Raw: 1.50933
2025-07-18 02:43:10,329 - logger.py:50 - Epoch 479 Training Summary: Avg Total Loss: 0.77866, Avg Main MSE: 0.77866, Time: 17.29s
2025-07-18 02:43:28,666 - logger.py:50 - Epoch 479 Summary | Train MSE (x10^-2): 77.8662 | Val MSE (x10^-2): 24.2701 | Time: 35.63s
2025-07-18 02:43:31,899 - logger.py:50 - Epoch: [480][0/6]	Total Loss: 0.79144	Main MSE (x10^-2): 79.1444	LR: 2.73e-06	EMPP_Raw: 1.53275
2025-07-18 02:43:45,891 - logger.py:50 - Epoch: [480][5/6]	Total Loss: 0.78239	Main MSE (x10^-2): 78.2388	LR: 2.73e-06	EMPP_Raw: 1.51459
2025-07-18 02:43:45,932 - logger.py:50 - Epoch 480 Training Summary: Avg Total Loss: 0.78239, Avg Main MSE: 0.78239, Time: 17.26s
2025-07-18 02:44:04,295 - logger.py:50 - Epoch 480 Summary | Train MSE (x10^-2): 78.2388 | Val MSE (x10^-2): 24.2459 | Time: 35.62s
2025-07-18 02:44:07,337 - logger.py:50 - Epoch: [481][0/6]	Total Loss: 0.73970	Main MSE (x10^-2): 73.9698	LR: 2.57e-06	EMPP_Raw: 1.43532
2025-07-18 02:44:21,524 - logger.py:50 - Epoch: [481][5/6]	Total Loss: 0.79057	Main MSE (x10^-2): 79.0571	LR: 2.57e-06	EMPP_Raw: 1.53207
2025-07-18 02:44:21,569 - logger.py:50 - Epoch 481 Training Summary: Avg Total Loss: 0.79057, Avg Main MSE: 0.79057, Time: 17.26s
2025-07-18 02:44:39,880 - logger.py:50 - Epoch 481 Summary | Train MSE (x10^-2): 79.0571 | Val MSE (x10^-2): 24.2092 | Time: 35.58s
2025-07-18 02:44:42,928 - logger.py:50 - Epoch: [482][0/6]	Total Loss: 0.76060	Main MSE (x10^-2): 76.0604	LR: 2.42e-06	EMPP_Raw: 1.47221
2025-07-18 02:44:57,231 - logger.py:50 - Epoch: [482][5/6]	Total Loss: 0.78298	Main MSE (x10^-2): 78.2983	LR: 2.42e-06	EMPP_Raw: 1.51608
2025-07-18 02:44:57,274 - logger.py:50 - Epoch 482 Training Summary: Avg Total Loss: 0.78298, Avg Main MSE: 0.78298, Time: 17.38s
2025-07-18 02:45:15,591 - logger.py:50 - Epoch 482 Summary | Train MSE (x10^-2): 78.2983 | Val MSE (x10^-2): 24.2150 | Time: 35.70s
2025-07-18 02:45:18,637 - logger.py:50 - Epoch: [483][0/6]	Total Loss: 0.76283	Main MSE (x10^-2): 76.2831	LR: 2.27e-06	EMPP_Raw: 1.47805
2025-07-18 02:45:32,685 - logger.py:50 - Epoch: [483][5/6]	Total Loss: 0.77244	Main MSE (x10^-2): 77.2435	LR: 2.27e-06	EMPP_Raw: 1.49514
2025-07-18 02:45:32,727 - logger.py:50 - Epoch 483 Training Summary: Avg Total Loss: 0.77244, Avg Main MSE: 0.77244, Time: 17.13s
2025-07-18 02:45:51,247 - logger.py:50 - Epoch 483 Summary | Train MSE (x10^-2): 77.2435 | Val MSE (x10^-2): 24.2486 | Time: 35.65s
2025-07-18 02:45:54,312 - logger.py:50 - Epoch: [484][0/6]	Total Loss: 0.78091	Main MSE (x10^-2): 78.0907	LR: 2.14e-06	EMPP_Raw: 1.50915
2025-07-18 02:46:08,355 - logger.py:50 - Epoch: [484][5/6]	Total Loss: 0.78210	Main MSE (x10^-2): 78.2098	LR: 2.14e-06	EMPP_Raw: 1.51360
2025-07-18 02:46:08,402 - logger.py:50 - Epoch 484 Training Summary: Avg Total Loss: 0.78210, Avg Main MSE: 0.78210, Time: 17.14s
2025-07-18 02:46:26,815 - logger.py:50 - Epoch 484 Summary | Train MSE (x10^-2): 78.2098 | Val MSE (x10^-2): 24.2369 | Time: 35.56s
2025-07-18 02:46:29,850 - logger.py:50 - Epoch: [485][0/6]	Total Loss: 0.80023	Main MSE (x10^-2): 80.0232	LR: 2.01e-06	EMPP_Raw: 1.54856
2025-07-18 02:46:43,889 - logger.py:50 - Epoch: [485][5/6]	Total Loss: 0.76584	Main MSE (x10^-2): 76.5844	LR: 2.01e-06	EMPP_Raw: 1.48237
2025-07-18 02:46:43,932 - logger.py:50 - Epoch 485 Training Summary: Avg Total Loss: 0.76584, Avg Main MSE: 0.76584, Time: 17.11s
2025-07-18 02:47:02,330 - logger.py:50 - Epoch 485 Summary | Train MSE (x10^-2): 76.5844 | Val MSE (x10^-2): 24.1959 | Time: 35.51s
2025-07-18 02:47:05,627 - logger.py:50 - Epoch: [486][0/6]	Total Loss: 0.79386	Main MSE (x10^-2): 79.3855	LR: 1.89e-06	EMPP_Raw: 1.53851
2025-07-18 02:47:19,680 - logger.py:50 - Epoch: [486][5/6]	Total Loss: 0.79649	Main MSE (x10^-2): 79.6491	LR: 1.89e-06	EMPP_Raw: 1.54292
2025-07-18 02:47:19,725 - logger.py:50 - Epoch 486 Training Summary: Avg Total Loss: 0.79649, Avg Main MSE: 0.79649, Time: 17.39s
2025-07-18 02:47:38,063 - logger.py:50 - Epoch 486 Summary | Train MSE (x10^-2): 79.6491 | Val MSE (x10^-2): 24.1911 | Time: 35.73s
2025-07-18 02:47:41,132 - logger.py:50 - Epoch: [487][0/6]	Total Loss: 0.74416	Main MSE (x10^-2): 74.4158	LR: 1.77e-06	EMPP_Raw: 1.43338
2025-07-18 02:47:55,307 - logger.py:50 - Epoch: [487][5/6]	Total Loss: 0.79066	Main MSE (x10^-2): 79.0664	LR: 1.77e-06	EMPP_Raw: 1.53133
2025-07-18 02:47:55,349 - logger.py:50 - Epoch 487 Training Summary: Avg Total Loss: 0.79066, Avg Main MSE: 0.79066, Time: 17.28s
2025-07-18 02:48:13,786 - logger.py:50 - Epoch 487 Summary | Train MSE (x10^-2): 79.0664 | Val MSE (x10^-2): 24.2145 | Time: 35.72s
2025-07-18 02:48:16,863 - logger.py:50 - Epoch: [488][0/6]	Total Loss: 0.76597	Main MSE (x10^-2): 76.5967	LR: 1.67e-06	EMPP_Raw: 1.48131
2025-07-18 02:48:31,120 - logger.py:50 - Epoch: [488][5/6]	Total Loss: 0.78494	Main MSE (x10^-2): 78.4938	LR: 1.67e-06	EMPP_Raw: 1.52058
2025-07-18 02:48:31,163 - logger.py:50 - Epoch 488 Training Summary: Avg Total Loss: 0.78494, Avg Main MSE: 0.78494, Time: 17.37s
2025-07-18 02:48:49,449 - logger.py:50 - Epoch 488 Summary | Train MSE (x10^-2): 78.4938 | Val MSE (x10^-2): 24.2147 | Time: 35.66s
2025-07-18 02:48:52,490 - logger.py:50 - Epoch: [489][0/6]	Total Loss: 0.75849	Main MSE (x10^-2): 75.8488	LR: 1.57e-06	EMPP_Raw: 1.46469
2025-07-18 02:49:06,559 - logger.py:50 - Epoch: [489][5/6]	Total Loss: 0.77527	Main MSE (x10^-2): 77.5267	LR: 1.57e-06	EMPP_Raw: 1.50044
2025-07-18 02:49:06,599 - logger.py:50 - Epoch 489 Training Summary: Avg Total Loss: 0.77527, Avg Main MSE: 0.77527, Time: 17.14s
2025-07-18 02:49:25,154 - logger.py:50 - Epoch 489 Summary | Train MSE (x10^-2): 77.5267 | Val MSE (x10^-2): 24.2080 | Time: 35.70s
2025-07-18 02:49:28,227 - logger.py:50 - Epoch: [490][0/6]	Total Loss: 0.81975	Main MSE (x10^-2): 81.9753	LR: 1.48e-06	EMPP_Raw: 1.59094
2025-07-18 02:49:42,291 - logger.py:50 - Epoch: [490][5/6]	Total Loss: 0.77687	Main MSE (x10^-2): 77.6867	LR: 1.48e-06	EMPP_Raw: 1.50189
2025-07-18 02:49:42,332 - logger.py:50 - Epoch 490 Training Summary: Avg Total Loss: 0.77687, Avg Main MSE: 0.77687, Time: 17.17s
2025-07-18 02:50:00,661 - logger.py:50 - Epoch 490 Summary | Train MSE (x10^-2): 77.6867 | Val MSE (x10^-2): 24.1921 | Time: 35.51s
2025-07-18 02:50:03,852 - logger.py:50 - Epoch: [491][0/6]	Total Loss: 0.74342	Main MSE (x10^-2): 74.3424	LR: 1.39e-06	EMPP_Raw: 1.44227
2025-07-18 02:50:18,067 - logger.py:50 - Epoch: [491][5/6]	Total Loss: 0.77274	Main MSE (x10^-2): 77.2739	LR: 1.39e-06	EMPP_Raw: 1.49860
2025-07-18 02:50:18,112 - logger.py:50 - Epoch 491 Training Summary: Avg Total Loss: 0.77274, Avg Main MSE: 0.77274, Time: 17.44s
2025-07-18 02:50:36,453 - logger.py:50 - Epoch 491 Summary | Train MSE (x10^-2): 77.2739 | Val MSE (x10^-2): 24.1849 | Time: 35.79s
2025-07-18 02:50:39,665 - logger.py:50 - Epoch: [492][0/6]	Total Loss: 0.74668	Main MSE (x10^-2): 74.6684	LR: 1.32e-06	EMPP_Raw: 1.44469
2025-07-18 02:50:53,736 - logger.py:50 - Epoch: [492][5/6]	Total Loss: 0.77600	Main MSE (x10^-2): 77.5998	LR: 1.32e-06	EMPP_Raw: 1.50203
2025-07-18 02:50:53,786 - logger.py:50 - Epoch 492 Training Summary: Avg Total Loss: 0.77600, Avg Main MSE: 0.77600, Time: 17.33s
2025-07-18 02:51:12,120 - logger.py:50 - Epoch 492 Summary | Train MSE (x10^-2): 77.5998 | Val MSE (x10^-2): 24.1858 | Time: 35.67s
2025-07-18 02:51:15,165 - logger.py:50 - Epoch: [493][0/6]	Total Loss: 0.80649	Main MSE (x10^-2): 80.6486	LR: 1.25e-06	EMPP_Raw: 1.56206
2025-07-18 02:51:29,376 - logger.py:50 - Epoch: [493][5/6]	Total Loss: 0.75455	Main MSE (x10^-2): 75.4547	LR: 1.25e-06	EMPP_Raw: 1.46011
2025-07-18 02:51:29,416 - logger.py:50 - Epoch 493 Training Summary: Avg Total Loss: 0.75455, Avg Main MSE: 0.75455, Time: 17.29s
2025-07-18 02:51:47,916 - logger.py:50 - Epoch 493 Summary | Train MSE (x10^-2): 75.4547 | Val MSE (x10^-2): 24.1997 | Time: 35.79s
2025-07-18 02:51:50,951 - logger.py:50 - Epoch: [494][0/6]	Total Loss: 0.71530	Main MSE (x10^-2): 71.5299	LR: 1.19e-06	EMPP_Raw: 1.37697
2025-07-18 02:52:05,134 - logger.py:50 - Epoch: [494][5/6]	Total Loss: 0.75145	Main MSE (x10^-2): 75.1452	LR: 1.19e-06	EMPP_Raw: 1.45297
2025-07-18 02:52:05,181 - logger.py:50 - Epoch 494 Training Summary: Avg Total Loss: 0.75145, Avg Main MSE: 0.75145, Time: 17.26s
2025-07-18 02:52:23,599 - logger.py:50 - Epoch 494 Summary | Train MSE (x10^-2): 75.1452 | Val MSE (x10^-2): 24.2043 | Time: 35.68s
2025-07-18 02:52:26,637 - logger.py:50 - Epoch: [495][0/6]	Total Loss: 0.75297	Main MSE (x10^-2): 75.2974	LR: 1.14e-06	EMPP_Raw: 1.45655
2025-07-18 02:52:40,667 - logger.py:50 - Epoch: [495][5/6]	Total Loss: 0.75972	Main MSE (x10^-2): 75.9717	LR: 1.14e-06	EMPP_Raw: 1.46976
2025-07-18 02:52:40,711 - logger.py:50 - Epoch 495 Training Summary: Avg Total Loss: 0.75972, Avg Main MSE: 0.75972, Time: 17.10s
2025-07-18 02:52:59,238 - logger.py:50 - Epoch 495 Summary | Train MSE (x10^-2): 75.9717 | Val MSE (x10^-2): 24.2034 | Time: 35.63s
2025-07-18 02:53:02,296 - logger.py:50 - Epoch: [496][0/6]	Total Loss: 0.73836	Main MSE (x10^-2): 73.8357	LR: 1.10e-06	EMPP_Raw: 1.42972
2025-07-18 02:53:16,364 - logger.py:50 - Epoch: [496][5/6]	Total Loss: 0.76851	Main MSE (x10^-2): 76.8507	LR: 1.10e-06	EMPP_Raw: 1.48745
2025-07-18 02:53:16,404 - logger.py:50 - Epoch 496 Training Summary: Avg Total Loss: 0.76851, Avg Main MSE: 0.76851, Time: 17.16s
2025-07-18 02:53:34,858 - logger.py:50 - Epoch 496 Summary | Train MSE (x10^-2): 76.8507 | Val MSE (x10^-2): 24.2134 | Time: 35.61s
2025-07-18 02:53:37,937 - logger.py:50 - Epoch: [497][0/6]	Total Loss: 0.78418	Main MSE (x10^-2): 78.4176	LR: 1.06e-06	EMPP_Raw: 1.52077
2025-07-18 02:53:51,970 - logger.py:50 - Epoch: [497][5/6]	Total Loss: 0.78712	Main MSE (x10^-2): 78.7118	LR: 1.06e-06	EMPP_Raw: 1.52563
2025-07-18 02:53:52,025 - logger.py:50 - Epoch 497 Training Summary: Avg Total Loss: 0.78712, Avg Main MSE: 0.78712, Time: 17.16s
2025-07-18 02:54:10,401 - logger.py:50 - Epoch 497 Summary | Train MSE (x10^-2): 78.7118 | Val MSE (x10^-2): 24.2200 | Time: 35.54s
2025-07-18 02:54:13,819 - logger.py:50 - Epoch: [498][0/6]	Total Loss: 0.77511	Main MSE (x10^-2): 77.5107	LR: 1.04e-06	EMPP_Raw: 1.50217
2025-07-18 02:54:27,832 - logger.py:50 - Epoch: [498][5/6]	Total Loss: 0.75470	Main MSE (x10^-2): 75.4705	LR: 1.04e-06	EMPP_Raw: 1.45880
2025-07-18 02:54:27,892 - logger.py:50 - Epoch 498 Training Summary: Avg Total Loss: 0.75470, Avg Main MSE: 0.75470, Time: 17.48s
2025-07-18 02:54:46,340 - logger.py:50 - Epoch 498 Summary | Train MSE (x10^-2): 75.4705 | Val MSE (x10^-2): 24.2316 | Time: 35.93s
2025-07-18 02:54:49,367 - logger.py:50 - Epoch: [499][0/6]	Total Loss: 0.82045	Main MSE (x10^-2): 82.0446	LR: 1.02e-06	EMPP_Raw: 1.59202
2025-07-18 02:55:03,381 - logger.py:50 - Epoch: [499][5/6]	Total Loss: 0.77782	Main MSE (x10^-2): 77.7822	LR: 1.02e-06	EMPP_Raw: 1.50584
2025-07-18 02:55:03,421 - logger.py:50 - Epoch 499 Training Summary: Avg Total Loss: 0.77782, Avg Main MSE: 0.77782, Time: 17.07s
2025-07-18 02:55:21,729 - logger.py:50 - Epoch 499 Summary | Train MSE (x10^-2): 77.7822 | Val MSE (x10^-2): 24.2281 | Time: 35.39s
2025-07-18 02:55:21,735 - logger.py:50 - --- Finished training for benzene ---
2025-07-18 02:55:21,736 - logger.py:50 - Final Best Val MSE (at Epoch 471): 0.241088 (x10^-2: 24.1088)
2025-07-18 02:55:21,736 - logger.py:50 - Final Test MSE (at Best Val Epoch): 0.249808 (x10^-2: 24.9808)
2025-07-18 02:55:21,748 - logger.py:50 - --- Starting training for ethanol ---
2025-07-18 02:55:21,748 - logger.py:50 - Namespace(amp=False, batch_size=80, clip_grad=1.0, contrastive_aug_mask_ratio=0.15, contrastive_loss_weight=0.1, contrastive_mask_token_idx=0, contrastive_prioritize_heteroatoms=False, contrastive_projection_dim=128, contrastive_temp=0.1, cooldown_epochs=10, data_path='data/md17', decay_rate=0.1, delta_frame=3000, device='cuda:0', drop_path=0.0, empp_atom_type_embed_irreps='16x0e', empp_loss_weight=0.5, empp_num_mask=1, empp_pos_pred_num_s2_channels=32, empp_pos_pred_res_s2grid=100, empp_pos_pred_temp_label=0.1, empp_pos_pred_temp_softmax=0.1, empp_prioritize_heteroatoms=True, empp_ssp_feature_dim='16x0e', enable_contrastive=False, epochs=500, exp_name='md17_final_run_20250717_152800', logger=<logger.FileLogger object at 0x7f24cf9e9e20>, loss='l2', lr=0.0004, max_test_samples=2000, max_train_samples=500, max_val_samples=2000, min_lr=1e-06, model_name='graph_attention_transformer_nonlinear_l2', molecule_type='ethanol', momentum=0.9, num_basis=128, opt='adamw', opt_betas=None, opt_eps=1e-08, output_dir='outputs/md17_final_run_20250717_152800', patience_epochs=10, pin_mem=True, print_freq=50, radius=5.0, sched='cosine', seed=42, ssp=True, warmup_epochs=10, warmup_lr=1e-06, weight_decay=1e-06, workers=8)
2025-07-18 02:55:21,749 - logger.py:50 - Loading datasets...
2025-07-18 02:55:24,085 - logger.py:50 - Creating model...
2025-07-18 02:55:32,298 - logger.py:50 - Number of params: 3,205,881
2025-07-18 02:55:36,305 - logger.py:50 - Epoch: [0][0/6]	Total Loss: 1.54198	Main MSE (x10^-2): 154.1978	LR: 1.00e-06	EMPP_Raw: 2.31322
2025-07-18 02:55:51,419 - logger.py:50 - Epoch: [0][5/6]	Total Loss: 1.49341	Main MSE (x10^-2): 149.3410	LR: 1.00e-06	EMPP_Raw: 2.23217
2025-07-18 02:55:51,462 - logger.py:50 - Epoch 0 Training Summary: Avg Total Loss: 1.49341, Avg Main MSE: 1.49341, Time: 19.16s
2025-07-18 02:56:28,173 - logger.py:50 - *** New Best Val MSE (x10^-2): 37.2659, Corresponding Test MSE (x10^-2): 36.5102 at Epoch 0 ***
2025-07-18 02:56:28,218 - logger.py:50 - Epoch 0 Summary | Train MSE (x10^-2): 149.3410 | Val MSE (x10^-2): 37.2659 | Time: 55.92s
2025-07-18 02:56:31,369 - logger.py:50 - Epoch: [1][0/6]	Total Loss: 1.52601	Main MSE (x10^-2): 152.6010	LR: 1.00e-06	EMPP_Raw: 2.28602
2025-07-18 02:56:45,268 - logger.py:50 - Epoch: [1][5/6]	Total Loss: 1.50600	Main MSE (x10^-2): 150.6003	LR: 1.00e-06	EMPP_Raw: 2.26451
2025-07-18 02:56:45,314 - logger.py:50 - Epoch 1 Training Summary: Avg Total Loss: 1.50600, Avg Main MSE: 1.50600, Time: 17.09s
2025-07-18 02:57:21,376 - logger.py:50 - *** New Best Val MSE (x10^-2): 37.2336, Corresponding Test MSE (x10^-2): 36.4785 at Epoch 1 ***
2025-07-18 02:57:21,424 - logger.py:50 - Epoch 1 Summary | Train MSE (x10^-2): 150.6003 | Val MSE (x10^-2): 37.2336 | Time: 53.21s
2025-07-18 02:57:24,573 - logger.py:50 - Epoch: [2][0/6]	Total Loss: 1.51993	Main MSE (x10^-2): 151.9929	LR: 4.09e-05	EMPP_Raw: 2.28840
2025-07-18 02:57:38,325 - logger.py:50 - Epoch: [2][5/6]	Total Loss: 1.41111	Main MSE (x10^-2): 141.1110	LR: 4.09e-05	EMPP_Raw: 2.09553
2025-07-18 02:57:38,367 - logger.py:50 - Epoch 2 Training Summary: Avg Total Loss: 1.41111, Avg Main MSE: 1.41111, Time: 16.94s
2025-07-18 02:58:14,661 - logger.py:50 - *** New Best Val MSE (x10^-2): 35.9938, Corresponding Test MSE (x10^-2): 35.2647 at Epoch 2 ***
2025-07-18 02:58:14,708 - logger.py:50 - Epoch 2 Summary | Train MSE (x10^-2): 141.1110 | Val MSE (x10^-2): 35.9938 | Time: 53.28s
2025-07-18 02:58:17,736 - logger.py:50 - Epoch: [3][0/6]	Total Loss: 1.30482	Main MSE (x10^-2): 130.4815	LR: 8.08e-05	EMPP_Raw: 1.96670
2025-07-18 02:58:31,547 - logger.py:50 - Epoch: [3][5/6]	Total Loss: 1.30548	Main MSE (x10^-2): 130.5483	LR: 8.08e-05	EMPP_Raw: 1.90525
2025-07-18 02:58:31,585 - logger.py:50 - Epoch 3 Training Summary: Avg Total Loss: 1.30548, Avg Main MSE: 1.30548, Time: 16.87s
2025-07-18 02:59:07,704 - logger.py:50 - *** New Best Val MSE (x10^-2): 33.5829, Corresponding Test MSE (x10^-2): 32.9213 at Epoch 3 ***
2025-07-18 02:59:07,752 - logger.py:50 - Epoch 3 Summary | Train MSE (x10^-2): 130.5483 | Val MSE (x10^-2): 33.5829 | Time: 53.04s
2025-07-18 02:59:10,761 - logger.py:50 - Epoch: [4][0/6]	Total Loss: 1.30063	Main MSE (x10^-2): 130.0628	LR: 1.21e-04	EMPP_Raw: 1.92635
2025-07-18 02:59:24,620 - logger.py:50 - Epoch: [4][5/6]	Total Loss: 1.24039	Main MSE (x10^-2): 124.0391	LR: 1.21e-04	EMPP_Raw: 1.83092
2025-07-18 02:59:24,663 - logger.py:50 - Epoch 4 Training Summary: Avg Total Loss: 1.24039, Avg Main MSE: 1.24039, Time: 16.91s
2025-07-18 03:00:00,822 - logger.py:50 - *** New Best Val MSE (x10^-2): 31.9950, Corresponding Test MSE (x10^-2): 31.4596 at Epoch 4 ***
2025-07-18 03:00:00,869 - logger.py:50 - Epoch 4 Summary | Train MSE (x10^-2): 124.0391 | Val MSE (x10^-2): 31.9950 | Time: 53.12s
2025-07-18 03:00:03,904 - logger.py:50 - Epoch: [5][0/6]	Total Loss: 1.17302	Main MSE (x10^-2): 117.3017	LR: 1.61e-04	EMPP_Raw: 1.75032
2025-07-18 03:00:17,701 - logger.py:50 - Epoch: [5][5/6]	Total Loss: 1.19719	Main MSE (x10^-2): 119.7192	LR: 1.61e-04	EMPP_Raw: 1.75657
2025-07-18 03:00:17,739 - logger.py:50 - Epoch 5 Training Summary: Avg Total Loss: 1.19719, Avg Main MSE: 1.19719, Time: 16.87s
2025-07-18 03:00:53,899 - logger.py:50 - *** New Best Val MSE (x10^-2): 31.1527, Corresponding Test MSE (x10^-2): 30.6523 at Epoch 5 ***
2025-07-18 03:00:53,946 - logger.py:50 - Epoch 5 Summary | Train MSE (x10^-2): 119.7192 | Val MSE (x10^-2): 31.1527 | Time: 53.08s
2025-07-18 03:00:56,984 - logger.py:50 - Epoch: [6][0/6]	Total Loss: 1.18323	Main MSE (x10^-2): 118.3234	LR: 2.00e-04	EMPP_Raw: 1.70167
2025-07-18 03:01:10,868 - logger.py:50 - Epoch: [6][5/6]	Total Loss: 1.15581	Main MSE (x10^-2): 115.5814	LR: 2.00e-04	EMPP_Raw: 1.69811
2025-07-18 03:01:10,908 - logger.py:50 - Epoch 6 Training Summary: Avg Total Loss: 1.15581, Avg Main MSE: 1.15581, Time: 16.96s
2025-07-18 03:01:47,175 - logger.py:50 - *** New Best Val MSE (x10^-2): 29.7889, Corresponding Test MSE (x10^-2): 29.2871 at Epoch 6 ***
2025-07-18 03:01:47,223 - logger.py:50 - Epoch 6 Summary | Train MSE (x10^-2): 115.5814 | Val MSE (x10^-2): 29.7889 | Time: 53.28s
2025-07-18 03:01:50,218 - logger.py:50 - Epoch: [7][0/6]	Total Loss: 1.14518	Main MSE (x10^-2): 114.5183	LR: 2.40e-04	EMPP_Raw: 1.64161
2025-07-18 03:02:04,206 - logger.py:50 - Epoch: [7][5/6]	Total Loss: 1.13355	Main MSE (x10^-2): 113.3553	LR: 2.40e-04	EMPP_Raw: 1.66278
2025-07-18 03:02:04,245 - logger.py:50 - Epoch 7 Training Summary: Avg Total Loss: 1.13355, Avg Main MSE: 1.13355, Time: 17.02s
2025-07-18 03:02:40,390 - logger.py:50 - *** New Best Val MSE (x10^-2): 29.3598, Corresponding Test MSE (x10^-2): 28.9718 at Epoch 7 ***
2025-07-18 03:02:40,441 - logger.py:50 - Epoch 7 Summary | Train MSE (x10^-2): 113.3553 | Val MSE (x10^-2): 29.3598 | Time: 53.22s
2025-07-18 03:02:43,457 - logger.py:50 - Epoch: [8][0/6]	Total Loss: 1.13856	Main MSE (x10^-2): 113.8563	LR: 2.80e-04	EMPP_Raw: 1.64312
2025-07-18 03:02:57,436 - logger.py:50 - Epoch: [8][5/6]	Total Loss: 1.12593	Main MSE (x10^-2): 112.5927	LR: 2.80e-04	EMPP_Raw: 1.65943
2025-07-18 03:02:57,481 - logger.py:50 - Epoch 8 Training Summary: Avg Total Loss: 1.12593, Avg Main MSE: 1.12593, Time: 17.04s
2025-07-18 03:03:33,488 - logger.py:50 - *** New Best Val MSE (x10^-2): 29.0630, Corresponding Test MSE (x10^-2): 28.6791 at Epoch 8 ***
2025-07-18 03:03:33,538 - logger.py:50 - Epoch 8 Summary | Train MSE (x10^-2): 112.5927 | Val MSE (x10^-2): 29.0630 | Time: 53.10s
2025-07-18 03:03:36,533 - logger.py:50 - Epoch: [9][0/6]	Total Loss: 1.11541	Main MSE (x10^-2): 111.5410	LR: 3.20e-04	EMPP_Raw: 1.63401
2025-07-18 03:03:50,540 - logger.py:50 - Epoch: [9][5/6]	Total Loss: 1.09862	Main MSE (x10^-2): 109.8625	LR: 3.20e-04	EMPP_Raw: 1.61677
2025-07-18 03:03:50,578 - logger.py:50 - Epoch 9 Training Summary: Avg Total Loss: 1.09862, Avg Main MSE: 1.09862, Time: 17.04s
2025-07-18 03:04:26,628 - logger.py:50 - *** New Best Val MSE (x10^-2): 28.9087, Corresponding Test MSE (x10^-2): 28.4880 at Epoch 9 ***
2025-07-18 03:04:26,676 - logger.py:50 - Epoch 9 Summary | Train MSE (x10^-2): 109.8625 | Val MSE (x10^-2): 28.9087 | Time: 53.14s
2025-07-18 03:04:29,667 - logger.py:50 - Epoch: [10][0/6]	Total Loss: 1.09172	Main MSE (x10^-2): 109.1719	LR: 3.60e-04	EMPP_Raw: 1.58947
2025-07-18 03:04:43,644 - logger.py:50 - Epoch: [10][5/6]	Total Loss: 1.09735	Main MSE (x10^-2): 109.7350	LR: 3.60e-04	EMPP_Raw: 1.61830
2025-07-18 03:04:43,682 - logger.py:50 - Epoch 10 Training Summary: Avg Total Loss: 1.09735, Avg Main MSE: 1.09735, Time: 17.00s
2025-07-18 03:05:19,585 - logger.py:50 - *** New Best Val MSE (x10^-2): 28.8845, Corresponding Test MSE (x10^-2): 28.5759 at Epoch 10 ***
2025-07-18 03:05:19,632 - logger.py:50 - Epoch 10 Summary | Train MSE (x10^-2): 109.7350 | Val MSE (x10^-2): 28.8845 | Time: 52.96s
2025-07-18 03:05:22,620 - logger.py:50 - Epoch: [11][0/6]	Total Loss: 1.08697	Main MSE (x10^-2): 108.6972	LR: 4.00e-04	EMPP_Raw: 1.59241
2025-07-18 03:05:36,578 - logger.py:50 - Epoch: [11][5/6]	Total Loss: 1.09403	Main MSE (x10^-2): 109.4033	LR: 4.00e-04	EMPP_Raw: 1.61151
2025-07-18 03:05:36,641 - logger.py:50 - Epoch 11 Training Summary: Avg Total Loss: 1.09403, Avg Main MSE: 1.09403, Time: 17.01s
2025-07-18 03:06:12,728 - logger.py:50 - *** New Best Val MSE (x10^-2): 28.5693, Corresponding Test MSE (x10^-2): 28.2164 at Epoch 11 ***
2025-07-18 03:06:12,775 - logger.py:50 - Epoch 11 Summary | Train MSE (x10^-2): 109.4033 | Val MSE (x10^-2): 28.5693 | Time: 53.14s
2025-07-18 03:06:15,772 - logger.py:50 - Epoch: [12][0/6]	Total Loss: 1.09598	Main MSE (x10^-2): 109.5975	LR: 4.00e-04	EMPP_Raw: 1.58468
2025-07-18 03:06:29,765 - logger.py:50 - Epoch: [12][5/6]	Total Loss: 1.10614	Main MSE (x10^-2): 110.6138	LR: 4.00e-04	EMPP_Raw: 1.63368
2025-07-18 03:06:29,807 - logger.py:50 - Epoch 12 Training Summary: Avg Total Loss: 1.10614, Avg Main MSE: 1.10614, Time: 17.03s
2025-07-18 03:07:05,832 - logger.py:50 - *** New Best Val MSE (x10^-2): 28.4845, Corresponding Test MSE (x10^-2): 28.1213 at Epoch 12 ***
2025-07-18 03:07:05,879 - logger.py:50 - Epoch 12 Summary | Train MSE (x10^-2): 110.6138 | Val MSE (x10^-2): 28.4845 | Time: 53.10s
2025-07-18 03:07:08,868 - logger.py:50 - Epoch: [13][0/6]	Total Loss: 1.07446	Main MSE (x10^-2): 107.4464	LR: 3.99e-04	EMPP_Raw: 1.63571
2025-07-18 03:07:22,842 - logger.py:50 - Epoch: [13][5/6]	Total Loss: 1.08562	Main MSE (x10^-2): 108.5617	LR: 3.99e-04	EMPP_Raw: 1.60125
2025-07-18 03:07:22,887 - logger.py:50 - Epoch 13 Training Summary: Avg Total Loss: 1.08562, Avg Main MSE: 1.08562, Time: 17.00s
2025-07-18 03:07:40,819 - logger.py:50 - Epoch 13 Summary | Train MSE (x10^-2): 108.5617 | Val MSE (x10^-2): 28.6594 | Time: 34.94s
2025-07-18 03:07:43,821 - logger.py:50 - Epoch: [14][0/6]	Total Loss: 1.09101	Main MSE (x10^-2): 109.1015	LR: 3.99e-04	EMPP_Raw: 1.57407
2025-07-18 03:07:57,675 - logger.py:50 - Epoch: [14][5/6]	Total Loss: 1.07871	Main MSE (x10^-2): 107.8711	LR: 3.99e-04	EMPP_Raw: 1.57203
2025-07-18 03:07:57,717 - logger.py:50 - Epoch 14 Training Summary: Avg Total Loss: 1.07871, Avg Main MSE: 1.07871, Time: 16.89s
2025-07-18 03:08:15,816 - logger.py:50 - Epoch 14 Summary | Train MSE (x10^-2): 107.8711 | Val MSE (x10^-2): 29.3880 | Time: 34.99s
2025-07-18 03:08:18,848 - logger.py:50 - Epoch: [15][0/6]	Total Loss: 1.07627	Main MSE (x10^-2): 107.6274	LR: 3.99e-04	EMPP_Raw: 1.61927
2025-07-18 03:08:32,736 - logger.py:50 - Epoch: [15][5/6]	Total Loss: 1.09121	Main MSE (x10^-2): 109.1205	LR: 3.99e-04	EMPP_Raw: 1.60221
2025-07-18 03:08:32,776 - logger.py:50 - Epoch 15 Training Summary: Avg Total Loss: 1.09121, Avg Main MSE: 1.09121, Time: 16.95s
2025-07-18 03:08:50,973 - logger.py:50 - Epoch 15 Summary | Train MSE (x10^-2): 109.1205 | Val MSE (x10^-2): 29.2793 | Time: 35.15s
2025-07-18 03:08:53,988 - logger.py:50 - Epoch: [16][0/6]	Total Loss: 1.06312	Main MSE (x10^-2): 106.3117	LR: 3.99e-04	EMPP_Raw: 1.54548
2025-07-18 03:09:07,894 - logger.py:50 - Epoch: [16][5/6]	Total Loss: 1.06786	Main MSE (x10^-2): 106.7862	LR: 3.99e-04	EMPP_Raw: 1.56264
2025-07-18 03:09:07,938 - logger.py:50 - Epoch 16 Training Summary: Avg Total Loss: 1.06786, Avg Main MSE: 1.06786, Time: 16.96s
2025-07-18 03:09:43,962 - logger.py:50 - *** New Best Val MSE (x10^-2): 28.2759, Corresponding Test MSE (x10^-2): 27.9414 at Epoch 16 ***
2025-07-18 03:09:44,009 - logger.py:50 - Epoch 16 Summary | Train MSE (x10^-2): 106.7862 | Val MSE (x10^-2): 28.2759 | Time: 53.03s
2025-07-18 03:09:47,073 - logger.py:50 - Epoch: [17][0/6]	Total Loss: 1.11007	Main MSE (x10^-2): 111.0071	LR: 3.99e-04	EMPP_Raw: 1.56127
2025-07-18 03:10:00,891 - logger.py:50 - Epoch: [17][5/6]	Total Loss: 1.06195	Main MSE (x10^-2): 106.1953	LR: 3.99e-04	EMPP_Raw: 1.55145
2025-07-18 03:10:00,933 - logger.py:50 - Epoch 17 Training Summary: Avg Total Loss: 1.06195, Avg Main MSE: 1.06195, Time: 16.92s
2025-07-18 03:10:18,951 - logger.py:50 - Epoch 17 Summary | Train MSE (x10^-2): 106.1953 | Val MSE (x10^-2): 28.5955 | Time: 34.94s
2025-07-18 03:10:22,127 - logger.py:50 - Epoch: [18][0/6]	Total Loss: 1.06768	Main MSE (x10^-2): 106.7681	LR: 3.99e-04	EMPP_Raw: 1.51304
2025-07-18 03:10:35,950 - logger.py:50 - Epoch: [18][5/6]	Total Loss: 1.05236	Main MSE (x10^-2): 105.2363	LR: 3.99e-04	EMPP_Raw: 1.52427
2025-07-18 03:10:36,006 - logger.py:50 - Epoch 18 Training Summary: Avg Total Loss: 1.05236, Avg Main MSE: 1.05236, Time: 17.05s
2025-07-18 03:10:54,005 - logger.py:50 - Epoch 18 Summary | Train MSE (x10^-2): 105.2363 | Val MSE (x10^-2): 28.3986 | Time: 35.05s
2025-07-18 03:10:57,168 - logger.py:50 - Epoch: [19][0/6]	Total Loss: 1.05489	Main MSE (x10^-2): 105.4890	LR: 3.99e-04	EMPP_Raw: 1.54786
2025-07-18 03:11:10,935 - logger.py:50 - Epoch: [19][5/6]	Total Loss: 1.05414	Main MSE (x10^-2): 105.4142	LR: 3.99e-04	EMPP_Raw: 1.54024
2025-07-18 03:11:10,981 - logger.py:50 - Epoch 19 Training Summary: Avg Total Loss: 1.05414, Avg Main MSE: 1.05414, Time: 16.97s
2025-07-18 03:11:29,015 - logger.py:50 - Epoch 19 Summary | Train MSE (x10^-2): 105.4142 | Val MSE (x10^-2): 28.6850 | Time: 35.00s
2025-07-18 03:11:32,190 - logger.py:50 - Epoch: [20][0/6]	Total Loss: 1.04936	Main MSE (x10^-2): 104.9363	LR: 3.99e-04	EMPP_Raw: 1.54214
2025-07-18 03:11:46,049 - logger.py:50 - Epoch: [20][5/6]	Total Loss: 1.05788	Main MSE (x10^-2): 105.7881	LR: 3.99e-04	EMPP_Raw: 1.54071
2025-07-18 03:11:46,095 - logger.py:50 - Epoch 20 Training Summary: Avg Total Loss: 1.05788, Avg Main MSE: 1.05788, Time: 17.07s
2025-07-18 03:12:22,169 - logger.py:50 - *** New Best Val MSE (x10^-2): 28.2686, Corresponding Test MSE (x10^-2): 27.9340 at Epoch 20 ***
2025-07-18 03:12:22,216 - logger.py:50 - Epoch 20 Summary | Train MSE (x10^-2): 105.7881 | Val MSE (x10^-2): 28.2686 | Time: 53.20s
2025-07-18 03:12:25,367 - logger.py:50 - Epoch: [21][0/6]	Total Loss: 1.05570	Main MSE (x10^-2): 105.5704	LR: 3.98e-04	EMPP_Raw: 1.56338
2025-07-18 03:12:39,145 - logger.py:50 - Epoch: [21][5/6]	Total Loss: 1.02364	Main MSE (x10^-2): 102.3641	LR: 3.98e-04	EMPP_Raw: 1.49248
2025-07-18 03:12:39,189 - logger.py:50 - Epoch 21 Training Summary: Avg Total Loss: 1.02364, Avg Main MSE: 1.02364, Time: 16.97s
2025-07-18 03:13:15,179 - logger.py:50 - *** New Best Val MSE (x10^-2): 28.2588, Corresponding Test MSE (x10^-2): 27.9084 at Epoch 21 ***
2025-07-18 03:13:15,226 - logger.py:50 - Epoch 21 Summary | Train MSE (x10^-2): 102.3641 | Val MSE (x10^-2): 28.2588 | Time: 53.01s
2025-07-18 03:13:18,363 - logger.py:50 - Epoch: [22][0/6]	Total Loss: 1.03573	Main MSE (x10^-2): 103.5730	LR: 3.98e-04	EMPP_Raw: 1.53009
2025-07-18 03:13:32,127 - logger.py:50 - Epoch: [22][5/6]	Total Loss: 1.04883	Main MSE (x10^-2): 104.8831	LR: 3.98e-04	EMPP_Raw: 1.53591
2025-07-18 03:13:32,169 - logger.py:50 - Epoch 22 Training Summary: Avg Total Loss: 1.04883, Avg Main MSE: 1.04883, Time: 16.94s
2025-07-18 03:14:08,229 - logger.py:50 - *** New Best Val MSE (x10^-2): 28.2013, Corresponding Test MSE (x10^-2): 27.8087 at Epoch 22 ***
2025-07-18 03:14:08,281 - logger.py:50 - Epoch 22 Summary | Train MSE (x10^-2): 104.8831 | Val MSE (x10^-2): 28.2013 | Time: 53.05s
2025-07-18 03:14:11,427 - logger.py:50 - Epoch: [23][0/6]	Total Loss: 1.04836	Main MSE (x10^-2): 104.8365	LR: 3.98e-04	EMPP_Raw: 1.48727
2025-07-18 03:14:25,250 - logger.py:50 - Epoch: [23][5/6]	Total Loss: 1.04440	Main MSE (x10^-2): 104.4396	LR: 3.98e-04	EMPP_Raw: 1.52421
2025-07-18 03:14:25,291 - logger.py:50 - Epoch 23 Training Summary: Avg Total Loss: 1.04440, Avg Main MSE: 1.04440, Time: 17.01s
2025-07-18 03:14:43,254 - logger.py:50 - Epoch 23 Summary | Train MSE (x10^-2): 104.4396 | Val MSE (x10^-2): 28.2313 | Time: 34.97s
2025-07-18 03:14:46,247 - logger.py:50 - Epoch: [24][0/6]	Total Loss: 1.07492	Main MSE (x10^-2): 107.4916	LR: 3.98e-04	EMPP_Raw: 1.54717
2025-07-18 03:15:00,194 - logger.py:50 - Epoch: [24][5/6]	Total Loss: 1.04340	Main MSE (x10^-2): 104.3399	LR: 3.98e-04	EMPP_Raw: 1.52877
2025-07-18 03:15:00,242 - logger.py:50 - Epoch 24 Training Summary: Avg Total Loss: 1.04340, Avg Main MSE: 1.04340, Time: 16.98s
2025-07-18 03:15:36,217 - logger.py:50 - *** New Best Val MSE (x10^-2): 28.1678, Corresponding Test MSE (x10^-2): 27.7707 at Epoch 24 ***
2025-07-18 03:15:36,264 - logger.py:50 - Epoch 24 Summary | Train MSE (x10^-2): 104.3399 | Val MSE (x10^-2): 28.1678 | Time: 53.00s
2025-07-18 03:15:39,247 - logger.py:50 - Epoch: [25][0/6]	Total Loss: 0.99940	Main MSE (x10^-2): 99.9400	LR: 3.98e-04	EMPP_Raw: 1.52109
2025-07-18 03:15:53,193 - logger.py:50 - Epoch: [25][5/6]	Total Loss: 1.03247	Main MSE (x10^-2): 103.2473	LR: 3.98e-04	EMPP_Raw: 1.50467
2025-07-18 03:15:53,231 - logger.py:50 - Epoch 25 Training Summary: Avg Total Loss: 1.03247, Avg Main MSE: 1.03247, Time: 16.96s
2025-07-18 03:16:11,341 - logger.py:50 - Epoch 25 Summary | Train MSE (x10^-2): 103.2473 | Val MSE (x10^-2): 28.3844 | Time: 35.08s
2025-07-18 03:16:14,354 - logger.py:50 - Epoch: [26][0/6]	Total Loss: 1.05412	Main MSE (x10^-2): 105.4124	LR: 3.98e-04	EMPP_Raw: 1.53578
2025-07-18 03:16:28,169 - logger.py:50 - Epoch: [26][5/6]	Total Loss: 1.03295	Main MSE (x10^-2): 103.2955	LR: 3.98e-04	EMPP_Raw: 1.50094
2025-07-18 03:16:28,214 - logger.py:50 - Epoch 26 Training Summary: Avg Total Loss: 1.03295, Avg Main MSE: 1.03295, Time: 16.86s
2025-07-18 03:17:04,282 - logger.py:50 - *** New Best Val MSE (x10^-2): 27.9922, Corresponding Test MSE (x10^-2): 27.5883 at Epoch 26 ***
2025-07-18 03:17:04,329 - logger.py:50 - Epoch 26 Summary | Train MSE (x10^-2): 103.2955 | Val MSE (x10^-2): 27.9922 | Time: 52.98s
2025-07-18 03:17:07,326 - logger.py:50 - Epoch: [27][0/6]	Total Loss: 1.05816	Main MSE (x10^-2): 105.8156	LR: 3.97e-04	EMPP_Raw: 1.53900
2025-07-18 03:17:21,337 - logger.py:50 - Epoch: [27][5/6]	Total Loss: 1.03611	Main MSE (x10^-2): 103.6114	LR: 3.97e-04	EMPP_Raw: 1.49923
2025-07-18 03:17:21,382 - logger.py:50 - Epoch 27 Training Summary: Avg Total Loss: 1.03611, Avg Main MSE: 1.03611, Time: 17.05s
2025-07-18 03:17:57,532 - logger.py:50 - *** New Best Val MSE (x10^-2): 27.9751, Corresponding Test MSE (x10^-2): 27.6050 at Epoch 27 ***
2025-07-18 03:17:57,580 - logger.py:50 - Epoch 27 Summary | Train MSE (x10^-2): 103.6114 | Val MSE (x10^-2): 27.9751 | Time: 53.25s
2025-07-18 03:18:00,588 - logger.py:50 - Epoch: [28][0/6]	Total Loss: 1.04722	Main MSE (x10^-2): 104.7223	LR: 3.97e-04	EMPP_Raw: 1.50993
2025-07-18 03:18:14,632 - logger.py:50 - Epoch: [28][5/6]	Total Loss: 1.03001	Main MSE (x10^-2): 103.0006	LR: 3.97e-04	EMPP_Raw: 1.50108
2025-07-18 03:18:14,675 - logger.py:50 - Epoch 28 Training Summary: Avg Total Loss: 1.03001, Avg Main MSE: 1.03001, Time: 17.09s
2025-07-18 03:18:32,800 - logger.py:50 - Epoch 28 Summary | Train MSE (x10^-2): 103.0006 | Val MSE (x10^-2): 28.1515 | Time: 35.22s
2025-07-18 03:18:35,820 - logger.py:50 - Epoch: [29][0/6]	Total Loss: 0.96849	Main MSE (x10^-2): 96.8485	LR: 3.97e-04	EMPP_Raw: 1.47061
2025-07-18 03:18:49,725 - logger.py:50 - Epoch: [29][5/6]	Total Loss: 1.02144	Main MSE (x10^-2): 102.1439	LR: 3.97e-04	EMPP_Raw: 1.47982
2025-07-18 03:18:49,771 - logger.py:50 - Epoch 29 Training Summary: Avg Total Loss: 1.02144, Avg Main MSE: 1.02144, Time: 16.96s
2025-07-18 03:19:07,939 - logger.py:50 - Epoch 29 Summary | Train MSE (x10^-2): 102.1439 | Val MSE (x10^-2): 28.1785 | Time: 35.13s
2025-07-18 03:19:10,959 - logger.py:50 - Epoch: [30][0/6]	Total Loss: 1.03304	Main MSE (x10^-2): 103.3038	LR: 3.97e-04	EMPP_Raw: 1.47979
2025-07-18 03:19:24,740 - logger.py:50 - Epoch: [30][5/6]	Total Loss: 1.02050	Main MSE (x10^-2): 102.0504	LR: 3.97e-04	EMPP_Raw: 1.48277
2025-07-18 03:19:24,783 - logger.py:50 - Epoch 30 Training Summary: Avg Total Loss: 1.02050, Avg Main MSE: 1.02050, Time: 16.84s
2025-07-18 03:20:00,938 - logger.py:50 - *** New Best Val MSE (x10^-2): 27.9744, Corresponding Test MSE (x10^-2): 27.5149 at Epoch 30 ***
2025-07-18 03:20:00,986 - logger.py:50 - Epoch 30 Summary | Train MSE (x10^-2): 102.0504 | Val MSE (x10^-2): 27.9744 | Time: 53.04s
2025-07-18 03:20:03,971 - logger.py:50 - Epoch: [31][0/6]	Total Loss: 1.01106	Main MSE (x10^-2): 101.1059	LR: 3.96e-04	EMPP_Raw: 1.46154
2025-07-18 03:20:17,846 - logger.py:50 - Epoch: [31][5/6]	Total Loss: 1.02397	Main MSE (x10^-2): 102.3971	LR: 3.96e-04	EMPP_Raw: 1.48896
2025-07-18 03:20:17,890 - logger.py:50 - Epoch 31 Training Summary: Avg Total Loss: 1.02397, Avg Main MSE: 1.02397, Time: 16.90s
2025-07-18 03:20:54,088 - logger.py:50 - *** New Best Val MSE (x10^-2): 27.8365, Corresponding Test MSE (x10^-2): 27.4315 at Epoch 31 ***
2025-07-18 03:20:54,135 - logger.py:50 - Epoch 31 Summary | Train MSE (x10^-2): 102.3971 | Val MSE (x10^-2): 27.8365 | Time: 53.15s
2025-07-18 03:20:57,121 - logger.py:50 - Epoch: [32][0/6]	Total Loss: 1.03204	Main MSE (x10^-2): 103.2044	LR: 3.96e-04	EMPP_Raw: 1.51175
2025-07-18 03:21:10,954 - logger.py:50 - Epoch: [32][5/6]	Total Loss: 1.01934	Main MSE (x10^-2): 101.9338	LR: 3.96e-04	EMPP_Raw: 1.48150
2025-07-18 03:21:10,992 - logger.py:50 - Epoch 32 Training Summary: Avg Total Loss: 1.01934, Avg Main MSE: 1.01934, Time: 16.85s
2025-07-18 03:21:29,068 - logger.py:50 - Epoch 32 Summary | Train MSE (x10^-2): 101.9338 | Val MSE (x10^-2): 28.0118 | Time: 34.93s
2025-07-18 03:21:32,061 - logger.py:50 - Epoch: [33][0/6]	Total Loss: 1.02357	Main MSE (x10^-2): 102.3566	LR: 3.96e-04	EMPP_Raw: 1.52691
2025-07-18 03:21:45,863 - logger.py:50 - Epoch: [33][5/6]	Total Loss: 1.03004	Main MSE (x10^-2): 103.0042	LR: 3.96e-04	EMPP_Raw: 1.50778
2025-07-18 03:21:45,906 - logger.py:50 - Epoch 33 Training Summary: Avg Total Loss: 1.03004, Avg Main MSE: 1.03004, Time: 16.83s
2025-07-18 03:22:21,987 - logger.py:50 - *** New Best Val MSE (x10^-2): 27.8054, Corresponding Test MSE (x10^-2): 27.3825 at Epoch 33 ***
2025-07-18 03:22:22,034 - logger.py:50 - Epoch 33 Summary | Train MSE (x10^-2): 103.0042 | Val MSE (x10^-2): 27.8054 | Time: 52.96s
2025-07-18 03:22:25,062 - logger.py:50 - Epoch: [34][0/6]	Total Loss: 0.99530	Main MSE (x10^-2): 99.5300	LR: 3.96e-04	EMPP_Raw: 1.43097
2025-07-18 03:22:38,839 - logger.py:50 - Epoch: [34][5/6]	Total Loss: 1.02384	Main MSE (x10^-2): 102.3838	LR: 3.96e-04	EMPP_Raw: 1.48715
2025-07-18 03:22:38,878 - logger.py:50 - Epoch 34 Training Summary: Avg Total Loss: 1.02384, Avg Main MSE: 1.02384, Time: 16.84s
2025-07-18 03:22:57,001 - logger.py:50 - Epoch 34 Summary | Train MSE (x10^-2): 102.3838 | Val MSE (x10^-2): 28.0414 | Time: 34.97s
2025-07-18 03:23:00,003 - logger.py:50 - Epoch: [35][0/6]	Total Loss: 0.98152	Main MSE (x10^-2): 98.1522	LR: 3.95e-04	EMPP_Raw: 1.51762
2025-07-18 03:23:13,867 - logger.py:50 - Epoch: [35][5/6]	Total Loss: 1.02343	Main MSE (x10^-2): 102.3431	LR: 3.95e-04	EMPP_Raw: 1.48337
2025-07-18 03:23:13,938 - logger.py:50 - Epoch 35 Training Summary: Avg Total Loss: 1.02343, Avg Main MSE: 1.02343, Time: 16.93s
2025-07-18 03:23:32,006 - logger.py:50 - Epoch 35 Summary | Train MSE (x10^-2): 102.3431 | Val MSE (x10^-2): 28.7421 | Time: 35.00s
2025-07-18 03:23:35,008 - logger.py:50 - Epoch: [36][0/6]	Total Loss: 1.03805	Main MSE (x10^-2): 103.8046	LR: 3.95e-04	EMPP_Raw: 1.50149
2025-07-18 03:23:48,839 - logger.py:50 - Epoch: [36][5/6]	Total Loss: 1.02260	Main MSE (x10^-2): 102.2600	LR: 3.95e-04	EMPP_Raw: 1.48204
2025-07-18 03:23:48,888 - logger.py:50 - Epoch 36 Training Summary: Avg Total Loss: 1.02260, Avg Main MSE: 1.02260, Time: 16.87s
2025-07-18 03:24:06,924 - logger.py:50 - Epoch 36 Summary | Train MSE (x10^-2): 102.2600 | Val MSE (x10^-2): 28.1250 | Time: 34.91s
2025-07-18 03:24:10,097 - logger.py:50 - Epoch: [37][0/6]	Total Loss: 0.96902	Main MSE (x10^-2): 96.9024	LR: 3.95e-04	EMPP_Raw: 1.44595
2025-07-18 03:24:23,915 - logger.py:50 - Epoch: [37][5/6]	Total Loss: 1.02446	Main MSE (x10^-2): 102.4460	LR: 3.95e-04	EMPP_Raw: 1.49205
2025-07-18 03:24:23,980 - logger.py:50 - Epoch 37 Training Summary: Avg Total Loss: 1.02446, Avg Main MSE: 1.02446, Time: 17.05s
2025-07-18 03:24:42,030 - logger.py:50 - Epoch 37 Summary | Train MSE (x10^-2): 102.4460 | Val MSE (x10^-2): 28.1611 | Time: 35.10s
2025-07-18 03:24:45,220 - logger.py:50 - Epoch: [38][0/6]	Total Loss: 1.00742	Main MSE (x10^-2): 100.7424	LR: 3.95e-04	EMPP_Raw: 1.48029
2025-07-18 03:24:58,979 - logger.py:50 - Epoch: [38][5/6]	Total Loss: 1.01274	Main MSE (x10^-2): 101.2742	LR: 3.95e-04	EMPP_Raw: 1.47402
2025-07-18 03:24:59,024 - logger.py:50 - Epoch 38 Training Summary: Avg Total Loss: 1.01274, Avg Main MSE: 1.01274, Time: 16.98s
2025-07-18 03:25:16,941 - logger.py:50 - Epoch 38 Summary | Train MSE (x10^-2): 101.2742 | Val MSE (x10^-2): 28.0776 | Time: 34.91s
2025-07-18 03:25:19,997 - logger.py:50 - Epoch: [39][0/6]	Total Loss: 1.00963	Main MSE (x10^-2): 100.9633	LR: 3.94e-04	EMPP_Raw: 1.47881
2025-07-18 03:25:34,023 - logger.py:50 - Epoch: [39][5/6]	Total Loss: 1.00878	Main MSE (x10^-2): 100.8782	LR: 3.94e-04	EMPP_Raw: 1.47288
2025-07-18 03:25:34,069 - logger.py:50 - Epoch 39 Training Summary: Avg Total Loss: 1.00878, Avg Main MSE: 1.00878, Time: 17.12s
2025-07-18 03:25:51,924 - logger.py:50 - Epoch 39 Summary | Train MSE (x10^-2): 100.8782 | Val MSE (x10^-2): 27.9955 | Time: 34.98s
2025-07-18 03:25:54,965 - logger.py:50 - Epoch: [40][0/6]	Total Loss: 1.04194	Main MSE (x10^-2): 104.1937	LR: 3.94e-04	EMPP_Raw: 1.53607
2025-07-18 03:26:08,779 - logger.py:50 - Epoch: [40][5/6]	Total Loss: 1.01277	Main MSE (x10^-2): 101.2766	LR: 3.94e-04	EMPP_Raw: 1.48233
2025-07-18 03:26:08,825 - logger.py:50 - Epoch 40 Training Summary: Avg Total Loss: 1.01277, Avg Main MSE: 1.01277, Time: 16.89s
2025-07-18 03:26:26,827 - logger.py:50 - Epoch 40 Summary | Train MSE (x10^-2): 101.2766 | Val MSE (x10^-2): 27.9418 | Time: 34.90s
2025-07-18 03:26:29,834 - logger.py:50 - Epoch: [41][0/6]	Total Loss: 0.99343	Main MSE (x10^-2): 99.3428	LR: 3.94e-04	EMPP_Raw: 1.46041
2025-07-18 03:26:43,646 - logger.py:50 - Epoch: [41][5/6]	Total Loss: 1.01435	Main MSE (x10^-2): 101.4345	LR: 3.94e-04	EMPP_Raw: 1.47274
2025-07-18 03:26:43,693 - logger.py:50 - Epoch 41 Training Summary: Avg Total Loss: 1.01435, Avg Main MSE: 1.01435, Time: 16.86s
2025-07-18 03:27:01,728 - logger.py:50 - Epoch 41 Summary | Train MSE (x10^-2): 101.4345 | Val MSE (x10^-2): 28.0336 | Time: 34.90s
2025-07-18 03:27:04,743 - logger.py:50 - Epoch: [42][0/6]	Total Loss: 1.00527	Main MSE (x10^-2): 100.5266	LR: 3.93e-04	EMPP_Raw: 1.48688
2025-07-18 03:27:18,584 - logger.py:50 - Epoch: [42][5/6]	Total Loss: 1.02454	Main MSE (x10^-2): 102.4536	LR: 3.93e-04	EMPP_Raw: 1.49160
2025-07-18 03:27:18,629 - logger.py:50 - Epoch 42 Training Summary: Avg Total Loss: 1.02454, Avg Main MSE: 1.02454, Time: 16.89s
2025-07-18 03:27:36,719 - logger.py:50 - Epoch 42 Summary | Train MSE (x10^-2): 102.4536 | Val MSE (x10^-2): 27.9027 | Time: 34.98s
2025-07-18 03:27:39,879 - logger.py:50 - Epoch: [43][0/6]	Total Loss: 1.03622	Main MSE (x10^-2): 103.6220	LR: 3.93e-04	EMPP_Raw: 1.49734
2025-07-18 03:27:53,717 - logger.py:50 - Epoch: [43][5/6]	Total Loss: 1.02255	Main MSE (x10^-2): 102.2553	LR: 3.93e-04	EMPP_Raw: 1.49578
2025-07-18 03:27:53,762 - logger.py:50 - Epoch 43 Training Summary: Avg Total Loss: 1.02255, Avg Main MSE: 1.02255, Time: 17.03s
2025-07-18 03:28:11,614 - logger.py:50 - Epoch 43 Summary | Train MSE (x10^-2): 102.2553 | Val MSE (x10^-2): 27.8742 | Time: 34.89s
2025-07-18 03:28:14,766 - logger.py:50 - Epoch: [44][0/6]	Total Loss: 1.00848	Main MSE (x10^-2): 100.8478	LR: 3.93e-04	EMPP_Raw: 1.50056
2025-07-18 03:28:28,561 - logger.py:50 - Epoch: [44][5/6]	Total Loss: 1.00720	Main MSE (x10^-2): 100.7199	LR: 3.93e-04	EMPP_Raw: 1.46873
2025-07-18 03:28:28,606 - logger.py:50 - Epoch 44 Training Summary: Avg Total Loss: 1.00720, Avg Main MSE: 1.00720, Time: 16.98s
2025-07-18 03:28:46,534 - logger.py:50 - Epoch 44 Summary | Train MSE (x10^-2): 100.7199 | Val MSE (x10^-2): 27.9261 | Time: 34.91s
2025-07-18 03:28:49,540 - logger.py:50 - Epoch: [45][0/6]	Total Loss: 0.99272	Main MSE (x10^-2): 99.2717	LR: 3.92e-04	EMPP_Raw: 1.49167
2025-07-18 03:29:03,521 - logger.py:50 - Epoch: [45][5/6]	Total Loss: 1.01051	Main MSE (x10^-2): 101.0514	LR: 3.92e-04	EMPP_Raw: 1.47847
2025-07-18 03:29:03,565 - logger.py:50 - Epoch 45 Training Summary: Avg Total Loss: 1.01051, Avg Main MSE: 1.01051, Time: 17.02s
2025-07-18 03:29:21,463 - logger.py:50 - Epoch 45 Summary | Train MSE (x10^-2): 101.0514 | Val MSE (x10^-2): 28.0276 | Time: 34.92s
2025-07-18 03:29:24,478 - logger.py:50 - Epoch: [46][0/6]	Total Loss: 1.00241	Main MSE (x10^-2): 100.2412	LR: 3.92e-04	EMPP_Raw: 1.50065
2025-07-18 03:29:38,518 - logger.py:50 - Epoch: [46][5/6]	Total Loss: 1.01758	Main MSE (x10^-2): 101.7580	LR: 3.92e-04	EMPP_Raw: 1.49464
2025-07-18 03:29:38,564 - logger.py:50 - Epoch 46 Training Summary: Avg Total Loss: 1.01758, Avg Main MSE: 1.01758, Time: 17.09s
2025-07-18 03:29:56,467 - logger.py:50 - Epoch 46 Summary | Train MSE (x10^-2): 101.7580 | Val MSE (x10^-2): 27.9027 | Time: 35.00s
2025-07-18 03:29:59,485 - logger.py:50 - Epoch: [47][0/6]	Total Loss: 1.07322	Main MSE (x10^-2): 107.3224	LR: 3.92e-04	EMPP_Raw: 1.54455
2025-07-18 03:30:13,308 - logger.py:50 - Epoch: [47][5/6]	Total Loss: 1.01553	Main MSE (x10^-2): 101.5530	LR: 3.92e-04	EMPP_Raw: 1.49366
2025-07-18 03:30:13,353 - logger.py:50 - Epoch 47 Training Summary: Avg Total Loss: 1.01553, Avg Main MSE: 1.01553, Time: 16.88s
2025-07-18 03:30:31,420 - logger.py:50 - Epoch 47 Summary | Train MSE (x10^-2): 101.5530 | Val MSE (x10^-2): 28.0918 | Time: 34.95s
2025-07-18 03:30:34,423 - logger.py:50 - Epoch: [48][0/6]	Total Loss: 1.02947	Main MSE (x10^-2): 102.9473	LR: 3.91e-04	EMPP_Raw: 1.44966
2025-07-18 03:30:48,196 - logger.py:50 - Epoch: [48][5/6]	Total Loss: 1.01426	Main MSE (x10^-2): 101.4257	LR: 3.91e-04	EMPP_Raw: 1.48377
2025-07-18 03:30:48,236 - logger.py:50 - Epoch 48 Training Summary: Avg Total Loss: 1.01426, Avg Main MSE: 1.01426, Time: 16.81s
2025-07-18 03:31:06,279 - logger.py:50 - Epoch 48 Summary | Train MSE (x10^-2): 101.4257 | Val MSE (x10^-2): 27.9385 | Time: 34.85s
2025-07-18 03:31:09,441 - logger.py:50 - Epoch: [49][0/6]	Total Loss: 1.01372	Main MSE (x10^-2): 101.3722	LR: 3.91e-04	EMPP_Raw: 1.50273
2025-07-18 03:31:23,219 - logger.py:50 - Epoch: [49][5/6]	Total Loss: 1.01595	Main MSE (x10^-2): 101.5952	LR: 3.91e-04	EMPP_Raw: 1.48869
2025-07-18 03:31:23,261 - logger.py:50 - Epoch 49 Training Summary: Avg Total Loss: 1.01595, Avg Main MSE: 1.01595, Time: 16.97s
2025-07-18 03:31:41,298 - logger.py:50 - Epoch 49 Summary | Train MSE (x10^-2): 101.5952 | Val MSE (x10^-2): 28.1859 | Time: 35.01s
2025-07-18 03:31:44,447 - logger.py:50 - Epoch: [50][0/6]	Total Loss: 0.97868	Main MSE (x10^-2): 97.8676	LR: 3.91e-04	EMPP_Raw: 1.48286
2025-07-18 03:31:58,164 - logger.py:50 - Epoch: [50][5/6]	Total Loss: 1.01675	Main MSE (x10^-2): 101.6754	LR: 3.91e-04	EMPP_Raw: 1.49019
2025-07-18 03:31:58,206 - logger.py:50 - Epoch 50 Training Summary: Avg Total Loss: 1.01675, Avg Main MSE: 1.01675, Time: 16.90s
2025-07-18 03:32:16,125 - logger.py:50 - Epoch 50 Summary | Train MSE (x10^-2): 101.6754 | Val MSE (x10^-2): 28.0629 | Time: 34.82s
2025-07-18 03:32:19,123 - logger.py:50 - Epoch: [51][0/6]	Total Loss: 1.04778	Main MSE (x10^-2): 104.7780	LR: 3.90e-04	EMPP_Raw: 1.51706
2025-07-18 03:32:33,086 - logger.py:50 - Epoch: [51][5/6]	Total Loss: 1.01205	Main MSE (x10^-2): 101.2052	LR: 3.90e-04	EMPP_Raw: 1.47868
2025-07-18 03:32:33,129 - logger.py:50 - Epoch 51 Training Summary: Avg Total Loss: 1.01205, Avg Main MSE: 1.01205, Time: 17.00s
2025-07-18 03:32:51,070 - logger.py:50 - Epoch 51 Summary | Train MSE (x10^-2): 101.2052 | Val MSE (x10^-2): 27.8746 | Time: 34.94s
2025-07-18 03:32:54,063 - logger.py:50 - Epoch: [52][0/6]	Total Loss: 0.98092	Main MSE (x10^-2): 98.0919	LR: 3.90e-04	EMPP_Raw: 1.43527
2025-07-18 03:33:08,016 - logger.py:50 - Epoch: [52][5/6]	Total Loss: 1.00589	Main MSE (x10^-2): 100.5893	LR: 3.90e-04	EMPP_Raw: 1.46502
2025-07-18 03:33:08,058 - logger.py:50 - Epoch 52 Training Summary: Avg Total Loss: 1.00589, Avg Main MSE: 1.00589, Time: 16.98s
2025-07-18 03:33:25,955 - logger.py:50 - Epoch 52 Summary | Train MSE (x10^-2): 100.5893 | Val MSE (x10^-2): 28.7429 | Time: 34.88s
2025-07-18 03:33:29,000 - logger.py:50 - Epoch: [53][0/6]	Total Loss: 1.00904	Main MSE (x10^-2): 100.9036	LR: 3.89e-04	EMPP_Raw: 1.44192
2025-07-18 03:33:42,811 - logger.py:50 - Epoch: [53][5/6]	Total Loss: 0.98696	Main MSE (x10^-2): 98.6962	LR: 3.89e-04	EMPP_Raw: 1.43806
2025-07-18 03:33:42,854 - logger.py:50 - Epoch 53 Training Summary: Avg Total Loss: 0.98696, Avg Main MSE: 0.98696, Time: 16.89s
2025-07-18 03:34:00,883 - logger.py:50 - Epoch 53 Summary | Train MSE (x10^-2): 98.6962 | Val MSE (x10^-2): 29.6568 | Time: 34.92s
2025-07-18 03:34:03,929 - logger.py:50 - Epoch: [54][0/6]	Total Loss: 0.99088	Main MSE (x10^-2): 99.0882	LR: 3.89e-04	EMPP_Raw: 1.46944
2025-07-18 03:34:17,719 - logger.py:50 - Epoch: [54][5/6]	Total Loss: 1.01586	Main MSE (x10^-2): 101.5864	LR: 3.89e-04	EMPP_Raw: 1.47131
2025-07-18 03:34:17,768 - logger.py:50 - Epoch 54 Training Summary: Avg Total Loss: 1.01586, Avg Main MSE: 1.01586, Time: 16.88s
2025-07-18 03:34:35,738 - logger.py:50 - Epoch 54 Summary | Train MSE (x10^-2): 101.5864 | Val MSE (x10^-2): 29.7150 | Time: 34.85s
2025-07-18 03:34:38,947 - logger.py:50 - Epoch: [55][0/6]	Total Loss: 1.06500	Main MSE (x10^-2): 106.4996	LR: 3.89e-04	EMPP_Raw: 1.52802
2025-07-18 03:34:52,764 - logger.py:50 - Epoch: [55][5/6]	Total Loss: 1.01354	Main MSE (x10^-2): 101.3541	LR: 3.89e-04	EMPP_Raw: 1.47888
2025-07-18 03:34:52,828 - logger.py:50 - Epoch 55 Training Summary: Avg Total Loss: 1.01354, Avg Main MSE: 1.01354, Time: 17.08s
2025-07-18 03:35:10,826 - logger.py:50 - Epoch 55 Summary | Train MSE (x10^-2): 101.3541 | Val MSE (x10^-2): 28.7328 | Time: 35.08s
2025-07-18 03:35:14,016 - logger.py:50 - Epoch: [56][0/6]	Total Loss: 1.02090	Main MSE (x10^-2): 102.0900	LR: 3.88e-04	EMPP_Raw: 1.48015
2025-07-18 03:35:27,808 - logger.py:50 - Epoch: [56][5/6]	Total Loss: 1.01668	Main MSE (x10^-2): 101.6683	LR: 3.88e-04	EMPP_Raw: 1.49178
2025-07-18 03:35:27,849 - logger.py:50 - Epoch 56 Training Summary: Avg Total Loss: 1.01668, Avg Main MSE: 1.01668, Time: 17.01s
2025-07-18 03:35:45,880 - logger.py:50 - Epoch 56 Summary | Train MSE (x10^-2): 101.6683 | Val MSE (x10^-2): 28.3110 | Time: 35.05s
2025-07-18 03:35:49,045 - logger.py:50 - Epoch: [57][0/6]	Total Loss: 1.02031	Main MSE (x10^-2): 102.0309	LR: 3.88e-04	EMPP_Raw: 1.45863
2025-07-18 03:36:02,879 - logger.py:50 - Epoch: [57][5/6]	Total Loss: 1.01299	Main MSE (x10^-2): 101.2991	LR: 3.88e-04	EMPP_Raw: 1.48364
2025-07-18 03:36:02,923 - logger.py:50 - Epoch 57 Training Summary: Avg Total Loss: 1.01299, Avg Main MSE: 1.01299, Time: 17.03s
2025-07-18 03:36:20,964 - logger.py:50 - Epoch 57 Summary | Train MSE (x10^-2): 101.2991 | Val MSE (x10^-2): 28.6471 | Time: 35.08s
2025-07-18 03:36:23,956 - logger.py:50 - Epoch: [58][0/6]	Total Loss: 1.01911	Main MSE (x10^-2): 101.9113	LR: 3.87e-04	EMPP_Raw: 1.48445
2025-07-18 03:36:38,099 - logger.py:50 - Epoch: [58][5/6]	Total Loss: 1.00013	Main MSE (x10^-2): 100.0128	LR: 3.87e-04	EMPP_Raw: 1.46253
2025-07-18 03:36:38,141 - logger.py:50 - Epoch 58 Training Summary: Avg Total Loss: 1.00013, Avg Main MSE: 1.00013, Time: 17.17s
2025-07-18 03:36:56,062 - logger.py:50 - Epoch 58 Summary | Train MSE (x10^-2): 100.0128 | Val MSE (x10^-2): 28.5432 | Time: 35.09s
2025-07-18 03:36:59,101 - logger.py:50 - Epoch: [59][0/6]	Total Loss: 0.99187	Main MSE (x10^-2): 99.1870	LR: 3.87e-04	EMPP_Raw: 1.48244
2025-07-18 03:37:12,897 - logger.py:50 - Epoch: [59][5/6]	Total Loss: 0.99733	Main MSE (x10^-2): 99.7334	LR: 3.87e-04	EMPP_Raw: 1.46734
2025-07-18 03:37:12,942 - logger.py:50 - Epoch 59 Training Summary: Avg Total Loss: 0.99733, Avg Main MSE: 0.99733, Time: 16.87s
2025-07-18 03:37:31,065 - logger.py:50 - Epoch 59 Summary | Train MSE (x10^-2): 99.7334 | Val MSE (x10^-2): 28.1095 | Time: 35.00s
2025-07-18 03:37:34,103 - logger.py:50 - Epoch: [60][0/6]	Total Loss: 0.95100	Main MSE (x10^-2): 95.1004	LR: 3.86e-04	EMPP_Raw: 1.46800
2025-07-18 03:37:47,957 - logger.py:50 - Epoch: [60][5/6]	Total Loss: 1.00834	Main MSE (x10^-2): 100.8343	LR: 3.86e-04	EMPP_Raw: 1.49193
2025-07-18 03:37:47,998 - logger.py:50 - Epoch 60 Training Summary: Avg Total Loss: 1.00834, Avg Main MSE: 1.00834, Time: 16.93s
2025-07-18 03:38:06,058 - logger.py:50 - Epoch 60 Summary | Train MSE (x10^-2): 100.8343 | Val MSE (x10^-2): 28.0132 | Time: 34.99s
2025-07-18 03:38:09,068 - logger.py:50 - Epoch: [61][0/6]	Total Loss: 1.01901	Main MSE (x10^-2): 101.9013	LR: 3.86e-04	EMPP_Raw: 1.48290
2025-07-18 03:38:22,881 - logger.py:50 - Epoch: [61][5/6]	Total Loss: 1.01373	Main MSE (x10^-2): 101.3731	LR: 3.86e-04	EMPP_Raw: 1.49835
2025-07-18 03:38:22,924 - logger.py:50 - Epoch 61 Training Summary: Avg Total Loss: 1.01373, Avg Main MSE: 1.01373, Time: 16.86s
2025-07-18 03:38:40,950 - logger.py:50 - Epoch 61 Summary | Train MSE (x10^-2): 101.3731 | Val MSE (x10^-2): 27.8785 | Time: 34.89s
2025-07-18 03:38:44,115 - logger.py:50 - Epoch: [62][0/6]	Total Loss: 0.97983	Main MSE (x10^-2): 97.9835	LR: 3.86e-04	EMPP_Raw: 1.45520
2025-07-18 03:38:58,003 - logger.py:50 - Epoch: [62][5/6]	Total Loss: 1.00682	Main MSE (x10^-2): 100.6815	LR: 3.86e-04	EMPP_Raw: 1.47962
2025-07-18 03:38:58,048 - logger.py:50 - Epoch 62 Training Summary: Avg Total Loss: 1.00682, Avg Main MSE: 1.00682, Time: 17.09s
2025-07-18 03:39:16,342 - logger.py:50 - Epoch 62 Summary | Train MSE (x10^-2): 100.6815 | Val MSE (x10^-2): 28.8644 | Time: 35.39s
2025-07-18 03:39:19,499 - logger.py:50 - Epoch: [63][0/6]	Total Loss: 1.03807	Main MSE (x10^-2): 103.8067	LR: 3.85e-04	EMPP_Raw: 1.52655
2025-07-18 03:39:33,299 - logger.py:50 - Epoch: [63][5/6]	Total Loss: 1.01680	Main MSE (x10^-2): 101.6801	LR: 3.85e-04	EMPP_Raw: 1.49954
2025-07-18 03:39:33,341 - logger.py:50 - Epoch 63 Training Summary: Avg Total Loss: 1.01680, Avg Main MSE: 1.01680, Time: 16.99s
2025-07-18 03:39:51,338 - logger.py:50 - Epoch 63 Summary | Train MSE (x10^-2): 101.6801 | Val MSE (x10^-2): 28.2044 | Time: 34.99s
2025-07-18 03:39:54,340 - logger.py:50 - Epoch: [64][0/6]	Total Loss: 0.99279	Main MSE (x10^-2): 99.2794	LR: 3.85e-04	EMPP_Raw: 1.44309
2025-07-18 03:40:08,374 - logger.py:50 - Epoch: [64][5/6]	Total Loss: 0.99908	Main MSE (x10^-2): 99.9080	LR: 3.85e-04	EMPP_Raw: 1.46623
2025-07-18 03:40:08,418 - logger.py:50 - Epoch 64 Training Summary: Avg Total Loss: 0.99908, Avg Main MSE: 0.99908, Time: 17.07s
2025-07-18 03:40:26,346 - logger.py:50 - Epoch 64 Summary | Train MSE (x10^-2): 99.9080 | Val MSE (x10^-2): 28.8579 | Time: 35.00s
2025-07-18 03:40:29,361 - logger.py:50 - Epoch: [65][0/6]	Total Loss: 1.00463	Main MSE (x10^-2): 100.4631	LR: 3.84e-04	EMPP_Raw: 1.44621
2025-07-18 03:40:43,331 - logger.py:50 - Epoch: [65][5/6]	Total Loss: 0.99550	Main MSE (x10^-2): 99.5497	LR: 3.84e-04	EMPP_Raw: 1.46998
2025-07-18 03:40:43,376 - logger.py:50 - Epoch 65 Training Summary: Avg Total Loss: 0.99550, Avg Main MSE: 0.99550, Time: 17.02s
2025-07-18 03:41:01,310 - logger.py:50 - Epoch 65 Summary | Train MSE (x10^-2): 99.5497 | Val MSE (x10^-2): 28.2430 | Time: 34.96s
2025-07-18 03:41:04,315 - logger.py:50 - Epoch: [66][0/6]	Total Loss: 0.98790	Main MSE (x10^-2): 98.7902	LR: 3.84e-04	EMPP_Raw: 1.49270
2025-07-18 03:41:18,432 - logger.py:50 - Epoch: [66][5/6]	Total Loss: 1.00213	Main MSE (x10^-2): 100.2132	LR: 3.84e-04	EMPP_Raw: 1.48014
2025-07-18 03:41:18,475 - logger.py:50 - Epoch 66 Training Summary: Avg Total Loss: 1.00213, Avg Main MSE: 1.00213, Time: 17.16s
2025-07-18 03:41:36,676 - logger.py:50 - Epoch 66 Summary | Train MSE (x10^-2): 100.2132 | Val MSE (x10^-2): 28.7808 | Time: 35.36s
2025-07-18 03:41:39,662 - logger.py:50 - Epoch: [67][0/6]	Total Loss: 1.02629	Main MSE (x10^-2): 102.6292	LR: 3.83e-04	EMPP_Raw: 1.48546
2025-07-18 03:41:53,423 - logger.py:50 - Epoch: [67][5/6]	Total Loss: 0.99997	Main MSE (x10^-2): 99.9973	LR: 3.83e-04	EMPP_Raw: 1.47626
2025-07-18 03:41:53,464 - logger.py:50 - Epoch 67 Training Summary: Avg Total Loss: 0.99997, Avg Main MSE: 0.99997, Time: 16.78s
2025-07-18 03:42:11,432 - logger.py:50 - Epoch 67 Summary | Train MSE (x10^-2): 99.9973 | Val MSE (x10^-2): 28.2285 | Time: 34.75s
2025-07-18 03:42:14,631 - logger.py:50 - Epoch: [68][0/6]	Total Loss: 0.99085	Main MSE (x10^-2): 99.0850	LR: 3.83e-04	EMPP_Raw: 1.49627
2025-07-18 03:42:28,402 - logger.py:50 - Epoch: [68][5/6]	Total Loss: 0.99439	Main MSE (x10^-2): 99.4394	LR: 3.83e-04	EMPP_Raw: 1.47515
2025-07-18 03:42:28,442 - logger.py:50 - Epoch 68 Training Summary: Avg Total Loss: 0.99439, Avg Main MSE: 0.99439, Time: 17.00s
2025-07-18 03:42:46,510 - logger.py:50 - Epoch 68 Summary | Train MSE (x10^-2): 99.4394 | Val MSE (x10^-2): 29.2270 | Time: 35.07s
2025-07-18 03:42:49,676 - logger.py:50 - Epoch: [69][0/6]	Total Loss: 0.97994	Main MSE (x10^-2): 97.9935	LR: 3.82e-04	EMPP_Raw: 1.50092
2025-07-18 03:43:03,461 - logger.py:50 - Epoch: [69][5/6]	Total Loss: 0.99828	Main MSE (x10^-2): 99.8280	LR: 3.82e-04	EMPP_Raw: 1.47771
2025-07-18 03:43:03,504 - logger.py:50 - Epoch 69 Training Summary: Avg Total Loss: 0.99828, Avg Main MSE: 0.99828, Time: 16.98s
2025-07-18 03:43:21,545 - logger.py:50 - Epoch 69 Summary | Train MSE (x10^-2): 99.8280 | Val MSE (x10^-2): 28.8744 | Time: 35.03s
2025-07-18 03:43:24,772 - logger.py:50 - Epoch: [70][0/6]	Total Loss: 0.99389	Main MSE (x10^-2): 99.3890	LR: 3.82e-04	EMPP_Raw: 1.45789
2025-07-18 03:43:38,676 - logger.py:50 - Epoch: [70][5/6]	Total Loss: 0.98279	Main MSE (x10^-2): 98.2786	LR: 3.82e-04	EMPP_Raw: 1.46194
2025-07-18 03:43:38,721 - logger.py:50 - Epoch 70 Training Summary: Avg Total Loss: 0.98279, Avg Main MSE: 0.98279, Time: 17.17s
2025-07-18 03:43:56,898 - logger.py:50 - Epoch 70 Summary | Train MSE (x10^-2): 98.2786 | Val MSE (x10^-2): 29.0337 | Time: 35.35s
2025-07-18 03:43:59,886 - logger.py:50 - Epoch: [71][0/6]	Total Loss: 1.01988	Main MSE (x10^-2): 101.9878	LR: 3.81e-04	EMPP_Raw: 1.50801
2025-07-18 03:44:13,801 - logger.py:50 - Epoch: [71][5/6]	Total Loss: 0.99467	Main MSE (x10^-2): 99.4670	LR: 3.81e-04	EMPP_Raw: 1.47368
2025-07-18 03:44:13,850 - logger.py:50 - Epoch 71 Training Summary: Avg Total Loss: 0.99467, Avg Main MSE: 0.99467, Time: 16.94s
2025-07-18 03:44:31,940 - logger.py:50 - Epoch 71 Summary | Train MSE (x10^-2): 99.4670 | Val MSE (x10^-2): 28.4772 | Time: 35.04s
2025-07-18 03:44:34,954 - logger.py:50 - Epoch: [72][0/6]	Total Loss: 0.98747	Main MSE (x10^-2): 98.7467	LR: 3.80e-04	EMPP_Raw: 1.46063
2025-07-18 03:44:48,721 - logger.py:50 - Epoch: [72][5/6]	Total Loss: 0.99286	Main MSE (x10^-2): 99.2863	LR: 3.80e-04	EMPP_Raw: 1.47333
2025-07-18 03:44:48,766 - logger.py:50 - Epoch 72 Training Summary: Avg Total Loss: 0.99286, Avg Main MSE: 0.99286, Time: 16.82s
2025-07-18 03:45:06,776 - logger.py:50 - Epoch 72 Summary | Train MSE (x10^-2): 99.2863 | Val MSE (x10^-2): 28.3897 | Time: 34.83s
2025-07-18 03:45:09,807 - logger.py:50 - Epoch: [73][0/6]	Total Loss: 0.98212	Main MSE (x10^-2): 98.2120	LR: 3.80e-04	EMPP_Raw: 1.45300
2025-07-18 03:45:23,781 - logger.py:50 - Epoch: [73][5/6]	Total Loss: 0.98310	Main MSE (x10^-2): 98.3104	LR: 3.80e-04	EMPP_Raw: 1.45847
2025-07-18 03:45:23,829 - logger.py:50 - Epoch 73 Training Summary: Avg Total Loss: 0.98310, Avg Main MSE: 0.98310, Time: 17.05s
2025-07-18 03:45:41,892 - logger.py:50 - Epoch 73 Summary | Train MSE (x10^-2): 98.3104 | Val MSE (x10^-2): 28.9234 | Time: 35.11s
2025-07-18 03:45:44,915 - logger.py:50 - Epoch: [74][0/6]	Total Loss: 0.97700	Main MSE (x10^-2): 97.6995	LR: 3.79e-04	EMPP_Raw: 1.41604
2025-07-18 03:45:58,734 - logger.py:50 - Epoch: [74][5/6]	Total Loss: 0.97921	Main MSE (x10^-2): 97.9206	LR: 3.79e-04	EMPP_Raw: 1.45430
2025-07-18 03:45:58,776 - logger.py:50 - Epoch 74 Training Summary: Avg Total Loss: 0.97921, Avg Main MSE: 0.97921, Time: 16.87s
2025-07-18 03:46:16,804 - logger.py:50 - Epoch 74 Summary | Train MSE (x10^-2): 97.9206 | Val MSE (x10^-2): 28.5449 | Time: 34.91s
2025-07-18 03:46:19,965 - logger.py:50 - Epoch: [75][0/6]	Total Loss: 0.95086	Main MSE (x10^-2): 95.0864	LR: 3.79e-04	EMPP_Raw: 1.44876
2025-07-18 03:46:33,844 - logger.py:50 - Epoch: [75][5/6]	Total Loss: 0.98541	Main MSE (x10^-2): 98.5414	LR: 3.79e-04	EMPP_Raw: 1.46617
2025-07-18 03:46:33,888 - logger.py:50 - Epoch 75 Training Summary: Avg Total Loss: 0.98541, Avg Main MSE: 0.98541, Time: 17.08s
2025-07-18 03:46:51,840 - logger.py:50 - Epoch 75 Summary | Train MSE (x10^-2): 98.5414 | Val MSE (x10^-2): 29.1619 | Time: 35.03s
2025-07-18 03:46:55,055 - logger.py:50 - Epoch: [76][0/6]	Total Loss: 0.99223	Main MSE (x10^-2): 99.2231	LR: 3.78e-04	EMPP_Raw: 1.48557
2025-07-18 03:47:08,811 - logger.py:50 - Epoch: [76][5/6]	Total Loss: 0.98221	Main MSE (x10^-2): 98.2208	LR: 3.78e-04	EMPP_Raw: 1.47453
2025-07-18 03:47:08,855 - logger.py:50 - Epoch 76 Training Summary: Avg Total Loss: 0.98221, Avg Main MSE: 0.98221, Time: 17.01s
2025-07-18 03:47:26,838 - logger.py:50 - Epoch 76 Summary | Train MSE (x10^-2): 98.2208 | Val MSE (x10^-2): 29.8022 | Time: 34.99s
2025-07-18 03:47:29,832 - logger.py:50 - Epoch: [77][0/6]	Total Loss: 0.96139	Main MSE (x10^-2): 96.1388	LR: 3.78e-04	EMPP_Raw: 1.45038
2025-07-18 03:47:43,837 - logger.py:50 - Epoch: [77][5/6]	Total Loss: 0.97785	Main MSE (x10^-2): 97.7847	LR: 3.78e-04	EMPP_Raw: 1.45778
2025-07-18 03:47:43,879 - logger.py:50 - Epoch 77 Training Summary: Avg Total Loss: 0.97785, Avg Main MSE: 0.97785, Time: 17.03s
2025-07-18 03:48:01,831 - logger.py:50 - Epoch 77 Summary | Train MSE (x10^-2): 97.7847 | Val MSE (x10^-2): 29.7303 | Time: 34.99s
2025-07-18 03:48:04,832 - logger.py:50 - Epoch: [78][0/6]	Total Loss: 0.94316	Main MSE (x10^-2): 94.3165	LR: 3.77e-04	EMPP_Raw: 1.40045
2025-07-18 03:48:18,800 - logger.py:50 - Epoch: [78][5/6]	Total Loss: 0.97430	Main MSE (x10^-2): 97.4304	LR: 3.77e-04	EMPP_Raw: 1.45126
2025-07-18 03:48:18,850 - logger.py:50 - Epoch 78 Training Summary: Avg Total Loss: 0.97430, Avg Main MSE: 0.97430, Time: 17.01s
2025-07-18 03:48:36,798 - logger.py:50 - Epoch 78 Summary | Train MSE (x10^-2): 97.4304 | Val MSE (x10^-2): 30.4043 | Time: 34.96s
2025-07-18 03:48:39,860 - logger.py:50 - Epoch: [79][0/6]	Total Loss: 0.98765	Main MSE (x10^-2): 98.7648	LR: 3.77e-04	EMPP_Raw: 1.49213
2025-07-18 03:48:53,682 - logger.py:50 - Epoch: [79][5/6]	Total Loss: 0.98096	Main MSE (x10^-2): 98.0956	LR: 3.77e-04	EMPP_Raw: 1.46285
2025-07-18 03:48:53,724 - logger.py:50 - Epoch 79 Training Summary: Avg Total Loss: 0.98096, Avg Main MSE: 0.98096, Time: 16.92s
2025-07-18 03:49:11,734 - logger.py:50 - Epoch 79 Summary | Train MSE (x10^-2): 98.0956 | Val MSE (x10^-2): 30.0747 | Time: 34.93s
2025-07-18 03:49:14,831 - logger.py:50 - Epoch: [80][0/6]	Total Loss: 0.95669	Main MSE (x10^-2): 95.6695	LR: 3.76e-04	EMPP_Raw: 1.48062
2025-07-18 03:49:28,605 - logger.py:50 - Epoch: [80][5/6]	Total Loss: 0.97590	Main MSE (x10^-2): 97.5905	LR: 3.76e-04	EMPP_Raw: 1.47384
2025-07-18 03:49:28,652 - logger.py:50 - Epoch 80 Training Summary: Avg Total Loss: 0.97590, Avg Main MSE: 0.97590, Time: 16.91s
2025-07-18 03:49:46,725 - logger.py:50 - Epoch 80 Summary | Train MSE (x10^-2): 97.5905 | Val MSE (x10^-2): 29.9395 | Time: 34.99s
2025-07-18 03:49:49,876 - logger.py:50 - Epoch: [81][0/6]	Total Loss: 0.96064	Main MSE (x10^-2): 96.0644	LR: 3.75e-04	EMPP_Raw: 1.48518
2025-07-18 03:50:03,708 - logger.py:50 - Epoch: [81][5/6]	Total Loss: 0.96044	Main MSE (x10^-2): 96.0441	LR: 3.75e-04	EMPP_Raw: 1.45265
2025-07-18 03:50:03,747 - logger.py:50 - Epoch 81 Training Summary: Avg Total Loss: 0.96044, Avg Main MSE: 0.96044, Time: 17.01s
2025-07-18 03:50:21,749 - logger.py:50 - Epoch 81 Summary | Train MSE (x10^-2): 96.0441 | Val MSE (x10^-2): 30.8072 | Time: 35.02s
2025-07-18 03:50:24,929 - logger.py:50 - Epoch: [82][0/6]	Total Loss: 0.96435	Main MSE (x10^-2): 96.4354	LR: 3.75e-04	EMPP_Raw: 1.48124
2025-07-18 03:50:38,719 - logger.py:50 - Epoch: [82][5/6]	Total Loss: 0.96250	Main MSE (x10^-2): 96.2504	LR: 3.75e-04	EMPP_Raw: 1.45225
2025-07-18 03:50:38,761 - logger.py:50 - Epoch 82 Training Summary: Avg Total Loss: 0.96250, Avg Main MSE: 0.96250, Time: 17.00s
2025-07-18 03:50:56,721 - logger.py:50 - Epoch 82 Summary | Train MSE (x10^-2): 96.2504 | Val MSE (x10^-2): 31.0960 | Time: 34.97s
2025-07-18 03:50:59,958 - logger.py:50 - Epoch: [83][0/6]	Total Loss: 0.96405	Main MSE (x10^-2): 96.4053	LR: 3.74e-04	EMPP_Raw: 1.51976
2025-07-18 03:51:13,788 - logger.py:50 - Epoch: [83][5/6]	Total Loss: 0.96967	Main MSE (x10^-2): 96.9674	LR: 3.74e-04	EMPP_Raw: 1.48303
2025-07-18 03:51:13,830 - logger.py:50 - Epoch 83 Training Summary: Avg Total Loss: 0.96967, Avg Main MSE: 0.96967, Time: 17.10s
2025-07-18 03:51:31,831 - logger.py:50 - Epoch 83 Summary | Train MSE (x10^-2): 96.9674 | Val MSE (x10^-2): 31.0106 | Time: 35.10s
2025-07-18 03:51:34,857 - logger.py:50 - Epoch: [84][0/6]	Total Loss: 0.97377	Main MSE (x10^-2): 97.3767	LR: 3.73e-04	EMPP_Raw: 1.47731
2025-07-18 03:51:48,875 - logger.py:50 - Epoch: [84][5/6]	Total Loss: 0.95468	Main MSE (x10^-2): 95.4684	LR: 3.73e-04	EMPP_Raw: 1.45265
2025-07-18 03:51:48,923 - logger.py:50 - Epoch 84 Training Summary: Avg Total Loss: 0.95468, Avg Main MSE: 0.95468, Time: 17.08s
2025-07-18 03:52:06,877 - logger.py:50 - Epoch 84 Summary | Train MSE (x10^-2): 95.4684 | Val MSE (x10^-2): 31.6609 | Time: 35.04s
2025-07-18 03:52:09,888 - logger.py:50 - Epoch: [85][0/6]	Total Loss: 0.94109	Main MSE (x10^-2): 94.1090	LR: 3.73e-04	EMPP_Raw: 1.46879
2025-07-18 03:52:23,750 - logger.py:50 - Epoch: [85][5/6]	Total Loss: 0.97152	Main MSE (x10^-2): 97.1518	LR: 3.73e-04	EMPP_Raw: 1.45331
2025-07-18 03:52:23,791 - logger.py:50 - Epoch 85 Training Summary: Avg Total Loss: 0.97152, Avg Main MSE: 0.97152, Time: 16.90s
2025-07-18 03:52:42,003 - logger.py:50 - Epoch 85 Summary | Train MSE (x10^-2): 97.1518 | Val MSE (x10^-2): 32.5103 | Time: 35.12s
2025-07-18 03:52:45,051 - logger.py:50 - Epoch: [86][0/6]	Total Loss: 1.01664	Main MSE (x10^-2): 101.6642	LR: 3.72e-04	EMPP_Raw: 1.54179
2025-07-18 03:52:58,840 - logger.py:50 - Epoch: [86][5/6]	Total Loss: 0.97369	Main MSE (x10^-2): 97.3685	LR: 3.72e-04	EMPP_Raw: 1.47254
2025-07-18 03:52:58,881 - logger.py:50 - Epoch 86 Training Summary: Avg Total Loss: 0.97369, Avg Main MSE: 0.97369, Time: 16.87s
2025-07-18 03:53:17,217 - logger.py:50 - Epoch 86 Summary | Train MSE (x10^-2): 97.3685 | Val MSE (x10^-2): 30.4331 | Time: 35.21s
2025-07-18 03:53:20,244 - logger.py:50 - Epoch: [87][0/6]	Total Loss: 0.95781	Main MSE (x10^-2): 95.7807	LR: 3.72e-04	EMPP_Raw: 1.53668
2025-07-18 03:53:34,186 - logger.py:50 - Epoch: [87][5/6]	Total Loss: 0.95079	Main MSE (x10^-2): 95.0785	LR: 3.72e-04	EMPP_Raw: 1.46447
2025-07-18 03:53:34,230 - logger.py:50 - Epoch 87 Training Summary: Avg Total Loss: 0.95079, Avg Main MSE: 0.95079, Time: 17.00s
2025-07-18 03:53:52,250 - logger.py:50 - Epoch 87 Summary | Train MSE (x10^-2): 95.0785 | Val MSE (x10^-2): 33.1119 | Time: 35.03s
2025-07-18 03:53:55,421 - logger.py:50 - Epoch: [88][0/6]	Total Loss: 0.96323	Main MSE (x10^-2): 96.3227	LR: 3.71e-04	EMPP_Raw: 1.47813
2025-07-18 03:54:09,294 - logger.py:50 - Epoch: [88][5/6]	Total Loss: 0.96073	Main MSE (x10^-2): 96.0730	LR: 3.71e-04	EMPP_Raw: 1.47605
2025-07-18 03:54:09,342 - logger.py:50 - Epoch 88 Training Summary: Avg Total Loss: 0.96073, Avg Main MSE: 0.96073, Time: 17.08s
2025-07-18 03:54:27,353 - logger.py:50 - Epoch 88 Summary | Train MSE (x10^-2): 96.0730 | Val MSE (x10^-2): 32.1796 | Time: 35.10s
2025-07-18 03:54:30,523 - logger.py:50 - Epoch: [89][0/6]	Total Loss: 0.91405	Main MSE (x10^-2): 91.4050	LR: 3.70e-04	EMPP_Raw: 1.45260
2025-07-18 03:54:44,288 - logger.py:50 - Epoch: [89][5/6]	Total Loss: 0.95079	Main MSE (x10^-2): 95.0793	LR: 3.70e-04	EMPP_Raw: 1.47059
2025-07-18 03:54:44,332 - logger.py:50 - Epoch 89 Training Summary: Avg Total Loss: 0.95079, Avg Main MSE: 0.95079, Time: 16.97s
2025-07-18 03:55:02,239 - logger.py:50 - Epoch 89 Summary | Train MSE (x10^-2): 95.0793 | Val MSE (x10^-2): 34.4332 | Time: 34.88s
2025-07-18 03:55:05,253 - logger.py:50 - Epoch: [90][0/6]	Total Loss: 0.96891	Main MSE (x10^-2): 96.8914	LR: 3.70e-04	EMPP_Raw: 1.49179
2025-07-18 03:55:19,614 - logger.py:50 - Epoch: [90][5/6]	Total Loss: 0.94094	Main MSE (x10^-2): 94.0937	LR: 3.70e-04	EMPP_Raw: 1.45947
2025-07-18 03:55:19,656 - logger.py:50 - Epoch 90 Training Summary: Avg Total Loss: 0.94094, Avg Main MSE: 0.94094, Time: 17.41s
2025-07-18 03:55:37,671 - logger.py:50 - Epoch 90 Summary | Train MSE (x10^-2): 94.0937 | Val MSE (x10^-2): 31.1183 | Time: 35.43s
2025-07-18 03:55:40,677 - logger.py:50 - Epoch: [91][0/6]	Total Loss: 0.96969	Main MSE (x10^-2): 96.9693	LR: 3.69e-04	EMPP_Raw: 1.51198
2025-07-18 03:55:54,695 - logger.py:50 - Epoch: [91][5/6]	Total Loss: 0.94272	Main MSE (x10^-2): 94.2725	LR: 3.69e-04	EMPP_Raw: 1.47276
2025-07-18 03:55:54,738 - logger.py:50 - Epoch 91 Training Summary: Avg Total Loss: 0.94272, Avg Main MSE: 0.94272, Time: 17.06s
2025-07-18 03:56:12,657 - logger.py:50 - Epoch 91 Summary | Train MSE (x10^-2): 94.2725 | Val MSE (x10^-2): 32.4304 | Time: 34.98s
2025-07-18 03:56:15,651 - logger.py:50 - Epoch: [92][0/6]	Total Loss: 0.89072	Main MSE (x10^-2): 89.0716	LR: 3.68e-04	EMPP_Raw: 1.42050
2025-07-18 03:56:29,440 - logger.py:50 - Epoch: [92][5/6]	Total Loss: 0.93573	Main MSE (x10^-2): 93.5732	LR: 3.68e-04	EMPP_Raw: 1.47353
2025-07-18 03:56:29,485 - logger.py:50 - Epoch 92 Training Summary: Avg Total Loss: 0.93573, Avg Main MSE: 0.93573, Time: 16.82s
2025-07-18 03:56:47,472 - logger.py:50 - Epoch 92 Summary | Train MSE (x10^-2): 93.5732 | Val MSE (x10^-2): 33.3120 | Time: 34.81s
2025-07-18 03:56:50,458 - logger.py:50 - Epoch: [93][0/6]	Total Loss: 0.96804	Main MSE (x10^-2): 96.8038	LR: 3.68e-04	EMPP_Raw: 1.51296
2025-07-18 03:57:04,266 - logger.py:50 - Epoch: [93][5/6]	Total Loss: 0.94224	Main MSE (x10^-2): 94.2237	LR: 3.68e-04	EMPP_Raw: 1.48319
2025-07-18 03:57:04,311 - logger.py:50 - Epoch 93 Training Summary: Avg Total Loss: 0.94224, Avg Main MSE: 0.94224, Time: 16.83s
2025-07-18 03:57:22,431 - logger.py:50 - Epoch 93 Summary | Train MSE (x10^-2): 94.2237 | Val MSE (x10^-2): 32.3980 | Time: 34.96s
2025-07-18 03:57:25,574 - logger.py:50 - Epoch: [94][0/6]	Total Loss: 0.90275	Main MSE (x10^-2): 90.2751	LR: 3.67e-04	EMPP_Raw: 1.49505
2025-07-18 03:57:39,525 - logger.py:50 - Epoch: [94][5/6]	Total Loss: 0.93109	Main MSE (x10^-2): 93.1087	LR: 3.67e-04	EMPP_Raw: 1.46347
2025-07-18 03:57:39,571 - logger.py:50 - Epoch 94 Training Summary: Avg Total Loss: 0.93109, Avg Main MSE: 0.93109, Time: 17.13s
2025-07-18 03:57:57,549 - logger.py:50 - Epoch 94 Summary | Train MSE (x10^-2): 93.1087 | Val MSE (x10^-2): 35.8766 | Time: 35.11s
2025-07-18 03:58:00,787 - logger.py:50 - Epoch: [95][0/6]	Total Loss: 0.92859	Main MSE (x10^-2): 92.8589	LR: 3.66e-04	EMPP_Raw: 1.48846
2025-07-18 03:58:14,636 - logger.py:50 - Epoch: [95][5/6]	Total Loss: 0.92408	Main MSE (x10^-2): 92.4082	LR: 3.66e-04	EMPP_Raw: 1.45750
2025-07-18 03:58:14,683 - logger.py:50 - Epoch 95 Training Summary: Avg Total Loss: 0.92408, Avg Main MSE: 0.92408, Time: 17.12s
2025-07-18 03:58:32,784 - logger.py:50 - Epoch 95 Summary | Train MSE (x10^-2): 92.4082 | Val MSE (x10^-2): 32.8388 | Time: 35.23s
2025-07-18 03:58:35,992 - logger.py:50 - Epoch: [96][0/6]	Total Loss: 0.92033	Main MSE (x10^-2): 92.0334	LR: 3.66e-04	EMPP_Raw: 1.44172
2025-07-18 03:58:49,783 - logger.py:50 - Epoch: [96][5/6]	Total Loss: 0.91663	Main MSE (x10^-2): 91.6628	LR: 3.66e-04	EMPP_Raw: 1.45374
2025-07-18 03:58:49,825 - logger.py:50 - Epoch 96 Training Summary: Avg Total Loss: 0.91663, Avg Main MSE: 0.91663, Time: 17.03s
2025-07-18 03:59:07,706 - logger.py:50 - Epoch 96 Summary | Train MSE (x10^-2): 91.6628 | Val MSE (x10^-2): 35.4323 | Time: 34.92s
2025-07-18 03:59:10,740 - logger.py:50 - Epoch: [97][0/6]	Total Loss: 0.93210	Main MSE (x10^-2): 93.2100	LR: 3.65e-04	EMPP_Raw: 1.44572
2025-07-18 03:59:24,714 - logger.py:50 - Epoch: [97][5/6]	Total Loss: 0.92447	Main MSE (x10^-2): 92.4472	LR: 3.65e-04	EMPP_Raw: 1.46545
2025-07-18 03:59:24,758 - logger.py:50 - Epoch 97 Training Summary: Avg Total Loss: 0.92447, Avg Main MSE: 0.92447, Time: 17.04s
2025-07-18 03:59:42,703 - logger.py:50 - Epoch 97 Summary | Train MSE (x10^-2): 92.4472 | Val MSE (x10^-2): 34.3971 | Time: 34.99s
2025-07-18 03:59:45,767 - logger.py:50 - Epoch: [98][0/6]	Total Loss: 0.97661	Main MSE (x10^-2): 97.6609	LR: 3.64e-04	EMPP_Raw: 1.45305
2025-07-18 03:59:59,607 - logger.py:50 - Epoch: [98][5/6]	Total Loss: 0.92644	Main MSE (x10^-2): 92.6442	LR: 3.64e-04	EMPP_Raw: 1.45081
2025-07-18 03:59:59,653 - logger.py:50 - Epoch 98 Training Summary: Avg Total Loss: 0.92644, Avg Main MSE: 0.92644, Time: 16.94s
2025-07-18 04:00:17,739 - logger.py:50 - Epoch 98 Summary | Train MSE (x10^-2): 92.6442 | Val MSE (x10^-2): 36.1080 | Time: 35.03s
2025-07-18 04:00:20,732 - logger.py:50 - Epoch: [99][0/6]	Total Loss: 0.91615	Main MSE (x10^-2): 91.6147	LR: 3.63e-04	EMPP_Raw: 1.47932
2025-07-18 04:00:34,505 - logger.py:50 - Epoch: [99][5/6]	Total Loss: 0.92886	Main MSE (x10^-2): 92.8864	LR: 3.63e-04	EMPP_Raw: 1.48518
2025-07-18 04:00:34,549 - logger.py:50 - Epoch 99 Training Summary: Avg Total Loss: 0.92886, Avg Main MSE: 0.92886, Time: 16.80s
2025-07-18 04:00:52,682 - logger.py:50 - Epoch 99 Summary | Train MSE (x10^-2): 92.8864 | Val MSE (x10^-2): 33.7506 | Time: 34.94s
2025-07-18 04:00:55,709 - logger.py:50 - Epoch: [100][0/6]	Total Loss: 0.90619	Main MSE (x10^-2): 90.6193	LR: 3.63e-04	EMPP_Raw: 1.46713
2025-07-18 04:01:09,787 - logger.py:50 - Epoch: [100][5/6]	Total Loss: 0.90661	Main MSE (x10^-2): 90.6605	LR: 3.63e-04	EMPP_Raw: 1.45740
2025-07-18 04:01:09,828 - logger.py:50 - Epoch 100 Training Summary: Avg Total Loss: 0.90661, Avg Main MSE: 0.90661, Time: 17.14s
2025-07-18 04:01:28,002 - logger.py:50 - Epoch 100 Summary | Train MSE (x10^-2): 90.6605 | Val MSE (x10^-2): 33.3328 | Time: 35.31s
2025-07-18 04:01:31,177 - logger.py:50 - Epoch: [101][0/6]	Total Loss: 0.88124	Main MSE (x10^-2): 88.1236	LR: 3.62e-04	EMPP_Raw: 1.45559
2025-07-18 04:01:45,141 - logger.py:50 - Epoch: [101][5/6]	Total Loss: 0.89991	Main MSE (x10^-2): 89.9910	LR: 3.62e-04	EMPP_Raw: 1.46587
2025-07-18 04:01:45,185 - logger.py:50 - Epoch 101 Training Summary: Avg Total Loss: 0.89991, Avg Main MSE: 0.89991, Time: 17.17s
2025-07-18 04:02:03,291 - logger.py:50 - Epoch 101 Summary | Train MSE (x10^-2): 89.9910 | Val MSE (x10^-2): 33.9937 | Time: 35.28s
2025-07-18 04:02:06,482 - logger.py:50 - Epoch: [102][0/6]	Total Loss: 0.87704	Main MSE (x10^-2): 87.7037	LR: 3.61e-04	EMPP_Raw: 1.45260
2025-07-18 04:02:20,309 - logger.py:50 - Epoch: [102][5/6]	Total Loss: 0.88589	Main MSE (x10^-2): 88.5887	LR: 3.61e-04	EMPP_Raw: 1.46175
2025-07-18 04:02:20,362 - logger.py:50 - Epoch 102 Training Summary: Avg Total Loss: 0.88589, Avg Main MSE: 0.88589, Time: 17.06s
2025-07-18 04:02:38,313 - logger.py:50 - Epoch 102 Summary | Train MSE (x10^-2): 88.5887 | Val MSE (x10^-2): 35.7258 | Time: 35.02s
2025-07-18 04:02:41,313 - logger.py:50 - Epoch: [103][0/6]	Total Loss: 0.86137	Main MSE (x10^-2): 86.1368	LR: 3.60e-04	EMPP_Raw: 1.47417
2025-07-18 04:02:55,270 - logger.py:50 - Epoch: [103][5/6]	Total Loss: 0.88810	Main MSE (x10^-2): 88.8105	LR: 3.60e-04	EMPP_Raw: 1.45070
2025-07-18 04:02:55,319 - logger.py:50 - Epoch 103 Training Summary: Avg Total Loss: 0.88810, Avg Main MSE: 0.88810, Time: 17.00s
2025-07-18 04:03:13,243 - logger.py:50 - Epoch 103 Summary | Train MSE (x10^-2): 88.8105 | Val MSE (x10^-2): 36.1488 | Time: 34.92s
2025-07-18 04:03:16,329 - logger.py:50 - Epoch: [104][0/6]	Total Loss: 0.86162	Main MSE (x10^-2): 86.1620	LR: 3.60e-04	EMPP_Raw: 1.45890
2025-07-18 04:03:30,510 - logger.py:50 - Epoch: [104][5/6]	Total Loss: 0.88537	Main MSE (x10^-2): 88.5373	LR: 3.60e-04	EMPP_Raw: 1.45981
2025-07-18 04:03:30,558 - logger.py:50 - Epoch 104 Training Summary: Avg Total Loss: 0.88537, Avg Main MSE: 0.88537, Time: 17.31s
2025-07-18 04:03:48,696 - logger.py:50 - Epoch 104 Summary | Train MSE (x10^-2): 88.5373 | Val MSE (x10^-2): 35.6293 | Time: 35.45s
2025-07-18 04:03:51,708 - logger.py:50 - Epoch: [105][0/6]	Total Loss: 0.89560	Main MSE (x10^-2): 89.5599	LR: 3.59e-04	EMPP_Raw: 1.49242
2025-07-18 04:04:05,593 - logger.py:50 - Epoch: [105][5/6]	Total Loss: 0.88244	Main MSE (x10^-2): 88.2435	LR: 3.59e-04	EMPP_Raw: 1.46779
2025-07-18 04:04:05,639 - logger.py:50 - Epoch 105 Training Summary: Avg Total Loss: 0.88244, Avg Main MSE: 0.88244, Time: 16.93s
2025-07-18 04:04:23,901 - logger.py:50 - Epoch 105 Summary | Train MSE (x10^-2): 88.2435 | Val MSE (x10^-2): 36.9455 | Time: 35.20s
2025-07-18 04:04:27,060 - logger.py:50 - Epoch: [106][0/6]	Total Loss: 0.90032	Main MSE (x10^-2): 90.0317	LR: 3.58e-04	EMPP_Raw: 1.48272
2025-07-18 04:04:41,048 - logger.py:50 - Epoch: [106][5/6]	Total Loss: 0.87591	Main MSE (x10^-2): 87.5915	LR: 3.58e-04	EMPP_Raw: 1.46823
2025-07-18 04:04:41,095 - logger.py:50 - Epoch 106 Training Summary: Avg Total Loss: 0.87591, Avg Main MSE: 0.87591, Time: 17.18s
2025-07-18 04:04:59,065 - logger.py:50 - Epoch 106 Summary | Train MSE (x10^-2): 87.5915 | Val MSE (x10^-2): 35.8265 | Time: 35.16s
2025-07-18 04:05:02,222 - logger.py:50 - Epoch: [107][0/6]	Total Loss: 0.86974	Main MSE (x10^-2): 86.9740	LR: 3.57e-04	EMPP_Raw: 1.48437
2025-07-18 04:05:16,057 - logger.py:50 - Epoch: [107][5/6]	Total Loss: 0.86779	Main MSE (x10^-2): 86.7794	LR: 3.57e-04	EMPP_Raw: 1.47232
2025-07-18 04:05:16,102 - logger.py:50 - Epoch 107 Training Summary: Avg Total Loss: 0.86779, Avg Main MSE: 0.86779, Time: 17.03s
2025-07-18 04:05:34,157 - logger.py:50 - Epoch 107 Summary | Train MSE (x10^-2): 86.7794 | Val MSE (x10^-2): 36.3007 | Time: 35.09s
2025-07-18 04:05:37,372 - logger.py:50 - Epoch: [108][0/6]	Total Loss: 0.86149	Main MSE (x10^-2): 86.1486	LR: 3.57e-04	EMPP_Raw: 1.45062
2025-07-18 04:05:51,274 - logger.py:50 - Epoch: [108][5/6]	Total Loss: 0.86013	Main MSE (x10^-2): 86.0133	LR: 3.57e-04	EMPP_Raw: 1.46154
2025-07-18 04:05:51,316 - logger.py:50 - Epoch 108 Training Summary: Avg Total Loss: 0.86013, Avg Main MSE: 0.86013, Time: 17.15s
2025-07-18 04:06:09,309 - logger.py:50 - Epoch 108 Summary | Train MSE (x10^-2): 86.0133 | Val MSE (x10^-2): 36.4259 | Time: 35.15s
2025-07-18 04:06:12,365 - logger.py:50 - Epoch: [109][0/6]	Total Loss: 0.86552	Main MSE (x10^-2): 86.5516	LR: 3.56e-04	EMPP_Raw: 1.45940
2025-07-18 04:06:26,356 - logger.py:50 - Epoch: [109][5/6]	Total Loss: 0.85543	Main MSE (x10^-2): 85.5431	LR: 3.56e-04	EMPP_Raw: 1.46107
2025-07-18 04:06:26,401 - logger.py:50 - Epoch 109 Training Summary: Avg Total Loss: 0.85543, Avg Main MSE: 0.85543, Time: 17.08s
2025-07-18 04:06:44,424 - logger.py:50 - Epoch 109 Summary | Train MSE (x10^-2): 85.5431 | Val MSE (x10^-2): 38.0806 | Time: 35.11s
2025-07-18 04:06:47,524 - logger.py:50 - Epoch: [110][0/6]	Total Loss: 0.86461	Main MSE (x10^-2): 86.4611	LR: 3.55e-04	EMPP_Raw: 1.49221
2025-07-18 04:07:01,756 - logger.py:50 - Epoch: [110][5/6]	Total Loss: 0.85154	Main MSE (x10^-2): 85.1542	LR: 3.55e-04	EMPP_Raw: 1.46728
2025-07-18 04:07:01,819 - logger.py:50 - Epoch 110 Training Summary: Avg Total Loss: 0.85154, Avg Main MSE: 0.85154, Time: 17.38s
2025-07-18 04:07:19,851 - logger.py:50 - Epoch 110 Summary | Train MSE (x10^-2): 85.1542 | Val MSE (x10^-2): 36.6267 | Time: 35.42s
2025-07-18 04:07:22,945 - logger.py:50 - Epoch: [111][0/6]	Total Loss: 0.85884	Main MSE (x10^-2): 85.8836	LR: 3.54e-04	EMPP_Raw: 1.49585
2025-07-18 04:07:36,782 - logger.py:50 - Epoch: [111][5/6]	Total Loss: 0.85716	Main MSE (x10^-2): 85.7164	LR: 3.54e-04	EMPP_Raw: 1.47495
2025-07-18 04:07:36,836 - logger.py:50 - Epoch 111 Training Summary: Avg Total Loss: 0.85716, Avg Main MSE: 0.85716, Time: 16.98s
2025-07-18 04:07:54,989 - logger.py:50 - Epoch 111 Summary | Train MSE (x10^-2): 85.7164 | Val MSE (x10^-2): 34.7584 | Time: 35.13s
2025-07-18 04:07:58,232 - logger.py:50 - Epoch: [112][0/6]	Total Loss: 0.86661	Main MSE (x10^-2): 86.6606	LR: 3.53e-04	EMPP_Raw: 1.41755
2025-07-18 04:08:11,991 - logger.py:50 - Epoch: [112][5/6]	Total Loss: 0.91271	Main MSE (x10^-2): 91.2711	LR: 3.53e-04	EMPP_Raw: 1.45407
2025-07-18 04:08:12,037 - logger.py:50 - Epoch 112 Training Summary: Avg Total Loss: 0.91271, Avg Main MSE: 0.91271, Time: 17.04s
2025-07-18 04:08:30,108 - logger.py:50 - Epoch 112 Summary | Train MSE (x10^-2): 91.2711 | Val MSE (x10^-2): 36.6753 | Time: 35.11s
2025-07-18 04:08:33,260 - logger.py:50 - Epoch: [113][0/6]	Total Loss: 0.88214	Main MSE (x10^-2): 88.2138	LR: 3.53e-04	EMPP_Raw: 1.48471
2025-07-18 04:08:47,007 - logger.py:50 - Epoch: [113][5/6]	Total Loss: 0.85603	Main MSE (x10^-2): 85.6025	LR: 3.53e-04	EMPP_Raw: 1.45950
2025-07-18 04:08:47,052 - logger.py:50 - Epoch 113 Training Summary: Avg Total Loss: 0.85603, Avg Main MSE: 0.85603, Time: 16.93s
2025-07-18 04:09:05,003 - logger.py:50 - Epoch 113 Summary | Train MSE (x10^-2): 85.6025 | Val MSE (x10^-2): 39.3186 | Time: 34.89s
2025-07-18 04:09:08,178 - logger.py:50 - Epoch: [114][0/6]	Total Loss: 0.81561	Main MSE (x10^-2): 81.5612	LR: 3.52e-04	EMPP_Raw: 1.40179
2025-07-18 04:09:22,067 - logger.py:50 - Epoch: [114][5/6]	Total Loss: 0.84295	Main MSE (x10^-2): 84.2951	LR: 3.52e-04	EMPP_Raw: 1.47197
2025-07-18 04:09:22,119 - logger.py:50 - Epoch 114 Training Summary: Avg Total Loss: 0.84295, Avg Main MSE: 0.84295, Time: 17.11s
2025-07-18 04:09:40,196 - logger.py:50 - Epoch 114 Summary | Train MSE (x10^-2): 84.2951 | Val MSE (x10^-2): 36.6148 | Time: 35.19s
2025-07-18 04:09:43,263 - logger.py:50 - Epoch: [115][0/6]	Total Loss: 0.83775	Main MSE (x10^-2): 83.7753	LR: 3.51e-04	EMPP_Raw: 1.47848
2025-07-18 04:09:57,242 - logger.py:50 - Epoch: [115][5/6]	Total Loss: 0.84092	Main MSE (x10^-2): 84.0917	LR: 3.51e-04	EMPP_Raw: 1.47930
2025-07-18 04:09:57,288 - logger.py:50 - Epoch 115 Training Summary: Avg Total Loss: 0.84092, Avg Main MSE: 0.84092, Time: 17.08s
2025-07-18 04:10:15,294 - logger.py:50 - Epoch 115 Summary | Train MSE (x10^-2): 84.0917 | Val MSE (x10^-2): 38.2667 | Time: 35.09s
2025-07-18 04:10:18,283 - logger.py:50 - Epoch: [116][0/6]	Total Loss: 0.83188	Main MSE (x10^-2): 83.1877	LR: 3.50e-04	EMPP_Raw: 1.45206
2025-07-18 04:10:32,063 - logger.py:50 - Epoch: [116][5/6]	Total Loss: 0.83403	Main MSE (x10^-2): 83.4031	LR: 3.50e-04	EMPP_Raw: 1.46391
2025-07-18 04:10:32,121 - logger.py:50 - Epoch 116 Training Summary: Avg Total Loss: 0.83403, Avg Main MSE: 0.83403, Time: 16.82s
2025-07-18 04:10:50,244 - logger.py:50 - Epoch 116 Summary | Train MSE (x10^-2): 83.4031 | Val MSE (x10^-2): 39.1296 | Time: 34.95s
2025-07-18 04:10:53,279 - logger.py:50 - Epoch: [117][0/6]	Total Loss: 0.79903	Main MSE (x10^-2): 79.9030	LR: 3.49e-04	EMPP_Raw: 1.43041
2025-07-18 04:11:07,053 - logger.py:50 - Epoch: [117][5/6]	Total Loss: 0.83119	Main MSE (x10^-2): 83.1186	LR: 3.49e-04	EMPP_Raw: 1.46201
2025-07-18 04:11:07,097 - logger.py:50 - Epoch 117 Training Summary: Avg Total Loss: 0.83119, Avg Main MSE: 0.83119, Time: 16.84s
2025-07-18 04:11:25,128 - logger.py:50 - Epoch 117 Summary | Train MSE (x10^-2): 83.1186 | Val MSE (x10^-2): 37.7501 | Time: 34.88s
2025-07-18 04:11:28,285 - logger.py:50 - Epoch: [118][0/6]	Total Loss: 0.81449	Main MSE (x10^-2): 81.4488	LR: 3.48e-04	EMPP_Raw: 1.42078
2025-07-18 04:11:42,104 - logger.py:50 - Epoch: [118][5/6]	Total Loss: 0.82687	Main MSE (x10^-2): 82.6874	LR: 3.48e-04	EMPP_Raw: 1.45783
2025-07-18 04:11:42,147 - logger.py:50 - Epoch 118 Training Summary: Avg Total Loss: 0.82687, Avg Main MSE: 0.82687, Time: 17.01s
2025-07-18 04:12:00,095 - logger.py:50 - Epoch 118 Summary | Train MSE (x10^-2): 82.6874 | Val MSE (x10^-2): 36.2219 | Time: 34.96s
2025-07-18 04:12:03,128 - logger.py:50 - Epoch: [119][0/6]	Total Loss: 0.80887	Main MSE (x10^-2): 80.8867	LR: 3.48e-04	EMPP_Raw: 1.44525
2025-07-18 04:12:17,027 - logger.py:50 - Epoch: [119][5/6]	Total Loss: 0.82661	Main MSE (x10^-2): 82.6611	LR: 3.48e-04	EMPP_Raw: 1.46198
2025-07-18 04:12:17,072 - logger.py:50 - Epoch 119 Training Summary: Avg Total Loss: 0.82661, Avg Main MSE: 0.82661, Time: 16.97s
2025-07-18 04:12:35,134 - logger.py:50 - Epoch 119 Summary | Train MSE (x10^-2): 82.6611 | Val MSE (x10^-2): 36.8250 | Time: 35.03s
2025-07-18 04:12:38,179 - logger.py:50 - Epoch: [120][0/6]	Total Loss: 0.81032	Main MSE (x10^-2): 81.0317	LR: 3.47e-04	EMPP_Raw: 1.41603
2025-07-18 04:12:52,127 - logger.py:50 - Epoch: [120][5/6]	Total Loss: 0.81832	Main MSE (x10^-2): 81.8324	LR: 3.47e-04	EMPP_Raw: 1.44407
2025-07-18 04:12:52,190 - logger.py:50 - Epoch 120 Training Summary: Avg Total Loss: 0.81832, Avg Main MSE: 0.81832, Time: 17.04s
2025-07-18 04:13:10,176 - logger.py:50 - Epoch 120 Summary | Train MSE (x10^-2): 81.8324 | Val MSE (x10^-2): 36.8099 | Time: 35.04s
2025-07-18 04:13:13,175 - logger.py:50 - Epoch: [121][0/6]	Total Loss: 0.83203	Main MSE (x10^-2): 83.2027	LR: 3.46e-04	EMPP_Raw: 1.48543
2025-07-18 04:13:26,999 - logger.py:50 - Epoch: [121][5/6]	Total Loss: 0.81271	Main MSE (x10^-2): 81.2709	LR: 3.46e-04	EMPP_Raw: 1.44830
2025-07-18 04:13:27,039 - logger.py:50 - Epoch 121 Training Summary: Avg Total Loss: 0.81271, Avg Main MSE: 0.81271, Time: 16.85s
2025-07-18 04:13:45,085 - logger.py:50 - Epoch 121 Summary | Train MSE (x10^-2): 81.2709 | Val MSE (x10^-2): 37.0150 | Time: 34.90s
2025-07-18 04:13:48,092 - logger.py:50 - Epoch: [122][0/6]	Total Loss: 0.82041	Main MSE (x10^-2): 82.0414	LR: 3.45e-04	EMPP_Raw: 1.48270
2025-07-18 04:14:02,072 - logger.py:50 - Epoch: [122][5/6]	Total Loss: 0.81479	Main MSE (x10^-2): 81.4789	LR: 3.45e-04	EMPP_Raw: 1.46697
2025-07-18 04:14:02,118 - logger.py:50 - Epoch 122 Training Summary: Avg Total Loss: 0.81479, Avg Main MSE: 0.81479, Time: 17.02s
2025-07-18 04:14:20,010 - logger.py:50 - Epoch 122 Summary | Train MSE (x10^-2): 81.4789 | Val MSE (x10^-2): 36.8386 | Time: 34.92s
2025-07-18 04:14:23,202 - logger.py:50 - Epoch: [123][0/6]	Total Loss: 0.84155	Main MSE (x10^-2): 84.1547	LR: 3.44e-04	EMPP_Raw: 1.50939
2025-07-18 04:14:36,979 - logger.py:50 - Epoch: [123][5/6]	Total Loss: 0.81743	Main MSE (x10^-2): 81.7429	LR: 3.44e-04	EMPP_Raw: 1.46410
2025-07-18 04:14:37,029 - logger.py:50 - Epoch 123 Training Summary: Avg Total Loss: 0.81743, Avg Main MSE: 0.81743, Time: 17.01s
2025-07-18 04:14:54,883 - logger.py:50 - Epoch 123 Summary | Train MSE (x10^-2): 81.7429 | Val MSE (x10^-2): 38.3409 | Time: 34.87s
2025-07-18 04:14:57,907 - logger.py:50 - Epoch: [124][0/6]	Total Loss: 0.81953	Main MSE (x10^-2): 81.9534	LR: 3.43e-04	EMPP_Raw: 1.47936
2025-07-18 04:15:11,811 - logger.py:50 - Epoch: [124][5/6]	Total Loss: 0.82423	Main MSE (x10^-2): 82.4227	LR: 3.43e-04	EMPP_Raw: 1.48602
2025-07-18 04:15:11,855 - logger.py:50 - Epoch 124 Training Summary: Avg Total Loss: 0.82423, Avg Main MSE: 0.82423, Time: 16.96s
2025-07-18 04:15:30,105 - logger.py:50 - Epoch 124 Summary | Train MSE (x10^-2): 82.4227 | Val MSE (x10^-2): 37.8355 | Time: 35.22s
2025-07-18 04:15:33,127 - logger.py:50 - Epoch: [125][0/6]	Total Loss: 0.85450	Main MSE (x10^-2): 85.4495	LR: 3.42e-04	EMPP_Raw: 1.53883
2025-07-18 04:15:47,066 - logger.py:50 - Epoch: [125][5/6]	Total Loss: 0.82245	Main MSE (x10^-2): 82.2451	LR: 3.42e-04	EMPP_Raw: 1.48047
2025-07-18 04:15:47,118 - logger.py:50 - Epoch 125 Training Summary: Avg Total Loss: 0.82245, Avg Main MSE: 0.82245, Time: 17.00s
2025-07-18 04:16:05,232 - logger.py:50 - Epoch 125 Summary | Train MSE (x10^-2): 82.2451 | Val MSE (x10^-2): 38.0089 | Time: 35.12s
2025-07-18 04:16:08,265 - logger.py:50 - Epoch: [126][0/6]	Total Loss: 0.81305	Main MSE (x10^-2): 81.3050	LR: 3.42e-04	EMPP_Raw: 1.47335
2025-07-18 04:16:22,130 - logger.py:50 - Epoch: [126][5/6]	Total Loss: 0.79738	Main MSE (x10^-2): 79.7380	LR: 3.42e-04	EMPP_Raw: 1.44246
2025-07-18 04:16:22,177 - logger.py:50 - Epoch 126 Training Summary: Avg Total Loss: 0.79738, Avg Main MSE: 0.79738, Time: 16.94s
2025-07-18 04:16:40,347 - logger.py:50 - Epoch 126 Summary | Train MSE (x10^-2): 79.7380 | Val MSE (x10^-2): 37.1378 | Time: 35.11s
2025-07-18 04:16:43,345 - logger.py:50 - Epoch: [127][0/6]	Total Loss: 0.84605	Main MSE (x10^-2): 84.6049	LR: 3.41e-04	EMPP_Raw: 1.53355
2025-07-18 04:16:57,135 - logger.py:50 - Epoch: [127][5/6]	Total Loss: 0.81799	Main MSE (x10^-2): 81.7992	LR: 3.41e-04	EMPP_Raw: 1.47765
2025-07-18 04:16:57,178 - logger.py:50 - Epoch 127 Training Summary: Avg Total Loss: 0.81799, Avg Main MSE: 0.81799, Time: 16.82s
2025-07-18 04:17:15,092 - logger.py:50 - Epoch 127 Summary | Train MSE (x10^-2): 81.7992 | Val MSE (x10^-2): 38.1774 | Time: 34.74s
2025-07-18 04:17:18,251 - logger.py:50 - Epoch: [128][0/6]	Total Loss: 0.83408	Main MSE (x10^-2): 83.4081	LR: 3.40e-04	EMPP_Raw: 1.47697
2025-07-18 04:17:32,050 - logger.py:50 - Epoch: [128][5/6]	Total Loss: 0.82693	Main MSE (x10^-2): 82.6931	LR: 3.40e-04	EMPP_Raw: 1.47376
2025-07-18 04:17:32,093 - logger.py:50 - Epoch 128 Training Summary: Avg Total Loss: 0.82693, Avg Main MSE: 0.82693, Time: 16.99s
2025-07-18 04:17:50,129 - logger.py:50 - Epoch 128 Summary | Train MSE (x10^-2): 82.6931 | Val MSE (x10^-2): 44.2699 | Time: 35.03s
2025-07-18 04:17:53,309 - logger.py:50 - Epoch: [129][0/6]	Total Loss: 0.83195	Main MSE (x10^-2): 83.1952	LR: 3.39e-04	EMPP_Raw: 1.50846
2025-07-18 04:18:07,126 - logger.py:50 - Epoch: [129][5/6]	Total Loss: 0.81732	Main MSE (x10^-2): 81.7318	LR: 3.39e-04	EMPP_Raw: 1.47841
2025-07-18 04:18:07,174 - logger.py:50 - Epoch 129 Training Summary: Avg Total Loss: 0.81732, Avg Main MSE: 0.81732, Time: 17.03s
2025-07-18 04:18:25,239 - logger.py:50 - Epoch 129 Summary | Train MSE (x10^-2): 81.7318 | Val MSE (x10^-2): 41.8260 | Time: 35.10s
2025-07-18 04:18:28,322 - logger.py:50 - Epoch: [130][0/6]	Total Loss: 0.80945	Main MSE (x10^-2): 80.9448	LR: 3.38e-04	EMPP_Raw: 1.46052
2025-07-18 04:18:42,252 - logger.py:50 - Epoch: [130][5/6]	Total Loss: 0.81148	Main MSE (x10^-2): 81.1481	LR: 3.38e-04	EMPP_Raw: 1.47207
2025-07-18 04:18:42,296 - logger.py:50 - Epoch 130 Training Summary: Avg Total Loss: 0.81148, Avg Main MSE: 0.81148, Time: 17.05s
2025-07-18 04:19:00,337 - logger.py:50 - Epoch 130 Summary | Train MSE (x10^-2): 81.1481 | Val MSE (x10^-2): 40.7228 | Time: 35.09s
2025-07-18 04:19:03,330 - logger.py:50 - Epoch: [131][0/6]	Total Loss: 0.80438	Main MSE (x10^-2): 80.4383	LR: 3.37e-04	EMPP_Raw: 1.47098
2025-07-18 04:19:17,291 - logger.py:50 - Epoch: [131][5/6]	Total Loss: 0.79539	Main MSE (x10^-2): 79.5395	LR: 3.37e-04	EMPP_Raw: 1.45697
2025-07-18 04:19:17,345 - logger.py:50 - Epoch 131 Training Summary: Avg Total Loss: 0.79539, Avg Main MSE: 0.79539, Time: 17.00s
2025-07-18 04:19:35,219 - logger.py:50 - Epoch 131 Summary | Train MSE (x10^-2): 79.5395 | Val MSE (x10^-2): 41.5837 | Time: 34.88s
2025-07-18 04:19:38,249 - logger.py:50 - Epoch: [132][0/6]	Total Loss: 0.78921	Main MSE (x10^-2): 78.9211	LR: 3.36e-04	EMPP_Raw: 1.46084
2025-07-18 04:19:52,096 - logger.py:50 - Epoch: [132][5/6]	Total Loss: 0.78361	Main MSE (x10^-2): 78.3608	LR: 3.36e-04	EMPP_Raw: 1.43776
2025-07-18 04:19:52,141 - logger.py:50 - Epoch 132 Training Summary: Avg Total Loss: 0.78361, Avg Main MSE: 0.78361, Time: 16.91s
2025-07-18 04:20:10,232 - logger.py:50 - Epoch 132 Summary | Train MSE (x10^-2): 78.3608 | Val MSE (x10^-2): 39.7291 | Time: 35.01s
2025-07-18 04:20:13,236 - logger.py:50 - Epoch: [133][0/6]	Total Loss: 0.80962	Main MSE (x10^-2): 80.9618	LR: 3.35e-04	EMPP_Raw: 1.50175
2025-07-18 04:20:27,047 - logger.py:50 - Epoch: [133][5/6]	Total Loss: 0.80457	Main MSE (x10^-2): 80.4574	LR: 3.35e-04	EMPP_Raw: 1.48005
2025-07-18 04:20:27,089 - logger.py:50 - Epoch 133 Training Summary: Avg Total Loss: 0.80457, Avg Main MSE: 0.80457, Time: 16.85s
2025-07-18 04:20:45,029 - logger.py:50 - Epoch 133 Summary | Train MSE (x10^-2): 80.4574 | Val MSE (x10^-2): 40.5359 | Time: 34.79s
2025-07-18 04:20:48,179 - logger.py:50 - Epoch: [134][0/6]	Total Loss: 0.81068	Main MSE (x10^-2): 81.0677	LR: 3.34e-04	EMPP_Raw: 1.49970
2025-07-18 04:21:01,940 - logger.py:50 - Epoch: [134][5/6]	Total Loss: 0.79715	Main MSE (x10^-2): 79.7148	LR: 3.34e-04	EMPP_Raw: 1.46919
2025-07-18 04:21:01,992 - logger.py:50 - Epoch 134 Training Summary: Avg Total Loss: 0.79715, Avg Main MSE: 0.79715, Time: 16.95s
2025-07-18 04:21:19,908 - logger.py:50 - Epoch 134 Summary | Train MSE (x10^-2): 79.7148 | Val MSE (x10^-2): 40.2943 | Time: 34.87s
2025-07-18 04:21:23,150 - logger.py:50 - Epoch: [135][0/6]	Total Loss: 0.77051	Main MSE (x10^-2): 77.0510	LR: 3.33e-04	EMPP_Raw: 1.41804
2025-07-18 04:21:37,072 - logger.py:50 - Epoch: [135][5/6]	Total Loss: 0.79277	Main MSE (x10^-2): 79.2773	LR: 3.33e-04	EMPP_Raw: 1.45767
2025-07-18 04:21:37,140 - logger.py:50 - Epoch 135 Training Summary: Avg Total Loss: 0.79277, Avg Main MSE: 0.79277, Time: 17.22s
2025-07-18 04:21:55,497 - logger.py:50 - Epoch 135 Summary | Train MSE (x10^-2): 79.2773 | Val MSE (x10^-2): 41.3409 | Time: 35.58s
2025-07-18 04:21:58,519 - logger.py:50 - Epoch: [136][0/6]	Total Loss: 0.78653	Main MSE (x10^-2): 78.6533	LR: 3.32e-04	EMPP_Raw: 1.44305
2025-07-18 04:22:12,526 - logger.py:50 - Epoch: [136][5/6]	Total Loss: 0.79786	Main MSE (x10^-2): 79.7864	LR: 3.32e-04	EMPP_Raw: 1.47157
2025-07-18 04:22:12,591 - logger.py:50 - Epoch 136 Training Summary: Avg Total Loss: 0.79786, Avg Main MSE: 0.79786, Time: 17.08s
2025-07-18 04:22:30,652 - logger.py:50 - Epoch 136 Summary | Train MSE (x10^-2): 79.7864 | Val MSE (x10^-2): 39.0410 | Time: 35.15s
2025-07-18 04:22:33,683 - logger.py:50 - Epoch: [137][0/6]	Total Loss: 0.77332	Main MSE (x10^-2): 77.3325	LR: 3.31e-04	EMPP_Raw: 1.43254
2025-07-18 04:22:47,661 - logger.py:50 - Epoch: [137][5/6]	Total Loss: 0.78409	Main MSE (x10^-2): 78.4093	LR: 3.31e-04	EMPP_Raw: 1.45001
2025-07-18 04:22:47,702 - logger.py:50 - Epoch 137 Training Summary: Avg Total Loss: 0.78409, Avg Main MSE: 0.78409, Time: 17.04s
2025-07-18 04:23:05,705 - logger.py:50 - Epoch 137 Summary | Train MSE (x10^-2): 78.4093 | Val MSE (x10^-2): 41.2001 | Time: 35.05s
2025-07-18 04:23:08,767 - logger.py:50 - Epoch: [138][0/6]	Total Loss: 0.79227	Main MSE (x10^-2): 79.2267	LR: 3.31e-04	EMPP_Raw: 1.47637
2025-07-18 04:23:22,820 - logger.py:50 - Epoch: [138][5/6]	Total Loss: 0.78716	Main MSE (x10^-2): 78.7155	LR: 3.31e-04	EMPP_Raw: 1.46025
2025-07-18 04:23:22,867 - logger.py:50 - Epoch 138 Training Summary: Avg Total Loss: 0.78716, Avg Main MSE: 0.78716, Time: 17.15s
2025-07-18 04:23:40,993 - logger.py:50 - Epoch 138 Summary | Train MSE (x10^-2): 78.7155 | Val MSE (x10^-2): 39.5252 | Time: 35.28s
2025-07-18 04:23:44,011 - logger.py:50 - Epoch: [139][0/6]	Total Loss: 0.80204	Main MSE (x10^-2): 80.2043	LR: 3.30e-04	EMPP_Raw: 1.49434
2025-07-18 04:23:57,855 - logger.py:50 - Epoch: [139][5/6]	Total Loss: 0.79892	Main MSE (x10^-2): 79.8922	LR: 3.30e-04	EMPP_Raw: 1.48279
2025-07-18 04:23:57,901 - logger.py:50 - Epoch 139 Training Summary: Avg Total Loss: 0.79892, Avg Main MSE: 0.79892, Time: 16.90s
2025-07-18 04:24:15,923 - logger.py:50 - Epoch 139 Summary | Train MSE (x10^-2): 79.8922 | Val MSE (x10^-2): 39.5711 | Time: 34.92s
2025-07-18 04:24:19,152 - logger.py:50 - Epoch: [140][0/6]	Total Loss: 0.78467	Main MSE (x10^-2): 78.4671	LR: 3.29e-04	EMPP_Raw: 1.47350
2025-07-18 04:24:32,972 - logger.py:50 - Epoch: [140][5/6]	Total Loss: 0.78349	Main MSE (x10^-2): 78.3491	LR: 3.29e-04	EMPP_Raw: 1.46372
2025-07-18 04:24:33,014 - logger.py:50 - Epoch 140 Training Summary: Avg Total Loss: 0.78349, Avg Main MSE: 0.78349, Time: 17.08s
2025-07-18 04:24:51,073 - logger.py:50 - Epoch 140 Summary | Train MSE (x10^-2): 78.3491 | Val MSE (x10^-2): 39.4550 | Time: 35.15s
2025-07-18 04:24:54,244 - logger.py:50 - Epoch: [141][0/6]	Total Loss: 0.79998	Main MSE (x10^-2): 79.9984	LR: 3.28e-04	EMPP_Raw: 1.48174
2025-07-18 04:25:08,135 - logger.py:50 - Epoch: [141][5/6]	Total Loss: 0.78164	Main MSE (x10^-2): 78.1644	LR: 3.28e-04	EMPP_Raw: 1.45820
2025-07-18 04:25:08,182 - logger.py:50 - Epoch 141 Training Summary: Avg Total Loss: 0.78164, Avg Main MSE: 0.78164, Time: 17.10s
2025-07-18 04:25:26,317 - logger.py:50 - Epoch 141 Summary | Train MSE (x10^-2): 78.1644 | Val MSE (x10^-2): 40.7275 | Time: 35.24s
2025-07-18 04:25:29,490 - logger.py:50 - Epoch: [142][0/6]	Total Loss: 0.78921	Main MSE (x10^-2): 78.9212	LR: 3.27e-04	EMPP_Raw: 1.48190
2025-07-18 04:25:43,367 - logger.py:50 - Epoch: [142][5/6]	Total Loss: 0.78445	Main MSE (x10^-2): 78.4453	LR: 3.27e-04	EMPP_Raw: 1.46619
2025-07-18 04:25:43,407 - logger.py:50 - Epoch 142 Training Summary: Avg Total Loss: 0.78445, Avg Main MSE: 0.78445, Time: 17.08s
2025-07-18 04:26:01,370 - logger.py:50 - Epoch 142 Summary | Train MSE (x10^-2): 78.4453 | Val MSE (x10^-2): 40.8879 | Time: 35.05s
2025-07-18 04:26:04,475 - logger.py:50 - Epoch: [143][0/6]	Total Loss: 0.79264	Main MSE (x10^-2): 79.2643	LR: 3.26e-04	EMPP_Raw: 1.46995
2025-07-18 04:26:18,566 - logger.py:50 - Epoch: [143][5/6]	Total Loss: 0.78680	Main MSE (x10^-2): 78.6804	LR: 3.26e-04	EMPP_Raw: 1.46814
2025-07-18 04:26:18,607 - logger.py:50 - Epoch 143 Training Summary: Avg Total Loss: 0.78680, Avg Main MSE: 0.78680, Time: 17.23s
2025-07-18 04:26:36,804 - logger.py:50 - Epoch 143 Summary | Train MSE (x10^-2): 78.6804 | Val MSE (x10^-2): 39.7922 | Time: 35.43s
2025-07-18 04:26:39,819 - logger.py:50 - Epoch: [144][0/6]	Total Loss: 0.79672	Main MSE (x10^-2): 79.6719	LR: 3.25e-04	EMPP_Raw: 1.48945
2025-07-18 04:26:53,667 - logger.py:50 - Epoch: [144][5/6]	Total Loss: 0.78500	Main MSE (x10^-2): 78.5005	LR: 3.25e-04	EMPP_Raw: 1.46428
2025-07-18 04:26:53,716 - logger.py:50 - Epoch 144 Training Summary: Avg Total Loss: 0.78500, Avg Main MSE: 0.78500, Time: 16.90s
2025-07-18 04:27:11,879 - logger.py:50 - Epoch 144 Summary | Train MSE (x10^-2): 78.5005 | Val MSE (x10^-2): 39.5579 | Time: 35.07s
2025-07-18 04:27:14,870 - logger.py:50 - Epoch: [145][0/6]	Total Loss: 0.78845	Main MSE (x10^-2): 78.8453	LR: 3.24e-04	EMPP_Raw: 1.47340
2025-07-18 04:27:28,662 - logger.py:50 - Epoch: [145][5/6]	Total Loss: 0.77119	Main MSE (x10^-2): 77.1186	LR: 3.24e-04	EMPP_Raw: 1.44763
2025-07-18 04:27:28,708 - logger.py:50 - Epoch 145 Training Summary: Avg Total Loss: 0.77119, Avg Main MSE: 0.77119, Time: 16.82s
2025-07-18 04:27:46,752 - logger.py:50 - Epoch 145 Summary | Train MSE (x10^-2): 77.1186 | Val MSE (x10^-2): 40.4509 | Time: 34.87s
2025-07-18 04:27:49,768 - logger.py:50 - Epoch: [146][0/6]	Total Loss: 0.75901	Main MSE (x10^-2): 75.9013	LR: 3.23e-04	EMPP_Raw: 1.41791
2025-07-18 04:28:03,590 - logger.py:50 - Epoch: [146][5/6]	Total Loss: 0.76969	Main MSE (x10^-2): 76.9690	LR: 3.23e-04	EMPP_Raw: 1.44496
2025-07-18 04:28:03,631 - logger.py:50 - Epoch 146 Training Summary: Avg Total Loss: 0.76969, Avg Main MSE: 0.76969, Time: 16.87s
2025-07-18 04:28:21,745 - logger.py:50 - Epoch 146 Summary | Train MSE (x10^-2): 76.9690 | Val MSE (x10^-2): 40.6448 | Time: 34.99s
2025-07-18 04:28:24,934 - logger.py:50 - Epoch: [147][0/6]	Total Loss: 0.78338	Main MSE (x10^-2): 78.3381	LR: 3.22e-04	EMPP_Raw: 1.47185
2025-07-18 04:28:38,726 - logger.py:50 - Epoch: [147][5/6]	Total Loss: 0.77358	Main MSE (x10^-2): 77.3575	LR: 3.22e-04	EMPP_Raw: 1.45302
2025-07-18 04:28:38,772 - logger.py:50 - Epoch 147 Training Summary: Avg Total Loss: 0.77358, Avg Main MSE: 0.77358, Time: 17.02s
2025-07-18 04:28:56,750 - logger.py:50 - Epoch 147 Summary | Train MSE (x10^-2): 77.3575 | Val MSE (x10^-2): 40.9943 | Time: 35.00s
2025-07-18 04:28:59,912 - logger.py:50 - Epoch: [148][0/6]	Total Loss: 0.78178	Main MSE (x10^-2): 78.1782	LR: 3.21e-04	EMPP_Raw: 1.45967
2025-07-18 04:29:13,644 - logger.py:50 - Epoch: [148][5/6]	Total Loss: 0.76572	Main MSE (x10^-2): 76.5724	LR: 3.21e-04	EMPP_Raw: 1.44382
2025-07-18 04:29:13,686 - logger.py:50 - Epoch 148 Training Summary: Avg Total Loss: 0.76572, Avg Main MSE: 0.76572, Time: 16.93s
2025-07-18 04:29:31,604 - logger.py:50 - Epoch 148 Summary | Train MSE (x10^-2): 76.5724 | Val MSE (x10^-2): 39.1572 | Time: 34.85s
2025-07-18 04:29:34,598 - logger.py:50 - Epoch: [149][0/6]	Total Loss: 0.76457	Main MSE (x10^-2): 76.4574	LR: 3.20e-04	EMPP_Raw: 1.43543
2025-07-18 04:29:48,520 - logger.py:50 - Epoch: [149][5/6]	Total Loss: 0.77401	Main MSE (x10^-2): 77.4006	LR: 3.20e-04	EMPP_Raw: 1.46050
2025-07-18 04:29:48,563 - logger.py:50 - Epoch 149 Training Summary: Avg Total Loss: 0.77401, Avg Main MSE: 0.77401, Time: 16.95s
2025-07-18 04:30:06,495 - logger.py:50 - Epoch 149 Summary | Train MSE (x10^-2): 77.4006 | Val MSE (x10^-2): 40.7380 | Time: 34.89s
2025-07-18 04:30:09,543 - logger.py:50 - Epoch: [150][0/6]	Total Loss: 0.77690	Main MSE (x10^-2): 77.6901	LR: 3.19e-04	EMPP_Raw: 1.47186
2025-07-18 04:30:23,524 - logger.py:50 - Epoch: [150][5/6]	Total Loss: 0.77712	Main MSE (x10^-2): 77.7124	LR: 3.19e-04	EMPP_Raw: 1.46369
2025-07-18 04:30:23,571 - logger.py:50 - Epoch 150 Training Summary: Avg Total Loss: 0.77712, Avg Main MSE: 0.77712, Time: 17.07s
2025-07-18 04:30:41,599 - logger.py:50 - Epoch 150 Summary | Train MSE (x10^-2): 77.7124 | Val MSE (x10^-2): 39.4129 | Time: 35.10s
2025-07-18 04:30:44,613 - logger.py:50 - Epoch: [151][0/6]	Total Loss: 0.75626	Main MSE (x10^-2): 75.6257	LR: 3.18e-04	EMPP_Raw: 1.41602
2025-07-18 04:30:58,402 - logger.py:50 - Epoch: [151][5/6]	Total Loss: 0.79028	Main MSE (x10^-2): 79.0276	LR: 3.18e-04	EMPP_Raw: 1.47911
2025-07-18 04:30:58,447 - logger.py:50 - Epoch 151 Training Summary: Avg Total Loss: 0.79028, Avg Main MSE: 0.79028, Time: 16.84s
2025-07-18 04:31:16,681 - logger.py:50 - Epoch 151 Summary | Train MSE (x10^-2): 79.0276 | Val MSE (x10^-2): 41.6736 | Time: 35.08s
2025-07-18 04:31:19,684 - logger.py:50 - Epoch: [152][0/6]	Total Loss: 0.77793	Main MSE (x10^-2): 77.7927	LR: 3.17e-04	EMPP_Raw: 1.46177
2025-07-18 04:31:33,509 - logger.py:50 - Epoch: [152][5/6]	Total Loss: 0.77610	Main MSE (x10^-2): 77.6101	LR: 3.17e-04	EMPP_Raw: 1.46309
2025-07-18 04:31:33,554 - logger.py:50 - Epoch 152 Training Summary: Avg Total Loss: 0.77610, Avg Main MSE: 0.77610, Time: 16.87s
2025-07-18 04:31:51,420 - logger.py:50 - Epoch 152 Summary | Train MSE (x10^-2): 77.6101 | Val MSE (x10^-2): 41.6628 | Time: 34.74s
2025-07-18 04:31:54,628 - logger.py:50 - Epoch: [153][0/6]	Total Loss: 0.73548	Main MSE (x10^-2): 73.5484	LR: 3.16e-04	EMPP_Raw: 1.38981
2025-07-18 04:32:08,499 - logger.py:50 - Epoch: [153][5/6]	Total Loss: 0.76924	Main MSE (x10^-2): 76.9242	LR: 3.16e-04	EMPP_Raw: 1.44852
2025-07-18 04:32:08,562 - logger.py:50 - Epoch 153 Training Summary: Avg Total Loss: 0.76924, Avg Main MSE: 0.76924, Time: 17.13s
2025-07-18 04:32:26,794 - logger.py:50 - Epoch 153 Summary | Train MSE (x10^-2): 76.9242 | Val MSE (x10^-2): 43.1179 | Time: 35.37s
2025-07-18 04:32:30,003 - logger.py:50 - Epoch: [154][0/6]	Total Loss: 0.77804	Main MSE (x10^-2): 77.8044	LR: 3.15e-04	EMPP_Raw: 1.46744
2025-07-18 04:32:43,802 - logger.py:50 - Epoch: [154][5/6]	Total Loss: 0.77837	Main MSE (x10^-2): 77.8368	LR: 3.15e-04	EMPP_Raw: 1.46846
2025-07-18 04:32:43,844 - logger.py:50 - Epoch 154 Training Summary: Avg Total Loss: 0.77837, Avg Main MSE: 0.77837, Time: 17.04s
2025-07-18 04:33:01,897 - logger.py:50 - Epoch 154 Summary | Train MSE (x10^-2): 77.8368 | Val MSE (x10^-2): 44.3348 | Time: 35.10s
2025-07-18 04:33:05,071 - logger.py:50 - Epoch: [155][0/6]	Total Loss: 0.77354	Main MSE (x10^-2): 77.3536	LR: 3.14e-04	EMPP_Raw: 1.45538
2025-07-18 04:33:18,981 - logger.py:50 - Epoch: [155][5/6]	Total Loss: 0.77011	Main MSE (x10^-2): 77.0110	LR: 3.14e-04	EMPP_Raw: 1.45348
2025-07-18 04:33:19,026 - logger.py:50 - Epoch 155 Training Summary: Avg Total Loss: 0.77011, Avg Main MSE: 0.77011, Time: 17.12s
2025-07-18 04:33:37,042 - logger.py:50 - Epoch 155 Summary | Train MSE (x10^-2): 77.0110 | Val MSE (x10^-2): 38.4159 | Time: 35.14s
2025-07-18 04:33:40,044 - logger.py:50 - Epoch: [156][0/6]	Total Loss: 0.79600	Main MSE (x10^-2): 79.6000	LR: 3.13e-04	EMPP_Raw: 1.51274
2025-07-18 04:33:54,049 - logger.py:50 - Epoch: [156][5/6]	Total Loss: 0.77627	Main MSE (x10^-2): 77.6265	LR: 3.13e-04	EMPP_Raw: 1.47475
2025-07-18 04:33:54,094 - logger.py:50 - Epoch 156 Training Summary: Avg Total Loss: 0.77627, Avg Main MSE: 0.77627, Time: 17.04s
2025-07-18 04:34:12,071 - logger.py:50 - Epoch 156 Summary | Train MSE (x10^-2): 77.6265 | Val MSE (x10^-2): 38.6360 | Time: 35.02s
2025-07-18 04:34:15,115 - logger.py:50 - Epoch: [157][0/6]	Total Loss: 0.77630	Main MSE (x10^-2): 77.6298	LR: 3.12e-04	EMPP_Raw: 1.47543
2025-07-18 04:34:28,906 - logger.py:50 - Epoch: [157][5/6]	Total Loss: 0.77226	Main MSE (x10^-2): 77.2262	LR: 3.12e-04	EMPP_Raw: 1.46719
2025-07-18 04:34:28,953 - logger.py:50 - Epoch 157 Training Summary: Avg Total Loss: 0.77226, Avg Main MSE: 0.77226, Time: 16.87s
2025-07-18 04:34:47,208 - logger.py:50 - Epoch 157 Summary | Train MSE (x10^-2): 77.2262 | Val MSE (x10^-2): 38.9641 | Time: 35.13s
2025-07-18 04:34:50,230 - logger.py:50 - Epoch: [158][0/6]	Total Loss: 0.77637	Main MSE (x10^-2): 77.6366	LR: 3.11e-04	EMPP_Raw: 1.45261
2025-07-18 04:35:04,059 - logger.py:50 - Epoch: [158][5/6]	Total Loss: 0.76463	Main MSE (x10^-2): 76.4633	LR: 3.11e-04	EMPP_Raw: 1.44952
2025-07-18 04:35:04,103 - logger.py:50 - Epoch 158 Training Summary: Avg Total Loss: 0.76463, Avg Main MSE: 0.76463, Time: 16.89s
2025-07-18 04:35:22,274 - logger.py:50 - Epoch 158 Summary | Train MSE (x10^-2): 76.4633 | Val MSE (x10^-2): 40.8617 | Time: 35.06s
2025-07-18 04:35:25,270 - logger.py:50 - Epoch: [159][0/6]	Total Loss: 0.73481	Main MSE (x10^-2): 73.4810	LR: 3.10e-04	EMPP_Raw: 1.38837
2025-07-18 04:35:39,082 - logger.py:50 - Epoch: [159][5/6]	Total Loss: 0.76181	Main MSE (x10^-2): 76.1813	LR: 3.10e-04	EMPP_Raw: 1.44839
2025-07-18 04:35:39,134 - logger.py:50 - Epoch 159 Training Summary: Avg Total Loss: 0.76181, Avg Main MSE: 0.76181, Time: 16.85s
2025-07-18 04:35:57,120 - logger.py:50 - Epoch 159 Summary | Train MSE (x10^-2): 76.1813 | Val MSE (x10^-2): 40.8103 | Time: 34.84s
2025-07-18 04:36:00,321 - logger.py:50 - Epoch: [160][0/6]	Total Loss: 0.78506	Main MSE (x10^-2): 78.5065	LR: 3.08e-04	EMPP_Raw: 1.49065
2025-07-18 04:36:14,123 - logger.py:50 - Epoch: [160][5/6]	Total Loss: 0.76775	Main MSE (x10^-2): 76.7750	LR: 3.08e-04	EMPP_Raw: 1.46016
2025-07-18 04:36:14,165 - logger.py:50 - Epoch 160 Training Summary: Avg Total Loss: 0.76775, Avg Main MSE: 0.76775, Time: 17.04s
2025-07-18 04:36:32,179 - logger.py:50 - Epoch 160 Summary | Train MSE (x10^-2): 76.7750 | Val MSE (x10^-2): 40.3941 | Time: 35.05s
2025-07-18 04:36:35,374 - logger.py:50 - Epoch: [161][0/6]	Total Loss: 0.78777	Main MSE (x10^-2): 78.7768	LR: 3.07e-04	EMPP_Raw: 1.50381
2025-07-18 04:36:49,258 - logger.py:50 - Epoch: [161][5/6]	Total Loss: 0.76360	Main MSE (x10^-2): 76.3602	LR: 3.07e-04	EMPP_Raw: 1.45685
2025-07-18 04:36:49,302 - logger.py:50 - Epoch 161 Training Summary: Avg Total Loss: 0.76360, Avg Main MSE: 0.76360, Time: 17.12s
2025-07-18 04:37:07,232 - logger.py:50 - Epoch 161 Summary | Train MSE (x10^-2): 76.3602 | Val MSE (x10^-2): 41.8699 | Time: 35.05s
2025-07-18 04:37:10,228 - logger.py:50 - Epoch: [162][0/6]	Total Loss: 0.73794	Main MSE (x10^-2): 73.7943	LR: 3.06e-04	EMPP_Raw: 1.41046
2025-07-18 04:37:24,218 - logger.py:50 - Epoch: [162][5/6]	Total Loss: 0.75470	Main MSE (x10^-2): 75.4702	LR: 3.06e-04	EMPP_Raw: 1.44244
2025-07-18 04:37:24,261 - logger.py:50 - Epoch 162 Training Summary: Avg Total Loss: 0.75470, Avg Main MSE: 0.75470, Time: 17.02s
2025-07-18 04:37:42,321 - logger.py:50 - Epoch 162 Summary | Train MSE (x10^-2): 75.4702 | Val MSE (x10^-2): 41.7559 | Time: 35.08s
2025-07-18 04:37:45,336 - logger.py:50 - Epoch: [163][0/6]	Total Loss: 0.77135	Main MSE (x10^-2): 77.1348	LR: 3.05e-04	EMPP_Raw: 1.47161
2025-07-18 04:37:59,468 - logger.py:50 - Epoch: [163][5/6]	Total Loss: 0.76528	Main MSE (x10^-2): 76.5275	LR: 3.05e-04	EMPP_Raw: 1.45898
2025-07-18 04:37:59,513 - logger.py:50 - Epoch 163 Training Summary: Avg Total Loss: 0.76528, Avg Main MSE: 0.76528, Time: 17.18s
2025-07-18 04:38:17,428 - logger.py:50 - Epoch 163 Summary | Train MSE (x10^-2): 76.5275 | Val MSE (x10^-2): 41.8359 | Time: 35.10s
2025-07-18 04:38:20,485 - logger.py:50 - Epoch: [164][0/6]	Total Loss: 0.77076	Main MSE (x10^-2): 77.0757	LR: 3.04e-04	EMPP_Raw: 1.47465
2025-07-18 04:38:34,319 - logger.py:50 - Epoch: [164][5/6]	Total Loss: 0.76906	Main MSE (x10^-2): 76.9059	LR: 3.04e-04	EMPP_Raw: 1.47283
2025-07-18 04:38:34,365 - logger.py:50 - Epoch 164 Training Summary: Avg Total Loss: 0.76906, Avg Main MSE: 0.76906, Time: 16.93s
2025-07-18 04:38:52,494 - logger.py:50 - Epoch 164 Summary | Train MSE (x10^-2): 76.9059 | Val MSE (x10^-2): 41.4348 | Time: 35.06s
2025-07-18 04:38:55,485 - logger.py:50 - Epoch: [165][0/6]	Total Loss: 0.77165	Main MSE (x10^-2): 77.1648	LR: 3.03e-04	EMPP_Raw: 1.47944
2025-07-18 04:39:09,288 - logger.py:50 - Epoch: [165][5/6]	Total Loss: 0.76219	Main MSE (x10^-2): 76.2187	LR: 3.03e-04	EMPP_Raw: 1.46068
2025-07-18 04:39:09,339 - logger.py:50 - Epoch 165 Training Summary: Avg Total Loss: 0.76219, Avg Main MSE: 0.76219, Time: 16.84s
2025-07-18 04:39:27,523 - logger.py:50 - Epoch 165 Summary | Train MSE (x10^-2): 76.2187 | Val MSE (x10^-2): 41.9894 | Time: 35.02s
2025-07-18 04:39:30,662 - logger.py:50 - Epoch: [166][0/6]	Total Loss: 0.78311	Main MSE (x10^-2): 78.3114	LR: 3.02e-04	EMPP_Raw: 1.50376
2025-07-18 04:39:44,572 - logger.py:50 - Epoch: [166][5/6]	Total Loss: 0.75929	Main MSE (x10^-2): 75.9285	LR: 3.02e-04	EMPP_Raw: 1.45621
2025-07-18 04:39:44,621 - logger.py:50 - Epoch 166 Training Summary: Avg Total Loss: 0.75929, Avg Main MSE: 0.75929, Time: 17.09s
2025-07-18 04:40:02,559 - logger.py:50 - Epoch 166 Summary | Train MSE (x10^-2): 75.9285 | Val MSE (x10^-2): 39.9896 | Time: 35.03s
2025-07-18 04:40:05,722 - logger.py:50 - Epoch: [167][0/6]	Total Loss: 0.77094	Main MSE (x10^-2): 77.0940	LR: 3.01e-04	EMPP_Raw: 1.46302
2025-07-18 04:40:19,509 - logger.py:50 - Epoch: [167][5/6]	Total Loss: 0.76201	Main MSE (x10^-2): 76.2015	LR: 3.01e-04	EMPP_Raw: 1.45459
2025-07-18 04:40:19,553 - logger.py:50 - Epoch 167 Training Summary: Avg Total Loss: 0.76201, Avg Main MSE: 0.76201, Time: 16.98s
2025-07-18 04:40:37,651 - logger.py:50 - Epoch 167 Summary | Train MSE (x10^-2): 76.2015 | Val MSE (x10^-2): 41.5090 | Time: 35.08s
2025-07-18 04:40:40,873 - logger.py:50 - Epoch: [168][0/6]	Total Loss: 0.77097	Main MSE (x10^-2): 77.0971	LR: 3.00e-04	EMPP_Raw: 1.47699
2025-07-18 04:40:54,715 - logger.py:50 - Epoch: [168][5/6]	Total Loss: 0.75754	Main MSE (x10^-2): 75.7545	LR: 3.00e-04	EMPP_Raw: 1.45316
2025-07-18 04:40:54,760 - logger.py:50 - Epoch 168 Training Summary: Avg Total Loss: 0.75754, Avg Main MSE: 0.75754, Time: 17.10s
2025-07-18 04:41:12,675 - logger.py:50 - Epoch 168 Summary | Train MSE (x10^-2): 75.7545 | Val MSE (x10^-2): 41.3389 | Time: 35.02s
2025-07-18 04:41:15,773 - logger.py:50 - Epoch: [169][0/6]	Total Loss: 0.76160	Main MSE (x10^-2): 76.1598	LR: 2.99e-04	EMPP_Raw: 1.46232
2025-07-18 04:41:29,915 - logger.py:50 - Epoch: [169][5/6]	Total Loss: 0.75591	Main MSE (x10^-2): 75.5908	LR: 2.99e-04	EMPP_Raw: 1.44870
2025-07-18 04:41:29,974 - logger.py:50 - Epoch 169 Training Summary: Avg Total Loss: 0.75591, Avg Main MSE: 0.75591, Time: 17.29s
2025-07-18 04:41:48,175 - logger.py:50 - Epoch 169 Summary | Train MSE (x10^-2): 75.5908 | Val MSE (x10^-2): 41.6261 | Time: 35.49s
2025-07-18 04:41:51,215 - logger.py:50 - Epoch: [170][0/6]	Total Loss: 0.77448	Main MSE (x10^-2): 77.4481	LR: 2.98e-04	EMPP_Raw: 1.47904
2025-07-18 04:42:05,080 - logger.py:50 - Epoch: [170][5/6]	Total Loss: 0.74938	Main MSE (x10^-2): 74.9378	LR: 2.98e-04	EMPP_Raw: 1.43671
2025-07-18 04:42:05,121 - logger.py:50 - Epoch 170 Training Summary: Avg Total Loss: 0.74938, Avg Main MSE: 0.74938, Time: 16.94s
2025-07-18 04:42:23,216 - logger.py:50 - Epoch 170 Summary | Train MSE (x10^-2): 74.9378 | Val MSE (x10^-2): 41.5326 | Time: 35.04s
2025-07-18 04:42:26,216 - logger.py:50 - Epoch: [171][0/6]	Total Loss: 0.75983	Main MSE (x10^-2): 75.9835	LR: 2.97e-04	EMPP_Raw: 1.44739
2025-07-18 04:42:40,004 - logger.py:50 - Epoch: [171][5/6]	Total Loss: 0.75336	Main MSE (x10^-2): 75.3364	LR: 2.97e-04	EMPP_Raw: 1.44454
2025-07-18 04:42:40,044 - logger.py:50 - Epoch 171 Training Summary: Avg Total Loss: 0.75336, Avg Main MSE: 0.75336, Time: 16.82s
2025-07-18 04:42:58,200 - logger.py:50 - Epoch 171 Summary | Train MSE (x10^-2): 75.3364 | Val MSE (x10^-2): 42.9808 | Time: 34.98s
2025-07-18 04:43:01,233 - logger.py:50 - Epoch: [172][0/6]	Total Loss: 0.76371	Main MSE (x10^-2): 76.3715	LR: 2.96e-04	EMPP_Raw: 1.46528
2025-07-18 04:43:15,043 - logger.py:50 - Epoch: [172][5/6]	Total Loss: 0.75588	Main MSE (x10^-2): 75.5885	LR: 2.96e-04	EMPP_Raw: 1.45023
2025-07-18 04:43:15,086 - logger.py:50 - Epoch 172 Training Summary: Avg Total Loss: 0.75588, Avg Main MSE: 0.75588, Time: 16.88s
2025-07-18 04:43:33,154 - logger.py:50 - Epoch 172 Summary | Train MSE (x10^-2): 75.5885 | Val MSE (x10^-2): 40.9875 | Time: 34.95s
2025-07-18 04:43:36,373 - logger.py:50 - Epoch: [173][0/6]	Total Loss: 0.76831	Main MSE (x10^-2): 76.8306	LR: 2.94e-04	EMPP_Raw: 1.47801
2025-07-18 04:43:50,225 - logger.py:50 - Epoch: [173][5/6]	Total Loss: 0.76394	Main MSE (x10^-2): 76.3939	LR: 2.94e-04	EMPP_Raw: 1.46785
2025-07-18 04:43:50,265 - logger.py:50 - Epoch 173 Training Summary: Avg Total Loss: 0.76394, Avg Main MSE: 0.76394, Time: 17.10s
2025-07-18 04:44:08,462 - logger.py:50 - Epoch 173 Summary | Train MSE (x10^-2): 76.3939 | Val MSE (x10^-2): 40.6219 | Time: 35.30s
2025-07-18 04:44:11,614 - logger.py:50 - Epoch: [174][0/6]	Total Loss: 0.75352	Main MSE (x10^-2): 75.3519	LR: 2.93e-04	EMPP_Raw: 1.43984
2025-07-18 04:44:25,381 - logger.py:50 - Epoch: [174][5/6]	Total Loss: 0.75884	Main MSE (x10^-2): 75.8843	LR: 2.93e-04	EMPP_Raw: 1.45048
2025-07-18 04:44:25,422 - logger.py:50 - Epoch 174 Training Summary: Avg Total Loss: 0.75884, Avg Main MSE: 0.75884, Time: 16.95s
2025-07-18 04:44:43,642 - logger.py:50 - Epoch 174 Summary | Train MSE (x10^-2): 75.8843 | Val MSE (x10^-2): 41.8349 | Time: 35.17s
2025-07-18 04:44:46,688 - logger.py:50 - Epoch: [175][0/6]	Total Loss: 0.72270	Main MSE (x10^-2): 72.2700	LR: 2.92e-04	EMPP_Raw: 1.38255
2025-07-18 04:45:00,686 - logger.py:50 - Epoch: [175][5/6]	Total Loss: 0.75479	Main MSE (x10^-2): 75.4786	LR: 2.92e-04	EMPP_Raw: 1.44449
2025-07-18 04:45:00,726 - logger.py:50 - Epoch 175 Training Summary: Avg Total Loss: 0.75479, Avg Main MSE: 0.75479, Time: 17.07s
2025-07-18 04:45:18,726 - logger.py:50 - Epoch 175 Summary | Train MSE (x10^-2): 75.4786 | Val MSE (x10^-2): 41.4425 | Time: 35.08s
2025-07-18 04:45:21,767 - logger.py:50 - Epoch: [176][0/6]	Total Loss: 0.76265	Main MSE (x10^-2): 76.2646	LR: 2.91e-04	EMPP_Raw: 1.46433
2025-07-18 04:45:35,770 - logger.py:50 - Epoch: [176][5/6]	Total Loss: 0.76077	Main MSE (x10^-2): 76.0774	LR: 2.91e-04	EMPP_Raw: 1.45836
2025-07-18 04:45:35,814 - logger.py:50 - Epoch 176 Training Summary: Avg Total Loss: 0.76077, Avg Main MSE: 0.76077, Time: 17.08s
2025-07-18 04:45:53,879 - logger.py:50 - Epoch 176 Summary | Train MSE (x10^-2): 76.0774 | Val MSE (x10^-2): 41.3062 | Time: 35.15s
2025-07-18 04:45:56,890 - logger.py:50 - Epoch: [177][0/6]	Total Loss: 0.76546	Main MSE (x10^-2): 76.5456	LR: 2.90e-04	EMPP_Raw: 1.46108
2025-07-18 04:46:10,775 - logger.py:50 - Epoch: [177][5/6]	Total Loss: 0.75638	Main MSE (x10^-2): 75.6378	LR: 2.90e-04	EMPP_Raw: 1.45237
2025-07-18 04:46:10,821 - logger.py:50 - Epoch 177 Training Summary: Avg Total Loss: 0.75638, Avg Main MSE: 0.75638, Time: 16.93s
2025-07-18 04:46:28,937 - logger.py:50 - Epoch 177 Summary | Train MSE (x10^-2): 75.6378 | Val MSE (x10^-2): 40.2368 | Time: 35.05s
2025-07-18 04:46:32,019 - logger.py:50 - Epoch: [178][0/6]	Total Loss: 0.75730	Main MSE (x10^-2): 75.7305	LR: 2.89e-04	EMPP_Raw: 1.44214
2025-07-18 04:46:45,999 - logger.py:50 - Epoch: [178][5/6]	Total Loss: 0.76895	Main MSE (x10^-2): 76.8948	LR: 2.89e-04	EMPP_Raw: 1.48043
2025-07-18 04:46:46,041 - logger.py:50 - Epoch 178 Training Summary: Avg Total Loss: 0.76895, Avg Main MSE: 0.76895, Time: 17.09s
2025-07-18 04:47:04,320 - logger.py:50 - Epoch 178 Summary | Train MSE (x10^-2): 76.8948 | Val MSE (x10^-2): 38.8947 | Time: 35.38s
2025-07-18 04:47:07,574 - logger.py:50 - Epoch: [179][0/6]	Total Loss: 0.74816	Main MSE (x10^-2): 74.8158	LR: 2.88e-04	EMPP_Raw: 1.44842
2025-07-18 04:47:21,383 - logger.py:50 - Epoch: [179][5/6]	Total Loss: 0.76064	Main MSE (x10^-2): 76.0642	LR: 2.88e-04	EMPP_Raw: 1.46061
2025-07-18 04:47:21,424 - logger.py:50 - Epoch 179 Training Summary: Avg Total Loss: 0.76064, Avg Main MSE: 0.76064, Time: 17.09s
2025-07-18 04:47:39,385 - logger.py:50 - Epoch 179 Summary | Train MSE (x10^-2): 76.0642 | Val MSE (x10^-2): 38.4127 | Time: 35.06s
2025-07-18 04:47:42,550 - logger.py:50 - Epoch: [180][0/6]	Total Loss: 0.76851	Main MSE (x10^-2): 76.8506	LR: 2.87e-04	EMPP_Raw: 1.47579
2025-07-18 04:47:56,348 - logger.py:50 - Epoch: [180][5/6]	Total Loss: 0.75668	Main MSE (x10^-2): 75.6680	LR: 2.87e-04	EMPP_Raw: 1.45596
2025-07-18 04:47:56,390 - logger.py:50 - Epoch 180 Training Summary: Avg Total Loss: 0.75668, Avg Main MSE: 0.75668, Time: 17.00s
2025-07-18 04:48:14,268 - logger.py:50 - Epoch 180 Summary | Train MSE (x10^-2): 75.6680 | Val MSE (x10^-2): 40.8762 | Time: 34.88s
2025-07-18 04:48:17,435 - logger.py:50 - Epoch: [181][0/6]	Total Loss: 0.74501	Main MSE (x10^-2): 74.5010	LR: 2.85e-04	EMPP_Raw: 1.43697
2025-07-18 04:48:31,210 - logger.py:50 - Epoch: [181][5/6]	Total Loss: 0.75121	Main MSE (x10^-2): 75.1209	LR: 2.85e-04	EMPP_Raw: 1.45201
2025-07-18 04:48:31,257 - logger.py:50 - Epoch 181 Training Summary: Avg Total Loss: 0.75121, Avg Main MSE: 0.75121, Time: 16.98s
2025-07-18 04:48:49,237 - logger.py:50 - Epoch 181 Summary | Train MSE (x10^-2): 75.1209 | Val MSE (x10^-2): 41.1010 | Time: 34.96s
2025-07-18 04:48:52,251 - logger.py:50 - Epoch: [182][0/6]	Total Loss: 0.75943	Main MSE (x10^-2): 75.9428	LR: 2.84e-04	EMPP_Raw: 1.46154
2025-07-18 04:49:06,280 - logger.py:50 - Epoch: [182][5/6]	Total Loss: 0.74676	Main MSE (x10^-2): 74.6764	LR: 2.84e-04	EMPP_Raw: 1.44185
2025-07-18 04:49:06,336 - logger.py:50 - Epoch 182 Training Summary: Avg Total Loss: 0.74676, Avg Main MSE: 0.74676, Time: 17.09s
2025-07-18 04:49:24,346 - logger.py:50 - Epoch 182 Summary | Train MSE (x10^-2): 74.6764 | Val MSE (x10^-2): 42.1865 | Time: 35.10s
2025-07-18 04:49:27,409 - logger.py:50 - Epoch: [183][0/6]	Total Loss: 0.72666	Main MSE (x10^-2): 72.6661	LR: 2.83e-04	EMPP_Raw: 1.40240
2025-07-18 04:49:41,211 - logger.py:50 - Epoch: [183][5/6]	Total Loss: 0.75729	Main MSE (x10^-2): 75.7293	LR: 2.83e-04	EMPP_Raw: 1.45893
2025-07-18 04:49:41,252 - logger.py:50 - Epoch 183 Training Summary: Avg Total Loss: 0.75729, Avg Main MSE: 0.75729, Time: 16.90s
2025-07-18 04:49:59,285 - logger.py:50 - Epoch 183 Summary | Train MSE (x10^-2): 75.7293 | Val MSE (x10^-2): 41.0755 | Time: 34.93s
2025-07-18 04:50:02,272 - logger.py:50 - Epoch: [184][0/6]	Total Loss: 0.75640	Main MSE (x10^-2): 75.6404	LR: 2.82e-04	EMPP_Raw: 1.46111
2025-07-18 04:50:16,124 - logger.py:50 - Epoch: [184][5/6]	Total Loss: 0.74811	Main MSE (x10^-2): 74.8106	LR: 2.82e-04	EMPP_Raw: 1.44378
2025-07-18 04:50:16,169 - logger.py:50 - Epoch 184 Training Summary: Avg Total Loss: 0.74811, Avg Main MSE: 0.74811, Time: 16.88s
2025-07-18 04:50:34,401 - logger.py:50 - Epoch 184 Summary | Train MSE (x10^-2): 74.8106 | Val MSE (x10^-2): 39.5668 | Time: 35.11s
2025-07-18 04:50:37,404 - logger.py:50 - Epoch: [185][0/6]	Total Loss: 0.73452	Main MSE (x10^-2): 73.4517	LR: 2.81e-04	EMPP_Raw: 1.40986
2025-07-18 04:50:51,257 - logger.py:50 - Epoch: [185][5/6]	Total Loss: 0.75636	Main MSE (x10^-2): 75.6359	LR: 2.81e-04	EMPP_Raw: 1.45834
2025-07-18 04:50:51,295 - logger.py:50 - Epoch 185 Training Summary: Avg Total Loss: 0.75636, Avg Main MSE: 0.75636, Time: 16.89s
2025-07-18 04:51:09,384 - logger.py:50 - Epoch 185 Summary | Train MSE (x10^-2): 75.6359 | Val MSE (x10^-2): 39.2939 | Time: 34.98s
2025-07-18 04:51:12,553 - logger.py:50 - Epoch: [186][0/6]	Total Loss: 0.74067	Main MSE (x10^-2): 74.0667	LR: 2.80e-04	EMPP_Raw: 1.43170
2025-07-18 04:51:26,418 - logger.py:50 - Epoch: [186][5/6]	Total Loss: 0.76281	Main MSE (x10^-2): 76.2812	LR: 2.80e-04	EMPP_Raw: 1.46922
2025-07-18 04:51:26,480 - logger.py:50 - Epoch 186 Training Summary: Avg Total Loss: 0.76281, Avg Main MSE: 0.76281, Time: 17.09s
2025-07-18 04:51:44,414 - logger.py:50 - Epoch 186 Summary | Train MSE (x10^-2): 76.2812 | Val MSE (x10^-2): 40.3260 | Time: 35.02s
2025-07-18 04:51:47,573 - logger.py:50 - Epoch: [187][0/6]	Total Loss: 0.72896	Main MSE (x10^-2): 72.8964	LR: 2.79e-04	EMPP_Raw: 1.40555
2025-07-18 04:52:01,328 - logger.py:50 - Epoch: [187][5/6]	Total Loss: 0.74975	Main MSE (x10^-2): 74.9750	LR: 2.79e-04	EMPP_Raw: 1.44584
2025-07-18 04:52:01,374 - logger.py:50 - Epoch 187 Training Summary: Avg Total Loss: 0.74975, Avg Main MSE: 0.74975, Time: 16.95s
2025-07-18 04:52:19,426 - logger.py:50 - Epoch 187 Summary | Train MSE (x10^-2): 74.9750 | Val MSE (x10^-2): 39.5990 | Time: 35.01s
2025-07-18 04:52:22,437 - logger.py:50 - Epoch: [188][0/6]	Total Loss: 0.75355	Main MSE (x10^-2): 75.3546	LR: 2.77e-04	EMPP_Raw: 1.44693
2025-07-18 04:52:36,345 - logger.py:50 - Epoch: [188][5/6]	Total Loss: 0.74737	Main MSE (x10^-2): 74.7366	LR: 2.77e-04	EMPP_Raw: 1.43914
2025-07-18 04:52:36,385 - logger.py:50 - Epoch 188 Training Summary: Avg Total Loss: 0.74737, Avg Main MSE: 0.74737, Time: 16.95s
2025-07-18 04:52:54,367 - logger.py:50 - Epoch 188 Summary | Train MSE (x10^-2): 74.7366 | Val MSE (x10^-2): 37.9939 | Time: 34.93s
2025-07-18 04:52:57,364 - logger.py:50 - Epoch: [189][0/6]	Total Loss: 0.77752	Main MSE (x10^-2): 77.7517	LR: 2.76e-04	EMPP_Raw: 1.49657
2025-07-18 04:53:11,363 - logger.py:50 - Epoch: [189][5/6]	Total Loss: 0.75091	Main MSE (x10^-2): 75.0914	LR: 2.76e-04	EMPP_Raw: 1.44894
2025-07-18 04:53:11,416 - logger.py:50 - Epoch 189 Training Summary: Avg Total Loss: 0.75091, Avg Main MSE: 0.75091, Time: 17.04s
2025-07-18 04:53:29,516 - logger.py:50 - Epoch 189 Summary | Train MSE (x10^-2): 75.0914 | Val MSE (x10^-2): 39.6540 | Time: 35.14s
2025-07-18 04:53:32,560 - logger.py:50 - Epoch: [190][0/6]	Total Loss: 0.75997	Main MSE (x10^-2): 75.9968	LR: 2.75e-04	EMPP_Raw: 1.47278
2025-07-18 04:53:46,658 - logger.py:50 - Epoch: [190][5/6]	Total Loss: 0.74190	Main MSE (x10^-2): 74.1903	LR: 2.75e-04	EMPP_Raw: 1.43484
2025-07-18 04:53:46,705 - logger.py:50 - Epoch 190 Training Summary: Avg Total Loss: 0.74190, Avg Main MSE: 0.74190, Time: 17.18s
2025-07-18 04:54:05,037 - logger.py:50 - Epoch 190 Summary | Train MSE (x10^-2): 74.1903 | Val MSE (x10^-2): 41.9539 | Time: 35.51s
2025-07-18 04:54:08,072 - logger.py:50 - Epoch: [191][0/6]	Total Loss: 0.73860	Main MSE (x10^-2): 73.8602	LR: 2.74e-04	EMPP_Raw: 1.42837
2025-07-18 04:54:22,331 - logger.py:50 - Epoch: [191][5/6]	Total Loss: 0.74408	Main MSE (x10^-2): 74.4081	LR: 2.74e-04	EMPP_Raw: 1.43993
2025-07-18 04:54:22,376 - logger.py:50 - Epoch 191 Training Summary: Avg Total Loss: 0.74408, Avg Main MSE: 0.74408, Time: 17.33s
2025-07-18 04:54:40,404 - logger.py:50 - Epoch 191 Summary | Train MSE (x10^-2): 74.4081 | Val MSE (x10^-2): 41.2439 | Time: 35.36s
2025-07-18 04:54:43,560 - logger.py:50 - Epoch: [192][0/6]	Total Loss: 0.73995	Main MSE (x10^-2): 73.9954	LR: 2.73e-04	EMPP_Raw: 1.43908
2025-07-18 04:54:57,442 - logger.py:50 - Epoch: [192][5/6]	Total Loss: 0.75917	Main MSE (x10^-2): 75.9174	LR: 2.73e-04	EMPP_Raw: 1.46992
2025-07-18 04:54:57,484 - logger.py:50 - Epoch 192 Training Summary: Avg Total Loss: 0.75917, Avg Main MSE: 0.75917, Time: 17.07s
2025-07-18 04:55:15,687 - logger.py:50 - Epoch 192 Summary | Train MSE (x10^-2): 75.9174 | Val MSE (x10^-2): 42.8534 | Time: 35.28s
2025-07-18 04:55:18,910 - logger.py:50 - Epoch: [193][0/6]	Total Loss: 0.75820	Main MSE (x10^-2): 75.8196	LR: 2.72e-04	EMPP_Raw: 1.47213
2025-07-18 04:55:32,758 - logger.py:50 - Epoch: [193][5/6]	Total Loss: 0.76097	Main MSE (x10^-2): 76.0975	LR: 2.72e-04	EMPP_Raw: 1.47447
2025-07-18 04:55:32,803 - logger.py:50 - Epoch 193 Training Summary: Avg Total Loss: 0.76097, Avg Main MSE: 0.76097, Time: 17.11s
2025-07-18 04:55:50,820 - logger.py:50 - Epoch 193 Summary | Train MSE (x10^-2): 76.0975 | Val MSE (x10^-2): 40.8515 | Time: 35.13s
2025-07-18 04:55:53,980 - logger.py:50 - Epoch: [194][0/6]	Total Loss: 0.75702	Main MSE (x10^-2): 75.7019	LR: 2.70e-04	EMPP_Raw: 1.46370
2025-07-18 04:56:07,718 - logger.py:50 - Epoch: [194][5/6]	Total Loss: 0.75130	Main MSE (x10^-2): 75.1300	LR: 2.70e-04	EMPP_Raw: 1.45682
2025-07-18 04:56:07,760 - logger.py:50 - Epoch 194 Training Summary: Avg Total Loss: 0.75130, Avg Main MSE: 0.75130, Time: 16.93s
2025-07-18 04:56:25,931 - logger.py:50 - Epoch 194 Summary | Train MSE (x10^-2): 75.1300 | Val MSE (x10^-2): 39.6620 | Time: 35.11s
2025-07-18 04:56:28,951 - logger.py:50 - Epoch: [195][0/6]	Total Loss: 0.74421	Main MSE (x10^-2): 74.4215	LR: 2.69e-04	EMPP_Raw: 1.44410
2025-07-18 04:56:42,879 - logger.py:50 - Epoch: [195][5/6]	Total Loss: 0.75572	Main MSE (x10^-2): 75.5717	LR: 2.69e-04	EMPP_Raw: 1.46688
2025-07-18 04:56:42,923 - logger.py:50 - Epoch 195 Training Summary: Avg Total Loss: 0.75572, Avg Main MSE: 0.75572, Time: 16.98s
2025-07-18 04:57:00,974 - logger.py:50 - Epoch 195 Summary | Train MSE (x10^-2): 75.5717 | Val MSE (x10^-2): 39.8977 | Time: 35.04s
2025-07-18 04:57:03,965 - logger.py:50 - Epoch: [196][0/6]	Total Loss: 0.74778	Main MSE (x10^-2): 74.7781	LR: 2.68e-04	EMPP_Raw: 1.45035
2025-07-18 04:57:17,746 - logger.py:50 - Epoch: [196][5/6]	Total Loss: 0.74862	Main MSE (x10^-2): 74.8622	LR: 2.68e-04	EMPP_Raw: 1.45107
2025-07-18 04:57:17,787 - logger.py:50 - Epoch 196 Training Summary: Avg Total Loss: 0.74862, Avg Main MSE: 0.74862, Time: 16.81s
2025-07-18 04:57:35,889 - logger.py:50 - Epoch 196 Summary | Train MSE (x10^-2): 74.8622 | Val MSE (x10^-2): 39.5528 | Time: 34.91s
2025-07-18 04:57:38,875 - logger.py:50 - Epoch: [197][0/6]	Total Loss: 0.74949	Main MSE (x10^-2): 74.9490	LR: 2.67e-04	EMPP_Raw: 1.45580
2025-07-18 04:57:52,748 - logger.py:50 - Epoch: [197][5/6]	Total Loss: 0.73967	Main MSE (x10^-2): 73.9669	LR: 2.67e-04	EMPP_Raw: 1.43534
2025-07-18 04:57:52,795 - logger.py:50 - Epoch 197 Training Summary: Avg Total Loss: 0.73967, Avg Main MSE: 0.73967, Time: 16.90s
2025-07-18 04:58:10,999 - logger.py:50 - Epoch 197 Summary | Train MSE (x10^-2): 73.9669 | Val MSE (x10^-2): 40.9629 | Time: 35.10s
2025-07-18 04:58:14,041 - logger.py:50 - Epoch: [198][0/6]	Total Loss: 0.73721	Main MSE (x10^-2): 73.7213	LR: 2.66e-04	EMPP_Raw: 1.43304
2025-07-18 04:58:28,036 - logger.py:50 - Epoch: [198][5/6]	Total Loss: 0.75110	Main MSE (x10^-2): 75.1097	LR: 2.66e-04	EMPP_Raw: 1.45781
2025-07-18 04:58:28,083 - logger.py:50 - Epoch 198 Training Summary: Avg Total Loss: 0.75110, Avg Main MSE: 0.75110, Time: 17.07s
2025-07-18 04:58:45,970 - logger.py:50 - Epoch 198 Summary | Train MSE (x10^-2): 75.1097 | Val MSE (x10^-2): 40.7582 | Time: 34.96s
2025-07-18 04:58:49,160 - logger.py:50 - Epoch: [199][0/6]	Total Loss: 0.74409	Main MSE (x10^-2): 74.4093	LR: 2.65e-04	EMPP_Raw: 1.44678
2025-07-18 04:59:02,974 - logger.py:50 - Epoch: [199][5/6]	Total Loss: 0.74716	Main MSE (x10^-2): 74.7162	LR: 2.65e-04	EMPP_Raw: 1.44927
2025-07-18 04:59:03,020 - logger.py:50 - Epoch 199 Training Summary: Avg Total Loss: 0.74716, Avg Main MSE: 0.74716, Time: 17.04s
2025-07-18 04:59:20,961 - logger.py:50 - Epoch 199 Summary | Train MSE (x10^-2): 74.7162 | Val MSE (x10^-2): 40.5552 | Time: 34.99s
2025-07-18 04:59:24,129 - logger.py:50 - Epoch: [200][0/6]	Total Loss: 0.73663	Main MSE (x10^-2): 73.6629	LR: 2.63e-04	EMPP_Raw: 1.42313
2025-07-18 04:59:37,894 - logger.py:50 - Epoch: [200][5/6]	Total Loss: 0.74278	Main MSE (x10^-2): 74.2780	LR: 2.63e-04	EMPP_Raw: 1.43911
2025-07-18 04:59:37,938 - logger.py:50 - Epoch 200 Training Summary: Avg Total Loss: 0.74278, Avg Main MSE: 0.74278, Time: 16.97s
2025-07-18 04:59:55,920 - logger.py:50 - Epoch 200 Summary | Train MSE (x10^-2): 74.2780 | Val MSE (x10^-2): 41.5612 | Time: 34.95s
2025-07-18 04:59:58,943 - logger.py:50 - Epoch: [201][0/6]	Total Loss: 0.76364	Main MSE (x10^-2): 76.3638	LR: 2.62e-04	EMPP_Raw: 1.48196
2025-07-18 05:00:12,945 - logger.py:50 - Epoch: [201][5/6]	Total Loss: 0.76102	Main MSE (x10^-2): 76.1016	LR: 2.62e-04	EMPP_Raw: 1.47368
2025-07-18 05:00:12,992 - logger.py:50 - Epoch 201 Training Summary: Avg Total Loss: 0.76102, Avg Main MSE: 0.76102, Time: 17.06s
2025-07-18 05:00:31,080 - logger.py:50 - Epoch 201 Summary | Train MSE (x10^-2): 76.1016 | Val MSE (x10^-2): 41.7640 | Time: 35.15s
2025-07-18 05:00:34,085 - logger.py:50 - Epoch: [202][0/6]	Total Loss: 0.74393	Main MSE (x10^-2): 74.3929	LR: 2.61e-04	EMPP_Raw: 1.43623
2025-07-18 05:00:48,055 - logger.py:50 - Epoch: [202][5/6]	Total Loss: 0.74203	Main MSE (x10^-2): 74.2031	LR: 2.61e-04	EMPP_Raw: 1.43326
2025-07-18 05:00:48,096 - logger.py:50 - Epoch 202 Training Summary: Avg Total Loss: 0.74203, Avg Main MSE: 0.74203, Time: 17.01s
2025-07-18 05:01:06,086 - logger.py:50 - Epoch 202 Summary | Train MSE (x10^-2): 74.2031 | Val MSE (x10^-2): 43.3775 | Time: 35.00s
2025-07-18 05:01:09,142 - logger.py:50 - Epoch: [203][0/6]	Total Loss: 0.73545	Main MSE (x10^-2): 73.5453	LR: 2.60e-04	EMPP_Raw: 1.41991
2025-07-18 05:01:22,976 - logger.py:50 - Epoch: [203][5/6]	Total Loss: 0.74249	Main MSE (x10^-2): 74.2492	LR: 2.60e-04	EMPP_Raw: 1.43699
2025-07-18 05:01:23,021 - logger.py:50 - Epoch 203 Training Summary: Avg Total Loss: 0.74249, Avg Main MSE: 0.74249, Time: 16.93s
2025-07-18 05:01:41,323 - logger.py:50 - Epoch 203 Summary | Train MSE (x10^-2): 74.2492 | Val MSE (x10^-2): 43.0802 | Time: 35.23s
2025-07-18 05:01:44,368 - logger.py:50 - Epoch: [204][0/6]	Total Loss: 0.76000	Main MSE (x10^-2): 76.0004	LR: 2.59e-04	EMPP_Raw: 1.47768
2025-07-18 05:01:58,162 - logger.py:50 - Epoch: [204][5/6]	Total Loss: 0.75489	Main MSE (x10^-2): 75.4887	LR: 2.59e-04	EMPP_Raw: 1.46469
2025-07-18 05:01:58,211 - logger.py:50 - Epoch 204 Training Summary: Avg Total Loss: 0.75489, Avg Main MSE: 0.75489, Time: 16.88s
2025-07-18 05:02:16,228 - logger.py:50 - Epoch 204 Summary | Train MSE (x10^-2): 75.4887 | Val MSE (x10^-2): 40.6178 | Time: 34.90s
2025-07-18 05:02:19,447 - logger.py:50 - Epoch: [205][0/6]	Total Loss: 0.71473	Main MSE (x10^-2): 71.4733	LR: 2.57e-04	EMPP_Raw: 1.38629
2025-07-18 05:02:33,226 - logger.py:50 - Epoch: [205][5/6]	Total Loss: 0.73742	Main MSE (x10^-2): 73.7419	LR: 2.57e-04	EMPP_Raw: 1.42895
2025-07-18 05:02:33,269 - logger.py:50 - Epoch 205 Training Summary: Avg Total Loss: 0.73742, Avg Main MSE: 0.73742, Time: 17.03s
2025-07-18 05:02:51,208 - logger.py:50 - Epoch 205 Summary | Train MSE (x10^-2): 73.7419 | Val MSE (x10^-2): 41.1946 | Time: 34.97s
2025-07-18 05:02:54,429 - logger.py:50 - Epoch: [206][0/6]	Total Loss: 0.75199	Main MSE (x10^-2): 75.1990	LR: 2.56e-04	EMPP_Raw: 1.45798
2025-07-18 05:03:08,231 - logger.py:50 - Epoch: [206][5/6]	Total Loss: 0.75244	Main MSE (x10^-2): 75.2438	LR: 2.56e-04	EMPP_Raw: 1.46297
2025-07-18 05:03:08,275 - logger.py:50 - Epoch 206 Training Summary: Avg Total Loss: 0.75244, Avg Main MSE: 0.75244, Time: 17.06s
2025-07-18 05:03:26,137 - logger.py:50 - Epoch 206 Summary | Train MSE (x10^-2): 75.2438 | Val MSE (x10^-2): 40.9706 | Time: 34.92s
2025-07-18 05:03:29,312 - logger.py:50 - Epoch: [207][0/6]	Total Loss: 0.78223	Main MSE (x10^-2): 78.2225	LR: 2.55e-04	EMPP_Raw: 1.51708
2025-07-18 05:03:43,101 - logger.py:50 - Epoch: [207][5/6]	Total Loss: 0.75454	Main MSE (x10^-2): 75.4542	LR: 2.55e-04	EMPP_Raw: 1.46371
2025-07-18 05:03:43,143 - logger.py:50 - Epoch 207 Training Summary: Avg Total Loss: 0.75454, Avg Main MSE: 0.75454, Time: 17.00s
2025-07-18 05:04:01,108 - logger.py:50 - Epoch 207 Summary | Train MSE (x10^-2): 75.4542 | Val MSE (x10^-2): 41.0403 | Time: 34.96s
2025-07-18 05:04:04,134 - logger.py:50 - Epoch: [208][0/6]	Total Loss: 0.75345	Main MSE (x10^-2): 75.3450	LR: 2.54e-04	EMPP_Raw: 1.46129
2025-07-18 05:04:18,112 - logger.py:50 - Epoch: [208][5/6]	Total Loss: 0.73898	Main MSE (x10^-2): 73.8981	LR: 2.54e-04	EMPP_Raw: 1.43131
2025-07-18 05:04:18,153 - logger.py:50 - Epoch 208 Training Summary: Avg Total Loss: 0.73898, Avg Main MSE: 0.73898, Time: 17.04s
2025-07-18 05:04:36,340 - logger.py:50 - Epoch 208 Summary | Train MSE (x10^-2): 73.8981 | Val MSE (x10^-2): 38.3943 | Time: 35.23s
2025-07-18 05:04:39,326 - logger.py:50 - Epoch: [209][0/6]	Total Loss: 0.73509	Main MSE (x10^-2): 73.5087	LR: 2.53e-04	EMPP_Raw: 1.42468
2025-07-18 05:04:53,128 - logger.py:50 - Epoch: [209][5/6]	Total Loss: 0.73731	Main MSE (x10^-2): 73.7307	LR: 2.53e-04	EMPP_Raw: 1.43138
2025-07-18 05:04:53,178 - logger.py:50 - Epoch 209 Training Summary: Avg Total Loss: 0.73731, Avg Main MSE: 0.73731, Time: 16.83s
2025-07-18 05:05:11,295 - logger.py:50 - Epoch 209 Summary | Train MSE (x10^-2): 73.7307 | Val MSE (x10^-2): 38.5419 | Time: 34.95s
2025-07-18 05:05:14,341 - logger.py:50 - Epoch: [210][0/6]	Total Loss: 0.72539	Main MSE (x10^-2): 72.5387	LR: 2.51e-04	EMPP_Raw: 1.41185
2025-07-18 05:05:28,177 - logger.py:50 - Epoch: [210][5/6]	Total Loss: 0.74242	Main MSE (x10^-2): 74.2424	LR: 2.51e-04	EMPP_Raw: 1.44060
2025-07-18 05:05:28,223 - logger.py:50 - Epoch 210 Training Summary: Avg Total Loss: 0.74242, Avg Main MSE: 0.74242, Time: 16.92s
2025-07-18 05:05:46,364 - logger.py:50 - Epoch 210 Summary | Train MSE (x10^-2): 74.2424 | Val MSE (x10^-2): 41.4025 | Time: 35.06s
2025-07-18 05:05:49,414 - logger.py:50 - Epoch: [211][0/6]	Total Loss: 0.75912	Main MSE (x10^-2): 75.9122	LR: 2.50e-04	EMPP_Raw: 1.47575
2025-07-18 05:06:03,189 - logger.py:50 - Epoch: [211][5/6]	Total Loss: 0.74195	Main MSE (x10^-2): 74.1953	LR: 2.50e-04	EMPP_Raw: 1.43966
2025-07-18 05:06:03,236 - logger.py:50 - Epoch 211 Training Summary: Avg Total Loss: 0.74195, Avg Main MSE: 0.74195, Time: 16.86s
2025-07-18 05:06:21,260 - logger.py:50 - Epoch 211 Summary | Train MSE (x10^-2): 74.1953 | Val MSE (x10^-2): 40.9988 | Time: 34.89s
2025-07-18 05:06:24,412 - logger.py:50 - Epoch: [212][0/6]	Total Loss: 0.72825	Main MSE (x10^-2): 72.8247	LR: 2.49e-04	EMPP_Raw: 1.41777
2025-07-18 05:06:38,287 - logger.py:50 - Epoch: [212][5/6]	Total Loss: 0.72887	Main MSE (x10^-2): 72.8870	LR: 2.49e-04	EMPP_Raw: 1.41291
2025-07-18 05:06:38,337 - logger.py:50 - Epoch 212 Training Summary: Avg Total Loss: 0.72887, Avg Main MSE: 0.72887, Time: 17.07s
2025-07-18 05:06:56,421 - logger.py:50 - Epoch 212 Summary | Train MSE (x10^-2): 72.8870 | Val MSE (x10^-2): 43.7419 | Time: 35.16s
2025-07-18 05:06:59,602 - logger.py:50 - Epoch: [213][0/6]	Total Loss: 0.76493	Main MSE (x10^-2): 76.4933	LR: 2.48e-04	EMPP_Raw: 1.48429
2025-07-18 05:07:13,303 - logger.py:50 - Epoch: [213][5/6]	Total Loss: 0.75131	Main MSE (x10^-2): 75.1305	LR: 2.48e-04	EMPP_Raw: 1.45893
2025-07-18 05:07:13,348 - logger.py:50 - Epoch 213 Training Summary: Avg Total Loss: 0.75131, Avg Main MSE: 0.75131, Time: 16.92s
2025-07-18 05:07:31,277 - logger.py:50 - Epoch 213 Summary | Train MSE (x10^-2): 75.1305 | Val MSE (x10^-2): 40.1602 | Time: 34.85s
2025-07-18 05:07:34,271 - logger.py:50 - Epoch: [214][0/6]	Total Loss: 0.75421	Main MSE (x10^-2): 75.4215	LR: 2.46e-04	EMPP_Raw: 1.47042
2025-07-18 05:07:48,243 - logger.py:50 - Epoch: [214][5/6]	Total Loss: 0.74427	Main MSE (x10^-2): 74.4270	LR: 2.46e-04	EMPP_Raw: 1.44636
2025-07-18 05:07:48,289 - logger.py:50 - Epoch 214 Training Summary: Avg Total Loss: 0.74427, Avg Main MSE: 0.74427, Time: 17.00s
2025-07-18 05:08:06,325 - logger.py:50 - Epoch 214 Summary | Train MSE (x10^-2): 74.4270 | Val MSE (x10^-2): 38.6132 | Time: 35.04s
2025-07-18 05:08:09,368 - logger.py:50 - Epoch: [215][0/6]	Total Loss: 0.72095	Main MSE (x10^-2): 72.0954	LR: 2.45e-04	EMPP_Raw: 1.40316
2025-07-18 05:08:23,431 - logger.py:50 - Epoch: [215][5/6]	Total Loss: 0.73733	Main MSE (x10^-2): 73.7333	LR: 2.45e-04	EMPP_Raw: 1.43427
2025-07-18 05:08:23,479 - logger.py:50 - Epoch 215 Training Summary: Avg Total Loss: 0.73733, Avg Main MSE: 0.73733, Time: 17.14s
2025-07-18 05:08:41,511 - logger.py:50 - Epoch 215 Summary | Train MSE (x10^-2): 73.7333 | Val MSE (x10^-2): 40.6138 | Time: 35.18s
2025-07-18 05:08:44,570 - logger.py:50 - Epoch: [216][0/6]	Total Loss: 0.75605	Main MSE (x10^-2): 75.6048	LR: 2.44e-04	EMPP_Raw: 1.47403
2025-07-18 05:08:58,464 - logger.py:50 - Epoch: [216][5/6]	Total Loss: 0.74235	Main MSE (x10^-2): 74.2351	LR: 2.44e-04	EMPP_Raw: 1.44349
2025-07-18 05:08:58,507 - logger.py:50 - Epoch 216 Training Summary: Avg Total Loss: 0.74235, Avg Main MSE: 0.74235, Time: 16.99s
2025-07-18 05:09:16,742 - logger.py:50 - Epoch 216 Summary | Train MSE (x10^-2): 74.2351 | Val MSE (x10^-2): 42.0316 | Time: 35.22s
2025-07-18 05:09:19,750 - logger.py:50 - Epoch: [217][0/6]	Total Loss: 0.74621	Main MSE (x10^-2): 74.6210	LR: 2.43e-04	EMPP_Raw: 1.45185
2025-07-18 05:09:33,540 - logger.py:50 - Epoch: [217][5/6]	Total Loss: 0.74082	Main MSE (x10^-2): 74.0818	LR: 2.43e-04	EMPP_Raw: 1.44007
2025-07-18 05:09:33,583 - logger.py:50 - Epoch 217 Training Summary: Avg Total Loss: 0.74082, Avg Main MSE: 0.74082, Time: 16.83s
2025-07-18 05:09:51,525 - logger.py:50 - Epoch 217 Summary | Train MSE (x10^-2): 74.0818 | Val MSE (x10^-2): 41.8570 | Time: 34.78s
2025-07-18 05:09:54,727 - logger.py:50 - Epoch: [218][0/6]	Total Loss: 0.75070	Main MSE (x10^-2): 75.0700	LR: 2.42e-04	EMPP_Raw: 1.46267
2025-07-18 05:10:08,614 - logger.py:50 - Epoch: [218][5/6]	Total Loss: 0.73581	Main MSE (x10^-2): 73.5809	LR: 2.42e-04	EMPP_Raw: 1.43305
2025-07-18 05:10:08,660 - logger.py:50 - Epoch 218 Training Summary: Avg Total Loss: 0.73581, Avg Main MSE: 0.73581, Time: 17.13s
2025-07-18 05:10:26,582 - logger.py:50 - Epoch 218 Summary | Train MSE (x10^-2): 73.5809 | Val MSE (x10^-2): 41.8673 | Time: 35.05s
2025-07-18 05:10:29,852 - logger.py:50 - Epoch: [219][0/6]	Total Loss: 0.74697	Main MSE (x10^-2): 74.6972	LR: 2.40e-04	EMPP_Raw: 1.45457
2025-07-18 05:10:43,731 - logger.py:50 - Epoch: [219][5/6]	Total Loss: 0.74247	Main MSE (x10^-2): 74.2473	LR: 2.40e-04	EMPP_Raw: 1.44656
2025-07-18 05:10:43,785 - logger.py:50 - Epoch 219 Training Summary: Avg Total Loss: 0.74247, Avg Main MSE: 0.74247, Time: 17.19s
2025-07-18 05:11:01,718 - logger.py:50 - Epoch 219 Summary | Train MSE (x10^-2): 74.2473 | Val MSE (x10^-2): 41.1415 | Time: 35.13s
2025-07-18 05:11:04,896 - logger.py:50 - Epoch: [220][0/6]	Total Loss: 0.75528	Main MSE (x10^-2): 75.5281	LR: 2.39e-04	EMPP_Raw: 1.47265
2025-07-18 05:11:18,693 - logger.py:50 - Epoch: [220][5/6]	Total Loss: 0.73780	Main MSE (x10^-2): 73.7796	LR: 2.39e-04	EMPP_Raw: 1.43595
2025-07-18 05:11:18,741 - logger.py:50 - Epoch 220 Training Summary: Avg Total Loss: 0.73780, Avg Main MSE: 0.73780, Time: 17.01s
2025-07-18 05:11:36,695 - logger.py:50 - Epoch 220 Summary | Train MSE (x10^-2): 73.7796 | Val MSE (x10^-2): 40.5699 | Time: 34.97s
2025-07-18 05:11:39,769 - logger.py:50 - Epoch: [221][0/6]	Total Loss: 0.73711	Main MSE (x10^-2): 73.7114	LR: 2.38e-04	EMPP_Raw: 1.43893
2025-07-18 05:11:53,743 - logger.py:50 - Epoch: [221][5/6]	Total Loss: 0.73827	Main MSE (x10^-2): 73.8270	LR: 2.38e-04	EMPP_Raw: 1.43841
2025-07-18 05:11:53,784 - logger.py:50 - Epoch 221 Training Summary: Avg Total Loss: 0.73827, Avg Main MSE: 0.73827, Time: 17.08s
2025-07-18 05:12:11,675 - logger.py:50 - Epoch 221 Summary | Train MSE (x10^-2): 73.8270 | Val MSE (x10^-2): 39.6460 | Time: 34.97s
2025-07-18 05:12:14,705 - logger.py:50 - Epoch: [222][0/6]	Total Loss: 0.74814	Main MSE (x10^-2): 74.8137	LR: 2.37e-04	EMPP_Raw: 1.45282
2025-07-18 05:12:28,512 - logger.py:50 - Epoch: [222][5/6]	Total Loss: 0.73565	Main MSE (x10^-2): 73.5649	LR: 2.37e-04	EMPP_Raw: 1.43161
2025-07-18 05:12:28,559 - logger.py:50 - Epoch 222 Training Summary: Avg Total Loss: 0.73565, Avg Main MSE: 0.73565, Time: 16.87s
2025-07-18 05:12:46,607 - logger.py:50 - Epoch 222 Summary | Train MSE (x10^-2): 73.5649 | Val MSE (x10^-2): 40.8086 | Time: 34.93s
2025-07-18 05:12:49,603 - logger.py:50 - Epoch: [223][0/6]	Total Loss: 0.74964	Main MSE (x10^-2): 74.9642	LR: 2.35e-04	EMPP_Raw: 1.46408
2025-07-18 05:13:03,376 - logger.py:50 - Epoch: [223][5/6]	Total Loss: 0.73838	Main MSE (x10^-2): 73.8376	LR: 2.35e-04	EMPP_Raw: 1.43835
2025-07-18 05:13:03,422 - logger.py:50 - Epoch 223 Training Summary: Avg Total Loss: 0.73838, Avg Main MSE: 0.73838, Time: 16.80s
2025-07-18 05:13:21,387 - logger.py:50 - Epoch 223 Summary | Train MSE (x10^-2): 73.8376 | Val MSE (x10^-2): 39.8487 | Time: 34.77s
2025-07-18 05:13:24,369 - logger.py:50 - Epoch: [224][0/6]	Total Loss: 0.77576	Main MSE (x10^-2): 77.5756	LR: 2.34e-04	EMPP_Raw: 1.51142
2025-07-18 05:13:38,179 - logger.py:50 - Epoch: [224][5/6]	Total Loss: 0.74895	Main MSE (x10^-2): 74.8946	LR: 2.34e-04	EMPP_Raw: 1.45859
2025-07-18 05:13:38,221 - logger.py:50 - Epoch 224 Training Summary: Avg Total Loss: 0.74895, Avg Main MSE: 0.74895, Time: 16.82s
2025-07-18 05:13:56,231 - logger.py:50 - Epoch 224 Summary | Train MSE (x10^-2): 74.8946 | Val MSE (x10^-2): 41.1595 | Time: 34.84s
2025-07-18 05:13:59,388 - logger.py:50 - Epoch: [225][0/6]	Total Loss: 0.72357	Main MSE (x10^-2): 72.3566	LR: 2.33e-04	EMPP_Raw: 1.40588
2025-07-18 05:14:13,148 - logger.py:50 - Epoch: [225][5/6]	Total Loss: 0.75478	Main MSE (x10^-2): 75.4785	LR: 2.33e-04	EMPP_Raw: 1.47053
2025-07-18 05:14:13,190 - logger.py:50 - Epoch 225 Training Summary: Avg Total Loss: 0.75478, Avg Main MSE: 0.75478, Time: 16.95s
2025-07-18 05:14:31,134 - logger.py:50 - Epoch 225 Summary | Train MSE (x10^-2): 75.4785 | Val MSE (x10^-2): 42.3550 | Time: 34.90s
2025-07-18 05:14:34,284 - logger.py:50 - Epoch: [226][0/6]	Total Loss: 0.73987	Main MSE (x10^-2): 73.9872	LR: 2.32e-04	EMPP_Raw: 1.44471
2025-07-18 05:14:48,011 - logger.py:50 - Epoch: [226][5/6]	Total Loss: 0.73636	Main MSE (x10^-2): 73.6362	LR: 2.32e-04	EMPP_Raw: 1.43866
2025-07-18 05:14:48,055 - logger.py:50 - Epoch 226 Training Summary: Avg Total Loss: 0.73636, Avg Main MSE: 0.73636, Time: 16.91s
2025-07-18 05:15:05,883 - logger.py:50 - Epoch 226 Summary | Train MSE (x10^-2): 73.6362 | Val MSE (x10^-2): 40.9960 | Time: 34.75s
2025-07-18 05:15:08,890 - logger.py:50 - Epoch: [227][0/6]	Total Loss: 0.72951	Main MSE (x10^-2): 72.9511	LR: 2.30e-04	EMPP_Raw: 1.42625
2025-07-18 05:15:22,850 - logger.py:50 - Epoch: [227][5/6]	Total Loss: 0.73794	Main MSE (x10^-2): 73.7940	LR: 2.30e-04	EMPP_Raw: 1.43873
2025-07-18 05:15:22,889 - logger.py:50 - Epoch 227 Training Summary: Avg Total Loss: 0.73794, Avg Main MSE: 0.73794, Time: 16.99s
2025-07-18 05:15:40,775 - logger.py:50 - Epoch 227 Summary | Train MSE (x10^-2): 73.7940 | Val MSE (x10^-2): 39.9761 | Time: 34.88s
2025-07-18 05:15:43,780 - logger.py:50 - Epoch: [228][0/6]	Total Loss: 0.75876	Main MSE (x10^-2): 75.8763	LR: 2.29e-04	EMPP_Raw: 1.48190
2025-07-18 05:15:57,732 - logger.py:50 - Epoch: [228][5/6]	Total Loss: 0.74389	Main MSE (x10^-2): 74.3891	LR: 2.29e-04	EMPP_Raw: 1.45202
2025-07-18 05:15:57,775 - logger.py:50 - Epoch 228 Training Summary: Avg Total Loss: 0.74389, Avg Main MSE: 0.74389, Time: 16.99s
2025-07-18 05:16:15,663 - logger.py:50 - Epoch 228 Summary | Train MSE (x10^-2): 74.3891 | Val MSE (x10^-2): 40.7377 | Time: 34.88s
2025-07-18 05:16:18,650 - logger.py:50 - Epoch: [229][0/6]	Total Loss: 0.73341	Main MSE (x10^-2): 73.3411	LR: 2.28e-04	EMPP_Raw: 1.43524
2025-07-18 05:16:32,385 - logger.py:50 - Epoch: [229][5/6]	Total Loss: 0.73730	Main MSE (x10^-2): 73.7295	LR: 2.28e-04	EMPP_Raw: 1.43860
2025-07-18 05:16:32,429 - logger.py:50 - Epoch 229 Training Summary: Avg Total Loss: 0.73730, Avg Main MSE: 0.73730, Time: 16.76s
2025-07-18 05:16:50,395 - logger.py:50 - Epoch 229 Summary | Train MSE (x10^-2): 73.7295 | Val MSE (x10^-2): 40.8209 | Time: 34.73s
2025-07-18 05:16:53,417 - logger.py:50 - Epoch: [230][0/6]	Total Loss: 0.72198	Main MSE (x10^-2): 72.1975	LR: 2.27e-04	EMPP_Raw: 1.40584
2025-07-18 05:17:07,230 - logger.py:50 - Epoch: [230][5/6]	Total Loss: 0.74389	Main MSE (x10^-2): 74.3888	LR: 2.27e-04	EMPP_Raw: 1.45114
2025-07-18 05:17:07,273 - logger.py:50 - Epoch 230 Training Summary: Avg Total Loss: 0.74389, Avg Main MSE: 0.74389, Time: 16.87s
2025-07-18 05:17:25,186 - logger.py:50 - Epoch 230 Summary | Train MSE (x10^-2): 74.3888 | Val MSE (x10^-2): 41.1608 | Time: 34.79s
2025-07-18 05:17:28,369 - logger.py:50 - Epoch: [231][0/6]	Total Loss: 0.76202	Main MSE (x10^-2): 76.2016	LR: 2.26e-04	EMPP_Raw: 1.48849
2025-07-18 05:17:42,161 - logger.py:50 - Epoch: [231][5/6]	Total Loss: 0.74593	Main MSE (x10^-2): 74.5926	LR: 2.26e-04	EMPP_Raw: 1.45552
2025-07-18 05:17:42,204 - logger.py:50 - Epoch 231 Training Summary: Avg Total Loss: 0.74593, Avg Main MSE: 0.74593, Time: 17.01s
2025-07-18 05:18:00,059 - logger.py:50 - Epoch 231 Summary | Train MSE (x10^-2): 74.5926 | Val MSE (x10^-2): 41.3637 | Time: 34.87s
2025-07-18 05:18:03,212 - logger.py:50 - Epoch: [232][0/6]	Total Loss: 0.71777	Main MSE (x10^-2): 71.7766	LR: 2.24e-04	EMPP_Raw: 1.40207
2025-07-18 05:18:16,945 - logger.py:50 - Epoch: [232][5/6]	Total Loss: 0.73503	Main MSE (x10^-2): 73.5035	LR: 2.24e-04	EMPP_Raw: 1.43329
2025-07-18 05:18:16,993 - logger.py:50 - Epoch 232 Training Summary: Avg Total Loss: 0.73503, Avg Main MSE: 0.73503, Time: 16.92s
2025-07-18 05:18:35,028 - logger.py:50 - Epoch 232 Summary | Train MSE (x10^-2): 73.5035 | Val MSE (x10^-2): 43.3521 | Time: 34.96s
2025-07-18 05:18:38,251 - logger.py:50 - Epoch: [233][0/6]	Total Loss: 0.73124	Main MSE (x10^-2): 73.1237	LR: 2.23e-04	EMPP_Raw: 1.42345
2025-07-18 05:18:52,049 - logger.py:50 - Epoch: [233][5/6]	Total Loss: 0.73906	Main MSE (x10^-2): 73.9056	LR: 2.23e-04	EMPP_Raw: 1.44184
2025-07-18 05:18:52,093 - logger.py:50 - Epoch 233 Training Summary: Avg Total Loss: 0.73906, Avg Main MSE: 0.73906, Time: 17.06s
2025-07-18 05:19:10,009 - logger.py:50 - Epoch 233 Summary | Train MSE (x10^-2): 73.9056 | Val MSE (x10^-2): 41.3738 | Time: 34.97s
2025-07-18 05:19:13,013 - logger.py:50 - Epoch: [234][0/6]	Total Loss: 0.73547	Main MSE (x10^-2): 73.5474	LR: 2.22e-04	EMPP_Raw: 1.43349
2025-07-18 05:19:26,969 - logger.py:50 - Epoch: [234][5/6]	Total Loss: 0.74075	Main MSE (x10^-2): 74.0748	LR: 2.22e-04	EMPP_Raw: 1.44697
2025-07-18 05:19:27,019 - logger.py:50 - Epoch 234 Training Summary: Avg Total Loss: 0.74075, Avg Main MSE: 0.74075, Time: 17.00s
2025-07-18 05:19:44,969 - logger.py:50 - Epoch 234 Summary | Train MSE (x10^-2): 74.0748 | Val MSE (x10^-2): 39.5682 | Time: 34.96s
2025-07-18 05:19:47,976 - logger.py:50 - Epoch: [235][0/6]	Total Loss: 0.73066	Main MSE (x10^-2): 73.0662	LR: 2.21e-04	EMPP_Raw: 1.42989
2025-07-18 05:20:01,776 - logger.py:50 - Epoch: [235][5/6]	Total Loss: 0.73776	Main MSE (x10^-2): 73.7759	LR: 2.21e-04	EMPP_Raw: 1.44211
2025-07-18 05:20:01,824 - logger.py:50 - Epoch 235 Training Summary: Avg Total Loss: 0.73776, Avg Main MSE: 0.73776, Time: 16.85s
2025-07-18 05:20:19,982 - logger.py:50 - Epoch 235 Summary | Train MSE (x10^-2): 73.7759 | Val MSE (x10^-2): 40.0210 | Time: 35.01s
2025-07-18 05:20:22,972 - logger.py:50 - Epoch: [236][0/6]	Total Loss: 0.74949	Main MSE (x10^-2): 74.9493	LR: 2.19e-04	EMPP_Raw: 1.46164
2025-07-18 05:20:36,762 - logger.py:50 - Epoch: [236][5/6]	Total Loss: 0.74161	Main MSE (x10^-2): 74.1608	LR: 2.19e-04	EMPP_Raw: 1.44907
2025-07-18 05:20:36,806 - logger.py:50 - Epoch 236 Training Summary: Avg Total Loss: 0.74161, Avg Main MSE: 0.74161, Time: 16.81s
2025-07-18 05:20:54,801 - logger.py:50 - Epoch 236 Summary | Train MSE (x10^-2): 74.1608 | Val MSE (x10^-2): 40.2740 | Time: 34.81s
2025-07-18 05:20:57,844 - logger.py:50 - Epoch: [237][0/6]	Total Loss: 0.73558	Main MSE (x10^-2): 73.5584	LR: 2.18e-04	EMPP_Raw: 1.43999
2025-07-18 05:21:11,658 - logger.py:50 - Epoch: [237][5/6]	Total Loss: 0.74138	Main MSE (x10^-2): 74.1377	LR: 2.18e-04	EMPP_Raw: 1.44999
2025-07-18 05:21:11,700 - logger.py:50 - Epoch 237 Training Summary: Avg Total Loss: 0.74138, Avg Main MSE: 0.74138, Time: 16.89s
2025-07-18 05:21:29,536 - logger.py:50 - Epoch 237 Summary | Train MSE (x10^-2): 74.1377 | Val MSE (x10^-2): 40.0010 | Time: 34.73s
2025-07-18 05:21:32,741 - logger.py:50 - Epoch: [238][0/6]	Total Loss: 0.73666	Main MSE (x10^-2): 73.6660	LR: 2.17e-04	EMPP_Raw: 1.44155
2025-07-18 05:21:46,535 - logger.py:50 - Epoch: [238][5/6]	Total Loss: 0.74575	Main MSE (x10^-2): 74.5749	LR: 2.17e-04	EMPP_Raw: 1.45841
2025-07-18 05:21:46,581 - logger.py:50 - Epoch 238 Training Summary: Avg Total Loss: 0.74575, Avg Main MSE: 0.74575, Time: 17.04s
2025-07-18 05:22:04,491 - logger.py:50 - Epoch 238 Summary | Train MSE (x10^-2): 74.5749 | Val MSE (x10^-2): 40.6553 | Time: 34.95s
2025-07-18 05:22:07,645 - logger.py:50 - Epoch: [239][0/6]	Total Loss: 0.73176	Main MSE (x10^-2): 73.1756	LR: 2.16e-04	EMPP_Raw: 1.42990
2025-07-18 05:22:21,452 - logger.py:50 - Epoch: [239][5/6]	Total Loss: 0.73576	Main MSE (x10^-2): 73.5759	LR: 2.16e-04	EMPP_Raw: 1.43655
2025-07-18 05:22:21,495 - logger.py:50 - Epoch 239 Training Summary: Avg Total Loss: 0.73576, Avg Main MSE: 0.73576, Time: 16.99s
2025-07-18 05:22:39,388 - logger.py:50 - Epoch 239 Summary | Train MSE (x10^-2): 73.5759 | Val MSE (x10^-2): 40.0648 | Time: 34.89s
2025-07-18 05:22:42,444 - logger.py:50 - Epoch: [240][0/6]	Total Loss: 0.73123	Main MSE (x10^-2): 73.1230	LR: 2.14e-04	EMPP_Raw: 1.42915
2025-07-18 05:22:56,371 - logger.py:50 - Epoch: [240][5/6]	Total Loss: 0.73919	Main MSE (x10^-2): 73.9191	LR: 2.14e-04	EMPP_Raw: 1.44430
2025-07-18 05:22:56,417 - logger.py:50 - Epoch 240 Training Summary: Avg Total Loss: 0.73919, Avg Main MSE: 0.73919, Time: 17.02s
2025-07-18 05:23:14,388 - logger.py:50 - Epoch 240 Summary | Train MSE (x10^-2): 73.9191 | Val MSE (x10^-2): 40.2409 | Time: 34.99s
2025-07-18 05:23:17,431 - logger.py:50 - Epoch: [241][0/6]	Total Loss: 0.73022	Main MSE (x10^-2): 73.0220	LR: 2.13e-04	EMPP_Raw: 1.42584
2025-07-18 05:23:31,349 - logger.py:50 - Epoch: [241][5/6]	Total Loss: 0.73487	Main MSE (x10^-2): 73.4868	LR: 2.13e-04	EMPP_Raw: 1.43496
2025-07-18 05:23:31,392 - logger.py:50 - Epoch 241 Training Summary: Avg Total Loss: 0.73487, Avg Main MSE: 0.73487, Time: 16.99s
2025-07-18 05:23:49,248 - logger.py:50 - Epoch 241 Summary | Train MSE (x10^-2): 73.4868 | Val MSE (x10^-2): 41.7361 | Time: 34.85s
2025-07-18 05:23:52,242 - logger.py:50 - Epoch: [242][0/6]	Total Loss: 0.71134	Main MSE (x10^-2): 71.1335	LR: 2.12e-04	EMPP_Raw: 1.38816
2025-07-18 05:24:06,018 - logger.py:50 - Epoch: [242][5/6]	Total Loss: 0.73908	Main MSE (x10^-2): 73.9084	LR: 2.12e-04	EMPP_Raw: 1.44321
2025-07-18 05:24:06,059 - logger.py:50 - Epoch 242 Training Summary: Avg Total Loss: 0.73908, Avg Main MSE: 0.73908, Time: 16.80s
2025-07-18 05:24:24,139 - logger.py:50 - Epoch 242 Summary | Train MSE (x10^-2): 73.9084 | Val MSE (x10^-2): 42.6071 | Time: 34.88s
2025-07-18 05:24:27,186 - logger.py:50 - Epoch: [243][0/6]	Total Loss: 0.72000	Main MSE (x10^-2): 71.9999	LR: 2.11e-04	EMPP_Raw: 1.40657
2025-07-18 05:24:40,960 - logger.py:50 - Epoch: [243][5/6]	Total Loss: 0.74607	Main MSE (x10^-2): 74.6071	LR: 2.11e-04	EMPP_Raw: 1.45685
2025-07-18 05:24:41,003 - logger.py:50 - Epoch 243 Training Summary: Avg Total Loss: 0.74607, Avg Main MSE: 0.74607, Time: 16.85s
2025-07-18 05:24:58,983 - logger.py:50 - Epoch 243 Summary | Train MSE (x10^-2): 74.6071 | Val MSE (x10^-2): 41.4014 | Time: 34.84s
2025-07-18 05:25:02,171 - logger.py:50 - Epoch: [244][0/6]	Total Loss: 0.72345	Main MSE (x10^-2): 72.3447	LR: 2.09e-04	EMPP_Raw: 1.41029
2025-07-18 05:25:15,905 - logger.py:50 - Epoch: [244][5/6]	Total Loss: 0.72865	Main MSE (x10^-2): 72.8653	LR: 2.09e-04	EMPP_Raw: 1.42192
2025-07-18 05:25:15,948 - logger.py:50 - Epoch 244 Training Summary: Avg Total Loss: 0.72865, Avg Main MSE: 0.72865, Time: 16.96s
2025-07-18 05:25:33,797 - logger.py:50 - Epoch 244 Summary | Train MSE (x10^-2): 72.8653 | Val MSE (x10^-2): 42.0425 | Time: 34.81s
2025-07-18 05:25:36,968 - logger.py:50 - Epoch: [245][0/6]	Total Loss: 0.72839	Main MSE (x10^-2): 72.8390	LR: 2.08e-04	EMPP_Raw: 1.41831
2025-07-18 05:25:50,754 - logger.py:50 - Epoch: [245][5/6]	Total Loss: 0.74145	Main MSE (x10^-2): 74.1448	LR: 2.08e-04	EMPP_Raw: 1.44815
2025-07-18 05:25:50,799 - logger.py:50 - Epoch 245 Training Summary: Avg Total Loss: 0.74145, Avg Main MSE: 0.74145, Time: 16.99s
2025-07-18 05:26:08,743 - logger.py:50 - Epoch 245 Summary | Train MSE (x10^-2): 74.1448 | Val MSE (x10^-2): 41.5996 | Time: 34.94s
2025-07-18 05:26:11,883 - logger.py:50 - Epoch: [246][0/6]	Total Loss: 0.75061	Main MSE (x10^-2): 75.0608	LR: 2.07e-04	EMPP_Raw: 1.46756
2025-07-18 05:26:25,619 - logger.py:50 - Epoch: [246][5/6]	Total Loss: 0.73855	Main MSE (x10^-2): 73.8552	LR: 2.07e-04	EMPP_Raw: 1.44379
2025-07-18 05:26:25,659 - logger.py:50 - Epoch 246 Training Summary: Avg Total Loss: 0.73855, Avg Main MSE: 0.73855, Time: 16.91s
2025-07-18 05:26:43,719 - logger.py:50 - Epoch 246 Summary | Train MSE (x10^-2): 73.8552 | Val MSE (x10^-2): 40.9101 | Time: 34.97s
2025-07-18 05:26:46,754 - logger.py:50 - Epoch: [247][0/6]	Total Loss: 0.73814	Main MSE (x10^-2): 73.8143	LR: 2.06e-04	EMPP_Raw: 1.44540
2025-07-18 05:27:00,671 - logger.py:50 - Epoch: [247][5/6]	Total Loss: 0.74688	Main MSE (x10^-2): 74.6880	LR: 2.06e-04	EMPP_Raw: 1.46065
2025-07-18 05:27:00,721 - logger.py:50 - Epoch 247 Training Summary: Avg Total Loss: 0.74688, Avg Main MSE: 0.74688, Time: 16.99s
2025-07-18 05:27:18,707 - logger.py:50 - Epoch 247 Summary | Train MSE (x10^-2): 74.6880 | Val MSE (x10^-2): 40.0850 | Time: 34.98s
2025-07-18 05:27:21,695 - logger.py:50 - Epoch: [248][0/6]	Total Loss: 0.71620	Main MSE (x10^-2): 71.6204	LR: 2.04e-04	EMPP_Raw: 1.40563
2025-07-18 05:27:35,535 - logger.py:50 - Epoch: [248][5/6]	Total Loss: 0.73077	Main MSE (x10^-2): 73.0772	LR: 2.04e-04	EMPP_Raw: 1.43046
2025-07-18 05:27:35,580 - logger.py:50 - Epoch 248 Training Summary: Avg Total Loss: 0.73077, Avg Main MSE: 0.73077, Time: 16.86s
2025-07-18 05:27:53,765 - logger.py:50 - Epoch 248 Summary | Train MSE (x10^-2): 73.0772 | Val MSE (x10^-2): 41.4716 | Time: 35.05s
2025-07-18 05:27:56,834 - logger.py:50 - Epoch: [249][0/6]	Total Loss: 0.71705	Main MSE (x10^-2): 71.7051	LR: 2.03e-04	EMPP_Raw: 1.40469
2025-07-18 05:28:10,562 - logger.py:50 - Epoch: [249][5/6]	Total Loss: 0.73977	Main MSE (x10^-2): 73.9774	LR: 2.03e-04	EMPP_Raw: 1.44838
2025-07-18 05:28:10,604 - logger.py:50 - Epoch 249 Training Summary: Avg Total Loss: 0.73977, Avg Main MSE: 0.73977, Time: 16.83s
2025-07-18 05:28:28,606 - logger.py:50 - Epoch 249 Summary | Train MSE (x10^-2): 73.9774 | Val MSE (x10^-2): 40.4831 | Time: 34.84s
2025-07-18 05:28:31,661 - logger.py:50 - Epoch: [250][0/6]	Total Loss: 0.73145	Main MSE (x10^-2): 73.1451	LR: 2.02e-04	EMPP_Raw: 1.43254
2025-07-18 05:28:45,434 - logger.py:50 - Epoch: [250][5/6]	Total Loss: 0.73985	Main MSE (x10^-2): 73.9852	LR: 2.02e-04	EMPP_Raw: 1.44648
2025-07-18 05:28:45,479 - logger.py:50 - Epoch 250 Training Summary: Avg Total Loss: 0.73985, Avg Main MSE: 0.73985, Time: 16.86s
2025-07-18 05:29:03,380 - logger.py:50 - Epoch 250 Summary | Train MSE (x10^-2): 73.9852 | Val MSE (x10^-2): 40.3049 | Time: 34.77s
2025-07-18 05:29:06,510 - logger.py:50 - Epoch: [251][0/6]	Total Loss: 0.75097	Main MSE (x10^-2): 75.0974	LR: 2.00e-04	EMPP_Raw: 1.46700
2025-07-18 05:29:20,243 - logger.py:50 - Epoch: [251][5/6]	Total Loss: 0.74553	Main MSE (x10^-2): 74.5530	LR: 2.00e-04	EMPP_Raw: 1.45796
2025-07-18 05:29:20,282 - logger.py:50 - Epoch 251 Training Summary: Avg Total Loss: 0.74553, Avg Main MSE: 0.74553, Time: 16.89s
2025-07-18 05:29:38,205 - logger.py:50 - Epoch 251 Summary | Train MSE (x10^-2): 74.5530 | Val MSE (x10^-2): 41.6330 | Time: 34.82s
2025-07-18 05:29:41,360 - logger.py:50 - Epoch: [252][0/6]	Total Loss: 0.74351	Main MSE (x10^-2): 74.3506	LR: 1.99e-04	EMPP_Raw: 1.45891
2025-07-18 05:29:55,118 - logger.py:50 - Epoch: [252][5/6]	Total Loss: 0.73635	Main MSE (x10^-2): 73.6348	LR: 1.99e-04	EMPP_Raw: 1.44055
2025-07-18 05:29:55,161 - logger.py:50 - Epoch 252 Training Summary: Avg Total Loss: 0.73635, Avg Main MSE: 0.73635, Time: 16.95s
2025-07-18 05:30:13,044 - logger.py:50 - Epoch 252 Summary | Train MSE (x10^-2): 73.6348 | Val MSE (x10^-2): 40.8586 | Time: 34.83s
2025-07-18 05:30:16,037 - logger.py:50 - Epoch: [253][0/6]	Total Loss: 0.73017	Main MSE (x10^-2): 73.0174	LR: 1.98e-04	EMPP_Raw: 1.43119
2025-07-18 05:30:29,960 - logger.py:50 - Epoch: [253][5/6]	Total Loss: 0.74603	Main MSE (x10^-2): 74.6035	LR: 1.98e-04	EMPP_Raw: 1.45970
2025-07-18 05:30:30,005 - logger.py:50 - Epoch 253 Training Summary: Avg Total Loss: 0.74603, Avg Main MSE: 0.74603, Time: 16.95s
2025-07-18 05:30:47,845 - logger.py:50 - Epoch 253 Summary | Train MSE (x10^-2): 74.6035 | Val MSE (x10^-2): 40.8245 | Time: 34.79s
2025-07-18 05:30:50,836 - logger.py:50 - Epoch: [254][0/6]	Total Loss: 0.75676	Main MSE (x10^-2): 75.6763	LR: 1.97e-04	EMPP_Raw: 1.48252
2025-07-18 05:31:04,779 - logger.py:50 - Epoch: [254][5/6]	Total Loss: 0.74818	Main MSE (x10^-2): 74.8184	LR: 1.97e-04	EMPP_Raw: 1.46394
2025-07-18 05:31:04,822 - logger.py:50 - Epoch 254 Training Summary: Avg Total Loss: 0.74818, Avg Main MSE: 0.74818, Time: 16.97s
2025-07-18 05:31:22,664 - logger.py:50 - Epoch 254 Summary | Train MSE (x10^-2): 74.8184 | Val MSE (x10^-2): 41.2236 | Time: 34.81s
2025-07-18 05:31:25,662 - logger.py:50 - Epoch: [255][0/6]	Total Loss: 0.76073	Main MSE (x10^-2): 76.0732	LR: 1.95e-04	EMPP_Raw: 1.49031
2025-07-18 05:31:39,409 - logger.py:50 - Epoch: [255][5/6]	Total Loss: 0.74110	Main MSE (x10^-2): 74.1104	LR: 1.95e-04	EMPP_Raw: 1.45004
2025-07-18 05:31:39,453 - logger.py:50 - Epoch 255 Training Summary: Avg Total Loss: 0.74110, Avg Main MSE: 0.74110, Time: 16.78s
2025-07-18 05:31:57,575 - logger.py:50 - Epoch 255 Summary | Train MSE (x10^-2): 74.1104 | Val MSE (x10^-2): 41.2137 | Time: 34.90s
2025-07-18 05:32:00,574 - logger.py:50 - Epoch: [256][0/6]	Total Loss: 0.73018	Main MSE (x10^-2): 73.0184	LR: 1.94e-04	EMPP_Raw: 1.42505
2025-07-18 05:32:14,368 - logger.py:50 - Epoch: [256][5/6]	Total Loss: 0.73385	Main MSE (x10^-2): 73.3846	LR: 1.94e-04	EMPP_Raw: 1.43449
2025-07-18 05:32:14,410 - logger.py:50 - Epoch 256 Training Summary: Avg Total Loss: 0.73385, Avg Main MSE: 0.73385, Time: 16.83s
2025-07-18 05:32:32,338 - logger.py:50 - Epoch 256 Summary | Train MSE (x10^-2): 73.3846 | Val MSE (x10^-2): 40.3704 | Time: 34.76s
2025-07-18 05:32:35,485 - logger.py:50 - Epoch: [257][0/6]	Total Loss: 0.72484	Main MSE (x10^-2): 72.4842	LR: 1.93e-04	EMPP_Raw: 1.42137
2025-07-18 05:32:49,256 - logger.py:50 - Epoch: [257][5/6]	Total Loss: 0.73257	Main MSE (x10^-2): 73.2572	LR: 1.93e-04	EMPP_Raw: 1.43411
2025-07-18 05:32:49,299 - logger.py:50 - Epoch 257 Training Summary: Avg Total Loss: 0.73257, Avg Main MSE: 0.73257, Time: 16.95s
2025-07-18 05:33:07,156 - logger.py:50 - Epoch 257 Summary | Train MSE (x10^-2): 73.2572 | Val MSE (x10^-2): 40.6382 | Time: 34.81s
2025-07-18 05:33:10,381 - logger.py:50 - Epoch: [258][0/6]	Total Loss: 0.72335	Main MSE (x10^-2): 72.3345	LR: 1.92e-04	EMPP_Raw: 1.41638
2025-07-18 05:33:24,131 - logger.py:50 - Epoch: [258][5/6]	Total Loss: 0.72778	Main MSE (x10^-2): 72.7776	LR: 1.92e-04	EMPP_Raw: 1.42458
2025-07-18 05:33:24,174 - logger.py:50 - Epoch 258 Training Summary: Avg Total Loss: 0.72778, Avg Main MSE: 0.72778, Time: 17.01s
2025-07-18 05:33:42,126 - logger.py:50 - Epoch 258 Summary | Train MSE (x10^-2): 72.7776 | Val MSE (x10^-2): 41.4858 | Time: 34.96s
2025-07-18 05:33:45,304 - logger.py:50 - Epoch: [259][0/6]	Total Loss: 0.74869	Main MSE (x10^-2): 74.8691	LR: 1.90e-04	EMPP_Raw: 1.46831
2025-07-18 05:33:59,045 - logger.py:50 - Epoch: [259][5/6]	Total Loss: 0.74210	Main MSE (x10^-2): 74.2098	LR: 1.90e-04	EMPP_Raw: 1.45517
2025-07-18 05:33:59,088 - logger.py:50 - Epoch 259 Training Summary: Avg Total Loss: 0.74210, Avg Main MSE: 0.74210, Time: 16.95s
2025-07-18 05:34:17,126 - logger.py:50 - Epoch 259 Summary | Train MSE (x10^-2): 74.2098 | Val MSE (x10^-2): 41.8837 | Time: 35.00s
2025-07-18 05:34:20,160 - logger.py:50 - Epoch: [260][0/6]	Total Loss: 0.72496	Main MSE (x10^-2): 72.4959	LR: 1.89e-04	EMPP_Raw: 1.42312
2025-07-18 05:34:34,069 - logger.py:50 - Epoch: [260][5/6]	Total Loss: 0.73710	Main MSE (x10^-2): 73.7105	LR: 1.89e-04	EMPP_Raw: 1.44491
2025-07-18 05:34:34,113 - logger.py:50 - Epoch 260 Training Summary: Avg Total Loss: 0.73710, Avg Main MSE: 0.73710, Time: 16.98s
2025-07-18 05:34:52,064 - logger.py:50 - Epoch 260 Summary | Train MSE (x10^-2): 73.7105 | Val MSE (x10^-2): 41.9727 | Time: 34.93s
2025-07-18 05:34:55,085 - logger.py:50 - Epoch: [261][0/6]	Total Loss: 0.75225	Main MSE (x10^-2): 75.2250	LR: 1.88e-04	EMPP_Raw: 1.47505
2025-07-18 05:35:08,899 - logger.py:50 - Epoch: [261][5/6]	Total Loss: 0.73502	Main MSE (x10^-2): 73.5022	LR: 1.88e-04	EMPP_Raw: 1.43885
2025-07-18 05:35:08,939 - logger.py:50 - Epoch 261 Training Summary: Avg Total Loss: 0.73502, Avg Main MSE: 0.73502, Time: 16.86s
2025-07-18 05:35:26,961 - logger.py:50 - Epoch 261 Summary | Train MSE (x10^-2): 73.5022 | Val MSE (x10^-2): 38.2534 | Time: 34.89s
2025-07-18 05:35:29,948 - logger.py:50 - Epoch: [262][0/6]	Total Loss: 0.73964	Main MSE (x10^-2): 73.9639	LR: 1.87e-04	EMPP_Raw: 1.44285
2025-07-18 05:35:43,788 - logger.py:50 - Epoch: [262][5/6]	Total Loss: 0.74226	Main MSE (x10^-2): 74.2262	LR: 1.87e-04	EMPP_Raw: 1.45352
2025-07-18 05:35:43,831 - logger.py:50 - Epoch 262 Training Summary: Avg Total Loss: 0.74226, Avg Main MSE: 0.74226, Time: 16.86s
2025-07-18 05:36:01,844 - logger.py:50 - Epoch 262 Summary | Train MSE (x10^-2): 74.2262 | Val MSE (x10^-2): 42.7219 | Time: 34.88s
2025-07-18 05:36:04,859 - logger.py:50 - Epoch: [263][0/6]	Total Loss: 0.71554	Main MSE (x10^-2): 71.5542	LR: 1.85e-04	EMPP_Raw: 1.40305
2025-07-18 05:36:18,731 - logger.py:50 - Epoch: [263][5/6]	Total Loss: 0.72906	Main MSE (x10^-2): 72.9058	LR: 1.85e-04	EMPP_Raw: 1.42864
2025-07-18 05:36:18,778 - logger.py:50 - Epoch 263 Training Summary: Avg Total Loss: 0.72906, Avg Main MSE: 0.72906, Time: 16.92s
2025-07-18 05:36:36,639 - logger.py:50 - Epoch 263 Summary | Train MSE (x10^-2): 72.9058 | Val MSE (x10^-2): 41.3039 | Time: 34.79s
2025-07-18 05:36:39,810 - logger.py:50 - Epoch: [264][0/6]	Total Loss: 0.72467	Main MSE (x10^-2): 72.4672	LR: 1.84e-04	EMPP_Raw: 1.42095
2025-07-18 05:36:53,726 - logger.py:50 - Epoch: [264][5/6]	Total Loss: 0.72661	Main MSE (x10^-2): 72.6606	LR: 1.84e-04	EMPP_Raw: 1.42419
2025-07-18 05:36:53,770 - logger.py:50 - Epoch 264 Training Summary: Avg Total Loss: 0.72661, Avg Main MSE: 0.72661, Time: 17.12s
2025-07-18 05:37:11,678 - logger.py:50 - Epoch 264 Summary | Train MSE (x10^-2): 72.6606 | Val MSE (x10^-2): 39.9054 | Time: 35.03s
2025-07-18 05:37:14,841 - logger.py:50 - Epoch: [265][0/6]	Total Loss: 0.70323	Main MSE (x10^-2): 70.3233	LR: 1.83e-04	EMPP_Raw: 1.37889
2025-07-18 05:37:28,723 - logger.py:50 - Epoch: [265][5/6]	Total Loss: 0.72856	Main MSE (x10^-2): 72.8562	LR: 1.83e-04	EMPP_Raw: 1.42791
2025-07-18 05:37:28,772 - logger.py:50 - Epoch 265 Training Summary: Avg Total Loss: 0.72856, Avg Main MSE: 0.72856, Time: 17.08s
2025-07-18 05:37:46,575 - logger.py:50 - Epoch 265 Summary | Train MSE (x10^-2): 72.8562 | Val MSE (x10^-2): 40.3285 | Time: 34.89s
2025-07-18 05:37:49,595 - logger.py:50 - Epoch: [266][0/6]	Total Loss: 0.72888	Main MSE (x10^-2): 72.8882	LR: 1.82e-04	EMPP_Raw: 1.42875
2025-07-18 05:38:03,590 - logger.py:50 - Epoch: [266][5/6]	Total Loss: 0.72822	Main MSE (x10^-2): 72.8224	LR: 1.82e-04	EMPP_Raw: 1.42607
2025-07-18 05:38:03,636 - logger.py:50 - Epoch 266 Training Summary: Avg Total Loss: 0.72822, Avg Main MSE: 0.72822, Time: 17.05s
2025-07-18 05:38:21,656 - logger.py:50 - Epoch 266 Summary | Train MSE (x10^-2): 72.8224 | Val MSE (x10^-2): 39.9258 | Time: 35.08s
2025-07-18 05:38:24,654 - logger.py:50 - Epoch: [267][0/6]	Total Loss: 0.71223	Main MSE (x10^-2): 71.2232	LR: 1.80e-04	EMPP_Raw: 1.39769
2025-07-18 05:38:38,639 - logger.py:50 - Epoch: [267][5/6]	Total Loss: 0.74710	Main MSE (x10^-2): 74.7103	LR: 1.80e-04	EMPP_Raw: 1.46538
2025-07-18 05:38:38,680 - logger.py:50 - Epoch 267 Training Summary: Avg Total Loss: 0.74710, Avg Main MSE: 0.74710, Time: 17.01s
2025-07-18 05:38:56,580 - logger.py:50 - Epoch 267 Summary | Train MSE (x10^-2): 74.7103 | Val MSE (x10^-2): 40.2200 | Time: 34.92s
2025-07-18 05:38:59,624 - logger.py:50 - Epoch: [268][0/6]	Total Loss: 0.71902	Main MSE (x10^-2): 71.9021	LR: 1.79e-04	EMPP_Raw: 1.40937
2025-07-18 05:39:13,461 - logger.py:50 - Epoch: [268][5/6]	Total Loss: 0.73790	Main MSE (x10^-2): 73.7899	LR: 1.79e-04	EMPP_Raw: 1.44768
2025-07-18 05:39:13,502 - logger.py:50 - Epoch 268 Training Summary: Avg Total Loss: 0.73790, Avg Main MSE: 0.73790, Time: 16.91s
2025-07-18 05:39:31,591 - logger.py:50 - Epoch 268 Summary | Train MSE (x10^-2): 73.7899 | Val MSE (x10^-2): 41.4570 | Time: 35.01s
2025-07-18 05:39:34,594 - logger.py:50 - Epoch: [269][0/6]	Total Loss: 0.71176	Main MSE (x10^-2): 71.1764	LR: 1.78e-04	EMPP_Raw: 1.39670
2025-07-18 05:39:48,417 - logger.py:50 - Epoch: [269][5/6]	Total Loss: 0.72496	Main MSE (x10^-2): 72.4960	LR: 1.78e-04	EMPP_Raw: 1.42270
2025-07-18 05:39:48,467 - logger.py:50 - Epoch 269 Training Summary: Avg Total Loss: 0.72496, Avg Main MSE: 0.72496, Time: 16.87s
2025-07-18 05:40:06,368 - logger.py:50 - Epoch 269 Summary | Train MSE (x10^-2): 72.4960 | Val MSE (x10^-2): 41.5483 | Time: 34.77s
2025-07-18 05:40:09,531 - logger.py:50 - Epoch: [270][0/6]	Total Loss: 0.71804	Main MSE (x10^-2): 71.8045	LR: 1.77e-04	EMPP_Raw: 1.40626
2025-07-18 05:40:23,347 - logger.py:50 - Epoch: [270][5/6]	Total Loss: 0.72306	Main MSE (x10^-2): 72.3060	LR: 1.77e-04	EMPP_Raw: 1.41795
2025-07-18 05:40:23,392 - logger.py:50 - Epoch 270 Training Summary: Avg Total Loss: 0.72306, Avg Main MSE: 0.72306, Time: 17.01s
2025-07-18 05:40:41,371 - logger.py:50 - Epoch 270 Summary | Train MSE (x10^-2): 72.3060 | Val MSE (x10^-2): 41.1438 | Time: 35.00s
2025-07-18 05:40:44,543 - logger.py:50 - Epoch: [271][0/6]	Total Loss: 0.74546	Main MSE (x10^-2): 74.5456	LR: 1.75e-04	EMPP_Raw: 1.46345
2025-07-18 05:40:58,407 - logger.py:50 - Epoch: [271][5/6]	Total Loss: 0.74570	Main MSE (x10^-2): 74.5704	LR: 1.75e-04	EMPP_Raw: 1.46186
2025-07-18 05:40:58,454 - logger.py:50 - Epoch 271 Training Summary: Avg Total Loss: 0.74570, Avg Main MSE: 0.74570, Time: 17.07s
2025-07-18 05:41:16,468 - logger.py:50 - Epoch 271 Summary | Train MSE (x10^-2): 74.5704 | Val MSE (x10^-2): 40.0903 | Time: 35.09s
2025-07-18 05:41:19,642 - logger.py:50 - Epoch: [272][0/6]	Total Loss: 0.70950	Main MSE (x10^-2): 70.9499	LR: 1.74e-04	EMPP_Raw: 1.38877
2025-07-18 05:41:33,457 - logger.py:50 - Epoch: [272][5/6]	Total Loss: 0.73597	Main MSE (x10^-2): 73.5967	LR: 1.74e-04	EMPP_Raw: 1.44337
2025-07-18 05:41:33,499 - logger.py:50 - Epoch 272 Training Summary: Avg Total Loss: 0.73597, Avg Main MSE: 0.73597, Time: 17.02s
2025-07-18 05:41:51,417 - logger.py:50 - Epoch 272 Summary | Train MSE (x10^-2): 73.5967 | Val MSE (x10^-2): 39.8266 | Time: 34.94s
2025-07-18 05:41:54,457 - logger.py:50 - Epoch: [273][0/6]	Total Loss: 0.72910	Main MSE (x10^-2): 72.9098	LR: 1.73e-04	EMPP_Raw: 1.42688
2025-07-18 05:42:08,393 - logger.py:50 - Epoch: [273][5/6]	Total Loss: 0.73711	Main MSE (x10^-2): 73.7108	LR: 1.73e-04	EMPP_Raw: 1.44443
2025-07-18 05:42:08,437 - logger.py:50 - Epoch 273 Training Summary: Avg Total Loss: 0.73711, Avg Main MSE: 0.73711, Time: 17.01s
2025-07-18 05:42:26,450 - logger.py:50 - Epoch 273 Summary | Train MSE (x10^-2): 73.7108 | Val MSE (x10^-2): 40.7305 | Time: 35.02s
2025-07-18 05:42:29,447 - logger.py:50 - Epoch: [274][0/6]	Total Loss: 0.70498	Main MSE (x10^-2): 70.4985	LR: 1.72e-04	EMPP_Raw: 1.38398
2025-07-18 05:42:43,236 - logger.py:50 - Epoch: [274][5/6]	Total Loss: 0.73859	Main MSE (x10^-2): 73.8587	LR: 1.72e-04	EMPP_Raw: 1.45026
2025-07-18 05:42:43,282 - logger.py:50 - Epoch 274 Training Summary: Avg Total Loss: 0.73859, Avg Main MSE: 0.73859, Time: 16.82s
2025-07-18 05:43:01,312 - logger.py:50 - Epoch 274 Summary | Train MSE (x10^-2): 73.8587 | Val MSE (x10^-2): 41.1154 | Time: 34.86s
2025-07-18 05:43:04,297 - logger.py:50 - Epoch: [275][0/6]	Total Loss: 0.73920	Main MSE (x10^-2): 73.9202	LR: 1.71e-04	EMPP_Raw: 1.44598
2025-07-18 05:43:18,056 - logger.py:50 - Epoch: [275][5/6]	Total Loss: 0.73341	Main MSE (x10^-2): 73.3412	LR: 1.71e-04	EMPP_Raw: 1.43890
2025-07-18 05:43:18,105 - logger.py:50 - Epoch 275 Training Summary: Avg Total Loss: 0.73341, Avg Main MSE: 0.73341, Time: 16.78s
2025-07-18 05:43:36,096 - logger.py:50 - Epoch 275 Summary | Train MSE (x10^-2): 73.3412 | Val MSE (x10^-2): 42.8256 | Time: 34.78s
2025-07-18 05:43:39,103 - logger.py:50 - Epoch: [276][0/6]	Total Loss: 0.73073	Main MSE (x10^-2): 73.0732	LR: 1.69e-04	EMPP_Raw: 1.43474
2025-07-18 05:43:52,921 - logger.py:50 - Epoch: [276][5/6]	Total Loss: 0.73175	Main MSE (x10^-2): 73.1751	LR: 1.69e-04	EMPP_Raw: 1.43491
2025-07-18 05:43:52,969 - logger.py:50 - Epoch 276 Training Summary: Avg Total Loss: 0.73175, Avg Main MSE: 0.73175, Time: 16.86s
2025-07-18 05:44:11,037 - logger.py:50 - Epoch 276 Summary | Train MSE (x10^-2): 73.1751 | Val MSE (x10^-2): 40.3997 | Time: 34.93s
2025-07-18 05:44:14,195 - logger.py:50 - Epoch: [277][0/6]	Total Loss: 0.74873	Main MSE (x10^-2): 74.8725	LR: 1.68e-04	EMPP_Raw: 1.46997
2025-07-18 05:44:28,006 - logger.py:50 - Epoch: [277][5/6]	Total Loss: 0.74383	Main MSE (x10^-2): 74.3834	LR: 1.68e-04	EMPP_Raw: 1.45967
2025-07-18 05:44:28,052 - logger.py:50 - Epoch 277 Training Summary: Avg Total Loss: 0.74383, Avg Main MSE: 0.74383, Time: 17.01s
2025-07-18 05:44:46,030 - logger.py:50 - Epoch 277 Summary | Train MSE (x10^-2): 74.3834 | Val MSE (x10^-2): 39.5435 | Time: 34.99s
2025-07-18 05:44:49,170 - logger.py:50 - Epoch: [278][0/6]	Total Loss: 0.74121	Main MSE (x10^-2): 74.1211	LR: 1.67e-04	EMPP_Raw: 1.45261
2025-07-18 05:45:02,872 - logger.py:50 - Epoch: [278][5/6]	Total Loss: 0.72986	Main MSE (x10^-2): 72.9862	LR: 1.67e-04	EMPP_Raw: 1.43238
2025-07-18 05:45:02,916 - logger.py:50 - Epoch 278 Training Summary: Avg Total Loss: 0.72986, Avg Main MSE: 0.72986, Time: 16.88s
2025-07-18 05:45:20,927 - logger.py:50 - Epoch 278 Summary | Train MSE (x10^-2): 72.9862 | Val MSE (x10^-2): 41.0374 | Time: 34.89s
2025-07-18 05:45:23,920 - logger.py:50 - Epoch: [279][0/6]	Total Loss: 0.73458	Main MSE (x10^-2): 73.4581	LR: 1.66e-04	EMPP_Raw: 1.44352
2025-07-18 05:45:37,880 - logger.py:50 - Epoch: [279][5/6]	Total Loss: 0.73167	Main MSE (x10^-2): 73.1674	LR: 1.66e-04	EMPP_Raw: 1.43644
2025-07-18 05:45:37,924 - logger.py:50 - Epoch 279 Training Summary: Avg Total Loss: 0.73167, Avg Main MSE: 0.73167, Time: 16.99s
2025-07-18 05:45:55,838 - logger.py:50 - Epoch 279 Summary | Train MSE (x10^-2): 73.1674 | Val MSE (x10^-2): 40.7463 | Time: 34.90s
2025-07-18 05:45:58,828 - logger.py:50 - Epoch: [280][0/6]	Total Loss: 0.72947	Main MSE (x10^-2): 72.9465	LR: 1.64e-04	EMPP_Raw: 1.43269
2025-07-18 05:46:12,729 - logger.py:50 - Epoch: [280][5/6]	Total Loss: 0.73592	Main MSE (x10^-2): 73.5917	LR: 1.64e-04	EMPP_Raw: 1.44543
2025-07-18 05:46:12,776 - logger.py:50 - Epoch 280 Training Summary: Avg Total Loss: 0.73592, Avg Main MSE: 0.73592, Time: 16.93s
2025-07-18 05:46:30,735 - logger.py:50 - Epoch 280 Summary | Train MSE (x10^-2): 73.5917 | Val MSE (x10^-2): 40.4990 | Time: 34.89s
2025-07-18 05:46:33,772 - logger.py:50 - Epoch: [281][0/6]	Total Loss: 0.72409	Main MSE (x10^-2): 72.4090	LR: 1.63e-04	EMPP_Raw: 1.42272
2025-07-18 05:46:47,538 - logger.py:50 - Epoch: [281][5/6]	Total Loss: 0.73146	Main MSE (x10^-2): 73.1461	LR: 1.63e-04	EMPP_Raw: 1.43621
2025-07-18 05:46:47,588 - logger.py:50 - Epoch 281 Training Summary: Avg Total Loss: 0.73146, Avg Main MSE: 0.73146, Time: 16.84s
2025-07-18 05:47:05,675 - logger.py:50 - Epoch 281 Summary | Train MSE (x10^-2): 73.1461 | Val MSE (x10^-2): 39.8695 | Time: 34.93s
2025-07-18 05:47:08,724 - logger.py:50 - Epoch: [282][0/6]	Total Loss: 0.72194	Main MSE (x10^-2): 72.1935	LR: 1.62e-04	EMPP_Raw: 1.41811
2025-07-18 05:47:22,532 - logger.py:50 - Epoch: [282][5/6]	Total Loss: 0.73327	Main MSE (x10^-2): 73.3267	LR: 1.62e-04	EMPP_Raw: 1.43997
2025-07-18 05:47:22,575 - logger.py:50 - Epoch 282 Training Summary: Avg Total Loss: 0.73327, Avg Main MSE: 0.73327, Time: 16.89s
2025-07-18 05:47:40,481 - logger.py:50 - Epoch 282 Summary | Train MSE (x10^-2): 73.3267 | Val MSE (x10^-2): 41.3838 | Time: 34.80s
2025-07-18 05:47:43,628 - logger.py:50 - Epoch: [283][0/6]	Total Loss: 0.73984	Main MSE (x10^-2): 73.9839	LR: 1.61e-04	EMPP_Raw: 1.45352
2025-07-18 05:47:57,408 - logger.py:50 - Epoch: [283][5/6]	Total Loss: 0.73038	Main MSE (x10^-2): 73.0381	LR: 1.61e-04	EMPP_Raw: 1.43408
2025-07-18 05:47:57,447 - logger.py:50 - Epoch 283 Training Summary: Avg Total Loss: 0.73038, Avg Main MSE: 0.73038, Time: 16.96s
2025-07-18 05:48:15,408 - logger.py:50 - Epoch 283 Summary | Train MSE (x10^-2): 73.0381 | Val MSE (x10^-2): 41.7676 | Time: 34.92s
2025-07-18 05:48:18,565 - logger.py:50 - Epoch: [284][0/6]	Total Loss: 0.74136	Main MSE (x10^-2): 74.1359	LR: 1.59e-04	EMPP_Raw: 1.45524
2025-07-18 05:48:32,327 - logger.py:50 - Epoch: [284][5/6]	Total Loss: 0.73884	Main MSE (x10^-2): 73.8844	LR: 1.59e-04	EMPP_Raw: 1.45148
2025-07-18 05:48:32,370 - logger.py:50 - Epoch 284 Training Summary: Avg Total Loss: 0.73884, Avg Main MSE: 0.73884, Time: 16.95s
2025-07-18 05:48:50,262 - logger.py:50 - Epoch 284 Summary | Train MSE (x10^-2): 73.8844 | Val MSE (x10^-2): 41.1346 | Time: 34.85s
2025-07-18 05:48:53,437 - logger.py:50 - Epoch: [285][0/6]	Total Loss: 0.73941	Main MSE (x10^-2): 73.9407	LR: 1.58e-04	EMPP_Raw: 1.45370
2025-07-18 05:49:07,199 - logger.py:50 - Epoch: [285][5/6]	Total Loss: 0.72742	Main MSE (x10^-2): 72.7418	LR: 1.58e-04	EMPP_Raw: 1.42981
2025-07-18 05:49:07,246 - logger.py:50 - Epoch 285 Training Summary: Avg Total Loss: 0.72742, Avg Main MSE: 0.72742, Time: 16.97s
2025-07-18 05:49:25,108 - logger.py:50 - Epoch 285 Summary | Train MSE (x10^-2): 72.7418 | Val MSE (x10^-2): 40.5549 | Time: 34.84s
2025-07-18 05:49:28,102 - logger.py:50 - Epoch: [286][0/6]	Total Loss: 0.73703	Main MSE (x10^-2): 73.7029	LR: 1.57e-04	EMPP_Raw: 1.45106
2025-07-18 05:49:42,103 - logger.py:50 - Epoch: [286][5/6]	Total Loss: 0.74915	Main MSE (x10^-2): 74.9153	LR: 1.57e-04	EMPP_Raw: 1.47406
2025-07-18 05:49:42,145 - logger.py:50 - Epoch 286 Training Summary: Avg Total Loss: 0.74915, Avg Main MSE: 0.74915, Time: 17.03s
2025-07-18 05:49:59,996 - logger.py:50 - Epoch 286 Summary | Train MSE (x10^-2): 74.9153 | Val MSE (x10^-2): 40.4099 | Time: 34.88s
2025-07-18 05:50:03,034 - logger.py:50 - Epoch: [287][0/6]	Total Loss: 0.76791	Main MSE (x10^-2): 76.7909	LR: 1.56e-04	EMPP_Raw: 1.50739
2025-07-18 05:50:16,798 - logger.py:50 - Epoch: [287][5/6]	Total Loss: 0.73624	Main MSE (x10^-2): 73.6243	LR: 1.56e-04	EMPP_Raw: 1.44576
2025-07-18 05:50:16,843 - logger.py:50 - Epoch 287 Training Summary: Avg Total Loss: 0.73624, Avg Main MSE: 0.73624, Time: 16.84s
2025-07-18 05:50:34,960 - logger.py:50 - Epoch 287 Summary | Train MSE (x10^-2): 73.6243 | Val MSE (x10^-2): 40.0847 | Time: 34.96s
2025-07-18 05:50:37,942 - logger.py:50 - Epoch: [288][0/6]	Total Loss: 0.71788	Main MSE (x10^-2): 71.7881	LR: 1.55e-04	EMPP_Raw: 1.41058
2025-07-18 05:50:51,701 - logger.py:50 - Epoch: [288][5/6]	Total Loss: 0.73504	Main MSE (x10^-2): 73.5037	LR: 1.55e-04	EMPP_Raw: 1.44501
2025-07-18 05:50:51,745 - logger.py:50 - Epoch 288 Training Summary: Avg Total Loss: 0.73504, Avg Main MSE: 0.73504, Time: 16.78s
2025-07-18 05:51:09,772 - logger.py:50 - Epoch 288 Summary | Train MSE (x10^-2): 73.5037 | Val MSE (x10^-2): 40.3126 | Time: 34.81s
2025-07-18 05:51:12,784 - logger.py:50 - Epoch: [289][0/6]	Total Loss: 0.74133	Main MSE (x10^-2): 74.1327	LR: 1.53e-04	EMPP_Raw: 1.45570
2025-07-18 05:51:26,556 - logger.py:50 - Epoch: [289][5/6]	Total Loss: 0.73241	Main MSE (x10^-2): 73.2408	LR: 1.53e-04	EMPP_Raw: 1.43909
2025-07-18 05:51:26,600 - logger.py:50 - Epoch 289 Training Summary: Avg Total Loss: 0.73241, Avg Main MSE: 0.73241, Time: 16.82s
2025-07-18 05:51:44,570 - logger.py:50 - Epoch 289 Summary | Train MSE (x10^-2): 73.2408 | Val MSE (x10^-2): 41.0103 | Time: 34.79s
2025-07-18 05:51:47,725 - logger.py:50 - Epoch: [290][0/6]	Total Loss: 0.72767	Main MSE (x10^-2): 72.7667	LR: 1.52e-04	EMPP_Raw: 1.43094
2025-07-18 05:52:01,537 - logger.py:50 - Epoch: [290][5/6]	Total Loss: 0.72956	Main MSE (x10^-2): 72.9561	LR: 1.52e-04	EMPP_Raw: 1.43378
2025-07-18 05:52:01,581 - logger.py:50 - Epoch 290 Training Summary: Avg Total Loss: 0.72956, Avg Main MSE: 0.72956, Time: 17.00s
2025-07-18 05:52:19,588 - logger.py:50 - Epoch 290 Summary | Train MSE (x10^-2): 72.9561 | Val MSE (x10^-2): 41.6262 | Time: 35.01s
2025-07-18 05:52:22,752 - logger.py:50 - Epoch: [291][0/6]	Total Loss: 0.74831	Main MSE (x10^-2): 74.8313	LR: 1.51e-04	EMPP_Raw: 1.47428
2025-07-18 05:52:36,499 - logger.py:50 - Epoch: [291][5/6]	Total Loss: 0.74089	Main MSE (x10^-2): 74.0890	LR: 1.51e-04	EMPP_Raw: 1.45666
2025-07-18 05:52:36,544 - logger.py:50 - Epoch 291 Training Summary: Avg Total Loss: 0.74089, Avg Main MSE: 0.74089, Time: 16.95s
2025-07-18 05:52:54,445 - logger.py:50 - Epoch 291 Summary | Train MSE (x10^-2): 74.0890 | Val MSE (x10^-2): 41.5533 | Time: 34.85s
2025-07-18 05:52:57,457 - logger.py:50 - Epoch: [292][0/6]	Total Loss: 0.73218	Main MSE (x10^-2): 73.2179	LR: 1.50e-04	EMPP_Raw: 1.44040
2025-07-18 05:53:11,493 - logger.py:50 - Epoch: [292][5/6]	Total Loss: 0.73555	Main MSE (x10^-2): 73.5551	LR: 1.50e-04	EMPP_Raw: 1.44728
2025-07-18 05:53:11,536 - logger.py:50 - Epoch 292 Training Summary: Avg Total Loss: 0.73555, Avg Main MSE: 0.73555, Time: 17.08s
2025-07-18 05:53:29,432 - logger.py:50 - Epoch 292 Summary | Train MSE (x10^-2): 73.5551 | Val MSE (x10^-2): 40.7928 | Time: 34.98s
2025-07-18 05:53:32,440 - logger.py:50 - Epoch: [293][0/6]	Total Loss: 0.73574	Main MSE (x10^-2): 73.5740	LR: 1.48e-04	EMPP_Raw: 1.44623
2025-07-18 05:53:46,446 - logger.py:50 - Epoch: [293][5/6]	Total Loss: 0.72894	Main MSE (x10^-2): 72.8941	LR: 1.48e-04	EMPP_Raw: 1.43285
2025-07-18 05:53:46,487 - logger.py:50 - Epoch 293 Training Summary: Avg Total Loss: 0.72894, Avg Main MSE: 0.72894, Time: 17.05s
2025-07-18 05:54:04,453 - logger.py:50 - Epoch 293 Summary | Train MSE (x10^-2): 72.8941 | Val MSE (x10^-2): 41.7141 | Time: 35.02s
2025-07-18 05:54:07,499 - logger.py:50 - Epoch: [294][0/6]	Total Loss: 0.77439	Main MSE (x10^-2): 77.4388	LR: 1.47e-04	EMPP_Raw: 1.52796
2025-07-18 05:54:21,352 - logger.py:50 - Epoch: [294][5/6]	Total Loss: 0.73619	Main MSE (x10^-2): 73.6194	LR: 1.47e-04	EMPP_Raw: 1.44870
2025-07-18 05:54:21,397 - logger.py:50 - Epoch 294 Training Summary: Avg Total Loss: 0.73619, Avg Main MSE: 0.73619, Time: 16.93s
2025-07-18 05:54:39,561 - logger.py:50 - Epoch 294 Summary | Train MSE (x10^-2): 73.6194 | Val MSE (x10^-2): 40.2803 | Time: 35.10s
2025-07-18 05:54:42,558 - logger.py:50 - Epoch: [295][0/6]	Total Loss: 0.73047	Main MSE (x10^-2): 73.0473	LR: 1.46e-04	EMPP_Raw: 1.43637
2025-07-18 05:54:56,311 - logger.py:50 - Epoch: [295][5/6]	Total Loss: 0.72997	Main MSE (x10^-2): 72.9970	LR: 1.46e-04	EMPP_Raw: 1.43572
2025-07-18 05:54:56,352 - logger.py:50 - Epoch 295 Training Summary: Avg Total Loss: 0.72997, Avg Main MSE: 0.72997, Time: 16.78s
2025-07-18 05:55:14,313 - logger.py:50 - Epoch 295 Summary | Train MSE (x10^-2): 72.9970 | Val MSE (x10^-2): 40.4591 | Time: 34.75s
2025-07-18 05:55:17,475 - logger.py:50 - Epoch: [296][0/6]	Total Loss: 0.73273	Main MSE (x10^-2): 73.2726	LR: 1.45e-04	EMPP_Raw: 1.44255
2025-07-18 05:55:31,254 - logger.py:50 - Epoch: [296][5/6]	Total Loss: 0.73869	Main MSE (x10^-2): 73.8695	LR: 1.45e-04	EMPP_Raw: 1.45261
2025-07-18 05:55:31,299 - logger.py:50 - Epoch 296 Training Summary: Avg Total Loss: 0.73869, Avg Main MSE: 0.73869, Time: 16.98s
2025-07-18 05:55:49,199 - logger.py:50 - Epoch 296 Summary | Train MSE (x10^-2): 73.8695 | Val MSE (x10^-2): 41.5689 | Time: 34.88s
2025-07-18 05:55:52,348 - logger.py:50 - Epoch: [297][0/6]	Total Loss: 0.72980	Main MSE (x10^-2): 72.9805	LR: 1.44e-04	EMPP_Raw: 1.43656
2025-07-18 05:56:06,122 - logger.py:50 - Epoch: [297][5/6]	Total Loss: 0.72341	Main MSE (x10^-2): 72.3413	LR: 1.44e-04	EMPP_Raw: 1.42310
2025-07-18 05:56:06,168 - logger.py:50 - Epoch 297 Training Summary: Avg Total Loss: 0.72341, Avg Main MSE: 0.72341, Time: 16.96s
2025-07-18 05:56:24,039 - logger.py:50 - Epoch 297 Summary | Train MSE (x10^-2): 72.3413 | Val MSE (x10^-2): 40.7173 | Time: 34.83s
2025-07-18 05:56:27,205 - logger.py:50 - Epoch: [298][0/6]	Total Loss: 0.72544	Main MSE (x10^-2): 72.5444	LR: 1.42e-04	EMPP_Raw: 1.42627
2025-07-18 05:56:40,991 - logger.py:50 - Epoch: [298][5/6]	Total Loss: 0.73399	Main MSE (x10^-2): 73.3995	LR: 1.42e-04	EMPP_Raw: 1.44356
2025-07-18 05:56:41,032 - logger.py:50 - Epoch 298 Training Summary: Avg Total Loss: 0.73399, Avg Main MSE: 0.73399, Time: 16.98s
2025-07-18 05:56:58,854 - logger.py:50 - Epoch 298 Summary | Train MSE (x10^-2): 73.3995 | Val MSE (x10^-2): 39.6683 | Time: 34.81s
2025-07-18 05:57:01,841 - logger.py:50 - Epoch: [299][0/6]	Total Loss: 0.72442	Main MSE (x10^-2): 72.4420	LR: 1.41e-04	EMPP_Raw: 1.42555
2025-07-18 05:57:15,769 - logger.py:50 - Epoch: [299][5/6]	Total Loss: 0.72821	Main MSE (x10^-2): 72.8209	LR: 1.41e-04	EMPP_Raw: 1.43127
2025-07-18 05:57:15,815 - logger.py:50 - Epoch 299 Training Summary: Avg Total Loss: 0.72821, Avg Main MSE: 0.72821, Time: 16.95s
2025-07-18 05:57:33,644 - logger.py:50 - Epoch 299 Summary | Train MSE (x10^-2): 72.8209 | Val MSE (x10^-2): 41.6753 | Time: 34.78s
2025-07-18 05:57:36,638 - logger.py:50 - Epoch: [300][0/6]	Total Loss: 0.71101	Main MSE (x10^-2): 71.1013	LR: 1.40e-04	EMPP_Raw: 1.39589
2025-07-18 05:57:50,442 - logger.py:50 - Epoch: [300][5/6]	Total Loss: 0.72653	Main MSE (x10^-2): 72.6531	LR: 1.40e-04	EMPP_Raw: 1.42921
2025-07-18 05:57:50,482 - logger.py:50 - Epoch 300 Training Summary: Avg Total Loss: 0.72653, Avg Main MSE: 0.72653, Time: 16.83s
2025-07-18 05:58:08,464 - logger.py:50 - Epoch 300 Summary | Train MSE (x10^-2): 72.6531 | Val MSE (x10^-2): 40.1978 | Time: 34.81s
2025-07-18 05:58:11,467 - logger.py:50 - Epoch: [301][0/6]	Total Loss: 0.73156	Main MSE (x10^-2): 73.1562	LR: 1.39e-04	EMPP_Raw: 1.43799
2025-07-18 05:58:25,201 - logger.py:50 - Epoch: [301][5/6]	Total Loss: 0.72927	Main MSE (x10^-2): 72.9266	LR: 1.39e-04	EMPP_Raw: 1.43413
2025-07-18 05:58:25,246 - logger.py:50 - Epoch 301 Training Summary: Avg Total Loss: 0.72927, Avg Main MSE: 0.72927, Time: 16.77s
2025-07-18 05:58:43,415 - logger.py:50 - Epoch 301 Summary | Train MSE (x10^-2): 72.9266 | Val MSE (x10^-2): 39.8748 | Time: 34.94s
2025-07-18 05:58:46,456 - logger.py:50 - Epoch: [302][0/6]	Total Loss: 0.71913	Main MSE (x10^-2): 71.9130	LR: 1.38e-04	EMPP_Raw: 1.41323
2025-07-18 05:59:00,245 - logger.py:50 - Epoch: [302][5/6]	Total Loss: 0.72712	Main MSE (x10^-2): 72.7120	LR: 1.38e-04	EMPP_Raw: 1.43108
2025-07-18 05:59:00,289 - logger.py:50 - Epoch 302 Training Summary: Avg Total Loss: 0.72712, Avg Main MSE: 0.72712, Time: 16.87s
2025-07-18 05:59:18,171 - logger.py:50 - Epoch 302 Summary | Train MSE (x10^-2): 72.7120 | Val MSE (x10^-2): 40.4287 | Time: 34.75s
2025-07-18 05:59:21,345 - logger.py:50 - Epoch: [303][0/6]	Total Loss: 0.76172	Main MSE (x10^-2): 76.1716	LR: 1.36e-04	EMPP_Raw: 1.49742
2025-07-18 05:59:35,147 - logger.py:50 - Epoch: [303][5/6]	Total Loss: 0.73599	Main MSE (x10^-2): 73.5986	LR: 1.36e-04	EMPP_Raw: 1.44835
2025-07-18 05:59:35,188 - logger.py:50 - Epoch 303 Training Summary: Avg Total Loss: 0.73599, Avg Main MSE: 0.73599, Time: 17.01s
2025-07-18 05:59:53,091 - logger.py:50 - Epoch 303 Summary | Train MSE (x10^-2): 73.5986 | Val MSE (x10^-2): 41.6788 | Time: 34.91s
2025-07-18 05:59:56,256 - logger.py:50 - Epoch: [304][0/6]	Total Loss: 0.72018	Main MSE (x10^-2): 72.0185	LR: 1.35e-04	EMPP_Raw: 1.41502
2025-07-18 06:00:10,034 - logger.py:50 - Epoch: [304][5/6]	Total Loss: 0.73551	Main MSE (x10^-2): 73.5509	LR: 1.35e-04	EMPP_Raw: 1.44592
2025-07-18 06:00:10,073 - logger.py:50 - Epoch 304 Training Summary: Avg Total Loss: 0.73551, Avg Main MSE: 0.73551, Time: 16.97s
2025-07-18 06:00:27,907 - logger.py:50 - Epoch 304 Summary | Train MSE (x10^-2): 73.5509 | Val MSE (x10^-2): 41.5038 | Time: 34.81s
2025-07-18 06:00:30,921 - logger.py:50 - Epoch: [305][0/6]	Total Loss: 0.72065	Main MSE (x10^-2): 72.0646	LR: 1.34e-04	EMPP_Raw: 1.41981
2025-07-18 06:00:44,880 - logger.py:50 - Epoch: [305][5/6]	Total Loss: 0.72688	Main MSE (x10^-2): 72.6876	LR: 1.34e-04	EMPP_Raw: 1.43066
2025-07-18 06:00:44,921 - logger.py:50 - Epoch 305 Training Summary: Avg Total Loss: 0.72688, Avg Main MSE: 0.72688, Time: 17.01s
2025-07-18 06:01:02,764 - logger.py:50 - Epoch 305 Summary | Train MSE (x10^-2): 72.6876 | Val MSE (x10^-2): 41.1870 | Time: 34.86s
2025-07-18 06:01:05,764 - logger.py:50 - Epoch: [306][0/6]	Total Loss: 0.73926	Main MSE (x10^-2): 73.9258	LR: 1.33e-04	EMPP_Raw: 1.45495
2025-07-18 06:01:19,704 - logger.py:50 - Epoch: [306][5/6]	Total Loss: 0.73142	Main MSE (x10^-2): 73.1423	LR: 1.33e-04	EMPP_Raw: 1.43919
2025-07-18 06:01:19,750 - logger.py:50 - Epoch 306 Training Summary: Avg Total Loss: 0.73142, Avg Main MSE: 0.73142, Time: 16.98s
2025-07-18 06:01:37,773 - logger.py:50 - Epoch 306 Summary | Train MSE (x10^-2): 73.1423 | Val MSE (x10^-2): 40.5182 | Time: 35.00s
2025-07-18 06:01:40,798 - logger.py:50 - Epoch: [307][0/6]	Total Loss: 0.72153	Main MSE (x10^-2): 72.1528	LR: 1.32e-04	EMPP_Raw: 1.41778
2025-07-18 06:01:54,578 - logger.py:50 - Epoch: [307][5/6]	Total Loss: 0.73182	Main MSE (x10^-2): 73.1823	LR: 1.32e-04	EMPP_Raw: 1.44023
2025-07-18 06:01:54,619 - logger.py:50 - Epoch 307 Training Summary: Avg Total Loss: 0.73182, Avg Main MSE: 0.73182, Time: 16.84s
2025-07-18 06:02:12,473 - logger.py:50 - Epoch 307 Summary | Train MSE (x10^-2): 73.1823 | Val MSE (x10^-2): 40.5950 | Time: 34.69s
2025-07-18 06:02:15,602 - logger.py:50 - Epoch: [308][0/6]	Total Loss: 0.72109	Main MSE (x10^-2): 72.1092	LR: 1.31e-04	EMPP_Raw: 1.42042
2025-07-18 06:02:29,350 - logger.py:50 - Epoch: [308][5/6]	Total Loss: 0.72608	Main MSE (x10^-2): 72.6082	LR: 1.31e-04	EMPP_Raw: 1.42893
2025-07-18 06:02:29,391 - logger.py:50 - Epoch 308 Training Summary: Avg Total Loss: 0.72608, Avg Main MSE: 0.72608, Time: 16.91s
2025-07-18 06:02:47,372 - logger.py:50 - Epoch 308 Summary | Train MSE (x10^-2): 72.6082 | Val MSE (x10^-2): 42.0224 | Time: 34.89s
2025-07-18 06:02:50,561 - logger.py:50 - Epoch: [309][0/6]	Total Loss: 0.73737	Main MSE (x10^-2): 73.7369	LR: 1.29e-04	EMPP_Raw: 1.45220
2025-07-18 06:03:04,286 - logger.py:50 - Epoch: [309][5/6]	Total Loss: 0.72648	Main MSE (x10^-2): 72.6480	LR: 1.29e-04	EMPP_Raw: 1.42974
2025-07-18 06:03:04,336 - logger.py:50 - Epoch 309 Training Summary: Avg Total Loss: 0.72648, Avg Main MSE: 0.72648, Time: 16.96s
2025-07-18 06:03:22,234 - logger.py:50 - Epoch 309 Summary | Train MSE (x10^-2): 72.6480 | Val MSE (x10^-2): 41.9189 | Time: 34.86s
2025-07-18 06:03:25,385 - logger.py:50 - Epoch: [310][0/6]	Total Loss: 0.73634	Main MSE (x10^-2): 73.6340	LR: 1.28e-04	EMPP_Raw: 1.44694
2025-07-18 06:03:39,143 - logger.py:50 - Epoch: [310][5/6]	Total Loss: 0.73081	Main MSE (x10^-2): 73.0806	LR: 1.28e-04	EMPP_Raw: 1.43799
2025-07-18 06:03:39,184 - logger.py:50 - Epoch 310 Training Summary: Avg Total Loss: 0.73081, Avg Main MSE: 0.73081, Time: 16.94s
2025-07-18 06:03:57,114 - logger.py:50 - Epoch 310 Summary | Train MSE (x10^-2): 73.0806 | Val MSE (x10^-2): 41.0341 | Time: 34.87s
2025-07-18 06:04:00,137 - logger.py:50 - Epoch: [311][0/6]	Total Loss: 0.68990	Main MSE (x10^-2): 68.9903	LR: 1.27e-04	EMPP_Raw: 1.35757
2025-07-18 06:04:14,106 - logger.py:50 - Epoch: [311][5/6]	Total Loss: 0.72237	Main MSE (x10^-2): 72.2366	LR: 1.27e-04	EMPP_Raw: 1.42144
2025-07-18 06:04:14,151 - logger.py:50 - Epoch 311 Training Summary: Avg Total Loss: 0.72237, Avg Main MSE: 0.72237, Time: 17.03s
2025-07-18 06:04:32,057 - logger.py:50 - Epoch 311 Summary | Train MSE (x10^-2): 72.2366 | Val MSE (x10^-2): 40.5708 | Time: 34.94s
2025-07-18 06:04:35,057 - logger.py:50 - Epoch: [312][0/6]	Total Loss: 0.72021	Main MSE (x10^-2): 72.0210	LR: 1.26e-04	EMPP_Raw: 1.42058
2025-07-18 06:04:49,016 - logger.py:50 - Epoch: [312][5/6]	Total Loss: 0.73028	Main MSE (x10^-2): 73.0285	LR: 1.26e-04	EMPP_Raw: 1.43850
2025-07-18 06:04:49,059 - logger.py:50 - Epoch 312 Training Summary: Avg Total Loss: 0.73028, Avg Main MSE: 0.73028, Time: 16.99s
2025-07-18 06:05:06,974 - logger.py:50 - Epoch 312 Summary | Train MSE (x10^-2): 73.0285 | Val MSE (x10^-2): 41.1314 | Time: 34.91s
2025-07-18 06:05:10,014 - logger.py:50 - Epoch: [313][0/6]	Total Loss: 0.70916	Main MSE (x10^-2): 70.9163	LR: 1.25e-04	EMPP_Raw: 1.39705
2025-07-18 06:05:23,816 - logger.py:50 - Epoch: [313][5/6]	Total Loss: 0.72086	Main MSE (x10^-2): 72.0862	LR: 1.25e-04	EMPP_Raw: 1.41789
2025-07-18 06:05:23,855 - logger.py:50 - Epoch 313 Training Summary: Avg Total Loss: 0.72086, Avg Main MSE: 0.72086, Time: 16.87s
2025-07-18 06:05:41,804 - logger.py:50 - Epoch 313 Summary | Train MSE (x10^-2): 72.0862 | Val MSE (x10^-2): 40.1034 | Time: 34.82s
2025-07-18 06:05:45,044 - logger.py:50 - Epoch: [314][0/6]	Total Loss: 0.71997	Main MSE (x10^-2): 71.9970	LR: 1.24e-04	EMPP_Raw: 1.41550
2025-07-18 06:05:58,903 - logger.py:50 - Epoch: [314][5/6]	Total Loss: 0.72972	Main MSE (x10^-2): 72.9718	LR: 1.24e-04	EMPP_Raw: 1.43600
2025-07-18 06:05:58,945 - logger.py:50 - Epoch 314 Training Summary: Avg Total Loss: 0.72972, Avg Main MSE: 0.72972, Time: 17.13s
2025-07-18 06:06:17,020 - logger.py:50 - Epoch 314 Summary | Train MSE (x10^-2): 72.9718 | Val MSE (x10^-2): 40.1236 | Time: 35.21s
2025-07-18 06:06:20,206 - logger.py:50 - Epoch: [315][0/6]	Total Loss: 0.71291	Main MSE (x10^-2): 71.2908	LR: 1.22e-04	EMPP_Raw: 1.40334
2025-07-18 06:06:33,958 - logger.py:50 - Epoch: [315][5/6]	Total Loss: 0.72838	Main MSE (x10^-2): 72.8384	LR: 1.22e-04	EMPP_Raw: 1.43366
2025-07-18 06:06:34,002 - logger.py:50 - Epoch 315 Training Summary: Avg Total Loss: 0.72838, Avg Main MSE: 0.72838, Time: 16.97s
2025-07-18 06:06:51,870 - logger.py:50 - Epoch 315 Summary | Train MSE (x10^-2): 72.8384 | Val MSE (x10^-2): 41.8741 | Time: 34.84s
2025-07-18 06:06:55,028 - logger.py:50 - Epoch: [316][0/6]	Total Loss: 0.72305	Main MSE (x10^-2): 72.3054	LR: 1.21e-04	EMPP_Raw: 1.42193
2025-07-18 06:07:08,776 - logger.py:50 - Epoch: [316][5/6]	Total Loss: 0.73110	Main MSE (x10^-2): 73.1095	LR: 1.21e-04	EMPP_Raw: 1.43853
2025-07-18 06:07:08,823 - logger.py:50 - Epoch 316 Training Summary: Avg Total Loss: 0.73110, Avg Main MSE: 0.73110, Time: 16.94s
2025-07-18 06:07:26,808 - logger.py:50 - Epoch 316 Summary | Train MSE (x10^-2): 73.1095 | Val MSE (x10^-2): 40.8660 | Time: 34.93s
2025-07-18 06:07:29,844 - logger.py:50 - Epoch: [317][0/6]	Total Loss: 0.71537	Main MSE (x10^-2): 71.5366	LR: 1.20e-04	EMPP_Raw: 1.40747
2025-07-18 06:07:43,781 - logger.py:50 - Epoch: [317][5/6]	Total Loss: 0.72170	Main MSE (x10^-2): 72.1698	LR: 1.20e-04	EMPP_Raw: 1.42199
2025-07-18 06:07:43,827 - logger.py:50 - Epoch 317 Training Summary: Avg Total Loss: 0.72170, Avg Main MSE: 0.72170, Time: 17.01s
2025-07-18 06:08:01,718 - logger.py:50 - Epoch 317 Summary | Train MSE (x10^-2): 72.1698 | Val MSE (x10^-2): 40.2658 | Time: 34.90s
2025-07-18 06:08:04,757 - logger.py:50 - Epoch: [318][0/6]	Total Loss: 0.73312	Main MSE (x10^-2): 73.3124	LR: 1.19e-04	EMPP_Raw: 1.44768
2025-07-18 06:08:18,551 - logger.py:50 - Epoch: [318][5/6]	Total Loss: 0.73012	Main MSE (x10^-2): 73.0125	LR: 1.19e-04	EMPP_Raw: 1.43899
2025-07-18 06:08:18,592 - logger.py:50 - Epoch 318 Training Summary: Avg Total Loss: 0.73012, Avg Main MSE: 0.73012, Time: 16.86s
2025-07-18 06:08:36,622 - logger.py:50 - Epoch 318 Summary | Train MSE (x10^-2): 73.0125 | Val MSE (x10^-2): 39.8807 | Time: 34.90s
2025-07-18 06:08:39,682 - logger.py:50 - Epoch: [319][0/6]	Total Loss: 0.71965	Main MSE (x10^-2): 71.9653	LR: 1.18e-04	EMPP_Raw: 1.41699
2025-07-18 06:08:53,519 - logger.py:50 - Epoch: [319][5/6]	Total Loss: 0.73701	Main MSE (x10^-2): 73.7007	LR: 1.18e-04	EMPP_Raw: 1.45095
2025-07-18 06:08:53,564 - logger.py:50 - Epoch 319 Training Summary: Avg Total Loss: 0.73701, Avg Main MSE: 0.73701, Time: 16.93s
2025-07-18 06:09:11,387 - logger.py:50 - Epoch 319 Summary | Train MSE (x10^-2): 73.7007 | Val MSE (x10^-2): 40.7201 | Time: 34.76s
2025-07-18 06:09:14,554 - logger.py:50 - Epoch: [320][0/6]	Total Loss: 0.73160	Main MSE (x10^-2): 73.1597	LR: 1.17e-04	EMPP_Raw: 1.43856
2025-07-18 06:09:28,290 - logger.py:50 - Epoch: [320][5/6]	Total Loss: 0.72994	Main MSE (x10^-2): 72.9941	LR: 1.17e-04	EMPP_Raw: 1.43821
2025-07-18 06:09:28,332 - logger.py:50 - Epoch 320 Training Summary: Avg Total Loss: 0.72994, Avg Main MSE: 0.72994, Time: 16.94s
2025-07-18 06:09:46,349 - logger.py:50 - Epoch 320 Summary | Train MSE (x10^-2): 72.9941 | Val MSE (x10^-2): 40.4436 | Time: 34.96s
2025-07-18 06:09:49,326 - logger.py:50 - Epoch: [321][0/6]	Total Loss: 0.75018	Main MSE (x10^-2): 75.0179	LR: 1.16e-04	EMPP_Raw: 1.47751
2025-07-18 06:10:03,234 - logger.py:50 - Epoch: [321][5/6]	Total Loss: 0.73002	Main MSE (x10^-2): 73.0018	LR: 1.16e-04	EMPP_Raw: 1.43709
2025-07-18 06:10:03,279 - logger.py:50 - Epoch 321 Training Summary: Avg Total Loss: 0.73002, Avg Main MSE: 0.73002, Time: 16.92s
2025-07-18 06:10:21,152 - logger.py:50 - Epoch 321 Summary | Train MSE (x10^-2): 73.0018 | Val MSE (x10^-2): 40.1782 | Time: 34.80s
2025-07-18 06:10:24,141 - logger.py:50 - Epoch: [322][0/6]	Total Loss: 0.73170	Main MSE (x10^-2): 73.1699	LR: 1.14e-04	EMPP_Raw: 1.44083
2025-07-18 06:10:38,115 - logger.py:50 - Epoch: [322][5/6]	Total Loss: 0.72422	Main MSE (x10^-2): 72.4216	LR: 1.14e-04	EMPP_Raw: 1.42538
2025-07-18 06:10:38,156 - logger.py:50 - Epoch 322 Training Summary: Avg Total Loss: 0.72422, Avg Main MSE: 0.72422, Time: 16.99s
2025-07-18 06:10:56,110 - logger.py:50 - Epoch 322 Summary | Train MSE (x10^-2): 72.4216 | Val MSE (x10^-2): 41.0690 | Time: 34.95s
2025-07-18 06:10:59,110 - logger.py:50 - Epoch: [323][0/6]	Total Loss: 0.72226	Main MSE (x10^-2): 72.2260	LR: 1.13e-04	EMPP_Raw: 1.42541
2025-07-18 06:11:12,935 - logger.py:50 - Epoch: [323][5/6]	Total Loss: 0.73796	Main MSE (x10^-2): 73.7962	LR: 1.13e-04	EMPP_Raw: 1.45373
2025-07-18 06:11:12,977 - logger.py:50 - Epoch 323 Training Summary: Avg Total Loss: 0.73796, Avg Main MSE: 0.73796, Time: 16.86s
2025-07-18 06:11:31,028 - logger.py:50 - Epoch 323 Summary | Train MSE (x10^-2): 73.7962 | Val MSE (x10^-2): 40.3462 | Time: 34.91s
2025-07-18 06:11:34,023 - logger.py:50 - Epoch: [324][0/6]	Total Loss: 0.74357	Main MSE (x10^-2): 74.3572	LR: 1.12e-04	EMPP_Raw: 1.46674
2025-07-18 06:11:47,817 - logger.py:50 - Epoch: [324][5/6]	Total Loss: 0.73362	Main MSE (x10^-2): 73.3618	LR: 1.12e-04	EMPP_Raw: 1.44389
2025-07-18 06:11:47,866 - logger.py:50 - Epoch 324 Training Summary: Avg Total Loss: 0.73362, Avg Main MSE: 0.73362, Time: 16.83s
2025-07-18 06:12:05,771 - logger.py:50 - Epoch 324 Summary | Train MSE (x10^-2): 73.3618 | Val MSE (x10^-2): 40.8140 | Time: 34.74s
2025-07-18 06:12:08,961 - logger.py:50 - Epoch: [325][0/6]	Total Loss: 0.70900	Main MSE (x10^-2): 70.8997	LR: 1.11e-04	EMPP_Raw: 1.39607
2025-07-18 06:12:22,789 - logger.py:50 - Epoch: [325][5/6]	Total Loss: 0.72784	Main MSE (x10^-2): 72.7836	LR: 1.11e-04	EMPP_Raw: 1.43368
2025-07-18 06:12:22,840 - logger.py:50 - Epoch 325 Training Summary: Avg Total Loss: 0.72784, Avg Main MSE: 0.72784, Time: 17.06s
2025-07-18 06:12:40,639 - logger.py:50 - Epoch 325 Summary | Train MSE (x10^-2): 72.7836 | Val MSE (x10^-2): 41.0150 | Time: 34.86s
2025-07-18 06:12:43,635 - logger.py:50 - Epoch: [326][0/6]	Total Loss: 0.71680	Main MSE (x10^-2): 71.6805	LR: 1.10e-04	EMPP_Raw: 1.41220
2025-07-18 06:12:57,595 - logger.py:50 - Epoch: [326][5/6]	Total Loss: 0.72657	Main MSE (x10^-2): 72.6573	LR: 1.10e-04	EMPP_Raw: 1.43074
2025-07-18 06:12:57,633 - logger.py:50 - Epoch 326 Training Summary: Avg Total Loss: 0.72657, Avg Main MSE: 0.72657, Time: 16.98s
2025-07-18 06:13:15,555 - logger.py:50 - Epoch 326 Summary | Train MSE (x10^-2): 72.6573 | Val MSE (x10^-2): 39.9911 | Time: 34.91s
2025-07-18 06:13:18,540 - logger.py:50 - Epoch: [327][0/6]	Total Loss: 0.75276	Main MSE (x10^-2): 75.2756	LR: 1.09e-04	EMPP_Raw: 1.48061
2025-07-18 06:13:32,493 - logger.py:50 - Epoch: [327][5/6]	Total Loss: 0.72204	Main MSE (x10^-2): 72.2037	LR: 1.09e-04	EMPP_Raw: 1.42133
2025-07-18 06:13:32,538 - logger.py:50 - Epoch 327 Training Summary: Avg Total Loss: 0.72204, Avg Main MSE: 0.72204, Time: 16.97s
2025-07-18 06:13:50,529 - logger.py:50 - Epoch 327 Summary | Train MSE (x10^-2): 72.2037 | Val MSE (x10^-2): 40.0639 | Time: 34.97s
2025-07-18 06:13:53,518 - logger.py:50 - Epoch: [328][0/6]	Total Loss: 0.74305	Main MSE (x10^-2): 74.3047	LR: 1.08e-04	EMPP_Raw: 1.46479
2025-07-18 06:14:07,279 - logger.py:50 - Epoch: [328][5/6]	Total Loss: 0.73382	Main MSE (x10^-2): 73.3823	LR: 1.08e-04	EMPP_Raw: 1.44608
2025-07-18 06:14:07,318 - logger.py:50 - Epoch 328 Training Summary: Avg Total Loss: 0.73382, Avg Main MSE: 0.73382, Time: 16.78s
2025-07-18 06:14:25,372 - logger.py:50 - Epoch 328 Summary | Train MSE (x10^-2): 73.3823 | Val MSE (x10^-2): 40.8618 | Time: 34.84s
2025-07-18 06:14:28,397 - logger.py:50 - Epoch: [329][0/6]	Total Loss: 0.73784	Main MSE (x10^-2): 73.7837	LR: 1.07e-04	EMPP_Raw: 1.45483
2025-07-18 06:14:42,267 - logger.py:50 - Epoch: [329][5/6]	Total Loss: 0.73032	Main MSE (x10^-2): 73.0321	LR: 1.07e-04	EMPP_Raw: 1.43899
2025-07-18 06:14:42,308 - logger.py:50 - Epoch 329 Training Summary: Avg Total Loss: 0.73032, Avg Main MSE: 0.73032, Time: 16.93s
2025-07-18 06:15:00,374 - logger.py:50 - Epoch 329 Summary | Train MSE (x10^-2): 73.0321 | Val MSE (x10^-2): 40.7735 | Time: 35.00s
2025-07-18 06:15:03,557 - logger.py:50 - Epoch: [330][0/6]	Total Loss: 0.71375	Main MSE (x10^-2): 71.3754	LR: 1.05e-04	EMPP_Raw: 1.40866
2025-07-18 06:15:17,380 - logger.py:50 - Epoch: [330][5/6]	Total Loss: 0.71958	Main MSE (x10^-2): 71.9582	LR: 1.05e-04	EMPP_Raw: 1.41790
2025-07-18 06:15:17,424 - logger.py:50 - Epoch 330 Training Summary: Avg Total Loss: 0.71958, Avg Main MSE: 0.71958, Time: 17.04s
2025-07-18 06:15:35,327 - logger.py:50 - Epoch 330 Summary | Train MSE (x10^-2): 71.9582 | Val MSE (x10^-2): 41.4690 | Time: 34.95s
2025-07-18 06:15:38,505 - logger.py:50 - Epoch: [331][0/6]	Total Loss: 0.72929	Main MSE (x10^-2): 72.9289	LR: 1.04e-04	EMPP_Raw: 1.43507
2025-07-18 06:15:52,306 - logger.py:50 - Epoch: [331][5/6]	Total Loss: 0.73022	Main MSE (x10^-2): 73.0219	LR: 1.04e-04	EMPP_Raw: 1.43922
2025-07-18 06:15:52,353 - logger.py:50 - Epoch 331 Training Summary: Avg Total Loss: 0.73022, Avg Main MSE: 0.73022, Time: 17.02s
2025-07-18 06:16:10,314 - logger.py:50 - Epoch 331 Summary | Train MSE (x10^-2): 73.0219 | Val MSE (x10^-2): 39.8219 | Time: 34.98s
2025-07-18 06:16:13,301 - logger.py:50 - Epoch: [332][0/6]	Total Loss: 0.72338	Main MSE (x10^-2): 72.3384	LR: 1.03e-04	EMPP_Raw: 1.42620
2025-07-18 06:16:27,218 - logger.py:50 - Epoch: [332][5/6]	Total Loss: 0.72691	Main MSE (x10^-2): 72.6912	LR: 1.03e-04	EMPP_Raw: 1.43317
2025-07-18 06:16:27,263 - logger.py:50 - Epoch 332 Training Summary: Avg Total Loss: 0.72691, Avg Main MSE: 0.72691, Time: 16.94s
2025-07-18 06:16:45,208 - logger.py:50 - Epoch 332 Summary | Train MSE (x10^-2): 72.6912 | Val MSE (x10^-2): 41.9905 | Time: 34.89s
2025-07-18 06:16:48,210 - logger.py:50 - Epoch: [333][0/6]	Total Loss: 0.75243	Main MSE (x10^-2): 75.2431	LR: 1.02e-04	EMPP_Raw: 1.48457
2025-07-18 06:17:02,172 - logger.py:50 - Epoch: [333][5/6]	Total Loss: 0.73344	Main MSE (x10^-2): 73.3437	LR: 1.02e-04	EMPP_Raw: 1.44659
2025-07-18 06:17:02,218 - logger.py:50 - Epoch 333 Training Summary: Avg Total Loss: 0.73344, Avg Main MSE: 0.73344, Time: 17.00s
2025-07-18 06:17:20,086 - logger.py:50 - Epoch 333 Summary | Train MSE (x10^-2): 73.3437 | Val MSE (x10^-2): 40.8010 | Time: 34.87s
2025-07-18 06:17:23,101 - logger.py:50 - Epoch: [334][0/6]	Total Loss: 0.73413	Main MSE (x10^-2): 73.4129	LR: 1.01e-04	EMPP_Raw: 1.44894
2025-07-18 06:17:36,918 - logger.py:50 - Epoch: [334][5/6]	Total Loss: 0.72295	Main MSE (x10^-2): 72.2953	LR: 1.01e-04	EMPP_Raw: 1.42541
2025-07-18 06:17:36,963 - logger.py:50 - Epoch 334 Training Summary: Avg Total Loss: 0.72295, Avg Main MSE: 0.72295, Time: 16.87s
2025-07-18 06:17:54,946 - logger.py:50 - Epoch 334 Summary | Train MSE (x10^-2): 72.2953 | Val MSE (x10^-2): 40.3177 | Time: 34.85s
2025-07-18 06:17:57,940 - logger.py:50 - Epoch: [335][0/6]	Total Loss: 0.70770	Main MSE (x10^-2): 70.7696	LR: 1.00e-04	EMPP_Raw: 1.39763
2025-07-18 06:18:11,721 - logger.py:50 - Epoch: [335][5/6]	Total Loss: 0.72504	Main MSE (x10^-2): 72.5042	LR: 1.00e-04	EMPP_Raw: 1.43032
2025-07-18 06:18:11,767 - logger.py:50 - Epoch 335 Training Summary: Avg Total Loss: 0.72504, Avg Main MSE: 0.72504, Time: 16.81s
2025-07-18 06:18:29,643 - logger.py:50 - Epoch 335 Summary | Train MSE (x10^-2): 72.5042 | Val MSE (x10^-2): 40.3345 | Time: 34.69s
2025-07-18 06:18:32,834 - logger.py:50 - Epoch: [336][0/6]	Total Loss: 0.73024	Main MSE (x10^-2): 73.0242	LR: 9.89e-05	EMPP_Raw: 1.44241
2025-07-18 06:18:46,599 - logger.py:50 - Epoch: [336][5/6]	Total Loss: 0.73266	Main MSE (x10^-2): 73.2665	LR: 9.89e-05	EMPP_Raw: 1.44563
2025-07-18 06:18:46,644 - logger.py:50 - Epoch 336 Training Summary: Avg Total Loss: 0.73266, Avg Main MSE: 0.73266, Time: 16.99s
2025-07-18 06:19:04,517 - logger.py:50 - Epoch 336 Summary | Train MSE (x10^-2): 73.2665 | Val MSE (x10^-2): 40.5555 | Time: 34.87s
2025-07-18 06:19:07,674 - logger.py:50 - Epoch: [337][0/6]	Total Loss: 0.73853	Main MSE (x10^-2): 73.8532	LR: 9.79e-05	EMPP_Raw: 1.45720
2025-07-18 06:19:21,524 - logger.py:50 - Epoch: [337][5/6]	Total Loss: 0.72012	Main MSE (x10^-2): 72.0119	LR: 9.79e-05	EMPP_Raw: 1.41842
2025-07-18 06:19:21,573 - logger.py:50 - Epoch 337 Training Summary: Avg Total Loss: 0.72012, Avg Main MSE: 0.72012, Time: 17.05s
2025-07-18 06:19:39,498 - logger.py:50 - Epoch 337 Summary | Train MSE (x10^-2): 72.0119 | Val MSE (x10^-2): 40.4270 | Time: 34.98s
2025-07-18 06:19:42,561 - logger.py:50 - Epoch: [338][0/6]	Total Loss: 0.72773	Main MSE (x10^-2): 72.7731	LR: 9.68e-05	EMPP_Raw: 1.43337
2025-07-18 06:19:56,569 - logger.py:50 - Epoch: [338][5/6]	Total Loss: 0.72013	Main MSE (x10^-2): 72.0130	LR: 9.68e-05	EMPP_Raw: 1.41880
2025-07-18 06:19:56,610 - logger.py:50 - Epoch 338 Training Summary: Avg Total Loss: 0.72013, Avg Main MSE: 0.72013, Time: 17.10s
2025-07-18 06:20:14,591 - logger.py:50 - Epoch 338 Summary | Train MSE (x10^-2): 72.0130 | Val MSE (x10^-2): 39.9643 | Time: 35.09s
2025-07-18 06:20:17,602 - logger.py:50 - Epoch: [339][0/6]	Total Loss: 0.75105	Main MSE (x10^-2): 75.1054	LR: 9.57e-05	EMPP_Raw: 1.48213
2025-07-18 06:20:31,599 - logger.py:50 - Epoch: [339][5/6]	Total Loss: 0.73356	Main MSE (x10^-2): 73.3559	LR: 9.57e-05	EMPP_Raw: 1.44695
2025-07-18 06:20:31,647 - logger.py:50 - Epoch 339 Training Summary: Avg Total Loss: 0.73356, Avg Main MSE: 0.73356, Time: 17.05s
2025-07-18 06:20:49,538 - logger.py:50 - Epoch 339 Summary | Train MSE (x10^-2): 73.3559 | Val MSE (x10^-2): 41.4920 | Time: 34.94s
2025-07-18 06:20:52,556 - logger.py:50 - Epoch: [340][0/6]	Total Loss: 0.73514	Main MSE (x10^-2): 73.5143	LR: 9.47e-05	EMPP_Raw: 1.45050
2025-07-18 06:21:06,382 - logger.py:50 - Epoch: [340][5/6]	Total Loss: 0.71177	Main MSE (x10^-2): 71.1767	LR: 9.47e-05	EMPP_Raw: 1.40258
2025-07-18 06:21:06,430 - logger.py:50 - Epoch 340 Training Summary: Avg Total Loss: 0.71177, Avg Main MSE: 0.71177, Time: 16.88s
2025-07-18 06:21:24,444 - logger.py:50 - Epoch 340 Summary | Train MSE (x10^-2): 71.1767 | Val MSE (x10^-2): 40.3233 | Time: 34.90s
2025-07-18 06:21:27,496 - logger.py:50 - Epoch: [341][0/6]	Total Loss: 0.74618	Main MSE (x10^-2): 74.6177	LR: 9.36e-05	EMPP_Raw: 1.47152
2025-07-18 06:21:41,276 - logger.py:50 - Epoch: [341][5/6]	Total Loss: 0.73156	Main MSE (x10^-2): 73.1562	LR: 9.36e-05	EMPP_Raw: 1.44250
2025-07-18 06:21:41,324 - logger.py:50 - Epoch 341 Training Summary: Avg Total Loss: 0.73156, Avg Main MSE: 0.73156, Time: 16.87s
2025-07-18 06:21:59,178 - logger.py:50 - Epoch 341 Summary | Train MSE (x10^-2): 73.1562 | Val MSE (x10^-2): 40.3971 | Time: 34.73s
2025-07-18 06:22:02,338 - logger.py:50 - Epoch: [342][0/6]	Total Loss: 0.73135	Main MSE (x10^-2): 73.1350	LR: 9.25e-05	EMPP_Raw: 1.44290
2025-07-18 06:22:16,085 - logger.py:50 - Epoch: [342][5/6]	Total Loss: 0.72600	Main MSE (x10^-2): 72.6001	LR: 9.25e-05	EMPP_Raw: 1.43175
2025-07-18 06:22:16,128 - logger.py:50 - Epoch 342 Training Summary: Avg Total Loss: 0.72600, Avg Main MSE: 0.72600, Time: 16.94s
2025-07-18 06:22:34,039 - logger.py:50 - Epoch 342 Summary | Train MSE (x10^-2): 72.6001 | Val MSE (x10^-2): 41.5574 | Time: 34.86s
2025-07-18 06:22:37,184 - logger.py:50 - Epoch: [343][0/6]	Total Loss: 0.69632	Main MSE (x10^-2): 69.6325	LR: 9.15e-05	EMPP_Raw: 1.37439
2025-07-18 06:22:50,923 - logger.py:50 - Epoch: [343][5/6]	Total Loss: 0.72169	Main MSE (x10^-2): 72.1686	LR: 9.15e-05	EMPP_Raw: 1.42365
2025-07-18 06:22:50,964 - logger.py:50 - Epoch 343 Training Summary: Avg Total Loss: 0.72169, Avg Main MSE: 0.72169, Time: 16.92s
2025-07-18 06:23:08,991 - logger.py:50 - Epoch 343 Summary | Train MSE (x10^-2): 72.1686 | Val MSE (x10^-2): 40.7759 | Time: 34.95s
2025-07-18 06:23:12,150 - logger.py:50 - Epoch: [344][0/6]	Total Loss: 0.74092	Main MSE (x10^-2): 74.0917	LR: 9.04e-05	EMPP_Raw: 1.46264
2025-07-18 06:23:25,912 - logger.py:50 - Epoch: [344][5/6]	Total Loss: 0.72930	Main MSE (x10^-2): 72.9301	LR: 9.04e-05	EMPP_Raw: 1.43828
2025-07-18 06:23:25,956 - logger.py:50 - Epoch 344 Training Summary: Avg Total Loss: 0.72930, Avg Main MSE: 0.72930, Time: 16.96s
2025-07-18 06:23:43,954 - logger.py:50 - Epoch 344 Summary | Train MSE (x10^-2): 72.9301 | Val MSE (x10^-2): 40.7151 | Time: 34.96s
2025-07-18 06:23:46,959 - logger.py:50 - Epoch: [345][0/6]	Total Loss: 0.74169	Main MSE (x10^-2): 74.1688	LR: 8.94e-05	EMPP_Raw: 1.46500
2025-07-18 06:24:00,946 - logger.py:50 - Epoch: [345][5/6]	Total Loss: 0.72743	Main MSE (x10^-2): 72.7427	LR: 8.94e-05	EMPP_Raw: 1.43515
2025-07-18 06:24:00,992 - logger.py:50 - Epoch 345 Training Summary: Avg Total Loss: 0.72743, Avg Main MSE: 0.72743, Time: 17.03s
2025-07-18 06:24:18,904 - logger.py:50 - Epoch 345 Summary | Train MSE (x10^-2): 72.7427 | Val MSE (x10^-2): 41.4404 | Time: 34.95s
2025-07-18 06:24:21,897 - logger.py:50 - Epoch: [346][0/6]	Total Loss: 0.75591	Main MSE (x10^-2): 75.5910	LR: 8.84e-05	EMPP_Raw: 1.49427
2025-07-18 06:24:35,721 - logger.py:50 - Epoch: [346][5/6]	Total Loss: 0.74214	Main MSE (x10^-2): 74.2140	LR: 8.84e-05	EMPP_Raw: 1.46473
2025-07-18 06:24:35,763 - logger.py:50 - Epoch 346 Training Summary: Avg Total Loss: 0.74214, Avg Main MSE: 0.74214, Time: 16.85s
2025-07-18 06:24:53,853 - logger.py:50 - Epoch 346 Summary | Train MSE (x10^-2): 74.2140 | Val MSE (x10^-2): 40.8624 | Time: 34.94s
2025-07-18 06:24:56,849 - logger.py:50 - Epoch: [347][0/6]	Total Loss: 0.72618	Main MSE (x10^-2): 72.6183	LR: 8.73e-05	EMPP_Raw: 1.43052
2025-07-18 06:25:10,658 - logger.py:50 - Epoch: [347][5/6]	Total Loss: 0.72771	Main MSE (x10^-2): 72.7705	LR: 8.73e-05	EMPP_Raw: 1.43531
2025-07-18 06:25:10,699 - logger.py:50 - Epoch 347 Training Summary: Avg Total Loss: 0.72771, Avg Main MSE: 0.72771, Time: 16.84s
2025-07-18 06:25:28,694 - logger.py:50 - Epoch 347 Summary | Train MSE (x10^-2): 72.7705 | Val MSE (x10^-2): 40.9802 | Time: 34.83s
2025-07-18 06:25:31,728 - logger.py:50 - Epoch: [348][0/6]	Total Loss: 0.71531	Main MSE (x10^-2): 71.5313	LR: 8.63e-05	EMPP_Raw: 1.41145
2025-07-18 06:25:45,476 - logger.py:50 - Epoch: [348][5/6]	Total Loss: 0.72313	Main MSE (x10^-2): 72.3125	LR: 8.63e-05	EMPP_Raw: 1.42683
2025-07-18 06:25:45,519 - logger.py:50 - Epoch 348 Training Summary: Avg Total Loss: 0.72313, Avg Main MSE: 0.72313, Time: 16.82s
2025-07-18 06:26:03,369 - logger.py:50 - Epoch 348 Summary | Train MSE (x10^-2): 72.3125 | Val MSE (x10^-2): 41.4135 | Time: 34.67s
2025-07-18 06:26:06,551 - logger.py:50 - Epoch: [349][0/6]	Total Loss: 0.70292	Main MSE (x10^-2): 70.2924	LR: 8.53e-05	EMPP_Raw: 1.38705
2025-07-18 06:26:20,339 - logger.py:50 - Epoch: [349][5/6]	Total Loss: 0.71669	Main MSE (x10^-2): 71.6691	LR: 8.53e-05	EMPP_Raw: 1.41338
2025-07-18 06:26:20,384 - logger.py:50 - Epoch 349 Training Summary: Avg Total Loss: 0.71669, Avg Main MSE: 0.71669, Time: 17.01s
2025-07-18 06:26:38,331 - logger.py:50 - Epoch 349 Summary | Train MSE (x10^-2): 71.6691 | Val MSE (x10^-2): 40.7420 | Time: 34.96s
2025-07-18 06:26:41,547 - logger.py:50 - Epoch: [350][0/6]	Total Loss: 0.74196	Main MSE (x10^-2): 74.1956	LR: 8.43e-05	EMPP_Raw: 1.46282
2025-07-18 06:26:55,343 - logger.py:50 - Epoch: [350][5/6]	Total Loss: 0.73302	Main MSE (x10^-2): 73.3024	LR: 8.43e-05	EMPP_Raw: 1.44605
2025-07-18 06:26:55,384 - logger.py:50 - Epoch 350 Training Summary: Avg Total Loss: 0.73302, Avg Main MSE: 0.73302, Time: 17.04s
2025-07-18 06:27:13,324 - logger.py:50 - Epoch 350 Summary | Train MSE (x10^-2): 73.3024 | Val MSE (x10^-2): 40.7122 | Time: 34.99s
2025-07-18 06:27:16,320 - logger.py:50 - Epoch: [351][0/6]	Total Loss: 0.71929	Main MSE (x10^-2): 71.9293	LR: 8.32e-05	EMPP_Raw: 1.42043
2025-07-18 06:27:30,321 - logger.py:50 - Epoch: [351][5/6]	Total Loss: 0.72166	Main MSE (x10^-2): 72.1665	LR: 8.32e-05	EMPP_Raw: 1.42415
2025-07-18 06:27:30,367 - logger.py:50 - Epoch 351 Training Summary: Avg Total Loss: 0.72166, Avg Main MSE: 0.72166, Time: 17.04s
2025-07-18 06:27:48,262 - logger.py:50 - Epoch 351 Summary | Train MSE (x10^-2): 72.1665 | Val MSE (x10^-2): 40.8061 | Time: 34.93s
2025-07-18 06:27:51,238 - logger.py:50 - Epoch: [352][0/6]	Total Loss: 0.70833	Main MSE (x10^-2): 70.8333	LR: 8.22e-05	EMPP_Raw: 1.39812
2025-07-18 06:28:05,131 - logger.py:50 - Epoch: [352][5/6]	Total Loss: 0.72471	Main MSE (x10^-2): 72.4706	LR: 8.22e-05	EMPP_Raw: 1.43086
2025-07-18 06:28:05,171 - logger.py:50 - Epoch 352 Training Summary: Avg Total Loss: 0.72471, Avg Main MSE: 0.72471, Time: 16.90s
2025-07-18 06:28:23,037 - logger.py:50 - Epoch 352 Summary | Train MSE (x10^-2): 72.4706 | Val MSE (x10^-2): 41.0406 | Time: 34.77s
2025-07-18 06:28:26,032 - logger.py:50 - Epoch: [353][0/6]	Total Loss: 0.71926	Main MSE (x10^-2): 71.9261	LR: 8.12e-05	EMPP_Raw: 1.41830
2025-07-18 06:28:39,841 - logger.py:50 - Epoch: [353][5/6]	Total Loss: 0.72276	Main MSE (x10^-2): 72.2764	LR: 8.12e-05	EMPP_Raw: 1.42636
2025-07-18 06:28:39,890 - logger.py:50 - Epoch 353 Training Summary: Avg Total Loss: 0.72276, Avg Main MSE: 0.72276, Time: 16.85s
2025-07-18 06:28:58,033 - logger.py:50 - Epoch 353 Summary | Train MSE (x10^-2): 72.2764 | Val MSE (x10^-2): 41.1008 | Time: 34.99s
2025-07-18 06:29:01,019 - logger.py:50 - Epoch: [354][0/6]	Total Loss: 0.73387	Main MSE (x10^-2): 73.3869	LR: 8.02e-05	EMPP_Raw: 1.44958
2025-07-18 06:29:14,791 - logger.py:50 - Epoch: [354][5/6]	Total Loss: 0.73128	Main MSE (x10^-2): 73.1285	LR: 8.02e-05	EMPP_Raw: 1.44378
2025-07-18 06:29:14,840 - logger.py:50 - Epoch 354 Training Summary: Avg Total Loss: 0.73128, Avg Main MSE: 0.73128, Time: 16.79s
2025-07-18 06:29:32,758 - logger.py:50 - Epoch 354 Summary | Train MSE (x10^-2): 73.1285 | Val MSE (x10^-2): 40.8885 | Time: 34.72s
2025-07-18 06:29:35,899 - logger.py:50 - Epoch: [355][0/6]	Total Loss: 0.73112	Main MSE (x10^-2): 73.1121	LR: 7.92e-05	EMPP_Raw: 1.44525
2025-07-18 06:29:49,631 - logger.py:50 - Epoch: [355][5/6]	Total Loss: 0.72430	Main MSE (x10^-2): 72.4295	LR: 7.92e-05	EMPP_Raw: 1.42971
2025-07-18 06:29:49,674 - logger.py:50 - Epoch 355 Training Summary: Avg Total Loss: 0.72430, Avg Main MSE: 0.72430, Time: 16.91s
2025-07-18 06:30:07,542 - logger.py:50 - Epoch 355 Summary | Train MSE (x10^-2): 72.4295 | Val MSE (x10^-2): 40.8914 | Time: 34.78s
2025-07-18 06:30:10,705 - logger.py:50 - Epoch: [356][0/6]	Total Loss: 0.73550	Main MSE (x10^-2): 73.5502	LR: 7.82e-05	EMPP_Raw: 1.45091
2025-07-18 06:30:24,432 - logger.py:50 - Epoch: [356][5/6]	Total Loss: 0.72250	Main MSE (x10^-2): 72.2497	LR: 7.82e-05	EMPP_Raw: 1.42602
2025-07-18 06:30:24,479 - logger.py:50 - Epoch 356 Training Summary: Avg Total Loss: 0.72250, Avg Main MSE: 0.72250, Time: 16.93s
2025-07-18 06:30:42,408 - logger.py:50 - Epoch 356 Summary | Train MSE (x10^-2): 72.2497 | Val MSE (x10^-2): 41.3852 | Time: 34.86s
2025-07-18 06:30:45,575 - logger.py:50 - Epoch: [357][0/6]	Total Loss: 0.71273	Main MSE (x10^-2): 71.2735	LR: 7.72e-05	EMPP_Raw: 1.40784
2025-07-18 06:30:59,339 - logger.py:50 - Epoch: [357][5/6]	Total Loss: 0.72113	Main MSE (x10^-2): 72.1129	LR: 7.72e-05	EMPP_Raw: 1.42292
2025-07-18 06:30:59,382 - logger.py:50 - Epoch 357 Training Summary: Avg Total Loss: 0.72113, Avg Main MSE: 0.72113, Time: 16.97s
2025-07-18 06:31:17,253 - logger.py:50 - Epoch 357 Summary | Train MSE (x10^-2): 72.1129 | Val MSE (x10^-2): 40.3927 | Time: 34.84s
2025-07-18 06:31:20,246 - logger.py:50 - Epoch: [358][0/6]	Total Loss: 0.74433	Main MSE (x10^-2): 74.4333	LR: 7.63e-05	EMPP_Raw: 1.47022
2025-07-18 06:31:34,163 - logger.py:50 - Epoch: [358][5/6]	Total Loss: 0.73218	Main MSE (x10^-2): 73.2179	LR: 7.63e-05	EMPP_Raw: 1.44452
2025-07-18 06:31:34,211 - logger.py:50 - Epoch 358 Training Summary: Avg Total Loss: 0.73218, Avg Main MSE: 0.73218, Time: 16.95s
2025-07-18 06:31:52,106 - logger.py:50 - Epoch 358 Summary | Train MSE (x10^-2): 73.2179 | Val MSE (x10^-2): 40.9120 | Time: 34.85s
2025-07-18 06:31:55,104 - logger.py:50 - Epoch: [359][0/6]	Total Loss: 0.72176	Main MSE (x10^-2): 72.1762	LR: 7.53e-05	EMPP_Raw: 1.42569
2025-07-18 06:32:08,924 - logger.py:50 - Epoch: [359][5/6]	Total Loss: 0.72783	Main MSE (x10^-2): 72.7828	LR: 7.53e-05	EMPP_Raw: 1.43711
2025-07-18 06:32:08,971 - logger.py:50 - Epoch 359 Training Summary: Avg Total Loss: 0.72783, Avg Main MSE: 0.72783, Time: 16.86s
2025-07-18 06:32:27,044 - logger.py:50 - Epoch 359 Summary | Train MSE (x10^-2): 72.7828 | Val MSE (x10^-2): 40.4313 | Time: 34.93s
2025-07-18 06:32:30,032 - logger.py:50 - Epoch: [360][0/6]	Total Loss: 0.73951	Main MSE (x10^-2): 73.9512	LR: 7.43e-05	EMPP_Raw: 1.46238
2025-07-18 06:32:43,798 - logger.py:50 - Epoch: [360][5/6]	Total Loss: 0.72636	Main MSE (x10^-2): 72.6357	LR: 7.43e-05	EMPP_Raw: 1.43485
2025-07-18 06:32:43,840 - logger.py:50 - Epoch 360 Training Summary: Avg Total Loss: 0.72636, Avg Main MSE: 0.72636, Time: 16.79s
2025-07-18 06:33:01,888 - logger.py:50 - Epoch 360 Summary | Train MSE (x10^-2): 72.6357 | Val MSE (x10^-2): 41.1121 | Time: 34.84s
2025-07-18 06:33:04,888 - logger.py:50 - Epoch: [361][0/6]	Total Loss: 0.72189	Main MSE (x10^-2): 72.1894	LR: 7.33e-05	EMPP_Raw: 1.42530
2025-07-18 06:33:18,683 - logger.py:50 - Epoch: [361][5/6]	Total Loss: 0.72122	Main MSE (x10^-2): 72.1217	LR: 7.33e-05	EMPP_Raw: 1.42397
2025-07-18 06:33:18,725 - logger.py:50 - Epoch 361 Training Summary: Avg Total Loss: 0.72122, Avg Main MSE: 0.72122, Time: 16.83s
2025-07-18 06:33:36,623 - logger.py:50 - Epoch 361 Summary | Train MSE (x10^-2): 72.1217 | Val MSE (x10^-2): 39.8769 | Time: 34.73s
2025-07-18 06:33:39,810 - logger.py:50 - Epoch: [362][0/6]	Total Loss: 0.71850	Main MSE (x10^-2): 71.8495	LR: 7.24e-05	EMPP_Raw: 1.41515
2025-07-18 06:33:53,594 - logger.py:50 - Epoch: [362][5/6]	Total Loss: 0.72297	Main MSE (x10^-2): 72.2965	LR: 7.24e-05	EMPP_Raw: 1.42654
2025-07-18 06:33:53,639 - logger.py:50 - Epoch 362 Training Summary: Avg Total Loss: 0.72297, Avg Main MSE: 0.72297, Time: 17.01s
2025-07-18 06:34:11,493 - logger.py:50 - Epoch 362 Summary | Train MSE (x10^-2): 72.2965 | Val MSE (x10^-2): 41.3453 | Time: 34.86s
2025-07-18 06:34:14,629 - logger.py:50 - Epoch: [363][0/6]	Total Loss: 0.72365	Main MSE (x10^-2): 72.3653	LR: 7.14e-05	EMPP_Raw: 1.42916
2025-07-18 06:34:28,365 - logger.py:50 - Epoch: [363][5/6]	Total Loss: 0.72122	Main MSE (x10^-2): 72.1216	LR: 7.14e-05	EMPP_Raw: 1.42264
2025-07-18 06:34:28,406 - logger.py:50 - Epoch 363 Training Summary: Avg Total Loss: 0.72122, Avg Main MSE: 0.72122, Time: 16.90s
2025-07-18 06:34:46,301 - logger.py:50 - Epoch 363 Summary | Train MSE (x10^-2): 72.1216 | Val MSE (x10^-2): 40.2450 | Time: 34.80s
2025-07-18 06:34:49,298 - logger.py:50 - Epoch: [364][0/6]	Total Loss: 0.73654	Main MSE (x10^-2): 73.6545	LR: 7.05e-05	EMPP_Raw: 1.45520
2025-07-18 06:35:03,233 - logger.py:50 - Epoch: [364][5/6]	Total Loss: 0.72836	Main MSE (x10^-2): 72.8360	LR: 7.05e-05	EMPP_Raw: 1.43828
2025-07-18 06:35:03,277 - logger.py:50 - Epoch 364 Training Summary: Avg Total Loss: 0.72836, Avg Main MSE: 0.72836, Time: 16.97s
2025-07-18 06:35:21,247 - logger.py:50 - Epoch 364 Summary | Train MSE (x10^-2): 72.8360 | Val MSE (x10^-2): 40.7711 | Time: 34.94s
2025-07-18 06:35:24,257 - logger.py:50 - Epoch: [365][0/6]	Total Loss: 0.71316	Main MSE (x10^-2): 71.3164	LR: 6.95e-05	EMPP_Raw: 1.40791
2025-07-18 06:35:38,262 - logger.py:50 - Epoch: [365][5/6]	Total Loss: 0.72413	Main MSE (x10^-2): 72.4126	LR: 6.95e-05	EMPP_Raw: 1.42962
2025-07-18 06:35:38,308 - logger.py:50 - Epoch 365 Training Summary: Avg Total Loss: 0.72413, Avg Main MSE: 0.72413, Time: 17.05s
2025-07-18 06:35:56,157 - logger.py:50 - Epoch 365 Summary | Train MSE (x10^-2): 72.4126 | Val MSE (x10^-2): 40.8207 | Time: 34.90s
2025-07-18 06:35:59,151 - logger.py:50 - Epoch: [366][0/6]	Total Loss: 0.72177	Main MSE (x10^-2): 72.1771	LR: 6.86e-05	EMPP_Raw: 1.42584
2025-07-18 06:36:12,915 - logger.py:50 - Epoch: [366][5/6]	Total Loss: 0.72586	Main MSE (x10^-2): 72.5858	LR: 6.86e-05	EMPP_Raw: 1.43334
2025-07-18 06:36:12,963 - logger.py:50 - Epoch 366 Training Summary: Avg Total Loss: 0.72586, Avg Main MSE: 0.72586, Time: 16.80s
2025-07-18 06:36:31,003 - logger.py:50 - Epoch 366 Summary | Train MSE (x10^-2): 72.5858 | Val MSE (x10^-2): 41.5140 | Time: 34.84s
2025-07-18 06:36:34,038 - logger.py:50 - Epoch: [367][0/6]	Total Loss: 0.73075	Main MSE (x10^-2): 73.0752	LR: 6.76e-05	EMPP_Raw: 1.44582
2025-07-18 06:36:47,839 - logger.py:50 - Epoch: [367][5/6]	Total Loss: 0.73984	Main MSE (x10^-2): 73.9843	LR: 6.76e-05	EMPP_Raw: 1.46061
2025-07-18 06:36:47,881 - logger.py:50 - Epoch 367 Training Summary: Avg Total Loss: 0.73984, Avg Main MSE: 0.73984, Time: 16.87s
2025-07-18 06:37:05,784 - logger.py:50 - Epoch 367 Summary | Train MSE (x10^-2): 73.9843 | Val MSE (x10^-2): 40.1089 | Time: 34.78s
2025-07-18 06:37:08,919 - logger.py:50 - Epoch: [368][0/6]	Total Loss: 0.74459	Main MSE (x10^-2): 74.4591	LR: 6.67e-05	EMPP_Raw: 1.47071
2025-07-18 06:37:22,672 - logger.py:50 - Epoch: [368][5/6]	Total Loss: 0.72967	Main MSE (x10^-2): 72.9668	LR: 6.67e-05	EMPP_Raw: 1.44056
2025-07-18 06:37:22,718 - logger.py:50 - Epoch 368 Training Summary: Avg Total Loss: 0.72967, Avg Main MSE: 0.72967, Time: 16.92s
2025-07-18 06:37:40,630 - logger.py:50 - Epoch 368 Summary | Train MSE (x10^-2): 72.9668 | Val MSE (x10^-2): 40.7198 | Time: 34.84s
2025-07-18 06:37:43,829 - logger.py:50 - Epoch: [369][0/6]	Total Loss: 0.71427	Main MSE (x10^-2): 71.4272	LR: 6.58e-05	EMPP_Raw: 1.41044
2025-07-18 06:37:57,573 - logger.py:50 - Epoch: [369][5/6]	Total Loss: 0.72373	Main MSE (x10^-2): 72.3730	LR: 6.58e-05	EMPP_Raw: 1.42966
2025-07-18 06:37:57,619 - logger.py:50 - Epoch 369 Training Summary: Avg Total Loss: 0.72373, Avg Main MSE: 0.72373, Time: 16.98s
2025-07-18 06:38:15,706 - logger.py:50 - Epoch 369 Summary | Train MSE (x10^-2): 72.3730 | Val MSE (x10^-2): 40.3147 | Time: 35.07s
2025-07-18 06:38:18,867 - logger.py:50 - Epoch: [370][0/6]	Total Loss: 0.72800	Main MSE (x10^-2): 72.7999	LR: 6.48e-05	EMPP_Raw: 1.43835
2025-07-18 06:38:32,627 - logger.py:50 - Epoch: [370][5/6]	Total Loss: 0.71392	Main MSE (x10^-2): 71.3916	LR: 6.48e-05	EMPP_Raw: 1.40985
2025-07-18 06:38:32,668 - logger.py:50 - Epoch 370 Training Summary: Avg Total Loss: 0.71392, Avg Main MSE: 0.71392, Time: 16.95s
2025-07-18 06:38:50,714 - logger.py:50 - Epoch 370 Summary | Train MSE (x10^-2): 71.3916 | Val MSE (x10^-2): 41.7316 | Time: 35.00s
2025-07-18 06:38:53,702 - logger.py:50 - Epoch: [371][0/6]	Total Loss: 0.74354	Main MSE (x10^-2): 74.3545	LR: 6.39e-05	EMPP_Raw: 1.46730
2025-07-18 06:39:07,628 - logger.py:50 - Epoch: [371][5/6]	Total Loss: 0.73774	Main MSE (x10^-2): 73.7740	LR: 6.39e-05	EMPP_Raw: 1.45561
2025-07-18 06:39:07,674 - logger.py:50 - Epoch 371 Training Summary: Avg Total Loss: 0.73774, Avg Main MSE: 0.73774, Time: 16.95s
2025-07-18 06:39:25,564 - logger.py:50 - Epoch 371 Summary | Train MSE (x10^-2): 73.7740 | Val MSE (x10^-2): 39.8921 | Time: 34.84s
2025-07-18 06:39:28,603 - logger.py:50 - Epoch: [372][0/6]	Total Loss: 0.70811	Main MSE (x10^-2): 70.8115	LR: 6.30e-05	EMPP_Raw: 1.40060
2025-07-18 06:39:42,378 - logger.py:50 - Epoch: [372][5/6]	Total Loss: 0.71882	Main MSE (x10^-2): 71.8825	LR: 6.30e-05	EMPP_Raw: 1.42010
2025-07-18 06:39:42,423 - logger.py:50 - Epoch 372 Training Summary: Avg Total Loss: 0.71882, Avg Main MSE: 0.71882, Time: 16.85s
2025-07-18 06:40:00,436 - logger.py:50 - Epoch 372 Summary | Train MSE (x10^-2): 71.8825 | Val MSE (x10^-2): 41.2842 | Time: 34.87s
2025-07-18 06:40:03,437 - logger.py:50 - Epoch: [373][0/6]	Total Loss: 0.76224	Main MSE (x10^-2): 76.2240	LR: 6.21e-05	EMPP_Raw: 1.50695
2025-07-18 06:40:17,236 - logger.py:50 - Epoch: [373][5/6]	Total Loss: 0.71974	Main MSE (x10^-2): 71.9741	LR: 6.21e-05	EMPP_Raw: 1.42125
2025-07-18 06:40:17,276 - logger.py:50 - Epoch 373 Training Summary: Avg Total Loss: 0.71974, Avg Main MSE: 0.71974, Time: 16.83s
2025-07-18 06:40:35,327 - logger.py:50 - Epoch 373 Summary | Train MSE (x10^-2): 71.9741 | Val MSE (x10^-2): 40.3534 | Time: 34.89s
2025-07-18 06:40:38,377 - logger.py:50 - Epoch: [374][0/6]	Total Loss: 0.72648	Main MSE (x10^-2): 72.6482	LR: 6.12e-05	EMPP_Raw: 1.43469
2025-07-18 06:40:52,135 - logger.py:50 - Epoch: [374][5/6]	Total Loss: 0.73184	Main MSE (x10^-2): 73.1840	LR: 6.12e-05	EMPP_Raw: 1.44534
2025-07-18 06:40:52,181 - logger.py:50 - Epoch 374 Training Summary: Avg Total Loss: 0.73184, Avg Main MSE: 0.73184, Time: 16.84s
2025-07-18 06:41:10,013 - logger.py:50 - Epoch 374 Summary | Train MSE (x10^-2): 73.1840 | Val MSE (x10^-2): 40.6462 | Time: 34.68s
2025-07-18 06:41:13,166 - logger.py:50 - Epoch: [375][0/6]	Total Loss: 0.69333	Main MSE (x10^-2): 69.3334	LR: 6.03e-05	EMPP_Raw: 1.36699
2025-07-18 06:41:26,960 - logger.py:50 - Epoch: [375][5/6]	Total Loss: 0.72727	Main MSE (x10^-2): 72.7269	LR: 6.03e-05	EMPP_Raw: 1.43620
2025-07-18 06:41:27,007 - logger.py:50 - Epoch 375 Training Summary: Avg Total Loss: 0.72727, Avg Main MSE: 0.72727, Time: 16.98s
2025-07-18 06:41:44,871 - logger.py:50 - Epoch 375 Summary | Train MSE (x10^-2): 72.7269 | Val MSE (x10^-2): 40.7998 | Time: 34.85s
2025-07-18 06:41:48,059 - logger.py:50 - Epoch: [376][0/6]	Total Loss: 0.72746	Main MSE (x10^-2): 72.7465	LR: 5.94e-05	EMPP_Raw: 1.43637
2025-07-18 06:42:01,781 - logger.py:50 - Epoch: [376][5/6]	Total Loss: 0.73345	Main MSE (x10^-2): 73.3446	LR: 5.94e-05	EMPP_Raw: 1.44861
2025-07-18 06:42:01,825 - logger.py:50 - Epoch 376 Training Summary: Avg Total Loss: 0.73345, Avg Main MSE: 0.73345, Time: 16.94s
2025-07-18 06:42:19,655 - logger.py:50 - Epoch 376 Summary | Train MSE (x10^-2): 73.3446 | Val MSE (x10^-2): 41.1623 | Time: 34.78s
2025-07-18 06:42:22,643 - logger.py:50 - Epoch: [377][0/6]	Total Loss: 0.71432	Main MSE (x10^-2): 71.4320	LR: 5.85e-05	EMPP_Raw: 1.41159
2025-07-18 06:42:36,583 - logger.py:50 - Epoch: [377][5/6]	Total Loss: 0.72185	Main MSE (x10^-2): 72.1850	LR: 5.85e-05	EMPP_Raw: 1.42601
2025-07-18 06:42:36,634 - logger.py:50 - Epoch 377 Training Summary: Avg Total Loss: 0.72185, Avg Main MSE: 0.72185, Time: 16.97s
2025-07-18 06:42:54,492 - logger.py:50 - Epoch 377 Summary | Train MSE (x10^-2): 72.1850 | Val MSE (x10^-2): 39.8091 | Time: 34.83s
2025-07-18 06:42:57,482 - logger.py:50 - Epoch: [378][0/6]	Total Loss: 0.73770	Main MSE (x10^-2): 73.7697	LR: 5.77e-05	EMPP_Raw: 1.45717
2025-07-18 06:43:11,373 - logger.py:50 - Epoch: [378][5/6]	Total Loss: 0.71714	Main MSE (x10^-2): 71.7140	LR: 5.77e-05	EMPP_Raw: 1.41559
2025-07-18 06:43:11,424 - logger.py:50 - Epoch 378 Training Summary: Avg Total Loss: 0.71714, Avg Main MSE: 0.71714, Time: 16.92s
2025-07-18 06:43:29,394 - logger.py:50 - Epoch 378 Summary | Train MSE (x10^-2): 71.7140 | Val MSE (x10^-2): 41.0455 | Time: 34.90s
2025-07-18 06:43:32,389 - logger.py:50 - Epoch: [379][0/6]	Total Loss: 0.74985	Main MSE (x10^-2): 74.9853	LR: 5.68e-05	EMPP_Raw: 1.48292
2025-07-18 06:43:46,162 - logger.py:50 - Epoch: [379][5/6]	Total Loss: 0.72474	Main MSE (x10^-2): 72.4739	LR: 5.68e-05	EMPP_Raw: 1.43223
2025-07-18 06:43:46,210 - logger.py:50 - Epoch 379 Training Summary: Avg Total Loss: 0.72474, Avg Main MSE: 0.72474, Time: 16.81s
2025-07-18 06:44:04,287 - logger.py:50 - Epoch 379 Summary | Train MSE (x10^-2): 72.4739 | Val MSE (x10^-2): 40.5465 | Time: 34.89s
2025-07-18 06:44:07,283 - logger.py:50 - Epoch: [380][0/6]	Total Loss: 0.74067	Main MSE (x10^-2): 74.0665	LR: 5.59e-05	EMPP_Raw: 1.46451
2025-07-18 06:44:21,182 - logger.py:50 - Epoch: [380][5/6]	Total Loss: 0.73069	Main MSE (x10^-2): 73.0692	LR: 5.59e-05	EMPP_Raw: 1.44363
2025-07-18 06:44:21,227 - logger.py:50 - Epoch 380 Training Summary: Avg Total Loss: 0.73069, Avg Main MSE: 0.73069, Time: 16.93s
2025-07-18 06:44:39,207 - logger.py:50 - Epoch 380 Summary | Train MSE (x10^-2): 73.0692 | Val MSE (x10^-2): 40.6163 | Time: 34.91s
2025-07-18 06:44:42,357 - logger.py:50 - Epoch: [381][0/6]	Total Loss: 0.73552	Main MSE (x10^-2): 73.5524	LR: 5.51e-05	EMPP_Raw: 1.45387
2025-07-18 06:44:56,158 - logger.py:50 - Epoch: [381][5/6]	Total Loss: 0.72730	Main MSE (x10^-2): 72.7304	LR: 5.51e-05	EMPP_Raw: 1.43630
2025-07-18 06:44:56,201 - logger.py:50 - Epoch 381 Training Summary: Avg Total Loss: 0.72730, Avg Main MSE: 0.72730, Time: 16.99s
2025-07-18 06:45:14,079 - logger.py:50 - Epoch 381 Summary | Train MSE (x10^-2): 72.7304 | Val MSE (x10^-2): 41.0816 | Time: 34.87s
2025-07-18 06:45:17,250 - logger.py:50 - Epoch: [382][0/6]	Total Loss: 0.73635	Main MSE (x10^-2): 73.6352	LR: 5.42e-05	EMPP_Raw: 1.45419
2025-07-18 06:45:31,060 - logger.py:50 - Epoch: [382][5/6]	Total Loss: 0.72775	Main MSE (x10^-2): 72.7750	LR: 5.42e-05	EMPP_Raw: 1.43721
2025-07-18 06:45:31,107 - logger.py:50 - Epoch 382 Training Summary: Avg Total Loss: 0.72775, Avg Main MSE: 0.72775, Time: 17.02s
2025-07-18 06:45:49,078 - logger.py:50 - Epoch 382 Summary | Train MSE (x10^-2): 72.7750 | Val MSE (x10^-2): 40.2917 | Time: 34.99s
2025-07-18 06:45:52,232 - logger.py:50 - Epoch: [383][0/6]	Total Loss: 0.73312	Main MSE (x10^-2): 73.3124	LR: 5.34e-05	EMPP_Raw: 1.44880
2025-07-18 06:46:06,015 - logger.py:50 - Epoch: [383][5/6]	Total Loss: 0.72975	Main MSE (x10^-2): 72.9748	LR: 5.34e-05	EMPP_Raw: 1.44185
2025-07-18 06:46:06,060 - logger.py:50 - Epoch 383 Training Summary: Avg Total Loss: 0.72975, Avg Main MSE: 0.72975, Time: 16.97s
2025-07-18 06:46:23,985 - logger.py:50 - Epoch 383 Summary | Train MSE (x10^-2): 72.9748 | Val MSE (x10^-2): 40.5788 | Time: 34.90s
2025-07-18 06:46:27,012 - logger.py:50 - Epoch: [384][0/6]	Total Loss: 0.74484	Main MSE (x10^-2): 74.4836	LR: 5.25e-05	EMPP_Raw: 1.47256
2025-07-18 06:46:40,963 - logger.py:50 - Epoch: [384][5/6]	Total Loss: 0.73587	Main MSE (x10^-2): 73.5868	LR: 5.25e-05	EMPP_Raw: 1.45395
2025-07-18 06:46:41,006 - logger.py:50 - Epoch 384 Training Summary: Avg Total Loss: 0.73587, Avg Main MSE: 0.73587, Time: 17.01s
2025-07-18 06:46:58,904 - logger.py:50 - Epoch 384 Summary | Train MSE (x10^-2): 73.5868 | Val MSE (x10^-2): 40.9619 | Time: 34.91s
2025-07-18 06:47:01,919 - logger.py:50 - Epoch: [385][0/6]	Total Loss: 0.68002	Main MSE (x10^-2): 68.0019	LR: 5.17e-05	EMPP_Raw: 1.34231
2025-07-18 06:47:15,750 - logger.py:50 - Epoch: [385][5/6]	Total Loss: 0.71490	Main MSE (x10^-2): 71.4902	LR: 5.17e-05	EMPP_Raw: 1.41201
2025-07-18 06:47:15,798 - logger.py:50 - Epoch 385 Training Summary: Avg Total Loss: 0.71490, Avg Main MSE: 0.71490, Time: 16.88s
2025-07-18 06:47:33,842 - logger.py:50 - Epoch 385 Summary | Train MSE (x10^-2): 71.4902 | Val MSE (x10^-2): 40.3860 | Time: 34.93s
2025-07-18 06:47:36,884 - logger.py:50 - Epoch: [386][0/6]	Total Loss: 0.73453	Main MSE (x10^-2): 73.4526	LR: 5.09e-05	EMPP_Raw: 1.45076
2025-07-18 06:47:50,660 - logger.py:50 - Epoch: [386][5/6]	Total Loss: 0.74230	Main MSE (x10^-2): 74.2304	LR: 5.09e-05	EMPP_Raw: 1.46672
2025-07-18 06:47:50,704 - logger.py:50 - Epoch 386 Training Summary: Avg Total Loss: 0.74230, Avg Main MSE: 0.74230, Time: 16.85s
2025-07-18 06:48:08,778 - logger.py:50 - Epoch 386 Summary | Train MSE (x10^-2): 74.2304 | Val MSE (x10^-2): 41.1426 | Time: 34.93s
2025-07-18 06:48:11,791 - logger.py:50 - Epoch: [387][0/6]	Total Loss: 0.69517	Main MSE (x10^-2): 69.5167	LR: 5.00e-05	EMPP_Raw: 1.37306
2025-07-18 06:48:25,565 - logger.py:50 - Epoch: [387][5/6]	Total Loss: 0.71403	Main MSE (x10^-2): 71.4031	LR: 5.00e-05	EMPP_Raw: 1.41163
2025-07-18 06:48:25,610 - logger.py:50 - Epoch 387 Training Summary: Avg Total Loss: 0.71403, Avg Main MSE: 0.71403, Time: 16.82s
2025-07-18 06:48:43,563 - logger.py:50 - Epoch 387 Summary | Train MSE (x10^-2): 71.4031 | Val MSE (x10^-2): 40.8465 | Time: 34.78s
2025-07-18 06:48:46,704 - logger.py:50 - Epoch: [388][0/6]	Total Loss: 0.74240	Main MSE (x10^-2): 74.2404	LR: 4.92e-05	EMPP_Raw: 1.46996
2025-07-18 06:49:00,510 - logger.py:50 - Epoch: [388][5/6]	Total Loss: 0.73312	Main MSE (x10^-2): 73.3117	LR: 4.92e-05	EMPP_Raw: 1.44880
2025-07-18 06:49:00,553 - logger.py:50 - Epoch 388 Training Summary: Avg Total Loss: 0.73312, Avg Main MSE: 0.73312, Time: 16.98s
2025-07-18 06:49:18,490 - logger.py:50 - Epoch 388 Summary | Train MSE (x10^-2): 73.3117 | Val MSE (x10^-2): 41.1498 | Time: 34.92s
2025-07-18 06:49:21,645 - logger.py:50 - Epoch: [389][0/6]	Total Loss: 0.71580	Main MSE (x10^-2): 71.5801	LR: 4.84e-05	EMPP_Raw: 1.41482
2025-07-18 06:49:35,383 - logger.py:50 - Epoch: [389][5/6]	Total Loss: 0.72019	Main MSE (x10^-2): 72.0187	LR: 4.84e-05	EMPP_Raw: 1.42298
2025-07-18 06:49:35,427 - logger.py:50 - Epoch 389 Training Summary: Avg Total Loss: 0.72019, Avg Main MSE: 0.72019, Time: 16.93s
2025-07-18 06:49:53,459 - logger.py:50 - Epoch 389 Summary | Train MSE (x10^-2): 72.0187 | Val MSE (x10^-2): 40.6213 | Time: 34.96s
2025-07-18 06:49:56,465 - logger.py:50 - Epoch: [390][0/6]	Total Loss: 0.73106	Main MSE (x10^-2): 73.1061	LR: 4.76e-05	EMPP_Raw: 1.44193
2025-07-18 06:50:10,514 - logger.py:50 - Epoch: [390][5/6]	Total Loss: 0.72767	Main MSE (x10^-2): 72.7667	LR: 4.76e-05	EMPP_Raw: 1.43723
2025-07-18 06:50:10,554 - logger.py:50 - Epoch 390 Training Summary: Avg Total Loss: 0.72767, Avg Main MSE: 0.72767, Time: 17.08s
2025-07-18 06:50:28,455 - logger.py:50 - Epoch 390 Summary | Train MSE (x10^-2): 72.7667 | Val MSE (x10^-2): 40.8007 | Time: 34.99s
2025-07-18 06:50:31,448 - logger.py:50 - Epoch: [391][0/6]	Total Loss: 0.72868	Main MSE (x10^-2): 72.8680	LR: 4.68e-05	EMPP_Raw: 1.44077
2025-07-18 06:50:45,415 - logger.py:50 - Epoch: [391][5/6]	Total Loss: 0.73217	Main MSE (x10^-2): 73.2173	LR: 4.68e-05	EMPP_Raw: 1.44754
2025-07-18 06:50:45,460 - logger.py:50 - Epoch 391 Training Summary: Avg Total Loss: 0.73217, Avg Main MSE: 0.73217, Time: 17.00s
2025-07-18 06:51:03,343 - logger.py:50 - Epoch 391 Summary | Train MSE (x10^-2): 73.2173 | Val MSE (x10^-2): 40.5895 | Time: 34.88s
2025-07-18 06:51:06,321 - logger.py:50 - Epoch: [392][0/6]	Total Loss: 0.74328	Main MSE (x10^-2): 74.3276	LR: 4.60e-05	EMPP_Raw: 1.46768
2025-07-18 06:51:20,061 - logger.py:50 - Epoch: [392][5/6]	Total Loss: 0.72998	Main MSE (x10^-2): 72.9982	LR: 4.60e-05	EMPP_Raw: 1.44218
2025-07-18 06:51:20,102 - logger.py:50 - Epoch 392 Training Summary: Avg Total Loss: 0.72998, Avg Main MSE: 0.72998, Time: 16.75s
2025-07-18 06:51:38,135 - logger.py:50 - Epoch 392 Summary | Train MSE (x10^-2): 72.9982 | Val MSE (x10^-2): 40.5975 | Time: 34.79s
2025-07-18 06:51:41,138 - logger.py:50 - Epoch: [393][0/6]	Total Loss: 0.71175	Main MSE (x10^-2): 71.1751	LR: 4.52e-05	EMPP_Raw: 1.40656
2025-07-18 06:51:54,928 - logger.py:50 - Epoch: [393][5/6]	Total Loss: 0.72340	Main MSE (x10^-2): 72.3404	LR: 4.52e-05	EMPP_Raw: 1.42971
2025-07-18 06:51:54,972 - logger.py:50 - Epoch 393 Training Summary: Avg Total Loss: 0.72340, Avg Main MSE: 0.72340, Time: 16.83s
2025-07-18 06:52:12,847 - logger.py:50 - Epoch 393 Summary | Train MSE (x10^-2): 72.3404 | Val MSE (x10^-2): 40.4587 | Time: 34.71s
2025-07-18 06:52:16,012 - logger.py:50 - Epoch: [394][0/6]	Total Loss: 0.71481	Main MSE (x10^-2): 71.4805	LR: 4.44e-05	EMPP_Raw: 1.41249
2025-07-18 06:52:29,810 - logger.py:50 - Epoch: [394][5/6]	Total Loss: 0.72101	Main MSE (x10^-2): 72.1012	LR: 4.44e-05	EMPP_Raw: 1.42538
2025-07-18 06:52:29,852 - logger.py:50 - Epoch 394 Training Summary: Avg Total Loss: 0.72101, Avg Main MSE: 0.72101, Time: 17.00s
2025-07-18 06:52:47,654 - logger.py:50 - Epoch 394 Summary | Train MSE (x10^-2): 72.1012 | Val MSE (x10^-2): 40.4331 | Time: 34.80s
2025-07-18 06:52:50,809 - logger.py:50 - Epoch: [395][0/6]	Total Loss: 0.70986	Main MSE (x10^-2): 70.9855	LR: 4.36e-05	EMPP_Raw: 1.40356
2025-07-18 06:53:04,573 - logger.py:50 - Epoch: [395][5/6]	Total Loss: 0.72438	Main MSE (x10^-2): 72.4385	LR: 4.36e-05	EMPP_Raw: 1.43202
2025-07-18 06:53:04,622 - logger.py:50 - Epoch 395 Training Summary: Avg Total Loss: 0.72438, Avg Main MSE: 0.72438, Time: 16.96s
2025-07-18 06:53:22,504 - logger.py:50 - Epoch 395 Summary | Train MSE (x10^-2): 72.4385 | Val MSE (x10^-2): 40.5889 | Time: 34.85s
2025-07-18 06:53:25,661 - logger.py:50 - Epoch: [396][0/6]	Total Loss: 0.69988	Main MSE (x10^-2): 69.9878	LR: 4.29e-05	EMPP_Raw: 1.38279
2025-07-18 06:53:39,408 - logger.py:50 - Epoch: [396][5/6]	Total Loss: 0.72461	Main MSE (x10^-2): 72.4606	LR: 4.29e-05	EMPP_Raw: 1.43213
2025-07-18 06:53:39,452 - logger.py:50 - Epoch 396 Training Summary: Avg Total Loss: 0.72461, Avg Main MSE: 0.72461, Time: 16.94s
2025-07-18 06:53:57,432 - logger.py:50 - Epoch 396 Summary | Train MSE (x10^-2): 72.4606 | Val MSE (x10^-2): 40.8056 | Time: 34.92s
2025-07-18 06:54:00,485 - logger.py:50 - Epoch: [397][0/6]	Total Loss: 0.74157	Main MSE (x10^-2): 74.1568	LR: 4.21e-05	EMPP_Raw: 1.46591
2025-07-18 06:54:14,463 - logger.py:50 - Epoch: [397][5/6]	Total Loss: 0.72665	Main MSE (x10^-2): 72.6645	LR: 4.21e-05	EMPP_Raw: 1.43627
2025-07-18 06:54:14,509 - logger.py:50 - Epoch 397 Training Summary: Avg Total Loss: 0.72665, Avg Main MSE: 0.72665, Time: 17.07s
2025-07-18 06:54:32,573 - logger.py:50 - Epoch 397 Summary | Train MSE (x10^-2): 72.6645 | Val MSE (x10^-2): 40.6301 | Time: 35.14s
2025-07-18 06:54:35,585 - logger.py:50 - Epoch: [398][0/6]	Total Loss: 0.70436	Main MSE (x10^-2): 70.4357	LR: 4.13e-05	EMPP_Raw: 1.38677
2025-07-18 06:54:49,416 - logger.py:50 - Epoch: [398][5/6]	Total Loss: 0.72883	Main MSE (x10^-2): 72.8832	LR: 4.13e-05	EMPP_Raw: 1.43872
2025-07-18 06:54:49,459 - logger.py:50 - Epoch 398 Training Summary: Avg Total Loss: 0.72883, Avg Main MSE: 0.72883, Time: 16.88s
2025-07-18 06:55:07,621 - logger.py:50 - Epoch 398 Summary | Train MSE (x10^-2): 72.8832 | Val MSE (x10^-2): 40.8613 | Time: 35.04s
2025-07-18 06:55:10,674 - logger.py:50 - Epoch: [399][0/6]	Total Loss: 0.69379	Main MSE (x10^-2): 69.3787	LR: 4.06e-05	EMPP_Raw: 1.37016
2025-07-18 06:55:24,544 - logger.py:50 - Epoch: [399][5/6]	Total Loss: 0.71822	Main MSE (x10^-2): 71.8219	LR: 4.06e-05	EMPP_Raw: 1.41976
2025-07-18 06:55:24,585 - logger.py:50 - Epoch 399 Training Summary: Avg Total Loss: 0.71822, Avg Main MSE: 0.71822, Time: 16.95s
2025-07-18 06:55:42,775 - logger.py:50 - Epoch 399 Summary | Train MSE (x10^-2): 71.8219 | Val MSE (x10^-2): 40.8519 | Time: 35.15s
2025-07-18 06:55:45,777 - logger.py:50 - Epoch: [400][0/6]	Total Loss: 0.70173	Main MSE (x10^-2): 70.1726	LR: 3.98e-05	EMPP_Raw: 1.38779
2025-07-18 06:55:59,542 - logger.py:50 - Epoch: [400][5/6]	Total Loss: 0.71727	Main MSE (x10^-2): 71.7268	LR: 3.98e-05	EMPP_Raw: 1.41779
2025-07-18 06:55:59,597 - logger.py:50 - Epoch 400 Training Summary: Avg Total Loss: 0.71727, Avg Main MSE: 0.71727, Time: 16.81s
2025-07-18 06:56:17,411 - logger.py:50 - Epoch 400 Summary | Train MSE (x10^-2): 71.7268 | Val MSE (x10^-2): 40.6565 | Time: 34.63s
2025-07-18 06:56:20,576 - logger.py:50 - Epoch: [401][0/6]	Total Loss: 0.72542	Main MSE (x10^-2): 72.5419	LR: 3.91e-05	EMPP_Raw: 1.43593
2025-07-18 06:56:34,362 - logger.py:50 - Epoch: [401][5/6]	Total Loss: 0.72410	Main MSE (x10^-2): 72.4100	LR: 3.91e-05	EMPP_Raw: 1.43162
2025-07-18 06:56:34,405 - logger.py:50 - Epoch 401 Training Summary: Avg Total Loss: 0.72410, Avg Main MSE: 0.72410, Time: 16.98s
2025-07-18 06:56:52,412 - logger.py:50 - Epoch 401 Summary | Train MSE (x10^-2): 72.4100 | Val MSE (x10^-2): 40.8585 | Time: 35.00s
2025-07-18 06:56:55,613 - logger.py:50 - Epoch: [402][0/6]	Total Loss: 0.70947	Main MSE (x10^-2): 70.9470	LR: 3.84e-05	EMPP_Raw: 1.40296
2025-07-18 06:57:09,340 - logger.py:50 - Epoch: [402][5/6]	Total Loss: 0.72776	Main MSE (x10^-2): 72.7764	LR: 3.84e-05	EMPP_Raw: 1.43824
2025-07-18 06:57:09,406 - logger.py:50 - Epoch 402 Training Summary: Avg Total Loss: 0.72776, Avg Main MSE: 0.72776, Time: 16.98s
2025-07-18 06:57:27,250 - logger.py:50 - Epoch 402 Summary | Train MSE (x10^-2): 72.7764 | Val MSE (x10^-2): 40.3567 | Time: 34.83s
2025-07-18 06:57:30,291 - logger.py:50 - Epoch: [403][0/6]	Total Loss: 0.72013	Main MSE (x10^-2): 72.0126	LR: 3.76e-05	EMPP_Raw: 1.42232
2025-07-18 06:57:44,277 - logger.py:50 - Epoch: [403][5/6]	Total Loss: 0.72666	Main MSE (x10^-2): 72.6656	LR: 3.76e-05	EMPP_Raw: 1.43642
2025-07-18 06:57:44,318 - logger.py:50 - Epoch 403 Training Summary: Avg Total Loss: 0.72666, Avg Main MSE: 0.72666, Time: 17.06s
2025-07-18 06:58:02,192 - logger.py:50 - Epoch 403 Summary | Train MSE (x10^-2): 72.6656 | Val MSE (x10^-2): 41.0700 | Time: 34.94s
2025-07-18 06:58:05,189 - logger.py:50 - Epoch: [404][0/6]	Total Loss: 0.72643	Main MSE (x10^-2): 72.6430	LR: 3.69e-05	EMPP_Raw: 1.43560
2025-07-18 06:58:19,158 - logger.py:50 - Epoch: [404][5/6]	Total Loss: 0.72974	Main MSE (x10^-2): 72.9741	LR: 3.69e-05	EMPP_Raw: 1.44175
2025-07-18 06:58:19,196 - logger.py:50 - Epoch 404 Training Summary: Avg Total Loss: 0.72974, Avg Main MSE: 0.72974, Time: 17.00s
2025-07-18 06:58:37,203 - logger.py:50 - Epoch 404 Summary | Train MSE (x10^-2): 72.9741 | Val MSE (x10^-2): 40.2432 | Time: 35.01s
2025-07-18 06:58:40,234 - logger.py:50 - Epoch: [405][0/6]	Total Loss: 0.74241	Main MSE (x10^-2): 74.2409	LR: 3.62e-05	EMPP_Raw: 1.46591
2025-07-18 06:58:54,008 - logger.py:50 - Epoch: [405][5/6]	Total Loss: 0.72685	Main MSE (x10^-2): 72.6853	LR: 3.62e-05	EMPP_Raw: 1.43674
2025-07-18 06:58:54,055 - logger.py:50 - Epoch 405 Training Summary: Avg Total Loss: 0.72685, Avg Main MSE: 0.72685, Time: 16.84s
2025-07-18 06:59:12,078 - logger.py:50 - Epoch 405 Summary | Train MSE (x10^-2): 72.6853 | Val MSE (x10^-2): 40.8399 | Time: 34.87s
2025-07-18 06:59:15,093 - logger.py:50 - Epoch: [406][0/6]	Total Loss: 0.72630	Main MSE (x10^-2): 72.6297	LR: 3.55e-05	EMPP_Raw: 1.43502
2025-07-18 06:59:28,941 - logger.py:50 - Epoch: [406][5/6]	Total Loss: 0.72559	Main MSE (x10^-2): 72.5586	LR: 3.55e-05	EMPP_Raw: 1.43404
2025-07-18 06:59:28,983 - logger.py:50 - Epoch 406 Training Summary: Avg Total Loss: 0.72559, Avg Main MSE: 0.72559, Time: 16.90s
2025-07-18 06:59:46,872 - logger.py:50 - Epoch 406 Summary | Train MSE (x10^-2): 72.5586 | Val MSE (x10^-2): 40.4380 | Time: 34.79s
2025-07-18 06:59:50,007 - logger.py:50 - Epoch: [407][0/6]	Total Loss: 0.71487	Main MSE (x10^-2): 71.4867	LR: 3.48e-05	EMPP_Raw: 1.41321
2025-07-18 07:00:03,722 - logger.py:50 - Epoch: [407][5/6]	Total Loss: 0.72869	Main MSE (x10^-2): 72.8692	LR: 3.48e-05	EMPP_Raw: 1.44057
2025-07-18 07:00:03,768 - logger.py:50 - Epoch 407 Training Summary: Avg Total Loss: 0.72869, Avg Main MSE: 0.72869, Time: 16.89s
2025-07-18 07:00:21,613 - logger.py:50 - Epoch 407 Summary | Train MSE (x10^-2): 72.8692 | Val MSE (x10^-2): 40.8062 | Time: 34.74s
2025-07-18 07:00:24,801 - logger.py:50 - Epoch: [408][0/6]	Total Loss: 0.75058	Main MSE (x10^-2): 75.0578	LR: 3.41e-05	EMPP_Raw: 1.48227
2025-07-18 07:00:38,509 - logger.py:50 - Epoch: [408][5/6]	Total Loss: 0.73207	Main MSE (x10^-2): 73.2067	LR: 3.41e-05	EMPP_Raw: 1.44616
2025-07-18 07:00:38,553 - logger.py:50 - Epoch 408 Training Summary: Avg Total Loss: 0.73207, Avg Main MSE: 0.73207, Time: 16.93s
2025-07-18 07:00:56,716 - logger.py:50 - Epoch 408 Summary | Train MSE (x10^-2): 73.2067 | Val MSE (x10^-2): 40.5787 | Time: 35.10s
2025-07-18 07:00:59,867 - logger.py:50 - Epoch: [409][0/6]	Total Loss: 0.71513	Main MSE (x10^-2): 71.5131	LR: 3.34e-05	EMPP_Raw: 1.41442
2025-07-18 07:01:13,645 - logger.py:50 - Epoch: [409][5/6]	Total Loss: 0.72553	Main MSE (x10^-2): 72.5525	LR: 3.34e-05	EMPP_Raw: 1.43465
2025-07-18 07:01:13,686 - logger.py:50 - Epoch 409 Training Summary: Avg Total Loss: 0.72553, Avg Main MSE: 0.72553, Time: 16.96s
2025-07-18 07:01:31,564 - logger.py:50 - Epoch 409 Summary | Train MSE (x10^-2): 72.5525 | Val MSE (x10^-2): 40.4943 | Time: 34.84s
2025-07-18 07:01:34,555 - logger.py:50 - Epoch: [410][0/6]	Total Loss: 0.75355	Main MSE (x10^-2): 75.3548	LR: 3.27e-05	EMPP_Raw: 1.49022
2025-07-18 07:01:48,496 - logger.py:50 - Epoch: [410][5/6]	Total Loss: 0.73912	Main MSE (x10^-2): 73.9118	LR: 3.27e-05	EMPP_Raw: 1.46108
2025-07-18 07:01:48,537 - logger.py:50 - Epoch 410 Training Summary: Avg Total Loss: 0.73912, Avg Main MSE: 0.73912, Time: 16.96s
2025-07-18 07:02:06,461 - logger.py:50 - Epoch 410 Summary | Train MSE (x10^-2): 73.9118 | Val MSE (x10^-2): 40.8596 | Time: 34.89s
2025-07-18 07:02:09,465 - logger.py:50 - Epoch: [411][0/6]	Total Loss: 0.74064	Main MSE (x10^-2): 74.0639	LR: 3.21e-05	EMPP_Raw: 1.46553
2025-07-18 07:02:23,277 - logger.py:50 - Epoch: [411][5/6]	Total Loss: 0.72578	Main MSE (x10^-2): 72.5782	LR: 3.21e-05	EMPP_Raw: 1.43452
2025-07-18 07:02:23,319 - logger.py:50 - Epoch 411 Training Summary: Avg Total Loss: 0.72578, Avg Main MSE: 0.72578, Time: 16.85s
2025-07-18 07:02:41,366 - logger.py:50 - Epoch 411 Summary | Train MSE (x10^-2): 72.5782 | Val MSE (x10^-2): 40.3906 | Time: 34.90s
2025-07-18 07:02:44,403 - logger.py:50 - Epoch: [412][0/6]	Total Loss: 0.72716	Main MSE (x10^-2): 72.7160	LR: 3.14e-05	EMPP_Raw: 1.43831
2025-07-18 07:02:58,344 - logger.py:50 - Epoch: [412][5/6]	Total Loss: 0.72566	Main MSE (x10^-2): 72.5662	LR: 3.14e-05	EMPP_Raw: 1.43487
2025-07-18 07:02:58,390 - logger.py:50 - Epoch 412 Training Summary: Avg Total Loss: 0.72566, Avg Main MSE: 0.72566, Time: 17.02s
2025-07-18 07:03:16,556 - logger.py:50 - Epoch 412 Summary | Train MSE (x10^-2): 72.5662 | Val MSE (x10^-2): 41.2297 | Time: 35.18s
2025-07-18 07:03:19,557 - logger.py:50 - Epoch: [413][0/6]	Total Loss: 0.74119	Main MSE (x10^-2): 74.1187	LR: 3.07e-05	EMPP_Raw: 1.46362
2025-07-18 07:03:33,334 - logger.py:50 - Epoch: [413][5/6]	Total Loss: 0.72610	Main MSE (x10^-2): 72.6101	LR: 3.07e-05	EMPP_Raw: 1.43556
2025-07-18 07:03:33,378 - logger.py:50 - Epoch 413 Training Summary: Avg Total Loss: 0.72610, Avg Main MSE: 0.72610, Time: 16.81s
2025-07-18 07:03:51,227 - logger.py:50 - Epoch 413 Summary | Train MSE (x10^-2): 72.6101 | Val MSE (x10^-2): 40.5724 | Time: 34.67s
2025-07-18 07:03:54,362 - logger.py:50 - Epoch: [414][0/6]	Total Loss: 0.71209	Main MSE (x10^-2): 71.2090	LR: 3.01e-05	EMPP_Raw: 1.40856
2025-07-18 07:04:08,071 - logger.py:50 - Epoch: [414][5/6]	Total Loss: 0.72166	Main MSE (x10^-2): 72.1664	LR: 3.01e-05	EMPP_Raw: 1.42735
2025-07-18 07:04:08,115 - logger.py:50 - Epoch 414 Training Summary: Avg Total Loss: 0.72166, Avg Main MSE: 0.72166, Time: 16.88s
2025-07-18 07:04:25,997 - logger.py:50 - Epoch 414 Summary | Train MSE (x10^-2): 72.1664 | Val MSE (x10^-2): 40.6270 | Time: 34.76s
2025-07-18 07:04:29,209 - logger.py:50 - Epoch: [415][0/6]	Total Loss: 0.70386	Main MSE (x10^-2): 70.3861	LR: 2.94e-05	EMPP_Raw: 1.39104
2025-07-18 07:04:42,940 - logger.py:50 - Epoch: [415][5/6]	Total Loss: 0.71784	Main MSE (x10^-2): 71.7844	LR: 2.94e-05	EMPP_Raw: 1.41910
2025-07-18 07:04:42,985 - logger.py:50 - Epoch 415 Training Summary: Avg Total Loss: 0.71784, Avg Main MSE: 0.71784, Time: 16.98s
2025-07-18 07:05:00,878 - logger.py:50 - Epoch 415 Summary | Train MSE (x10^-2): 71.7844 | Val MSE (x10^-2): 40.7541 | Time: 34.88s
2025-07-18 07:05:03,860 - logger.py:50 - Epoch: [416][0/6]	Total Loss: 0.71104	Main MSE (x10^-2): 71.1039	LR: 2.88e-05	EMPP_Raw: 1.40600
2025-07-18 07:05:17,775 - logger.py:50 - Epoch: [416][5/6]	Total Loss: 0.72764	Main MSE (x10^-2): 72.7638	LR: 2.88e-05	EMPP_Raw: 1.43930
2025-07-18 07:05:17,818 - logger.py:50 - Epoch 416 Training Summary: Avg Total Loss: 0.72764, Avg Main MSE: 0.72764, Time: 16.93s
2025-07-18 07:05:35,821 - logger.py:50 - Epoch 416 Summary | Train MSE (x10^-2): 72.7638 | Val MSE (x10^-2): 40.5892 | Time: 34.94s
2025-07-18 07:05:38,875 - logger.py:50 - Epoch: [417][0/6]	Total Loss: 0.73206	Main MSE (x10^-2): 73.2061	LR: 2.81e-05	EMPP_Raw: 1.44847
2025-07-18 07:05:52,855 - logger.py:50 - Epoch: [417][5/6]	Total Loss: 0.72220	Main MSE (x10^-2): 72.2202	LR: 2.81e-05	EMPP_Raw: 1.42745
2025-07-18 07:05:52,902 - logger.py:50 - Epoch 417 Training Summary: Avg Total Loss: 0.72220, Avg Main MSE: 0.72220, Time: 17.07s
2025-07-18 07:06:10,749 - logger.py:50 - Epoch 417 Summary | Train MSE (x10^-2): 72.2202 | Val MSE (x10^-2): 40.8812 | Time: 34.92s
2025-07-18 07:06:13,735 - logger.py:50 - Epoch: [418][0/6]	Total Loss: 0.71646	Main MSE (x10^-2): 71.6457	LR: 2.75e-05	EMPP_Raw: 1.41785
2025-07-18 07:06:27,527 - logger.py:50 - Epoch: [418][5/6]	Total Loss: 0.72000	Main MSE (x10^-2): 72.0003	LR: 2.75e-05	EMPP_Raw: 1.42378
2025-07-18 07:06:27,571 - logger.py:50 - Epoch 418 Training Summary: Avg Total Loss: 0.72000, Avg Main MSE: 0.72000, Time: 16.81s
2025-07-18 07:06:45,697 - logger.py:50 - Epoch 418 Summary | Train MSE (x10^-2): 72.0003 | Val MSE (x10^-2): 40.7972 | Time: 34.94s
2025-07-18 07:06:48,693 - logger.py:50 - Epoch: [419][0/6]	Total Loss: 0.72224	Main MSE (x10^-2): 72.2244	LR: 2.69e-05	EMPP_Raw: 1.42729
2025-07-18 07:07:02,467 - logger.py:50 - Epoch: [419][5/6]	Total Loss: 0.73081	Main MSE (x10^-2): 73.0813	LR: 2.69e-05	EMPP_Raw: 1.44495
2025-07-18 07:07:02,512 - logger.py:50 - Epoch 419 Training Summary: Avg Total Loss: 0.73081, Avg Main MSE: 0.73081, Time: 16.81s
2025-07-18 07:07:20,389 - logger.py:50 - Epoch 419 Summary | Train MSE (x10^-2): 73.0813 | Val MSE (x10^-2): 40.4912 | Time: 34.69s
2025-07-18 07:07:23,525 - logger.py:50 - Epoch: [420][0/6]	Total Loss: 0.71597	Main MSE (x10^-2): 71.5975	LR: 2.63e-05	EMPP_Raw: 1.41579
2025-07-18 07:07:37,249 - logger.py:50 - Epoch: [420][5/6]	Total Loss: 0.73145	Main MSE (x10^-2): 73.1449	LR: 2.63e-05	EMPP_Raw: 1.44639
2025-07-18 07:07:37,292 - logger.py:50 - Epoch 420 Training Summary: Avg Total Loss: 0.73145, Avg Main MSE: 0.73145, Time: 16.90s
2025-07-18 07:07:55,120 - logger.py:50 - Epoch 420 Summary | Train MSE (x10^-2): 73.1449 | Val MSE (x10^-2): 40.6361 | Time: 34.73s
2025-07-18 07:07:58,302 - logger.py:50 - Epoch: [421][0/6]	Total Loss: 0.71119	Main MSE (x10^-2): 71.1190	LR: 2.57e-05	EMPP_Raw: 1.40555
2025-07-18 07:08:12,057 - logger.py:50 - Epoch: [421][5/6]	Total Loss: 0.71953	Main MSE (x10^-2): 71.9525	LR: 2.57e-05	EMPP_Raw: 1.42258
2025-07-18 07:08:12,105 - logger.py:50 - Epoch 421 Training Summary: Avg Total Loss: 0.71953, Avg Main MSE: 0.71953, Time: 16.97s
2025-07-18 07:08:29,975 - logger.py:50 - Epoch 421 Summary | Train MSE (x10^-2): 71.9525 | Val MSE (x10^-2): 40.4010 | Time: 34.85s
2025-07-18 07:08:33,143 - logger.py:50 - Epoch: [422][0/6]	Total Loss: 0.72017	Main MSE (x10^-2): 72.0167	LR: 2.51e-05	EMPP_Raw: 1.42218
2025-07-18 07:08:46,914 - logger.py:50 - Epoch: [422][5/6]	Total Loss: 0.71872	Main MSE (x10^-2): 71.8722	LR: 2.51e-05	EMPP_Raw: 1.42142
2025-07-18 07:08:46,957 - logger.py:50 - Epoch 422 Training Summary: Avg Total Loss: 0.71872, Avg Main MSE: 0.71872, Time: 16.97s
2025-07-18 07:09:04,885 - logger.py:50 - Epoch 422 Summary | Train MSE (x10^-2): 71.8722 | Val MSE (x10^-2): 40.7788 | Time: 34.90s
2025-07-18 07:09:07,874 - logger.py:50 - Epoch: [423][0/6]	Total Loss: 0.71981	Main MSE (x10^-2): 71.9811	LR: 2.45e-05	EMPP_Raw: 1.42463
2025-07-18 07:09:21,824 - logger.py:50 - Epoch: [423][5/6]	Total Loss: 0.72308	Main MSE (x10^-2): 72.3081	LR: 2.45e-05	EMPP_Raw: 1.43010
2025-07-18 07:09:21,865 - logger.py:50 - Epoch 423 Training Summary: Avg Total Loss: 0.72308, Avg Main MSE: 0.72308, Time: 16.97s
2025-07-18 07:09:39,760 - logger.py:50 - Epoch 423 Summary | Train MSE (x10^-2): 72.3081 | Val MSE (x10^-2): 40.3484 | Time: 34.87s
2025-07-18 07:09:42,754 - logger.py:50 - Epoch: [424][0/6]	Total Loss: 0.70756	Main MSE (x10^-2): 70.7563	LR: 2.39e-05	EMPP_Raw: 1.39863
2025-07-18 07:09:56,531 - logger.py:50 - Epoch: [424][5/6]	Total Loss: 0.72778	Main MSE (x10^-2): 72.7776	LR: 2.39e-05	EMPP_Raw: 1.43884
2025-07-18 07:09:56,584 - logger.py:50 - Epoch 424 Training Summary: Avg Total Loss: 0.72778, Avg Main MSE: 0.72778, Time: 16.81s
2025-07-18 07:10:14,542 - logger.py:50 - Epoch 424 Summary | Train MSE (x10^-2): 72.7776 | Val MSE (x10^-2): 40.7981 | Time: 34.78s
2025-07-18 07:10:17,541 - logger.py:50 - Epoch: [425][0/6]	Total Loss: 0.72529	Main MSE (x10^-2): 72.5288	LR: 2.33e-05	EMPP_Raw: 1.43448
2025-07-18 07:10:31,385 - logger.py:50 - Epoch: [425][5/6]	Total Loss: 0.71519	Main MSE (x10^-2): 71.5193	LR: 2.33e-05	EMPP_Raw: 1.41430
2025-07-18 07:10:31,425 - logger.py:50 - Epoch 425 Training Summary: Avg Total Loss: 0.71519, Avg Main MSE: 0.71519, Time: 16.87s
2025-07-18 07:10:49,382 - logger.py:50 - Epoch 425 Summary | Train MSE (x10^-2): 71.5193 | Val MSE (x10^-2): 40.5152 | Time: 34.83s
2025-07-18 07:10:52,373 - logger.py:50 - Epoch: [426][0/6]	Total Loss: 0.71848	Main MSE (x10^-2): 71.8482	LR: 2.27e-05	EMPP_Raw: 1.41962
2025-07-18 07:11:06,162 - logger.py:50 - Epoch: [426][5/6]	Total Loss: 0.71941	Main MSE (x10^-2): 71.9412	LR: 2.27e-05	EMPP_Raw: 1.42307
2025-07-18 07:11:06,210 - logger.py:50 - Epoch 426 Training Summary: Avg Total Loss: 0.71941, Avg Main MSE: 0.71941, Time: 16.82s
2025-07-18 07:11:24,063 - logger.py:50 - Epoch 426 Summary | Train MSE (x10^-2): 71.9412 | Val MSE (x10^-2): 40.7712 | Time: 34.68s
2025-07-18 07:11:27,220 - logger.py:50 - Epoch: [427][0/6]	Total Loss: 0.73517	Main MSE (x10^-2): 73.5167	LR: 2.22e-05	EMPP_Raw: 1.45424
2025-07-18 07:11:41,031 - logger.py:50 - Epoch: [427][5/6]	Total Loss: 0.71760	Main MSE (x10^-2): 71.7597	LR: 2.22e-05	EMPP_Raw: 1.41931
2025-07-18 07:11:41,075 - logger.py:50 - Epoch 427 Training Summary: Avg Total Loss: 0.71760, Avg Main MSE: 0.71760, Time: 17.00s
2025-07-18 07:11:59,004 - logger.py:50 - Epoch 427 Summary | Train MSE (x10^-2): 71.7597 | Val MSE (x10^-2): 40.8603 | Time: 34.93s
2025-07-18 07:12:02,165 - logger.py:50 - Epoch: [428][0/6]	Total Loss: 0.71901	Main MSE (x10^-2): 71.9006	LR: 2.16e-05	EMPP_Raw: 1.42280
2025-07-18 07:12:15,926 - logger.py:50 - Epoch: [428][5/6]	Total Loss: 0.73035	Main MSE (x10^-2): 73.0352	LR: 2.16e-05	EMPP_Raw: 1.44458
2025-07-18 07:12:15,969 - logger.py:50 - Epoch 428 Training Summary: Avg Total Loss: 0.73035, Avg Main MSE: 0.73035, Time: 16.95s
2025-07-18 07:12:33,886 - logger.py:50 - Epoch 428 Summary | Train MSE (x10^-2): 73.0352 | Val MSE (x10^-2): 40.7155 | Time: 34.88s
2025-07-18 07:12:36,939 - logger.py:50 - Epoch: [429][0/6]	Total Loss: 0.70533	Main MSE (x10^-2): 70.5333	LR: 2.11e-05	EMPP_Raw: 1.39556
2025-07-18 07:12:50,859 - logger.py:50 - Epoch: [429][5/6]	Total Loss: 0.71146	Main MSE (x10^-2): 71.1456	LR: 2.11e-05	EMPP_Raw: 1.40667
2025-07-18 07:12:50,903 - logger.py:50 - Epoch 429 Training Summary: Avg Total Loss: 0.71146, Avg Main MSE: 0.71146, Time: 17.01s
2025-07-18 07:13:08,862 - logger.py:50 - Epoch 429 Summary | Train MSE (x10^-2): 71.1456 | Val MSE (x10^-2): 40.5831 | Time: 34.97s
2025-07-18 07:13:11,900 - logger.py:50 - Epoch: [430][0/6]	Total Loss: 0.75368	Main MSE (x10^-2): 75.3680	LR: 2.05e-05	EMPP_Raw: 1.49083
2025-07-18 07:13:25,806 - logger.py:50 - Epoch: [430][5/6]	Total Loss: 0.72361	Main MSE (x10^-2): 72.3610	LR: 2.05e-05	EMPP_Raw: 1.43102
2025-07-18 07:13:25,850 - logger.py:50 - Epoch 430 Training Summary: Avg Total Loss: 0.72361, Avg Main MSE: 0.72361, Time: 16.98s
2025-07-18 07:13:43,658 - logger.py:50 - Epoch 430 Summary | Train MSE (x10^-2): 72.3610 | Val MSE (x10^-2): 40.7036 | Time: 34.79s
2025-07-18 07:13:46,644 - logger.py:50 - Epoch: [431][0/6]	Total Loss: 0.72234	Main MSE (x10^-2): 72.2340	LR: 2.00e-05	EMPP_Raw: 1.42728
2025-07-18 07:14:00,400 - logger.py:50 - Epoch: [431][5/6]	Total Loss: 0.72978	Main MSE (x10^-2): 72.9779	LR: 2.00e-05	EMPP_Raw: 1.44262
2025-07-18 07:14:00,441 - logger.py:50 - Epoch 431 Training Summary: Avg Total Loss: 0.72978, Avg Main MSE: 0.72978, Time: 16.77s
2025-07-18 07:14:18,394 - logger.py:50 - Epoch 431 Summary | Train MSE (x10^-2): 72.9779 | Val MSE (x10^-2): 40.4167 | Time: 34.73s
2025-07-18 07:14:21,391 - logger.py:50 - Epoch: [432][0/6]	Total Loss: 0.71593	Main MSE (x10^-2): 71.5934	LR: 1.95e-05	EMPP_Raw: 1.41464
2025-07-18 07:14:35,182 - logger.py:50 - Epoch: [432][5/6]	Total Loss: 0.72328	Main MSE (x10^-2): 72.3277	LR: 1.95e-05	EMPP_Raw: 1.43063
2025-07-18 07:14:35,229 - logger.py:50 - Epoch 432 Training Summary: Avg Total Loss: 0.72328, Avg Main MSE: 0.72328, Time: 16.83s
2025-07-18 07:14:53,100 - logger.py:50 - Epoch 432 Summary | Train MSE (x10^-2): 72.3277 | Val MSE (x10^-2): 40.3846 | Time: 34.70s
2025-07-18 07:14:56,249 - logger.py:50 - Epoch: [433][0/6]	Total Loss: 0.74459	Main MSE (x10^-2): 74.4586	LR: 1.89e-05	EMPP_Raw: 1.47185
2025-07-18 07:15:10,033 - logger.py:50 - Epoch: [433][5/6]	Total Loss: 0.72536	Main MSE (x10^-2): 72.5362	LR: 1.89e-05	EMPP_Raw: 1.43422
2025-07-18 07:15:10,074 - logger.py:50 - Epoch 433 Training Summary: Avg Total Loss: 0.72536, Avg Main MSE: 0.72536, Time: 16.96s
2025-07-18 07:15:28,095 - logger.py:50 - Epoch 433 Summary | Train MSE (x10^-2): 72.5362 | Val MSE (x10^-2): 40.6527 | Time: 34.99s
2025-07-18 07:15:31,240 - logger.py:50 - Epoch: [434][0/6]	Total Loss: 0.71979	Main MSE (x10^-2): 71.9788	LR: 1.84e-05	EMPP_Raw: 1.42409
2025-07-18 07:15:45,057 - logger.py:50 - Epoch: [434][5/6]	Total Loss: 0.72294	Main MSE (x10^-2): 72.2936	LR: 1.84e-05	EMPP_Raw: 1.42961
2025-07-18 07:15:45,097 - logger.py:50 - Epoch 434 Training Summary: Avg Total Loss: 0.72294, Avg Main MSE: 0.72294, Time: 16.99s
2025-07-18 07:16:03,021 - logger.py:50 - Epoch 434 Summary | Train MSE (x10^-2): 72.2936 | Val MSE (x10^-2): 40.4905 | Time: 34.92s
2025-07-18 07:16:06,190 - logger.py:50 - Epoch: [435][0/6]	Total Loss: 0.73190	Main MSE (x10^-2): 73.1899	LR: 1.79e-05	EMPP_Raw: 1.44812
2025-07-18 07:16:20,018 - logger.py:50 - Epoch: [435][5/6]	Total Loss: 0.72985	Main MSE (x10^-2): 72.9846	LR: 1.79e-05	EMPP_Raw: 1.44306
2025-07-18 07:16:20,061 - logger.py:50 - Epoch 435 Training Summary: Avg Total Loss: 0.72985, Avg Main MSE: 0.72985, Time: 17.03s
2025-07-18 07:16:38,033 - logger.py:50 - Epoch 435 Summary | Train MSE (x10^-2): 72.9846 | Val MSE (x10^-2): 40.5942 | Time: 35.01s
2025-07-18 07:16:41,015 - logger.py:50 - Epoch: [436][0/6]	Total Loss: 0.71540	Main MSE (x10^-2): 71.5398	LR: 1.74e-05	EMPP_Raw: 1.41441
2025-07-18 07:16:54,959 - logger.py:50 - Epoch: [436][5/6]	Total Loss: 0.73030	Main MSE (x10^-2): 73.0300	LR: 1.74e-05	EMPP_Raw: 1.44436
2025-07-18 07:16:55,003 - logger.py:50 - Epoch 436 Training Summary: Avg Total Loss: 0.73030, Avg Main MSE: 0.73030, Time: 16.96s
2025-07-18 07:17:12,862 - logger.py:50 - Epoch 436 Summary | Train MSE (x10^-2): 73.0300 | Val MSE (x10^-2): 40.6423 | Time: 34.83s
2025-07-18 07:17:15,848 - logger.py:50 - Epoch: [437][0/6]	Total Loss: 0.71399	Main MSE (x10^-2): 71.3989	LR: 1.69e-05	EMPP_Raw: 1.41224
2025-07-18 07:17:29,646 - logger.py:50 - Epoch: [437][5/6]	Total Loss: 0.72079	Main MSE (x10^-2): 72.0790	LR: 1.69e-05	EMPP_Raw: 1.42569
2025-07-18 07:17:29,689 - logger.py:50 - Epoch 437 Training Summary: Avg Total Loss: 0.72079, Avg Main MSE: 0.72079, Time: 16.82s
2025-07-18 07:17:47,849 - logger.py:50 - Epoch 437 Summary | Train MSE (x10^-2): 72.0790 | Val MSE (x10^-2): 40.8846 | Time: 34.98s
2025-07-18 07:17:50,849 - logger.py:50 - Epoch: [438][0/6]	Total Loss: 0.74220	Main MSE (x10^-2): 74.2204	LR: 1.64e-05	EMPP_Raw: 1.46931
2025-07-18 07:18:04,695 - logger.py:50 - Epoch: [438][5/6]	Total Loss: 0.72604	Main MSE (x10^-2): 72.6035	LR: 1.64e-05	EMPP_Raw: 1.43568
2025-07-18 07:18:04,742 - logger.py:50 - Epoch 438 Training Summary: Avg Total Loss: 0.72604, Avg Main MSE: 0.72604, Time: 16.88s
2025-07-18 07:18:22,929 - logger.py:50 - Epoch 438 Summary | Train MSE (x10^-2): 72.6035 | Val MSE (x10^-2): 40.9024 | Time: 35.07s
2025-07-18 07:18:25,926 - logger.py:50 - Epoch: [439][0/6]	Total Loss: 0.70883	Main MSE (x10^-2): 70.8829	LR: 1.59e-05	EMPP_Raw: 1.40085
2025-07-18 07:18:39,740 - logger.py:50 - Epoch: [439][5/6]	Total Loss: 0.72816	Main MSE (x10^-2): 72.8165	LR: 1.59e-05	EMPP_Raw: 1.44059
2025-07-18 07:18:39,784 - logger.py:50 - Epoch 439 Training Summary: Avg Total Loss: 0.72816, Avg Main MSE: 0.72816, Time: 16.85s
2025-07-18 07:18:57,778 - logger.py:50 - Epoch 439 Summary | Train MSE (x10^-2): 72.8165 | Val MSE (x10^-2): 40.7573 | Time: 34.85s
2025-07-18 07:19:00,993 - logger.py:50 - Epoch: [440][0/6]	Total Loss: 0.71747	Main MSE (x10^-2): 71.7466	LR: 1.55e-05	EMPP_Raw: 1.41877
2025-07-18 07:19:14,772 - logger.py:50 - Epoch: [440][5/6]	Total Loss: 0.72555	Main MSE (x10^-2): 72.5552	LR: 1.55e-05	EMPP_Raw: 1.43497
2025-07-18 07:19:14,823 - logger.py:50 - Epoch 440 Training Summary: Avg Total Loss: 0.72555, Avg Main MSE: 0.72555, Time: 17.04s
2025-07-18 07:19:32,859 - logger.py:50 - Epoch 440 Summary | Train MSE (x10^-2): 72.5552 | Val MSE (x10^-2): 40.5931 | Time: 35.08s
2025-07-18 07:19:36,030 - logger.py:50 - Epoch: [441][0/6]	Total Loss: 0.70674	Main MSE (x10^-2): 70.6742	LR: 1.50e-05	EMPP_Raw: 1.39721
2025-07-18 07:19:49,841 - logger.py:50 - Epoch: [441][5/6]	Total Loss: 0.71691	Main MSE (x10^-2): 71.6913	LR: 1.50e-05	EMPP_Raw: 1.41677
2025-07-18 07:19:49,882 - logger.py:50 - Epoch 441 Training Summary: Avg Total Loss: 0.71691, Avg Main MSE: 0.71691, Time: 17.01s
2025-07-18 07:20:07,857 - logger.py:50 - Epoch 441 Summary | Train MSE (x10^-2): 71.6913 | Val MSE (x10^-2): 40.6748 | Time: 34.99s
2025-07-18 07:20:10,875 - logger.py:50 - Epoch: [442][0/6]	Total Loss: 0.75019	Main MSE (x10^-2): 75.0191	LR: 1.46e-05	EMPP_Raw: 1.48449
2025-07-18 07:20:24,860 - logger.py:50 - Epoch: [442][5/6]	Total Loss: 0.73250	Main MSE (x10^-2): 73.2501	LR: 1.46e-05	EMPP_Raw: 1.44870
2025-07-18 07:20:24,903 - logger.py:50 - Epoch 442 Training Summary: Avg Total Loss: 0.73250, Avg Main MSE: 0.73250, Time: 17.04s
2025-07-18 07:20:42,761 - logger.py:50 - Epoch 442 Summary | Train MSE (x10^-2): 73.2501 | Val MSE (x10^-2): 40.8106 | Time: 34.90s
2025-07-18 07:20:45,758 - logger.py:50 - Epoch: [443][0/6]	Total Loss: 0.73379	Main MSE (x10^-2): 73.3792	LR: 1.41e-05	EMPP_Raw: 1.45159
2025-07-18 07:20:59,725 - logger.py:50 - Epoch: [443][5/6]	Total Loss: 0.72897	Main MSE (x10^-2): 72.8967	LR: 1.41e-05	EMPP_Raw: 1.44215
2025-07-18 07:20:59,768 - logger.py:50 - Epoch 443 Training Summary: Avg Total Loss: 0.72897, Avg Main MSE: 0.72897, Time: 17.00s
2025-07-18 07:21:17,633 - logger.py:50 - Epoch 443 Summary | Train MSE (x10^-2): 72.8967 | Val MSE (x10^-2): 40.6043 | Time: 34.87s
2025-07-18 07:21:20,673 - logger.py:50 - Epoch: [444][0/6]	Total Loss: 0.72747	Main MSE (x10^-2): 72.7475	LR: 1.37e-05	EMPP_Raw: 1.43942
2025-07-18 07:21:34,391 - logger.py:50 - Epoch: [444][5/6]	Total Loss: 0.72021	Main MSE (x10^-2): 72.0208	LR: 1.37e-05	EMPP_Raw: 1.42451
2025-07-18 07:21:34,434 - logger.py:50 - Epoch 444 Training Summary: Avg Total Loss: 0.72021, Avg Main MSE: 0.72021, Time: 16.79s
2025-07-18 07:21:52,457 - logger.py:50 - Epoch 444 Summary | Train MSE (x10^-2): 72.0208 | Val MSE (x10^-2): 40.6472 | Time: 34.82s
2025-07-18 07:21:55,447 - logger.py:50 - Epoch: [445][0/6]	Total Loss: 0.73722	Main MSE (x10^-2): 73.7219	LR: 1.32e-05	EMPP_Raw: 1.46040
2025-07-18 07:22:09,227 - logger.py:50 - Epoch: [445][5/6]	Total Loss: 0.72055	Main MSE (x10^-2): 72.0547	LR: 1.32e-05	EMPP_Raw: 1.42543
2025-07-18 07:22:09,269 - logger.py:50 - Epoch 445 Training Summary: Avg Total Loss: 0.72055, Avg Main MSE: 0.72055, Time: 16.80s
2025-07-18 07:22:27,145 - logger.py:50 - Epoch 445 Summary | Train MSE (x10^-2): 72.0547 | Val MSE (x10^-2): 40.7456 | Time: 34.68s
2025-07-18 07:22:30,309 - logger.py:50 - Epoch: [446][0/6]	Total Loss: 0.74109	Main MSE (x10^-2): 74.1092	LR: 1.28e-05	EMPP_Raw: 1.46676
2025-07-18 07:22:44,137 - logger.py:50 - Epoch: [446][5/6]	Total Loss: 0.72502	Main MSE (x10^-2): 72.5016	LR: 1.28e-05	EMPP_Raw: 1.43430
2025-07-18 07:22:44,186 - logger.py:50 - Epoch 446 Training Summary: Avg Total Loss: 0.72502, Avg Main MSE: 0.72502, Time: 17.03s
2025-07-18 07:23:02,111 - logger.py:50 - Epoch 446 Summary | Train MSE (x10^-2): 72.5016 | Val MSE (x10^-2): 40.6079 | Time: 34.96s
2025-07-18 07:23:05,265 - logger.py:50 - Epoch: [447][0/6]	Total Loss: 0.71123	Main MSE (x10^-2): 71.1231	LR: 1.24e-05	EMPP_Raw: 1.40707
2025-07-18 07:23:19,016 - logger.py:50 - Epoch: [447][5/6]	Total Loss: 0.72797	Main MSE (x10^-2): 72.7967	LR: 1.24e-05	EMPP_Raw: 1.43984
2025-07-18 07:23:19,061 - logger.py:50 - Epoch 447 Training Summary: Avg Total Loss: 0.72797, Avg Main MSE: 0.72797, Time: 16.94s
2025-07-18 07:23:37,021 - logger.py:50 - Epoch 447 Summary | Train MSE (x10^-2): 72.7967 | Val MSE (x10^-2): 40.5996 | Time: 34.90s
2025-07-18 07:23:40,186 - logger.py:50 - Epoch: [448][0/6]	Total Loss: 0.72276	Main MSE (x10^-2): 72.2762	LR: 1.20e-05	EMPP_Raw: 1.42971
2025-07-18 07:23:54,027 - logger.py:50 - Epoch: [448][5/6]	Total Loss: 0.71505	Main MSE (x10^-2): 71.5051	LR: 1.20e-05	EMPP_Raw: 1.41392
2025-07-18 07:23:54,072 - logger.py:50 - Epoch 448 Training Summary: Avg Total Loss: 0.71505, Avg Main MSE: 0.71505, Time: 17.04s
2025-07-18 07:24:11,885 - logger.py:50 - Epoch 448 Summary | Train MSE (x10^-2): 71.5051 | Val MSE (x10^-2): 40.3704 | Time: 34.86s
2025-07-18 07:24:14,885 - logger.py:50 - Epoch: [449][0/6]	Total Loss: 0.70379	Main MSE (x10^-2): 70.3792	LR: 1.16e-05	EMPP_Raw: 1.39188
2025-07-18 07:24:28,846 - logger.py:50 - Epoch: [449][5/6]	Total Loss: 0.72041	Main MSE (x10^-2): 72.0415	LR: 1.16e-05	EMPP_Raw: 1.42469
2025-07-18 07:24:28,892 - logger.py:50 - Epoch 449 Training Summary: Avg Total Loss: 0.72041, Avg Main MSE: 0.72041, Time: 17.00s
2025-07-18 07:24:46,851 - logger.py:50 - Epoch 449 Summary | Train MSE (x10^-2): 72.0415 | Val MSE (x10^-2): 40.6046 | Time: 34.96s
2025-07-18 07:24:49,842 - logger.py:50 - Epoch: [450][0/6]	Total Loss: 0.72458	Main MSE (x10^-2): 72.4581	LR: 1.12e-05	EMPP_Raw: 1.43219
2025-07-18 07:25:03,610 - logger.py:50 - Epoch: [450][5/6]	Total Loss: 0.72523	Main MSE (x10^-2): 72.5233	LR: 1.12e-05	EMPP_Raw: 1.43430
2025-07-18 07:25:03,653 - logger.py:50 - Epoch 450 Training Summary: Avg Total Loss: 0.72523, Avg Main MSE: 0.72523, Time: 16.79s
2025-07-18 07:25:21,727 - logger.py:50 - Epoch 450 Summary | Train MSE (x10^-2): 72.5233 | Val MSE (x10^-2): 40.7141 | Time: 34.87s
2025-07-18 07:25:24,717 - logger.py:50 - Epoch: [451][0/6]	Total Loss: 0.73818	Main MSE (x10^-2): 73.8179	LR: 1.08e-05	EMPP_Raw: 1.45981
2025-07-18 07:25:38,462 - logger.py:50 - Epoch: [451][5/6]	Total Loss: 0.71906	Main MSE (x10^-2): 71.9061	LR: 1.08e-05	EMPP_Raw: 1.42225
2025-07-18 07:25:38,506 - logger.py:50 - Epoch 451 Training Summary: Avg Total Loss: 0.71906, Avg Main MSE: 0.71906, Time: 16.77s
2025-07-18 07:25:56,674 - logger.py:50 - Epoch 451 Summary | Train MSE (x10^-2): 71.9061 | Val MSE (x10^-2): 40.5342 | Time: 34.94s
2025-07-18 07:25:59,700 - logger.py:50 - Epoch: [452][0/6]	Total Loss: 0.73530	Main MSE (x10^-2): 73.5299	LR: 1.04e-05	EMPP_Raw: 1.45421
2025-07-18 07:26:13,517 - logger.py:50 - Epoch: [452][5/6]	Total Loss: 0.72933	Main MSE (x10^-2): 72.9325	LR: 1.04e-05	EMPP_Raw: 1.44358
2025-07-18 07:26:13,561 - logger.py:50 - Epoch 452 Training Summary: Avg Total Loss: 0.72933, Avg Main MSE: 0.72933, Time: 16.88s
2025-07-18 07:26:31,454 - logger.py:50 - Epoch 452 Summary | Train MSE (x10^-2): 72.9325 | Val MSE (x10^-2): 40.5302 | Time: 34.77s
2025-07-18 07:26:34,600 - logger.py:50 - Epoch: [453][0/6]	Total Loss: 0.74689	Main MSE (x10^-2): 74.6891	LR: 1.00e-05	EMPP_Raw: 1.47708
2025-07-18 07:26:48,327 - logger.py:50 - Epoch: [453][5/6]	Total Loss: 0.72731	Main MSE (x10^-2): 72.7310	LR: 1.00e-05	EMPP_Raw: 1.43873
2025-07-18 07:26:48,367 - logger.py:50 - Epoch 453 Training Summary: Avg Total Loss: 0.72731, Avg Main MSE: 0.72731, Time: 16.90s
2025-07-18 07:27:06,415 - logger.py:50 - Epoch 453 Summary | Train MSE (x10^-2): 72.7310 | Val MSE (x10^-2): 40.6977 | Time: 34.96s
2025-07-18 07:27:09,581 - logger.py:50 - Epoch: [454][0/6]	Total Loss: 0.72183	Main MSE (x10^-2): 72.1834	LR: 9.64e-06	EMPP_Raw: 1.42801
2025-07-18 07:27:23,301 - logger.py:50 - Epoch: [454][5/6]	Total Loss: 0.71852	Main MSE (x10^-2): 71.8520	LR: 9.64e-06	EMPP_Raw: 1.42144
2025-07-18 07:27:23,349 - logger.py:50 - Epoch 454 Training Summary: Avg Total Loss: 0.71852, Avg Main MSE: 0.71852, Time: 16.92s
2025-07-18 07:27:41,223 - logger.py:50 - Epoch 454 Summary | Train MSE (x10^-2): 71.8520 | Val MSE (x10^-2): 40.6582 | Time: 34.80s
2025-07-18 07:27:44,219 - logger.py:50 - Epoch: [455][0/6]	Total Loss: 0.70669	Main MSE (x10^-2): 70.6693	LR: 9.27e-06	EMPP_Raw: 1.39752
2025-07-18 07:27:58,186 - logger.py:50 - Epoch: [455][5/6]	Total Loss: 0.71266	Main MSE (x10^-2): 71.2662	LR: 9.27e-06	EMPP_Raw: 1.40945
2025-07-18 07:27:58,233 - logger.py:50 - Epoch 455 Training Summary: Avg Total Loss: 0.71266, Avg Main MSE: 0.71266, Time: 17.00s
2025-07-18 07:28:16,158 - logger.py:50 - Epoch 455 Summary | Train MSE (x10^-2): 71.2662 | Val MSE (x10^-2): 40.5261 | Time: 34.93s
2025-07-18 07:28:19,165 - logger.py:50 - Epoch: [456][0/6]	Total Loss: 0.72218	Main MSE (x10^-2): 72.2175	LR: 8.92e-06	EMPP_Raw: 1.42939
2025-07-18 07:28:33,062 - logger.py:50 - Epoch: [456][5/6]	Total Loss: 0.72748	Main MSE (x10^-2): 72.7482	LR: 8.92e-06	EMPP_Raw: 1.43916
2025-07-18 07:28:33,105 - logger.py:50 - Epoch 456 Training Summary: Avg Total Loss: 0.72748, Avg Main MSE: 0.72748, Time: 16.94s
2025-07-18 07:28:50,956 - logger.py:50 - Epoch 456 Summary | Train MSE (x10^-2): 72.7482 | Val MSE (x10^-2): 40.6404 | Time: 34.79s
2025-07-18 07:28:53,949 - logger.py:50 - Epoch: [457][0/6]	Total Loss: 0.73253	Main MSE (x10^-2): 73.2530	LR: 8.58e-06	EMPP_Raw: 1.45066
2025-07-18 07:29:07,730 - logger.py:50 - Epoch: [457][5/6]	Total Loss: 0.72364	Main MSE (x10^-2): 72.3638	LR: 8.58e-06	EMPP_Raw: 1.43242
2025-07-18 07:29:07,777 - logger.py:50 - Epoch 457 Training Summary: Avg Total Loss: 0.72364, Avg Main MSE: 0.72364, Time: 16.81s
2025-07-18 07:29:25,769 - logger.py:50 - Epoch 457 Summary | Train MSE (x10^-2): 72.3638 | Val MSE (x10^-2): 40.6568 | Time: 34.81s
2025-07-18 07:29:28,751 - logger.py:50 - Epoch: [458][0/6]	Total Loss: 0.71639	Main MSE (x10^-2): 71.6390	LR: 8.24e-06	EMPP_Raw: 1.41722
2025-07-18 07:29:42,509 - logger.py:50 - Epoch: [458][5/6]	Total Loss: 0.72335	Main MSE (x10^-2): 72.3351	LR: 8.24e-06	EMPP_Raw: 1.43083
2025-07-18 07:29:42,569 - logger.py:50 - Epoch 458 Training Summary: Avg Total Loss: 0.72335, Avg Main MSE: 0.72335, Time: 16.79s
2025-07-18 07:30:00,516 - logger.py:50 - Epoch 458 Summary | Train MSE (x10^-2): 72.3351 | Val MSE (x10^-2): 40.5040 | Time: 34.74s
2025-07-18 07:30:03,660 - logger.py:50 - Epoch: [459][0/6]	Total Loss: 0.72798	Main MSE (x10^-2): 72.7985	LR: 7.91e-06	EMPP_Raw: 1.43938
2025-07-18 07:30:17,395 - logger.py:50 - Epoch: [459][5/6]	Total Loss: 0.72204	Main MSE (x10^-2): 72.2038	LR: 7.91e-06	EMPP_Raw: 1.42876
2025-07-18 07:30:17,435 - logger.py:50 - Epoch 459 Training Summary: Avg Total Loss: 0.72204, Avg Main MSE: 0.72204, Time: 16.91s
2025-07-18 07:30:35,370 - logger.py:50 - Epoch 459 Summary | Train MSE (x10^-2): 72.2038 | Val MSE (x10^-2): 40.5215 | Time: 34.85s
2025-07-18 07:30:38,528 - logger.py:50 - Epoch: [460][0/6]	Total Loss: 0.74154	Main MSE (x10^-2): 74.1539	LR: 7.58e-06	EMPP_Raw: 1.46769
2025-07-18 07:30:52,322 - logger.py:50 - Epoch: [460][5/6]	Total Loss: 0.72845	Main MSE (x10^-2): 72.8448	LR: 7.58e-06	EMPP_Raw: 1.44101
2025-07-18 07:30:52,364 - logger.py:50 - Epoch 460 Training Summary: Avg Total Loss: 0.72845, Avg Main MSE: 0.72845, Time: 16.98s
2025-07-18 07:31:10,209 - logger.py:50 - Epoch 460 Summary | Train MSE (x10^-2): 72.8448 | Val MSE (x10^-2): 40.7343 | Time: 34.83s
2025-07-18 07:31:13,392 - logger.py:50 - Epoch: [461][0/6]	Total Loss: 0.72665	Main MSE (x10^-2): 72.6645	LR: 7.27e-06	EMPP_Raw: 1.43722
2025-07-18 07:31:27,144 - logger.py:50 - Epoch: [461][5/6]	Total Loss: 0.72199	Main MSE (x10^-2): 72.1994	LR: 7.27e-06	EMPP_Raw: 1.42869
2025-07-18 07:31:27,184 - logger.py:50 - Epoch 461 Training Summary: Avg Total Loss: 0.72199, Avg Main MSE: 0.72199, Time: 16.97s
2025-07-18 07:31:45,014 - logger.py:50 - Epoch 461 Summary | Train MSE (x10^-2): 72.1994 | Val MSE (x10^-2): 40.8381 | Time: 34.80s
2025-07-18 07:31:48,055 - logger.py:50 - Epoch: [462][0/6]	Total Loss: 0.70267	Main MSE (x10^-2): 70.2665	LR: 6.96e-06	EMPP_Raw: 1.38956
2025-07-18 07:32:01,988 - logger.py:50 - Epoch: [462][5/6]	Total Loss: 0.71663	Main MSE (x10^-2): 71.6631	LR: 6.96e-06	EMPP_Raw: 1.41768
2025-07-18 07:32:02,029 - logger.py:50 - Epoch 462 Training Summary: Avg Total Loss: 0.71663, Avg Main MSE: 0.71663, Time: 17.01s
2025-07-18 07:32:20,047 - logger.py:50 - Epoch 462 Summary | Train MSE (x10^-2): 71.6631 | Val MSE (x10^-2): 40.7695 | Time: 35.03s
2025-07-18 07:32:23,041 - logger.py:50 - Epoch: [463][0/6]	Total Loss: 0.72789	Main MSE (x10^-2): 72.7892	LR: 6.66e-06	EMPP_Raw: 1.44023
2025-07-18 07:32:36,917 - logger.py:50 - Epoch: [463][5/6]	Total Loss: 0.73099	Main MSE (x10^-2): 73.0988	LR: 6.66e-06	EMPP_Raw: 1.44637
2025-07-18 07:32:36,962 - logger.py:50 - Epoch 463 Training Summary: Avg Total Loss: 0.73099, Avg Main MSE: 0.73099, Time: 16.90s
2025-07-18 07:32:54,902 - logger.py:50 - Epoch 463 Summary | Train MSE (x10^-2): 73.0988 | Val MSE (x10^-2): 40.6366 | Time: 34.85s
2025-07-18 07:32:57,930 - logger.py:50 - Epoch: [464][0/6]	Total Loss: 0.73599	Main MSE (x10^-2): 73.5992	LR: 6.37e-06	EMPP_Raw: 1.45169
2025-07-18 07:33:11,735 - logger.py:50 - Epoch: [464][5/6]	Total Loss: 0.72198	Main MSE (x10^-2): 72.1977	LR: 6.37e-06	EMPP_Raw: 1.42782
2025-07-18 07:33:11,781 - logger.py:50 - Epoch 464 Training Summary: Avg Total Loss: 0.72198, Avg Main MSE: 0.72198, Time: 16.87s
2025-07-18 07:33:29,982 - logger.py:50 - Epoch 464 Summary | Train MSE (x10^-2): 72.1977 | Val MSE (x10^-2): 40.5736 | Time: 35.07s
2025-07-18 07:33:32,967 - logger.py:50 - Epoch: [465][0/6]	Total Loss: 0.73857	Main MSE (x10^-2): 73.8568	LR: 6.08e-06	EMPP_Raw: 1.45945
2025-07-18 07:33:46,756 - logger.py:50 - Epoch: [465][5/6]	Total Loss: 0.72155	Main MSE (x10^-2): 72.1553	LR: 6.08e-06	EMPP_Raw: 1.42732
2025-07-18 07:33:46,793 - logger.py:50 - Epoch 465 Training Summary: Avg Total Loss: 0.72155, Avg Main MSE: 0.72155, Time: 16.80s
2025-07-18 07:34:04,726 - logger.py:50 - Epoch 465 Summary | Train MSE (x10^-2): 72.1553 | Val MSE (x10^-2): 40.5858 | Time: 34.74s
2025-07-18 07:34:07,908 - logger.py:50 - Epoch: [466][0/6]	Total Loss: 0.71575	Main MSE (x10^-2): 71.5745	LR: 5.80e-06	EMPP_Raw: 1.41510
2025-07-18 07:34:21,677 - logger.py:50 - Epoch: [466][5/6]	Total Loss: 0.72427	Main MSE (x10^-2): 72.4268	LR: 5.80e-06	EMPP_Raw: 1.43205
2025-07-18 07:34:21,720 - logger.py:50 - Epoch 466 Training Summary: Avg Total Loss: 0.72427, Avg Main MSE: 0.72427, Time: 16.98s
2025-07-18 07:34:39,645 - logger.py:50 - Epoch 466 Summary | Train MSE (x10^-2): 72.4268 | Val MSE (x10^-2): 40.7181 | Time: 34.91s
2025-07-18 07:34:42,808 - logger.py:50 - Epoch: [467][0/6]	Total Loss: 0.73398	Main MSE (x10^-2): 73.3979	LR: 5.54e-06	EMPP_Raw: 1.45354
2025-07-18 07:34:56,625 - logger.py:50 - Epoch: [467][5/6]	Total Loss: 0.71744	Main MSE (x10^-2): 71.7442	LR: 5.54e-06	EMPP_Raw: 1.41952
2025-07-18 07:34:56,679 - logger.py:50 - Epoch 467 Training Summary: Avg Total Loss: 0.71744, Avg Main MSE: 0.71744, Time: 17.03s
2025-07-18 07:35:14,617 - logger.py:50 - Epoch 467 Summary | Train MSE (x10^-2): 71.7442 | Val MSE (x10^-2): 40.6721 | Time: 34.97s
2025-07-18 07:35:17,631 - logger.py:50 - Epoch: [468][0/6]	Total Loss: 0.74895	Main MSE (x10^-2): 74.8955	LR: 5.27e-06	EMPP_Raw: 1.48123
2025-07-18 07:35:31,640 - logger.py:50 - Epoch: [468][5/6]	Total Loss: 0.72597	Main MSE (x10^-2): 72.5974	LR: 5.27e-06	EMPP_Raw: 1.43592
2025-07-18 07:35:31,686 - logger.py:50 - Epoch 468 Training Summary: Avg Total Loss: 0.72597, Avg Main MSE: 0.72597, Time: 17.06s
2025-07-18 07:35:49,705 - logger.py:50 - Epoch 468 Summary | Train MSE (x10^-2): 72.5974 | Val MSE (x10^-2): 40.5056 | Time: 35.08s
2025-07-18 07:35:52,750 - logger.py:50 - Epoch: [469][0/6]	Total Loss: 0.73633	Main MSE (x10^-2): 73.6331	LR: 5.02e-06	EMPP_Raw: 1.45757
2025-07-18 07:36:06,655 - logger.py:50 - Epoch: [469][5/6]	Total Loss: 0.71945	Main MSE (x10^-2): 71.9447	LR: 5.02e-06	EMPP_Raw: 1.42420
2025-07-18 07:36:06,697 - logger.py:50 - Epoch 469 Training Summary: Avg Total Loss: 0.71945, Avg Main MSE: 0.71945, Time: 16.98s
2025-07-18 07:36:24,597 - logger.py:50 - Epoch 469 Summary | Train MSE (x10^-2): 71.9447 | Val MSE (x10^-2): 40.4017 | Time: 34.89s
2025-07-18 07:36:27,605 - logger.py:50 - Epoch: [470][0/6]	Total Loss: 0.71564	Main MSE (x10^-2): 71.5639	LR: 4.77e-06	EMPP_Raw: 1.41575
2025-07-18 07:36:41,411 - logger.py:50 - Epoch: [470][5/6]	Total Loss: 0.72307	Main MSE (x10^-2): 72.3066	LR: 4.77e-06	EMPP_Raw: 1.43057
2025-07-18 07:36:41,453 - logger.py:50 - Epoch 470 Training Summary: Avg Total Loss: 0.72307, Avg Main MSE: 0.72307, Time: 16.85s
2025-07-18 07:36:59,469 - logger.py:50 - Epoch 470 Summary | Train MSE (x10^-2): 72.3066 | Val MSE (x10^-2): 40.5214 | Time: 34.87s
2025-07-18 07:37:02,485 - logger.py:50 - Epoch: [471][0/6]	Total Loss: 0.73098	Main MSE (x10^-2): 73.0975	LR: 4.53e-06	EMPP_Raw: 1.44554
2025-07-18 07:37:16,283 - logger.py:50 - Epoch: [471][5/6]	Total Loss: 0.72419	Main MSE (x10^-2): 72.4187	LR: 4.53e-06	EMPP_Raw: 1.43249
2025-07-18 07:37:16,329 - logger.py:50 - Epoch 471 Training Summary: Avg Total Loss: 0.72419, Avg Main MSE: 0.72419, Time: 16.85s
2025-07-18 07:37:34,514 - logger.py:50 - Epoch 471 Summary | Train MSE (x10^-2): 72.4187 | Val MSE (x10^-2): 40.5900 | Time: 35.04s
2025-07-18 07:37:37,732 - logger.py:50 - Epoch: [472][0/6]	Total Loss: 0.73375	Main MSE (x10^-2): 73.3751	LR: 4.30e-06	EMPP_Raw: 1.45239
2025-07-18 07:37:51,504 - logger.py:50 - Epoch: [472][5/6]	Total Loss: 0.73102	Main MSE (x10^-2): 73.1016	LR: 4.30e-06	EMPP_Raw: 1.44611
2025-07-18 07:37:51,547 - logger.py:50 - Epoch 472 Training Summary: Avg Total Loss: 0.73102, Avg Main MSE: 0.73102, Time: 17.02s
2025-07-18 07:38:09,484 - logger.py:50 - Epoch 472 Summary | Train MSE (x10^-2): 73.1016 | Val MSE (x10^-2): 40.6284 | Time: 34.96s
2025-07-18 07:38:12,635 - logger.py:50 - Epoch: [473][0/6]	Total Loss: 0.71692	Main MSE (x10^-2): 71.6923	LR: 4.08e-06	EMPP_Raw: 1.41818
2025-07-18 07:38:26,412 - logger.py:50 - Epoch: [473][5/6]	Total Loss: 0.72731	Main MSE (x10^-2): 72.7311	LR: 4.08e-06	EMPP_Raw: 1.43948
2025-07-18 07:38:26,459 - logger.py:50 - Epoch 473 Training Summary: Avg Total Loss: 0.72731, Avg Main MSE: 0.72731, Time: 16.97s
2025-07-18 07:38:44,322 - logger.py:50 - Epoch 473 Summary | Train MSE (x10^-2): 72.7311 | Val MSE (x10^-2): 40.6460 | Time: 34.83s
2025-07-18 07:38:47,493 - logger.py:50 - Epoch: [474][0/6]	Total Loss: 0.74969	Main MSE (x10^-2): 74.9691	LR: 3.86e-06	EMPP_Raw: 1.48394
2025-07-18 07:39:01,300 - logger.py:50 - Epoch: [474][5/6]	Total Loss: 0.72717	Main MSE (x10^-2): 72.7169	LR: 3.86e-06	EMPP_Raw: 1.43952
2025-07-18 07:39:01,346 - logger.py:50 - Epoch 474 Training Summary: Avg Total Loss: 0.72717, Avg Main MSE: 0.72717, Time: 17.02s
2025-07-18 07:39:19,237 - logger.py:50 - Epoch 474 Summary | Train MSE (x10^-2): 72.7169 | Val MSE (x10^-2): 40.6547 | Time: 34.91s
2025-07-18 07:39:22,253 - logger.py:50 - Epoch: [475][0/6]	Total Loss: 0.72851	Main MSE (x10^-2): 72.8510	LR: 3.66e-06	EMPP_Raw: 1.44090
2025-07-18 07:39:36,255 - logger.py:50 - Epoch: [475][5/6]	Total Loss: 0.72385	Main MSE (x10^-2): 72.3850	LR: 3.66e-06	EMPP_Raw: 1.43233
2025-07-18 07:39:36,297 - logger.py:50 - Epoch 475 Training Summary: Avg Total Loss: 0.72385, Avg Main MSE: 0.72385, Time: 17.05s
2025-07-18 07:39:54,186 - logger.py:50 - Epoch 475 Summary | Train MSE (x10^-2): 72.3850 | Val MSE (x10^-2): 40.6161 | Time: 34.94s
2025-07-18 07:39:57,210 - logger.py:50 - Epoch: [476][0/6]	Total Loss: 0.70234	Main MSE (x10^-2): 70.2336	LR: 3.46e-06	EMPP_Raw: 1.39068
2025-07-18 07:40:10,997 - logger.py:50 - Epoch: [476][5/6]	Total Loss: 0.72080	Main MSE (x10^-2): 72.0803	LR: 3.46e-06	EMPP_Raw: 1.42680
2025-07-18 07:40:11,041 - logger.py:50 - Epoch 476 Training Summary: Avg Total Loss: 0.72080, Avg Main MSE: 0.72080, Time: 16.85s
2025-07-18 07:40:29,050 - logger.py:50 - Epoch 476 Summary | Train MSE (x10^-2): 72.0803 | Val MSE (x10^-2): 40.5831 | Time: 34.86s
2025-07-18 07:40:32,076 - logger.py:50 - Epoch: [477][0/6]	Total Loss: 0.72156	Main MSE (x10^-2): 72.1558	LR: 3.26e-06	EMPP_Raw: 1.42686
2025-07-18 07:40:45,867 - logger.py:50 - Epoch: [477][5/6]	Total Loss: 0.72085	Main MSE (x10^-2): 72.0853	LR: 3.26e-06	EMPP_Raw: 1.42585
2025-07-18 07:40:45,909 - logger.py:50 - Epoch 477 Training Summary: Avg Total Loss: 0.72085, Avg Main MSE: 0.72085, Time: 16.85s
2025-07-18 07:41:04,106 - logger.py:50 - Epoch 477 Summary | Train MSE (x10^-2): 72.0853 | Val MSE (x10^-2): 40.5144 | Time: 35.05s
2025-07-18 07:41:07,110 - logger.py:50 - Epoch: [478][0/6]	Total Loss: 0.71723	Main MSE (x10^-2): 71.7229	LR: 3.08e-06	EMPP_Raw: 1.41993
2025-07-18 07:41:20,906 - logger.py:50 - Epoch: [478][5/6]	Total Loss: 0.72445	Main MSE (x10^-2): 72.4455	LR: 3.08e-06	EMPP_Raw: 1.43358
2025-07-18 07:41:20,949 - logger.py:50 - Epoch 478 Training Summary: Avg Total Loss: 0.72445, Avg Main MSE: 0.72445, Time: 16.83s
2025-07-18 07:41:38,752 - logger.py:50 - Epoch 478 Summary | Train MSE (x10^-2): 72.4455 | Val MSE (x10^-2): 40.4885 | Time: 34.64s
2025-07-18 07:41:41,906 - logger.py:50 - Epoch: [479][0/6]	Total Loss: 0.72128	Main MSE (x10^-2): 72.1279	LR: 2.90e-06	EMPP_Raw: 1.42599
2025-07-18 07:41:55,677 - logger.py:50 - Epoch: [479][5/6]	Total Loss: 0.72218	Main MSE (x10^-2): 72.2178	LR: 2.90e-06	EMPP_Raw: 1.42817
2025-07-18 07:41:55,716 - logger.py:50 - Epoch 479 Training Summary: Avg Total Loss: 0.72218, Avg Main MSE: 0.72218, Time: 16.96s
2025-07-18 07:42:13,631 - logger.py:50 - Epoch 479 Summary | Train MSE (x10^-2): 72.2178 | Val MSE (x10^-2): 40.5765 | Time: 34.87s
2025-07-18 07:42:16,784 - logger.py:50 - Epoch: [480][0/6]	Total Loss: 0.72995	Main MSE (x10^-2): 72.9952	LR: 2.73e-06	EMPP_Raw: 1.44652
2025-07-18 07:42:30,581 - logger.py:50 - Epoch: [480][5/6]	Total Loss: 0.72178	Main MSE (x10^-2): 72.1777	LR: 2.73e-06	EMPP_Raw: 1.42847
2025-07-18 07:42:30,624 - logger.py:50 - Epoch 480 Training Summary: Avg Total Loss: 0.72178, Avg Main MSE: 0.72178, Time: 16.98s
2025-07-18 07:42:48,516 - logger.py:50 - Epoch 480 Summary | Train MSE (x10^-2): 72.1777 | Val MSE (x10^-2): 40.6496 | Time: 34.88s
2025-07-18 07:42:51,508 - logger.py:50 - Epoch: [481][0/6]	Total Loss: 0.71853	Main MSE (x10^-2): 71.8533	LR: 2.57e-06	EMPP_Raw: 1.42215
2025-07-18 07:43:05,402 - logger.py:50 - Epoch: [481][5/6]	Total Loss: 0.72522	Main MSE (x10^-2): 72.5223	LR: 2.57e-06	EMPP_Raw: 1.43441
2025-07-18 07:43:05,443 - logger.py:50 - Epoch 481 Training Summary: Avg Total Loss: 0.72522, Avg Main MSE: 0.72522, Time: 16.92s
2025-07-18 07:43:23,331 - logger.py:50 - Epoch 481 Summary | Train MSE (x10^-2): 72.5223 | Val MSE (x10^-2): 40.6762 | Time: 34.81s
2025-07-18 07:43:26,379 - logger.py:50 - Epoch: [482][0/6]	Total Loss: 0.72106	Main MSE (x10^-2): 72.1057	LR: 2.42e-06	EMPP_Raw: 1.42732
2025-07-18 07:43:40,348 - logger.py:50 - Epoch: [482][5/6]	Total Loss: 0.71597	Main MSE (x10^-2): 71.5967	LR: 2.42e-06	EMPP_Raw: 1.41631
2025-07-18 07:43:40,389 - logger.py:50 - Epoch 482 Training Summary: Avg Total Loss: 0.71597, Avg Main MSE: 0.71597, Time: 17.05s
2025-07-18 07:43:58,270 - logger.py:50 - Epoch 482 Summary | Train MSE (x10^-2): 71.5967 | Val MSE (x10^-2): 40.6414 | Time: 34.93s
2025-07-18 07:44:01,254 - logger.py:50 - Epoch: [483][0/6]	Total Loss: 0.71668	Main MSE (x10^-2): 71.6680	LR: 2.27e-06	EMPP_Raw: 1.41630
2025-07-18 07:44:15,004 - logger.py:50 - Epoch: [483][5/6]	Total Loss: 0.71149	Main MSE (x10^-2): 71.1492	LR: 2.27e-06	EMPP_Raw: 1.40683
2025-07-18 07:44:15,046 - logger.py:50 - Epoch 483 Training Summary: Avg Total Loss: 0.71149, Avg Main MSE: 0.71149, Time: 16.77s
2025-07-18 07:44:33,171 - logger.py:50 - Epoch 483 Summary | Train MSE (x10^-2): 71.1492 | Val MSE (x10^-2): 40.5923 | Time: 34.89s
2025-07-18 07:44:36,216 - logger.py:50 - Epoch: [484][0/6]	Total Loss: 0.71757	Main MSE (x10^-2): 71.7570	LR: 2.14e-06	EMPP_Raw: 1.42017
2025-07-18 07:44:50,122 - logger.py:50 - Epoch: [484][5/6]	Total Loss: 0.71665	Main MSE (x10^-2): 71.6649	LR: 2.14e-06	EMPP_Raw: 1.41767
2025-07-18 07:44:50,168 - logger.py:50 - Epoch 484 Training Summary: Avg Total Loss: 0.71665, Avg Main MSE: 0.71665, Time: 16.99s
2025-07-18 07:45:08,050 - logger.py:50 - Epoch 484 Summary | Train MSE (x10^-2): 71.6649 | Val MSE (x10^-2): 40.5648 | Time: 34.87s
2025-07-18 07:45:11,219 - logger.py:50 - Epoch: [485][0/6]	Total Loss: 0.72925	Main MSE (x10^-2): 72.9246	LR: 2.01e-06	EMPP_Raw: 1.44285
2025-07-18 07:45:24,952 - logger.py:50 - Epoch: [485][5/6]	Total Loss: 0.72880	Main MSE (x10^-2): 72.8802	LR: 2.01e-06	EMPP_Raw: 1.44164
2025-07-18 07:45:24,990 - logger.py:50 - Epoch 485 Training Summary: Avg Total Loss: 0.72880, Avg Main MSE: 0.72880, Time: 16.93s
2025-07-18 07:45:42,871 - logger.py:50 - Epoch 485 Summary | Train MSE (x10^-2): 72.8802 | Val MSE (x10^-2): 40.5679 | Time: 34.81s
2025-07-18 07:45:46,025 - logger.py:50 - Epoch: [486][0/6]	Total Loss: 0.73090	Main MSE (x10^-2): 73.0895	LR: 1.89e-06	EMPP_Raw: 1.44436
2025-07-18 07:45:59,771 - logger.py:50 - Epoch: [486][5/6]	Total Loss: 0.72192	Main MSE (x10^-2): 72.1919	LR: 1.89e-06	EMPP_Raw: 1.42733
2025-07-18 07:45:59,815 - logger.py:50 - Epoch 486 Training Summary: Avg Total Loss: 0.72192, Avg Main MSE: 0.72192, Time: 16.93s
2025-07-18 07:46:17,736 - logger.py:50 - Epoch 486 Summary | Train MSE (x10^-2): 72.1919 | Val MSE (x10^-2): 40.5799 | Time: 34.86s
2025-07-18 07:46:20,917 - logger.py:50 - Epoch: [487][0/6]	Total Loss: 0.72543	Main MSE (x10^-2): 72.5434	LR: 1.77e-06	EMPP_Raw: 1.43482
2025-07-18 07:46:34,653 - logger.py:50 - Epoch: [487][5/6]	Total Loss: 0.72236	Main MSE (x10^-2): 72.2359	LR: 1.77e-06	EMPP_Raw: 1.42907
2025-07-18 07:46:34,695 - logger.py:50 - Epoch 487 Training Summary: Avg Total Loss: 0.72236, Avg Main MSE: 0.72236, Time: 16.95s
2025-07-18 07:46:52,515 - logger.py:50 - Epoch 487 Summary | Train MSE (x10^-2): 72.2359 | Val MSE (x10^-2): 40.5540 | Time: 34.77s
2025-07-18 07:46:55,524 - logger.py:50 - Epoch: [488][0/6]	Total Loss: 0.75137	Main MSE (x10^-2): 75.1369	LR: 1.67e-06	EMPP_Raw: 1.48833
2025-07-18 07:47:09,515 - logger.py:50 - Epoch: [488][5/6]	Total Loss: 0.73577	Main MSE (x10^-2): 73.5767	LR: 1.67e-06	EMPP_Raw: 1.45590
2025-07-18 07:47:09,561 - logger.py:50 - Epoch 488 Training Summary: Avg Total Loss: 0.73577, Avg Main MSE: 0.73577, Time: 17.04s
2025-07-18 07:47:27,505 - logger.py:50 - Epoch 488 Summary | Train MSE (x10^-2): 73.5767 | Val MSE (x10^-2): 40.5349 | Time: 34.98s
2025-07-18 07:47:30,496 - logger.py:50 - Epoch: [489][0/6]	Total Loss: 0.74239	Main MSE (x10^-2): 74.2391	LR: 1.57e-06	EMPP_Raw: 1.47005
2025-07-18 07:47:44,259 - logger.py:50 - Epoch: [489][5/6]	Total Loss: 0.72481	Main MSE (x10^-2): 72.4810	LR: 1.57e-06	EMPP_Raw: 1.43476
2025-07-18 07:47:44,303 - logger.py:50 - Epoch 489 Training Summary: Avg Total Loss: 0.72481, Avg Main MSE: 0.72481, Time: 16.79s
2025-07-18 07:48:02,459 - logger.py:50 - Epoch 489 Summary | Train MSE (x10^-2): 72.4810 | Val MSE (x10^-2): 40.5728 | Time: 34.95s
2025-07-18 07:48:05,500 - logger.py:50 - Epoch: [490][0/6]	Total Loss: 0.72473	Main MSE (x10^-2): 72.4732	LR: 1.48e-06	EMPP_Raw: 1.43472
2025-07-18 07:48:19,330 - logger.py:50 - Epoch: [490][5/6]	Total Loss: 0.72453	Main MSE (x10^-2): 72.4531	LR: 1.48e-06	EMPP_Raw: 1.43424
2025-07-18 07:48:19,378 - logger.py:50 - Epoch 490 Training Summary: Avg Total Loss: 0.72453, Avg Main MSE: 0.72453, Time: 16.91s
2025-07-18 07:48:37,408 - logger.py:50 - Epoch 490 Summary | Train MSE (x10^-2): 72.4531 | Val MSE (x10^-2): 40.6133 | Time: 34.94s
2025-07-18 07:48:40,409 - logger.py:50 - Epoch: [491][0/6]	Total Loss: 0.71488	Main MSE (x10^-2): 71.4883	LR: 1.39e-06	EMPP_Raw: 1.41422
2025-07-18 07:48:54,186 - logger.py:50 - Epoch: [491][5/6]	Total Loss: 0.72792	Main MSE (x10^-2): 72.7919	LR: 1.39e-06	EMPP_Raw: 1.44028
2025-07-18 07:48:54,229 - logger.py:50 - Epoch 491 Training Summary: Avg Total Loss: 0.72792, Avg Main MSE: 0.72792, Time: 16.81s
2025-07-18 07:49:12,118 - logger.py:50 - Epoch 491 Summary | Train MSE (x10^-2): 72.7919 | Val MSE (x10^-2): 40.6434 | Time: 34.70s
2025-07-18 07:49:15,250 - logger.py:50 - Epoch: [492][0/6]	Total Loss: 0.72399	Main MSE (x10^-2): 72.3994	LR: 1.32e-06	EMPP_Raw: 1.43500
2025-07-18 07:49:28,985 - logger.py:50 - Epoch: [492][5/6]	Total Loss: 0.73588	Main MSE (x10^-2): 73.5880	LR: 1.32e-06	EMPP_Raw: 1.45664
2025-07-18 07:49:29,027 - logger.py:50 - Epoch 492 Training Summary: Avg Total Loss: 0.73588, Avg Main MSE: 0.73588, Time: 16.90s
2025-07-18 07:49:46,983 - logger.py:50 - Epoch 492 Summary | Train MSE (x10^-2): 73.5880 | Val MSE (x10^-2): 40.6421 | Time: 34.86s
2025-07-18 07:49:50,159 - logger.py:50 - Epoch: [493][0/6]	Total Loss: 0.70497	Main MSE (x10^-2): 70.4974	LR: 1.25e-06	EMPP_Raw: 1.39433
2025-07-18 07:50:03,924 - logger.py:50 - Epoch: [493][5/6]	Total Loss: 0.71420	Main MSE (x10^-2): 71.4201	LR: 1.25e-06	EMPP_Raw: 1.41160
2025-07-18 07:50:03,968 - logger.py:50 - Epoch 493 Training Summary: Avg Total Loss: 0.71420, Avg Main MSE: 0.71420, Time: 16.98s
2025-07-18 07:50:21,956 - logger.py:50 - Epoch 493 Summary | Train MSE (x10^-2): 71.4201 | Val MSE (x10^-2): 40.6247 | Time: 34.97s
2025-07-18 07:50:24,943 - logger.py:50 - Epoch: [494][0/6]	Total Loss: 0.72667	Main MSE (x10^-2): 72.6670	LR: 1.19e-06	EMPP_Raw: 1.43810
2025-07-18 07:50:38,834 - logger.py:50 - Epoch: [494][5/6]	Total Loss: 0.72599	Main MSE (x10^-2): 72.5987	LR: 1.19e-06	EMPP_Raw: 1.43673
2025-07-18 07:50:38,878 - logger.py:50 - Epoch 494 Training Summary: Avg Total Loss: 0.72599, Avg Main MSE: 0.72599, Time: 16.91s
2025-07-18 07:50:56,887 - logger.py:50 - Epoch 494 Summary | Train MSE (x10^-2): 72.5987 | Val MSE (x10^-2): 40.6025 | Time: 34.93s
2025-07-18 07:50:59,940 - logger.py:50 - Epoch: [495][0/6]	Total Loss: 0.74967	Main MSE (x10^-2): 74.9668	LR: 1.14e-06	EMPP_Raw: 1.48496
2025-07-18 07:51:13,876 - logger.py:50 - Epoch: [495][5/6]	Total Loss: 0.71786	Main MSE (x10^-2): 71.7865	LR: 1.14e-06	EMPP_Raw: 1.42004
2025-07-18 07:51:13,921 - logger.py:50 - Epoch 495 Training Summary: Avg Total Loss: 0.71786, Avg Main MSE: 0.71786, Time: 17.02s
2025-07-18 07:51:31,722 - logger.py:50 - Epoch 495 Summary | Train MSE (x10^-2): 71.7865 | Val MSE (x10^-2): 40.5923 | Time: 34.83s
2025-07-18 07:51:34,729 - logger.py:50 - Epoch: [496][0/6]	Total Loss: 0.72008	Main MSE (x10^-2): 72.0079	LR: 1.10e-06	EMPP_Raw: 1.42632
2025-07-18 07:51:48,517 - logger.py:50 - Epoch: [496][5/6]	Total Loss: 0.71199	Main MSE (x10^-2): 71.1992	LR: 1.10e-06	EMPP_Raw: 1.40876
2025-07-18 07:51:48,559 - logger.py:50 - Epoch 496 Training Summary: Avg Total Loss: 0.71199, Avg Main MSE: 0.71199, Time: 16.83s
2025-07-18 07:52:06,698 - logger.py:50 - Epoch 496 Summary | Train MSE (x10^-2): 71.1992 | Val MSE (x10^-2): 40.5779 | Time: 34.97s
2025-07-18 07:52:09,682 - logger.py:50 - Epoch: [497][0/6]	Total Loss: 0.73159	Main MSE (x10^-2): 73.1595	LR: 1.06e-06	EMPP_Raw: 1.44779
2025-07-18 07:52:23,428 - logger.py:50 - Epoch: [497][5/6]	Total Loss: 0.72936	Main MSE (x10^-2): 72.9362	LR: 1.06e-06	EMPP_Raw: 1.44351
2025-07-18 07:52:23,473 - logger.py:50 - Epoch 497 Training Summary: Avg Total Loss: 0.72936, Avg Main MSE: 0.72936, Time: 16.77s
2025-07-18 07:52:41,307 - logger.py:50 - Epoch 497 Summary | Train MSE (x10^-2): 72.9362 | Val MSE (x10^-2): 40.5607 | Time: 34.60s
2025-07-18 07:52:44,485 - logger.py:50 - Epoch: [498][0/6]	Total Loss: 0.73236	Main MSE (x10^-2): 73.2363	LR: 1.04e-06	EMPP_Raw: 1.44696
2025-07-18 07:52:58,321 - logger.py:50 - Epoch: [498][5/6]	Total Loss: 0.72440	Main MSE (x10^-2): 72.4396	LR: 1.04e-06	EMPP_Raw: 1.43230
2025-07-18 07:52:58,360 - logger.py:50 - Epoch 498 Training Summary: Avg Total Loss: 0.72440, Avg Main MSE: 0.72440, Time: 17.04s
2025-07-18 07:53:16,255 - logger.py:50 - Epoch 498 Summary | Train MSE (x10^-2): 72.4396 | Val MSE (x10^-2): 40.5569 | Time: 34.94s
2025-07-18 07:53:19,437 - logger.py:50 - Epoch: [499][0/6]	Total Loss: 0.70194	Main MSE (x10^-2): 70.1940	LR: 1.02e-06	EMPP_Raw: 1.39062
2025-07-18 07:53:33,210 - logger.py:50 - Epoch: [499][5/6]	Total Loss: 0.71848	Main MSE (x10^-2): 71.8475	LR: 1.02e-06	EMPP_Raw: 1.42150
2025-07-18 07:53:33,265 - logger.py:50 - Epoch 499 Training Summary: Avg Total Loss: 0.71848, Avg Main MSE: 0.71848, Time: 17.00s
2025-07-18 07:53:51,193 - logger.py:50 - Epoch 499 Summary | Train MSE (x10^-2): 71.8475 | Val MSE (x10^-2): 40.5622 | Time: 34.93s
2025-07-18 07:53:51,197 - logger.py:50 - --- Finished training for ethanol ---
2025-07-18 07:53:51,197 - logger.py:50 - Final Best Val MSE (at Epoch 33): 0.278054 (x10^-2: 27.8054)
2025-07-18 07:53:51,197 - logger.py:50 - Final Test MSE (at Best Val Epoch): 0.273825 (x10^-2: 27.3825)
2025-07-18 07:53:51,209 - logger.py:50 - --- Starting training for malonaldehyde ---
2025-07-18 07:53:51,210 - logger.py:50 - Namespace(amp=False, batch_size=80, clip_grad=1.0, contrastive_aug_mask_ratio=0.15, contrastive_loss_weight=0.1, contrastive_mask_token_idx=0, contrastive_prioritize_heteroatoms=False, contrastive_projection_dim=128, contrastive_temp=0.1, cooldown_epochs=10, data_path='data/md17', decay_rate=0.1, delta_frame=3000, device='cuda:0', drop_path=0.0, empp_atom_type_embed_irreps='16x0e', empp_loss_weight=0.5, empp_num_mask=1, empp_pos_pred_num_s2_channels=32, empp_pos_pred_res_s2grid=100, empp_pos_pred_temp_label=0.1, empp_pos_pred_temp_softmax=0.1, empp_prioritize_heteroatoms=True, empp_ssp_feature_dim='16x0e', enable_contrastive=False, epochs=500, exp_name='md17_final_run_20250717_152800', logger=<logger.FileLogger object at 0x7f24b7775af0>, loss='l2', lr=0.0004, max_test_samples=2000, max_train_samples=500, max_val_samples=2000, min_lr=1e-06, model_name='graph_attention_transformer_nonlinear_l2', molecule_type='malonaldehyde', momentum=0.9, num_basis=128, opt='adamw', opt_betas=None, opt_eps=1e-08, output_dir='outputs/md17_final_run_20250717_152800', patience_epochs=10, pin_mem=True, print_freq=50, radius=5.0, sched='cosine', seed=42, ssp=True, warmup_epochs=10, warmup_lr=1e-06, weight_decay=1e-06, workers=8)
2025-07-18 07:53:51,211 - logger.py:50 - Loading datasets...
2025-07-18 07:54:25,601 - logger.py:50 - Creating model...
2025-07-18 07:54:33,787 - logger.py:50 - Number of params: 3,205,881
2025-07-18 07:54:37,795 - logger.py:50 - Epoch: [0][0/6]	Total Loss: 1.89003	Main MSE (x10^-2): 189.0026	LR: 1.00e-06	EMPP_Raw: 2.21696
2025-07-18 07:54:53,060 - logger.py:50 - Epoch: [0][5/6]	Total Loss: 1.90696	Main MSE (x10^-2): 190.6965	LR: 1.00e-06	EMPP_Raw: 2.24612
2025-07-18 07:54:53,113 - logger.py:50 - Epoch 0 Training Summary: Avg Total Loss: 1.90696, Avg Main MSE: 1.90696, Time: 19.32s
2025-07-18 07:55:29,753 - logger.py:50 - *** New Best Val MSE (x10^-2): 79.4292, Corresponding Test MSE (x10^-2): 81.3973 at Epoch 0 ***
2025-07-18 07:55:29,798 - logger.py:50 - Epoch 0 Summary | Train MSE (x10^-2): 190.6965 | Val MSE (x10^-2): 79.4292 | Time: 56.01s
2025-07-18 07:55:32,961 - logger.py:50 - Epoch: [1][0/6]	Total Loss: 1.86079	Main MSE (x10^-2): 186.0786	LR: 1.00e-06	EMPP_Raw: 2.26246
2025-07-18 07:55:46,789 - logger.py:50 - Epoch: [1][5/6]	Total Loss: 1.88934	Main MSE (x10^-2): 188.9337	LR: 1.00e-06	EMPP_Raw: 2.20002
2025-07-18 07:55:46,828 - logger.py:50 - Epoch 1 Training Summary: Avg Total Loss: 1.88934, Avg Main MSE: 1.88934, Time: 17.03s
2025-07-18 07:56:22,807 - logger.py:50 - *** New Best Val MSE (x10^-2): 79.3726, Corresponding Test MSE (x10^-2): 81.3394 at Epoch 1 ***
2025-07-18 07:56:22,854 - logger.py:50 - Epoch 1 Summary | Train MSE (x10^-2): 188.9337 | Val MSE (x10^-2): 79.3726 | Time: 53.06s
2025-07-18 07:56:26,090 - logger.py:50 - Epoch: [2][0/6]	Total Loss: 1.89415	Main MSE (x10^-2): 189.4153	LR: 4.09e-05	EMPP_Raw: 2.22307
2025-07-18 07:56:39,905 - logger.py:50 - Epoch: [2][5/6]	Total Loss: 1.83918	Main MSE (x10^-2): 183.9179	LR: 4.09e-05	EMPP_Raw: 2.11451
2025-07-18 07:56:39,948 - logger.py:50 - Epoch 2 Training Summary: Avg Total Loss: 1.83918, Avg Main MSE: 1.83918, Time: 17.09s
2025-07-18 07:57:16,159 - logger.py:50 - *** New Best Val MSE (x10^-2): 77.0935, Corresponding Test MSE (x10^-2): 79.0025 at Epoch 2 ***
2025-07-18 07:57:16,206 - logger.py:50 - Epoch 2 Summary | Train MSE (x10^-2): 183.9179 | Val MSE (x10^-2): 77.0935 | Time: 53.35s
2025-07-18 07:57:19,379 - logger.py:50 - Epoch: [3][0/6]	Total Loss: 1.74909	Main MSE (x10^-2): 174.9094	LR: 8.08e-05	EMPP_Raw: 2.03599
2025-07-18 07:57:33,140 - logger.py:50 - Epoch: [3][5/6]	Total Loss: 1.72848	Main MSE (x10^-2): 172.8476	LR: 8.08e-05	EMPP_Raw: 1.96674
2025-07-18 07:57:33,177 - logger.py:50 - Epoch 3 Training Summary: Avg Total Loss: 1.72848, Avg Main MSE: 1.72848, Time: 16.97s
2025-07-18 07:58:09,237 - logger.py:50 - *** New Best Val MSE (x10^-2): 72.1917, Corresponding Test MSE (x10^-2): 73.9595 at Epoch 3 ***
2025-07-18 07:58:09,283 - logger.py:50 - Epoch 3 Summary | Train MSE (x10^-2): 172.8476 | Val MSE (x10^-2): 72.1917 | Time: 53.08s
2025-07-18 07:58:12,486 - logger.py:50 - Epoch: [4][0/6]	Total Loss: 1.63463	Main MSE (x10^-2): 163.4627	LR: 1.21e-04	EMPP_Raw: 1.85638
2025-07-18 07:58:26,339 - logger.py:50 - Epoch: [4][5/6]	Total Loss: 1.61306	Main MSE (x10^-2): 161.3057	LR: 1.21e-04	EMPP_Raw: 1.85592
2025-07-18 07:58:26,376 - logger.py:50 - Epoch 4 Training Summary: Avg Total Loss: 1.61306, Avg Main MSE: 1.61306, Time: 17.09s
2025-07-18 07:59:02,469 - logger.py:50 - *** New Best Val MSE (x10^-2): 64.4742, Corresponding Test MSE (x10^-2): 65.9170 at Epoch 4 ***
2025-07-18 07:59:02,517 - logger.py:50 - Epoch 4 Summary | Train MSE (x10^-2): 161.3057 | Val MSE (x10^-2): 64.4742 | Time: 53.23s
2025-07-18 07:59:05,681 - logger.py:50 - Epoch: [5][0/6]	Total Loss: 1.62714	Main MSE (x10^-2): 162.7141	LR: 1.61e-04	EMPP_Raw: 1.86219
2025-07-18 07:59:19,516 - logger.py:50 - Epoch: [5][5/6]	Total Loss: 1.51539	Main MSE (x10^-2): 151.5386	LR: 1.61e-04	EMPP_Raw: 1.79910
2025-07-18 07:59:19,560 - logger.py:50 - Epoch 5 Training Summary: Avg Total Loss: 1.51539, Avg Main MSE: 1.51539, Time: 17.04s
2025-07-18 07:59:55,613 - logger.py:50 - *** New Best Val MSE (x10^-2): 59.4656, Corresponding Test MSE (x10^-2): 60.3646 at Epoch 5 ***
2025-07-18 07:59:55,660 - logger.py:50 - Epoch 5 Summary | Train MSE (x10^-2): 151.5386 | Val MSE (x10^-2): 59.4656 | Time: 53.14s
2025-07-18 07:59:58,702 - logger.py:50 - Epoch: [6][0/6]	Total Loss: 1.53872	Main MSE (x10^-2): 153.8720	LR: 2.00e-04	EMPP_Raw: 1.87246
2025-07-18 08:00:12,517 - logger.py:50 - Epoch: [6][5/6]	Total Loss: 1.44520	Main MSE (x10^-2): 144.5205	LR: 2.00e-04	EMPP_Raw: 1.77524
2025-07-18 08:00:12,560 - logger.py:50 - Epoch 6 Training Summary: Avg Total Loss: 1.44520, Avg Main MSE: 1.44520, Time: 16.90s
2025-07-18 08:00:48,497 - logger.py:50 - *** New Best Val MSE (x10^-2): 52.4361, Corresponding Test MSE (x10^-2): 53.2137 at Epoch 6 ***
2025-07-18 08:00:48,546 - logger.py:50 - Epoch 6 Summary | Train MSE (x10^-2): 144.5205 | Val MSE (x10^-2): 52.4361 | Time: 52.89s
2025-07-18 08:00:51,538 - logger.py:50 - Epoch: [7][0/6]	Total Loss: 1.37329	Main MSE (x10^-2): 137.3291	LR: 2.40e-04	EMPP_Raw: 1.76150
2025-07-18 08:01:05,374 - logger.py:50 - Epoch: [7][5/6]	Total Loss: 1.37842	Main MSE (x10^-2): 137.8419	LR: 2.40e-04	EMPP_Raw: 1.73312
2025-07-18 08:01:05,414 - logger.py:50 - Epoch 7 Training Summary: Avg Total Loss: 1.37842, Avg Main MSE: 1.37842, Time: 16.86s
2025-07-18 08:01:41,675 - logger.py:50 - *** New Best Val MSE (x10^-2): 51.0117, Corresponding Test MSE (x10^-2): 51.2813 at Epoch 7 ***
2025-07-18 08:01:41,723 - logger.py:50 - Epoch 7 Summary | Train MSE (x10^-2): 137.8419 | Val MSE (x10^-2): 51.0117 | Time: 53.18s
2025-07-18 08:01:44,749 - logger.py:50 - Epoch: [8][0/6]	Total Loss: 1.33797	Main MSE (x10^-2): 133.7974	LR: 2.80e-04	EMPP_Raw: 1.67368
2025-07-18 08:01:58,519 - logger.py:50 - Epoch: [8][5/6]	Total Loss: 1.36498	Main MSE (x10^-2): 136.4976	LR: 2.80e-04	EMPP_Raw: 1.71623
2025-07-18 08:01:58,561 - logger.py:50 - Epoch 8 Training Summary: Avg Total Loss: 1.36498, Avg Main MSE: 1.36498, Time: 16.83s
2025-07-18 08:02:34,679 - logger.py:50 - *** New Best Val MSE (x10^-2): 49.3534, Corresponding Test MSE (x10^-2): 49.9685 at Epoch 8 ***
2025-07-18 08:02:34,726 - logger.py:50 - Epoch 8 Summary | Train MSE (x10^-2): 136.4976 | Val MSE (x10^-2): 49.3534 | Time: 53.00s
2025-07-18 08:02:37,742 - logger.py:50 - Epoch: [9][0/6]	Total Loss: 1.34303	Main MSE (x10^-2): 134.3034	LR: 3.20e-04	EMPP_Raw: 1.68878
2025-07-18 08:02:51,512 - logger.py:50 - Epoch: [9][5/6]	Total Loss: 1.33830	Main MSE (x10^-2): 133.8303	LR: 3.20e-04	EMPP_Raw: 1.68646
2025-07-18 08:02:51,560 - logger.py:50 - Epoch 9 Training Summary: Avg Total Loss: 1.33830, Avg Main MSE: 1.33830, Time: 16.83s
2025-07-18 08:03:27,831 - logger.py:50 - *** New Best Val MSE (x10^-2): 49.1442, Corresponding Test MSE (x10^-2): 49.8605 at Epoch 9 ***
2025-07-18 08:03:27,879 - logger.py:50 - Epoch 9 Summary | Train MSE (x10^-2): 133.8303 | Val MSE (x10^-2): 49.1442 | Time: 53.15s
2025-07-18 08:03:30,870 - logger.py:50 - Epoch: [10][0/6]	Total Loss: 1.33329	Main MSE (x10^-2): 133.3292	LR: 3.60e-04	EMPP_Raw: 1.66723
2025-07-18 08:03:44,680 - logger.py:50 - Epoch: [10][5/6]	Total Loss: 1.33183	Main MSE (x10^-2): 133.1833	LR: 3.60e-04	EMPP_Raw: 1.67355
2025-07-18 08:03:44,724 - logger.py:50 - Epoch 10 Training Summary: Avg Total Loss: 1.33183, Avg Main MSE: 1.33183, Time: 16.84s
2025-07-18 08:04:02,772 - logger.py:50 - Epoch 10 Summary | Train MSE (x10^-2): 133.1833 | Val MSE (x10^-2): 49.5729 | Time: 34.89s
2025-07-18 08:04:05,755 - logger.py:50 - Epoch: [11][0/6]	Total Loss: 1.29533	Main MSE (x10^-2): 129.5334	LR: 4.00e-04	EMPP_Raw: 1.59403
2025-07-18 08:04:19,518 - logger.py:50 - Epoch: [11][5/6]	Total Loss: 1.30934	Main MSE (x10^-2): 130.9335	LR: 4.00e-04	EMPP_Raw: 1.62837
2025-07-18 08:04:19,562 - logger.py:50 - Epoch 11 Training Summary: Avg Total Loss: 1.30934, Avg Main MSE: 1.30934, Time: 16.78s
2025-07-18 08:04:55,564 - logger.py:50 - *** New Best Val MSE (x10^-2): 48.7246, Corresponding Test MSE (x10^-2): 49.3772 at Epoch 11 ***
2025-07-18 08:04:55,611 - logger.py:50 - Epoch 11 Summary | Train MSE (x10^-2): 130.9335 | Val MSE (x10^-2): 48.7246 | Time: 52.83s
2025-07-18 08:04:58,640 - logger.py:50 - Epoch: [12][0/6]	Total Loss: 1.30085	Main MSE (x10^-2): 130.0855	LR: 4.00e-04	EMPP_Raw: 1.61624
2025-07-18 08:05:12,412 - logger.py:50 - Epoch: [12][5/6]	Total Loss: 1.30464	Main MSE (x10^-2): 130.4636	LR: 4.00e-04	EMPP_Raw: 1.63771
2025-07-18 08:05:12,459 - logger.py:50 - Epoch 12 Training Summary: Avg Total Loss: 1.30464, Avg Main MSE: 1.30464, Time: 16.84s
2025-07-18 08:05:48,467 - logger.py:50 - *** New Best Val MSE (x10^-2): 48.0548, Corresponding Test MSE (x10^-2): 48.5195 at Epoch 12 ***
2025-07-18 08:05:48,514 - logger.py:50 - Epoch 12 Summary | Train MSE (x10^-2): 130.4636 | Val MSE (x10^-2): 48.0548 | Time: 52.90s
2025-07-18 08:05:51,499 - logger.py:50 - Epoch: [13][0/6]	Total Loss: 1.29019	Main MSE (x10^-2): 129.0189	LR: 3.99e-04	EMPP_Raw: 1.62410
2025-07-18 08:06:05,277 - logger.py:50 - Epoch: [13][5/6]	Total Loss: 1.28456	Main MSE (x10^-2): 128.4560	LR: 3.99e-04	EMPP_Raw: 1.59741
2025-07-18 08:06:05,322 - logger.py:50 - Epoch 13 Training Summary: Avg Total Loss: 1.28456, Avg Main MSE: 1.28456, Time: 16.80s
2025-07-18 08:06:23,372 - logger.py:50 - Epoch 13 Summary | Train MSE (x10^-2): 128.4560 | Val MSE (x10^-2): 48.2289 | Time: 34.86s
2025-07-18 08:06:26,376 - logger.py:50 - Epoch: [14][0/6]	Total Loss: 1.30776	Main MSE (x10^-2): 130.7759	LR: 3.99e-04	EMPP_Raw: 1.64737
2025-07-18 08:06:40,176 - logger.py:50 - Epoch: [14][5/6]	Total Loss: 1.27717	Main MSE (x10^-2): 127.7170	LR: 3.99e-04	EMPP_Raw: 1.59156
2025-07-18 08:06:40,219 - logger.py:50 - Epoch 14 Training Summary: Avg Total Loss: 1.27717, Avg Main MSE: 1.27717, Time: 16.84s
2025-07-18 08:06:58,157 - logger.py:50 - Epoch 14 Summary | Train MSE (x10^-2): 127.7170 | Val MSE (x10^-2): 48.0706 | Time: 34.78s
2025-07-18 08:07:01,327 - logger.py:50 - Epoch: [15][0/6]	Total Loss: 1.24797	Main MSE (x10^-2): 124.7972	LR: 3.99e-04	EMPP_Raw: 1.50869
2025-07-18 08:07:15,090 - logger.py:50 - Epoch: [15][5/6]	Total Loss: 1.25741	Main MSE (x10^-2): 125.7407	LR: 3.99e-04	EMPP_Raw: 1.55860
2025-07-18 08:07:15,134 - logger.py:50 - Epoch 15 Training Summary: Avg Total Loss: 1.25741, Avg Main MSE: 1.25741, Time: 16.97s
2025-07-18 08:07:50,940 - logger.py:50 - *** New Best Val MSE (x10^-2): 47.8265, Corresponding Test MSE (x10^-2): 48.2850 at Epoch 15 ***
2025-07-18 08:07:50,987 - logger.py:50 - Epoch 15 Summary | Train MSE (x10^-2): 125.7407 | Val MSE (x10^-2): 47.8265 | Time: 52.83s
2025-07-18 08:07:54,158 - logger.py:50 - Epoch: [16][0/6]	Total Loss: 1.28795	Main MSE (x10^-2): 128.7952	LR: 3.99e-04	EMPP_Raw: 1.56552
2025-07-18 08:08:07,930 - logger.py:50 - Epoch: [16][5/6]	Total Loss: 1.25927	Main MSE (x10^-2): 125.9268	LR: 3.99e-04	EMPP_Raw: 1.56900
2025-07-18 08:08:07,971 - logger.py:50 - Epoch 16 Training Summary: Avg Total Loss: 1.25927, Avg Main MSE: 1.25927, Time: 16.98s
2025-07-18 08:08:25,913 - logger.py:50 - Epoch 16 Summary | Train MSE (x10^-2): 125.9268 | Val MSE (x10^-2): 48.0049 | Time: 34.93s
2025-07-18 08:08:28,951 - logger.py:50 - Epoch: [17][0/6]	Total Loss: 1.25125	Main MSE (x10^-2): 125.1247	LR: 3.99e-04	EMPP_Raw: 1.55556
2025-07-18 08:08:42,880 - logger.py:50 - Epoch: [17][5/6]	Total Loss: 1.25163	Main MSE (x10^-2): 125.1631	LR: 3.99e-04	EMPP_Raw: 1.55038
2025-07-18 08:08:42,926 - logger.py:50 - Epoch 17 Training Summary: Avg Total Loss: 1.25163, Avg Main MSE: 1.25163, Time: 17.00s
2025-07-18 08:09:18,717 - logger.py:50 - *** New Best Val MSE (x10^-2): 47.2600, Corresponding Test MSE (x10^-2): 47.6140 at Epoch 17 ***
2025-07-18 08:09:18,763 - logger.py:50 - Epoch 17 Summary | Train MSE (x10^-2): 125.1631 | Val MSE (x10^-2): 47.2600 | Time: 52.84s
2025-07-18 08:09:21,748 - logger.py:50 - Epoch: [18][0/6]	Total Loss: 1.22639	Main MSE (x10^-2): 122.6390	LR: 3.99e-04	EMPP_Raw: 1.51904
2025-07-18 08:09:35,642 - logger.py:50 - Epoch: [18][5/6]	Total Loss: 1.26303	Main MSE (x10^-2): 126.3029	LR: 3.99e-04	EMPP_Raw: 1.57150
2025-07-18 08:09:35,683 - logger.py:50 - Epoch 18 Training Summary: Avg Total Loss: 1.26303, Avg Main MSE: 1.26303, Time: 16.92s
2025-07-18 08:09:53,643 - logger.py:50 - Epoch 18 Summary | Train MSE (x10^-2): 126.3029 | Val MSE (x10^-2): 47.2891 | Time: 34.88s
2025-07-18 08:09:56,630 - logger.py:50 - Epoch: [19][0/6]	Total Loss: 1.25785	Main MSE (x10^-2): 125.7854	LR: 3.99e-04	EMPP_Raw: 1.57790
2025-07-18 08:10:10,394 - logger.py:50 - Epoch: [19][5/6]	Total Loss: 1.24345	Main MSE (x10^-2): 124.3454	LR: 3.99e-04	EMPP_Raw: 1.54416
2025-07-18 08:10:10,435 - logger.py:50 - Epoch 19 Training Summary: Avg Total Loss: 1.24345, Avg Main MSE: 1.24345, Time: 16.78s
2025-07-18 08:10:46,465 - logger.py:50 - *** New Best Val MSE (x10^-2): 47.1426, Corresponding Test MSE (x10^-2): 47.3627 at Epoch 19 ***
2025-07-18 08:10:46,512 - logger.py:50 - Epoch 19 Summary | Train MSE (x10^-2): 124.3454 | Val MSE (x10^-2): 47.1426 | Time: 52.86s
2025-07-18 08:10:49,505 - logger.py:50 - Epoch: [20][0/6]	Total Loss: 1.22906	Main MSE (x10^-2): 122.9064	LR: 3.99e-04	EMPP_Raw: 1.54049
2025-07-18 08:11:03,466 - logger.py:50 - Epoch: [20][5/6]	Total Loss: 1.23700	Main MSE (x10^-2): 123.6999	LR: 3.99e-04	EMPP_Raw: 1.53829
2025-07-18 08:11:03,506 - logger.py:50 - Epoch 20 Training Summary: Avg Total Loss: 1.23700, Avg Main MSE: 1.23700, Time: 16.99s
2025-07-18 08:11:39,341 - logger.py:50 - *** New Best Val MSE (x10^-2): 47.0453, Corresponding Test MSE (x10^-2): 47.4063 at Epoch 20 ***
2025-07-18 08:11:39,391 - logger.py:50 - Epoch 20 Summary | Train MSE (x10^-2): 123.6999 | Val MSE (x10^-2): 47.0453 | Time: 52.88s
2025-07-18 08:11:42,373 - logger.py:50 - Epoch: [21][0/6]	Total Loss: 1.26738	Main MSE (x10^-2): 126.7380	LR: 3.98e-04	EMPP_Raw: 1.60954
2025-07-18 08:11:56,128 - logger.py:50 - Epoch: [21][5/6]	Total Loss: 1.23755	Main MSE (x10^-2): 123.7552	LR: 3.98e-04	EMPP_Raw: 1.54028
2025-07-18 08:11:56,169 - logger.py:50 - Epoch 21 Training Summary: Avg Total Loss: 1.23755, Avg Main MSE: 1.23755, Time: 16.77s
2025-07-18 08:12:14,207 - logger.py:50 - Epoch 21 Summary | Train MSE (x10^-2): 123.7552 | Val MSE (x10^-2): 47.2537 | Time: 34.82s
2025-07-18 08:12:17,215 - logger.py:50 - Epoch: [22][0/6]	Total Loss: 1.25114	Main MSE (x10^-2): 125.1136	LR: 3.98e-04	EMPP_Raw: 1.54532
2025-07-18 08:12:31,040 - logger.py:50 - Epoch: [22][5/6]	Total Loss: 1.24621	Main MSE (x10^-2): 124.6208	LR: 3.98e-04	EMPP_Raw: 1.54186
2025-07-18 08:12:31,087 - logger.py:50 - Epoch 22 Training Summary: Avg Total Loss: 1.24621, Avg Main MSE: 1.24621, Time: 16.87s
2025-07-18 08:12:49,140 - logger.py:50 - Epoch 22 Summary | Train MSE (x10^-2): 124.6208 | Val MSE (x10^-2): 47.8065 | Time: 34.93s
2025-07-18 08:12:52,183 - logger.py:50 - Epoch: [23][0/6]	Total Loss: 1.21945	Main MSE (x10^-2): 121.9455	LR: 3.98e-04	EMPP_Raw: 1.49739
2025-07-18 08:13:06,032 - logger.py:50 - Epoch: [23][5/6]	Total Loss: 1.22658	Main MSE (x10^-2): 122.6577	LR: 3.98e-04	EMPP_Raw: 1.51767
2025-07-18 08:13:06,079 - logger.py:50 - Epoch 23 Training Summary: Avg Total Loss: 1.22658, Avg Main MSE: 1.22658, Time: 16.93s
2025-07-18 08:13:24,019 - logger.py:50 - Epoch 23 Summary | Train MSE (x10^-2): 122.6577 | Val MSE (x10^-2): 47.4551 | Time: 34.87s
2025-07-18 08:13:27,015 - logger.py:50 - Epoch: [24][0/6]	Total Loss: 1.27538	Main MSE (x10^-2): 127.5383	LR: 3.98e-04	EMPP_Raw: 1.57622
2025-07-18 08:13:40,961 - logger.py:50 - Epoch: [24][5/6]	Total Loss: 1.24944	Main MSE (x10^-2): 124.9438	LR: 3.98e-04	EMPP_Raw: 1.56152
2025-07-18 08:13:41,002 - logger.py:50 - Epoch 24 Training Summary: Avg Total Loss: 1.24944, Avg Main MSE: 1.24944, Time: 16.97s
2025-07-18 08:13:59,034 - logger.py:50 - Epoch 24 Summary | Train MSE (x10^-2): 124.9438 | Val MSE (x10^-2): 47.4864 | Time: 35.01s
2025-07-18 08:14:02,034 - logger.py:50 - Epoch: [25][0/6]	Total Loss: 1.28262	Main MSE (x10^-2): 128.2620	LR: 3.98e-04	EMPP_Raw: 1.57460
2025-07-18 08:14:15,852 - logger.py:50 - Epoch: [25][5/6]	Total Loss: 1.24354	Main MSE (x10^-2): 124.3539	LR: 3.98e-04	EMPP_Raw: 1.54177
2025-07-18 08:14:15,894 - logger.py:50 - Epoch 25 Training Summary: Avg Total Loss: 1.24354, Avg Main MSE: 1.24354, Time: 16.85s
2025-07-18 08:14:33,879 - logger.py:50 - Epoch 25 Summary | Train MSE (x10^-2): 124.3539 | Val MSE (x10^-2): 47.7839 | Time: 34.84s
2025-07-18 08:14:36,883 - logger.py:50 - Epoch: [26][0/6]	Total Loss: 1.22371	Main MSE (x10^-2): 122.3709	LR: 3.98e-04	EMPP_Raw: 1.52179
2025-07-18 08:14:50,698 - logger.py:50 - Epoch: [26][5/6]	Total Loss: 1.22873	Main MSE (x10^-2): 122.8734	LR: 3.98e-04	EMPP_Raw: 1.51364
2025-07-18 08:14:50,744 - logger.py:50 - Epoch 26 Training Summary: Avg Total Loss: 1.22873, Avg Main MSE: 1.22873, Time: 16.86s
2025-07-18 08:15:26,732 - logger.py:50 - *** New Best Val MSE (x10^-2): 46.9997, Corresponding Test MSE (x10^-2): 47.2275 at Epoch 26 ***
2025-07-18 08:15:26,775 - logger.py:50 - Epoch 26 Summary | Train MSE (x10^-2): 122.8734 | Val MSE (x10^-2): 46.9997 | Time: 52.89s
2025-07-18 08:15:29,766 - logger.py:50 - Epoch: [27][0/6]	Total Loss: 1.25080	Main MSE (x10^-2): 125.0795	LR: 3.97e-04	EMPP_Raw: 1.56742
2025-07-18 08:15:43,526 - logger.py:50 - Epoch: [27][5/6]	Total Loss: 1.22784	Main MSE (x10^-2): 122.7844	LR: 3.97e-04	EMPP_Raw: 1.52769
2025-07-18 08:15:43,567 - logger.py:50 - Epoch 27 Training Summary: Avg Total Loss: 1.22784, Avg Main MSE: 1.22784, Time: 16.79s
2025-07-18 08:16:01,719 - logger.py:50 - Epoch 27 Summary | Train MSE (x10^-2): 122.7844 | Val MSE (x10^-2): 47.2575 | Time: 34.94s
2025-07-18 08:16:04,733 - logger.py:50 - Epoch: [28][0/6]	Total Loss: 1.24954	Main MSE (x10^-2): 124.9540	LR: 3.97e-04	EMPP_Raw: 1.56691
2025-07-18 08:16:18,527 - logger.py:50 - Epoch: [28][5/6]	Total Loss: 1.23132	Main MSE (x10^-2): 123.1325	LR: 3.97e-04	EMPP_Raw: 1.52482
2025-07-18 08:16:18,571 - logger.py:50 - Epoch 28 Training Summary: Avg Total Loss: 1.23132, Avg Main MSE: 1.23132, Time: 16.84s
2025-07-18 08:16:36,479 - logger.py:50 - Epoch 28 Summary | Train MSE (x10^-2): 123.1325 | Val MSE (x10^-2): 47.0850 | Time: 34.75s
2025-07-18 08:16:39,641 - logger.py:50 - Epoch: [29][0/6]	Total Loss: 1.21838	Main MSE (x10^-2): 121.8379	LR: 3.97e-04	EMPP_Raw: 1.50519
2025-07-18 08:16:53,420 - logger.py:50 - Epoch: [29][5/6]	Total Loss: 1.21259	Main MSE (x10^-2): 121.2590	LR: 3.97e-04	EMPP_Raw: 1.50855
2025-07-18 08:16:53,461 - logger.py:50 - Epoch 29 Training Summary: Avg Total Loss: 1.21259, Avg Main MSE: 1.21259, Time: 16.97s
2025-07-18 08:17:11,400 - logger.py:50 - Epoch 29 Summary | Train MSE (x10^-2): 121.2590 | Val MSE (x10^-2): 47.1853 | Time: 34.91s
2025-07-18 08:17:14,582 - logger.py:50 - Epoch: [30][0/6]	Total Loss: 1.20599	Main MSE (x10^-2): 120.5990	LR: 3.97e-04	EMPP_Raw: 1.49275
2025-07-18 08:17:28,383 - logger.py:50 - Epoch: [30][5/6]	Total Loss: 1.22821	Main MSE (x10^-2): 122.8209	LR: 3.97e-04	EMPP_Raw: 1.52536
2025-07-18 08:17:28,423 - logger.py:50 - Epoch 30 Training Summary: Avg Total Loss: 1.22821, Avg Main MSE: 1.22821, Time: 17.01s
2025-07-18 08:17:46,375 - logger.py:50 - Epoch 30 Summary | Train MSE (x10^-2): 122.8209 | Val MSE (x10^-2): 48.6336 | Time: 34.96s
2025-07-18 08:17:49,385 - logger.py:50 - Epoch: [31][0/6]	Total Loss: 1.22856	Main MSE (x10^-2): 122.8557	LR: 3.96e-04	EMPP_Raw: 1.51147
2025-07-18 08:18:03,364 - logger.py:50 - Epoch: [31][5/6]	Total Loss: 1.23290	Main MSE (x10^-2): 123.2897	LR: 3.96e-04	EMPP_Raw: 1.53243
2025-07-18 08:18:03,410 - logger.py:50 - Epoch 31 Training Summary: Avg Total Loss: 1.23290, Avg Main MSE: 1.23290, Time: 17.03s
2025-07-18 08:18:21,307 - logger.py:50 - Epoch 31 Summary | Train MSE (x10^-2): 123.2897 | Val MSE (x10^-2): 47.0136 | Time: 34.93s
2025-07-18 08:18:24,323 - logger.py:50 - Epoch: [32][0/6]	Total Loss: 1.21192	Main MSE (x10^-2): 121.1924	LR: 3.96e-04	EMPP_Raw: 1.52032
2025-07-18 08:18:38,334 - logger.py:50 - Epoch: [32][5/6]	Total Loss: 1.20969	Main MSE (x10^-2): 120.9693	LR: 3.96e-04	EMPP_Raw: 1.50160
2025-07-18 08:18:38,378 - logger.py:50 - Epoch 32 Training Summary: Avg Total Loss: 1.20969, Avg Main MSE: 1.20969, Time: 17.06s
2025-07-18 08:18:56,293 - logger.py:50 - Epoch 32 Summary | Train MSE (x10^-2): 120.9693 | Val MSE (x10^-2): 47.0352 | Time: 34.98s
2025-07-18 08:18:59,299 - logger.py:50 - Epoch: [33][0/6]	Total Loss: 1.24448	Main MSE (x10^-2): 124.4477	LR: 3.96e-04	EMPP_Raw: 1.55179
2025-07-18 08:19:13,149 - logger.py:50 - Epoch: [33][5/6]	Total Loss: 1.23544	Main MSE (x10^-2): 123.5442	LR: 3.96e-04	EMPP_Raw: 1.52893
2025-07-18 08:19:13,195 - logger.py:50 - Epoch 33 Training Summary: Avg Total Loss: 1.23544, Avg Main MSE: 1.23544, Time: 16.89s
2025-07-18 08:19:31,107 - logger.py:50 - Epoch 33 Summary | Train MSE (x10^-2): 123.5442 | Val MSE (x10^-2): 47.9246 | Time: 34.81s
2025-07-18 08:19:34,267 - logger.py:50 - Epoch: [34][0/6]	Total Loss: 1.18683	Main MSE (x10^-2): 118.6829	LR: 3.96e-04	EMPP_Raw: 1.46625
2025-07-18 08:19:48,005 - logger.py:50 - Epoch: [34][5/6]	Total Loss: 1.23357	Main MSE (x10^-2): 123.3567	LR: 3.96e-04	EMPP_Raw: 1.51196
2025-07-18 08:19:48,050 - logger.py:50 - Epoch 34 Training Summary: Avg Total Loss: 1.23357, Avg Main MSE: 1.23357, Time: 16.93s
2025-07-18 08:20:06,164 - logger.py:50 - Epoch 34 Summary | Train MSE (x10^-2): 123.3567 | Val MSE (x10^-2): 48.1555 | Time: 35.05s
2025-07-18 08:20:09,350 - logger.py:50 - Epoch: [35][0/6]	Total Loss: 1.19316	Main MSE (x10^-2): 119.3159	LR: 3.95e-04	EMPP_Raw: 1.47663
2025-07-18 08:20:23,129 - logger.py:50 - Epoch: [35][5/6]	Total Loss: 1.21014	Main MSE (x10^-2): 121.0138	LR: 3.95e-04	EMPP_Raw: 1.49806
2025-07-18 08:20:23,171 - logger.py:50 - Epoch 35 Training Summary: Avg Total Loss: 1.21014, Avg Main MSE: 1.21014, Time: 17.00s
2025-07-18 08:20:41,235 - logger.py:50 - Epoch 35 Summary | Train MSE (x10^-2): 121.0138 | Val MSE (x10^-2): 48.2460 | Time: 35.06s
2025-07-18 08:20:44,274 - logger.py:50 - Epoch: [36][0/6]	Total Loss: 1.22901	Main MSE (x10^-2): 122.9008	LR: 3.95e-04	EMPP_Raw: 1.48929
2025-07-18 08:20:58,173 - logger.py:50 - Epoch: [36][5/6]	Total Loss: 1.20376	Main MSE (x10^-2): 120.3757	LR: 3.95e-04	EMPP_Raw: 1.48474
2025-07-18 08:20:58,217 - logger.py:50 - Epoch 36 Training Summary: Avg Total Loss: 1.20376, Avg Main MSE: 1.20376, Time: 16.98s
2025-07-18 08:21:16,247 - logger.py:50 - Epoch 36 Summary | Train MSE (x10^-2): 120.3757 | Val MSE (x10^-2): 47.4118 | Time: 35.01s
2025-07-18 08:21:19,255 - logger.py:50 - Epoch: [37][0/6]	Total Loss: 1.23297	Main MSE (x10^-2): 123.2974	LR: 3.95e-04	EMPP_Raw: 1.51188
2025-07-18 08:21:33,032 - logger.py:50 - Epoch: [37][5/6]	Total Loss: 1.20557	Main MSE (x10^-2): 120.5570	LR: 3.95e-04	EMPP_Raw: 1.50114
2025-07-18 08:21:33,077 - logger.py:50 - Epoch 37 Training Summary: Avg Total Loss: 1.20557, Avg Main MSE: 1.20557, Time: 16.82s
2025-07-18 08:21:51,092 - logger.py:50 - Epoch 37 Summary | Train MSE (x10^-2): 120.5570 | Val MSE (x10^-2): 47.2783 | Time: 34.84s
2025-07-18 08:21:54,084 - logger.py:50 - Epoch: [38][0/6]	Total Loss: 1.19684	Main MSE (x10^-2): 119.6843	LR: 3.95e-04	EMPP_Raw: 1.49878
2025-07-18 08:22:07,848 - logger.py:50 - Epoch: [38][5/6]	Total Loss: 1.21441	Main MSE (x10^-2): 121.4406	LR: 3.95e-04	EMPP_Raw: 1.50923
2025-07-18 08:22:07,889 - logger.py:50 - Epoch 38 Training Summary: Avg Total Loss: 1.21441, Avg Main MSE: 1.21441, Time: 16.79s
2025-07-18 08:22:26,009 - logger.py:50 - Epoch 38 Summary | Train MSE (x10^-2): 121.4406 | Val MSE (x10^-2): 47.1903 | Time: 34.91s
2025-07-18 08:22:29,026 - logger.py:50 - Epoch: [39][0/6]	Total Loss: 1.23365	Main MSE (x10^-2): 123.3646	LR: 3.94e-04	EMPP_Raw: 1.51615
2025-07-18 08:22:42,869 - logger.py:50 - Epoch: [39][5/6]	Total Loss: 1.21991	Main MSE (x10^-2): 121.9909	LR: 3.94e-04	EMPP_Raw: 1.51473
2025-07-18 08:22:42,915 - logger.py:50 - Epoch 39 Training Summary: Avg Total Loss: 1.21991, Avg Main MSE: 1.21991, Time: 16.90s
2025-07-18 08:23:00,840 - logger.py:50 - Epoch 39 Summary | Train MSE (x10^-2): 121.9909 | Val MSE (x10^-2): 47.4403 | Time: 34.82s
2025-07-18 08:23:03,900 - logger.py:50 - Epoch: [40][0/6]	Total Loss: 1.22505	Main MSE (x10^-2): 122.5054	LR: 3.94e-04	EMPP_Raw: 1.54734
2025-07-18 08:23:17,856 - logger.py:50 - Epoch: [40][5/6]	Total Loss: 1.21159	Main MSE (x10^-2): 121.1590	LR: 3.94e-04	EMPP_Raw: 1.51012
2025-07-18 08:23:17,900 - logger.py:50 - Epoch 40 Training Summary: Avg Total Loss: 1.21159, Avg Main MSE: 1.21159, Time: 17.05s
2025-07-18 08:23:35,862 - logger.py:50 - Epoch 40 Summary | Train MSE (x10^-2): 121.1590 | Val MSE (x10^-2): 49.9424 | Time: 35.02s
2025-07-18 08:23:38,901 - logger.py:50 - Epoch: [41][0/6]	Total Loss: 1.21665	Main MSE (x10^-2): 121.6647	LR: 3.94e-04	EMPP_Raw: 1.48903
2025-07-18 08:23:52,707 - logger.py:50 - Epoch: [41][5/6]	Total Loss: 1.21464	Main MSE (x10^-2): 121.4643	LR: 3.94e-04	EMPP_Raw: 1.49339
2025-07-18 08:23:52,748 - logger.py:50 - Epoch 41 Training Summary: Avg Total Loss: 1.21464, Avg Main MSE: 1.21464, Time: 16.88s
2025-07-18 08:24:10,867 - logger.py:50 - Epoch 41 Summary | Train MSE (x10^-2): 121.4643 | Val MSE (x10^-2): 48.2027 | Time: 35.00s
2025-07-18 08:24:13,897 - logger.py:50 - Epoch: [42][0/6]	Total Loss: 1.22112	Main MSE (x10^-2): 122.1122	LR: 3.93e-04	EMPP_Raw: 1.50584
2025-07-18 08:24:27,708 - logger.py:50 - Epoch: [42][5/6]	Total Loss: 1.21214	Main MSE (x10^-2): 121.2144	LR: 3.93e-04	EMPP_Raw: 1.50968
2025-07-18 08:24:27,747 - logger.py:50 - Epoch 42 Training Summary: Avg Total Loss: 1.21214, Avg Main MSE: 1.21214, Time: 16.87s
2025-07-18 08:24:45,726 - logger.py:50 - Epoch 42 Summary | Train MSE (x10^-2): 121.2144 | Val MSE (x10^-2): 47.3653 | Time: 34.85s
2025-07-18 08:24:48,744 - logger.py:50 - Epoch: [43][0/6]	Total Loss: 1.24131	Main MSE (x10^-2): 124.1310	LR: 3.93e-04	EMPP_Raw: 1.56381
2025-07-18 08:25:02,560 - logger.py:50 - Epoch: [43][5/6]	Total Loss: 1.21148	Main MSE (x10^-2): 121.1482	LR: 3.93e-04	EMPP_Raw: 1.52257
2025-07-18 08:25:02,605 - logger.py:50 - Epoch 43 Training Summary: Avg Total Loss: 1.21148, Avg Main MSE: 1.21148, Time: 16.87s
2025-07-18 08:25:20,727 - logger.py:50 - Epoch 43 Summary | Train MSE (x10^-2): 121.1482 | Val MSE (x10^-2): 47.9448 | Time: 35.00s
2025-07-18 08:25:23,749 - logger.py:50 - Epoch: [44][0/6]	Total Loss: 1.23336	Main MSE (x10^-2): 123.3363	LR: 3.93e-04	EMPP_Raw: 1.54002
2025-07-18 08:25:37,571 - logger.py:50 - Epoch: [44][5/6]	Total Loss: 1.22594	Main MSE (x10^-2): 122.5938	LR: 3.93e-04	EMPP_Raw: 1.52391
2025-07-18 08:25:37,614 - logger.py:50 - Epoch 44 Training Summary: Avg Total Loss: 1.22594, Avg Main MSE: 1.22594, Time: 16.88s
2025-07-18 08:25:55,535 - logger.py:50 - Epoch 44 Summary | Train MSE (x10^-2): 122.5938 | Val MSE (x10^-2): 48.2243 | Time: 34.80s
2025-07-18 08:25:58,697 - logger.py:50 - Epoch: [45][0/6]	Total Loss: 1.20085	Main MSE (x10^-2): 120.0850	LR: 3.92e-04	EMPP_Raw: 1.52319
2025-07-18 08:26:12,474 - logger.py:50 - Epoch: [45][5/6]	Total Loss: 1.22070	Main MSE (x10^-2): 122.0703	LR: 3.92e-04	EMPP_Raw: 1.51100
2025-07-18 08:26:12,521 - logger.py:50 - Epoch 45 Training Summary: Avg Total Loss: 1.22070, Avg Main MSE: 1.22070, Time: 16.98s
2025-07-18 08:26:30,445 - logger.py:50 - Epoch 45 Summary | Train MSE (x10^-2): 122.0703 | Val MSE (x10^-2): 47.8387 | Time: 34.90s
2025-07-18 08:26:33,459 - logger.py:50 - Epoch: [46][0/6]	Total Loss: 1.22386	Main MSE (x10^-2): 122.3865	LR: 3.92e-04	EMPP_Raw: 1.51865
2025-07-18 08:26:47,455 - logger.py:50 - Epoch: [46][5/6]	Total Loss: 1.23743	Main MSE (x10^-2): 123.7429	LR: 3.92e-04	EMPP_Raw: 1.52353
2025-07-18 08:26:47,499 - logger.py:50 - Epoch 46 Training Summary: Avg Total Loss: 1.23743, Avg Main MSE: 1.23743, Time: 17.04s
2025-07-18 08:27:05,406 - logger.py:50 - Epoch 46 Summary | Train MSE (x10^-2): 123.7429 | Val MSE (x10^-2): 48.4524 | Time: 34.95s
2025-07-18 08:27:08,414 - logger.py:50 - Epoch: [47][0/6]	Total Loss: 1.18663	Main MSE (x10^-2): 118.6632	LR: 3.92e-04	EMPP_Raw: 1.47667
2025-07-18 08:27:22,210 - logger.py:50 - Epoch: [47][5/6]	Total Loss: 1.20771	Main MSE (x10^-2): 120.7709	LR: 3.92e-04	EMPP_Raw: 1.50958
2025-07-18 08:27:22,252 - logger.py:50 - Epoch 47 Training Summary: Avg Total Loss: 1.20771, Avg Main MSE: 1.20771, Time: 16.84s
2025-07-18 08:27:40,167 - logger.py:50 - Epoch 47 Summary | Train MSE (x10^-2): 120.7709 | Val MSE (x10^-2): 47.2902 | Time: 34.76s
2025-07-18 08:27:43,354 - logger.py:50 - Epoch: [48][0/6]	Total Loss: 1.16288	Main MSE (x10^-2): 116.2884	LR: 3.91e-04	EMPP_Raw: 1.46291
2025-07-18 08:27:57,119 - logger.py:50 - Epoch: [48][5/6]	Total Loss: 1.20899	Main MSE (x10^-2): 120.8989	LR: 3.91e-04	EMPP_Raw: 1.52032
2025-07-18 08:27:57,164 - logger.py:50 - Epoch 48 Training Summary: Avg Total Loss: 1.20899, Avg Main MSE: 1.20899, Time: 16.99s
2025-07-18 08:28:15,045 - logger.py:50 - Epoch 48 Summary | Train MSE (x10^-2): 120.8989 | Val MSE (x10^-2): 48.1305 | Time: 34.87s
2025-07-18 08:28:18,205 - logger.py:50 - Epoch: [49][0/6]	Total Loss: 1.22927	Main MSE (x10^-2): 122.9266	LR: 3.91e-04	EMPP_Raw: 1.51703
2025-07-18 08:28:31,933 - logger.py:50 - Epoch: [49][5/6]	Total Loss: 1.20826	Main MSE (x10^-2): 120.8255	LR: 3.91e-04	EMPP_Raw: 1.52304
2025-07-18 08:28:31,976 - logger.py:50 - Epoch 49 Training Summary: Avg Total Loss: 1.20826, Avg Main MSE: 1.20826, Time: 16.93s
2025-07-18 08:28:49,914 - logger.py:50 - Epoch 49 Summary | Train MSE (x10^-2): 120.8255 | Val MSE (x10^-2): 47.8401 | Time: 34.87s
2025-07-18 08:28:52,926 - logger.py:50 - Epoch: [50][0/6]	Total Loss: 1.19209	Main MSE (x10^-2): 119.2090	LR: 3.91e-04	EMPP_Raw: 1.49900
2025-07-18 08:29:06,884 - logger.py:50 - Epoch: [50][5/6]	Total Loss: 1.20647	Main MSE (x10^-2): 120.6471	LR: 3.91e-04	EMPP_Raw: 1.52135
2025-07-18 08:29:06,929 - logger.py:50 - Epoch 50 Training Summary: Avg Total Loss: 1.20647, Avg Main MSE: 1.20647, Time: 17.00s
2025-07-18 08:29:24,914 - logger.py:50 - Epoch 50 Summary | Train MSE (x10^-2): 120.6471 | Val MSE (x10^-2): 48.1831 | Time: 34.99s
2025-07-18 08:29:27,913 - logger.py:50 - Epoch: [51][0/6]	Total Loss: 1.20221	Main MSE (x10^-2): 120.2208	LR: 3.90e-04	EMPP_Raw: 1.50715
2025-07-18 08:29:41,727 - logger.py:50 - Epoch: [51][5/6]	Total Loss: 1.19545	Main MSE (x10^-2): 119.5445	LR: 3.90e-04	EMPP_Raw: 1.50876
2025-07-18 08:29:41,769 - logger.py:50 - Epoch 51 Training Summary: Avg Total Loss: 1.19545, Avg Main MSE: 1.19545, Time: 16.85s
2025-07-18 08:29:59,902 - logger.py:50 - Epoch 51 Summary | Train MSE (x10^-2): 119.5445 | Val MSE (x10^-2): 48.2047 | Time: 34.98s
2025-07-18 08:30:02,907 - logger.py:50 - Epoch: [52][0/6]	Total Loss: 1.17529	Main MSE (x10^-2): 117.5287	LR: 3.90e-04	EMPP_Raw: 1.48746
2025-07-18 08:30:16,709 - logger.py:50 - Epoch: [52][5/6]	Total Loss: 1.19067	Main MSE (x10^-2): 119.0674	LR: 3.90e-04	EMPP_Raw: 1.50099
2025-07-18 08:30:16,753 - logger.py:50 - Epoch 52 Training Summary: Avg Total Loss: 1.19067, Avg Main MSE: 1.19067, Time: 16.84s
2025-07-18 08:30:34,832 - logger.py:50 - Epoch 52 Summary | Train MSE (x10^-2): 119.0674 | Val MSE (x10^-2): 48.3091 | Time: 34.93s
2025-07-18 08:30:37,998 - logger.py:50 - Epoch: [53][0/6]	Total Loss: 1.18104	Main MSE (x10^-2): 118.1042	LR: 3.89e-04	EMPP_Raw: 1.48811
2025-07-18 08:30:51,769 - logger.py:50 - Epoch: [53][5/6]	Total Loss: 1.19861	Main MSE (x10^-2): 119.8608	LR: 3.89e-04	EMPP_Raw: 1.51265
2025-07-18 08:30:51,815 - logger.py:50 - Epoch 53 Training Summary: Avg Total Loss: 1.19861, Avg Main MSE: 1.19861, Time: 16.97s
2025-07-18 08:31:09,661 - logger.py:50 - Epoch 53 Summary | Train MSE (x10^-2): 119.8608 | Val MSE (x10^-2): 48.7184 | Time: 34.82s
2025-07-18 08:31:12,674 - logger.py:50 - Epoch: [54][0/6]	Total Loss: 1.18690	Main MSE (x10^-2): 118.6896	LR: 3.89e-04	EMPP_Raw: 1.53174
2025-07-18 08:31:26,710 - logger.py:50 - Epoch: [54][5/6]	Total Loss: 1.18982	Main MSE (x10^-2): 118.9822	LR: 3.89e-04	EMPP_Raw: 1.51226
2025-07-18 08:31:26,751 - logger.py:50 - Epoch 54 Training Summary: Avg Total Loss: 1.18982, Avg Main MSE: 1.18982, Time: 17.08s
2025-07-18 08:31:44,622 - logger.py:50 - Epoch 54 Summary | Train MSE (x10^-2): 118.9822 | Val MSE (x10^-2): 48.8797 | Time: 34.96s
2025-07-18 08:31:47,628 - logger.py:50 - Epoch: [55][0/6]	Total Loss: 1.19451	Main MSE (x10^-2): 119.4513	LR: 3.89e-04	EMPP_Raw: 1.55887
2025-07-18 08:32:01,407 - logger.py:50 - Epoch: [55][5/6]	Total Loss: 1.18670	Main MSE (x10^-2): 118.6700	LR: 3.89e-04	EMPP_Raw: 1.51098
2025-07-18 08:32:01,458 - logger.py:50 - Epoch 55 Training Summary: Avg Total Loss: 1.18670, Avg Main MSE: 1.18670, Time: 16.83s
2025-07-18 08:32:19,572 - logger.py:50 - Epoch 55 Summary | Train MSE (x10^-2): 118.6700 | Val MSE (x10^-2): 49.3153 | Time: 34.94s
2025-07-18 08:32:22,633 - logger.py:50 - Epoch: [56][0/6]	Total Loss: 1.20883	Main MSE (x10^-2): 120.8834	LR: 3.88e-04	EMPP_Raw: 1.52550
2025-07-18 08:32:36,484 - logger.py:50 - Epoch: [56][5/6]	Total Loss: 1.18836	Main MSE (x10^-2): 118.8360	LR: 3.88e-04	EMPP_Raw: 1.52098
2025-07-18 08:32:36,527 - logger.py:50 - Epoch 56 Training Summary: Avg Total Loss: 1.18836, Avg Main MSE: 1.18836, Time: 16.94s
2025-07-18 08:32:54,680 - logger.py:50 - Epoch 56 Summary | Train MSE (x10^-2): 118.8360 | Val MSE (x10^-2): 49.1544 | Time: 35.10s
2025-07-18 08:32:57,686 - logger.py:50 - Epoch: [57][0/6]	Total Loss: 1.17058	Main MSE (x10^-2): 117.0576	LR: 3.88e-04	EMPP_Raw: 1.49692
2025-07-18 08:33:11,485 - logger.py:50 - Epoch: [57][5/6]	Total Loss: 1.19568	Main MSE (x10^-2): 119.5683	LR: 3.88e-04	EMPP_Raw: 1.52473
2025-07-18 08:33:11,531 - logger.py:50 - Epoch 57 Training Summary: Avg Total Loss: 1.19568, Avg Main MSE: 1.19568, Time: 16.84s
2025-07-18 08:33:29,487 - logger.py:50 - Epoch 57 Summary | Train MSE (x10^-2): 119.5683 | Val MSE (x10^-2): 50.7067 | Time: 34.80s
2025-07-18 08:33:32,842 - logger.py:50 - Epoch: [58][0/6]	Total Loss: 1.16899	Main MSE (x10^-2): 116.8986	LR: 3.87e-04	EMPP_Raw: 1.48307
2025-07-18 08:33:46,630 - logger.py:50 - Epoch: [58][5/6]	Total Loss: 1.17784	Main MSE (x10^-2): 117.7837	LR: 3.87e-04	EMPP_Raw: 1.49748
2025-07-18 08:33:46,680 - logger.py:50 - Epoch 58 Training Summary: Avg Total Loss: 1.17784, Avg Main MSE: 1.17784, Time: 17.18s
2025-07-18 08:34:04,643 - logger.py:50 - Epoch 58 Summary | Train MSE (x10^-2): 117.7837 | Val MSE (x10^-2): 52.5563 | Time: 35.15s
2025-07-18 08:34:07,819 - logger.py:50 - Epoch: [59][0/6]	Total Loss: 1.21051	Main MSE (x10^-2): 121.0513	LR: 3.87e-04	EMPP_Raw: 1.51104
2025-07-18 08:34:21,616 - logger.py:50 - Epoch: [59][5/6]	Total Loss: 1.18981	Main MSE (x10^-2): 118.9812	LR: 3.87e-04	EMPP_Raw: 1.51194
2025-07-18 08:34:21,661 - logger.py:50 - Epoch 59 Training Summary: Avg Total Loss: 1.18981, Avg Main MSE: 1.18981, Time: 17.01s
2025-07-18 08:34:39,644 - logger.py:50 - Epoch 59 Summary | Train MSE (x10^-2): 118.9812 | Val MSE (x10^-2): 49.7097 | Time: 35.00s
2025-07-18 08:34:42,647 - logger.py:50 - Epoch: [60][0/6]	Total Loss: 1.18592	Main MSE (x10^-2): 118.5924	LR: 3.86e-04	EMPP_Raw: 1.50170
2025-07-18 08:34:56,592 - logger.py:50 - Epoch: [60][5/6]	Total Loss: 1.18529	Main MSE (x10^-2): 118.5292	LR: 3.86e-04	EMPP_Raw: 1.50726
2025-07-18 08:34:56,635 - logger.py:50 - Epoch 60 Training Summary: Avg Total Loss: 1.18529, Avg Main MSE: 1.18529, Time: 16.98s
2025-07-18 08:35:14,628 - logger.py:50 - Epoch 60 Summary | Train MSE (x10^-2): 118.5292 | Val MSE (x10^-2): 50.6693 | Time: 34.98s
2025-07-18 08:35:17,629 - logger.py:50 - Epoch: [61][0/6]	Total Loss: 1.17406	Main MSE (x10^-2): 117.4058	LR: 3.86e-04	EMPP_Raw: 1.53588
2025-07-18 08:35:31,398 - logger.py:50 - Epoch: [61][5/6]	Total Loss: 1.18774	Main MSE (x10^-2): 118.7744	LR: 3.86e-04	EMPP_Raw: 1.52992
2025-07-18 08:35:31,443 - logger.py:50 - Epoch 61 Training Summary: Avg Total Loss: 1.18774, Avg Main MSE: 1.18774, Time: 16.81s
2025-07-18 08:35:49,455 - logger.py:50 - Epoch 61 Summary | Train MSE (x10^-2): 118.7744 | Val MSE (x10^-2): 50.7672 | Time: 34.82s
2025-07-18 08:35:52,451 - logger.py:50 - Epoch: [62][0/6]	Total Loss: 1.14793	Main MSE (x10^-2): 114.7929	LR: 3.86e-04	EMPP_Raw: 1.45013
2025-07-18 08:36:06,200 - logger.py:50 - Epoch: [62][5/6]	Total Loss: 1.15783	Main MSE (x10^-2): 115.7832	LR: 3.86e-04	EMPP_Raw: 1.50511
2025-07-18 08:36:06,242 - logger.py:50 - Epoch 62 Training Summary: Avg Total Loss: 1.15783, Avg Main MSE: 1.15783, Time: 16.78s
2025-07-18 08:36:24,279 - logger.py:50 - Epoch 62 Summary | Train MSE (x10^-2): 115.7832 | Val MSE (x10^-2): 51.2800 | Time: 34.82s
2025-07-18 08:36:27,354 - logger.py:50 - Epoch: [63][0/6]	Total Loss: 1.13606	Main MSE (x10^-2): 113.6057	LR: 3.85e-04	EMPP_Raw: 1.50739
2025-07-18 08:36:41,141 - logger.py:50 - Epoch: [63][5/6]	Total Loss: 1.15994	Main MSE (x10^-2): 115.9940	LR: 3.85e-04	EMPP_Raw: 1.50596
2025-07-18 08:36:41,186 - logger.py:50 - Epoch 63 Training Summary: Avg Total Loss: 1.15994, Avg Main MSE: 1.15994, Time: 16.90s
2025-07-18 08:36:59,102 - logger.py:50 - Epoch 63 Summary | Train MSE (x10^-2): 115.9940 | Val MSE (x10^-2): 52.3624 | Time: 34.82s
2025-07-18 08:37:02,247 - logger.py:50 - Epoch: [64][0/6]	Total Loss: 1.15239	Main MSE (x10^-2): 115.2387	LR: 3.85e-04	EMPP_Raw: 1.50303
2025-07-18 08:37:15,961 - logger.py:50 - Epoch: [64][5/6]	Total Loss: 1.16821	Main MSE (x10^-2): 116.8212	LR: 3.85e-04	EMPP_Raw: 1.49972
2025-07-18 08:37:16,001 - logger.py:50 - Epoch 64 Training Summary: Avg Total Loss: 1.16821, Avg Main MSE: 1.16821, Time: 16.89s
2025-07-18 08:37:34,064 - logger.py:50 - Epoch 64 Summary | Train MSE (x10^-2): 116.8212 | Val MSE (x10^-2): 50.0888 | Time: 34.95s
2025-07-18 08:37:37,056 - logger.py:50 - Epoch: [65][0/6]	Total Loss: 1.15770	Main MSE (x10^-2): 115.7703	LR: 3.84e-04	EMPP_Raw: 1.50893
2025-07-18 08:37:50,939 - logger.py:50 - Epoch: [65][5/6]	Total Loss: 1.15601	Main MSE (x10^-2): 115.6009	LR: 3.84e-04	EMPP_Raw: 1.49679
2025-07-18 08:37:50,984 - logger.py:50 - Epoch 65 Training Summary: Avg Total Loss: 1.15601, Avg Main MSE: 1.15601, Time: 16.91s
2025-07-18 08:38:08,909 - logger.py:50 - Epoch 65 Summary | Train MSE (x10^-2): 115.6009 | Val MSE (x10^-2): 54.8470 | Time: 34.84s
2025-07-18 08:38:11,953 - logger.py:50 - Epoch: [66][0/6]	Total Loss: 1.17919	Main MSE (x10^-2): 117.9192	LR: 3.84e-04	EMPP_Raw: 1.51342
2025-07-18 08:38:25,864 - logger.py:50 - Epoch: [66][5/6]	Total Loss: 1.17512	Main MSE (x10^-2): 117.5117	LR: 3.84e-04	EMPP_Raw: 1.51353
2025-07-18 08:38:25,911 - logger.py:50 - Epoch 66 Training Summary: Avg Total Loss: 1.17512, Avg Main MSE: 1.17512, Time: 16.99s
2025-07-18 08:38:43,826 - logger.py:50 - Epoch 66 Summary | Train MSE (x10^-2): 117.5117 | Val MSE (x10^-2): 52.2607 | Time: 34.91s
2025-07-18 08:38:46,827 - logger.py:50 - Epoch: [67][0/6]	Total Loss: 1.13614	Main MSE (x10^-2): 113.6140	LR: 3.83e-04	EMPP_Raw: 1.53995
2025-07-18 08:39:00,572 - logger.py:50 - Epoch: [67][5/6]	Total Loss: 1.14147	Main MSE (x10^-2): 114.1472	LR: 3.83e-04	EMPP_Raw: 1.48258
2025-07-18 08:39:00,614 - logger.py:50 - Epoch 67 Training Summary: Avg Total Loss: 1.14147, Avg Main MSE: 1.14147, Time: 16.78s
2025-07-18 08:39:18,490 - logger.py:50 - Epoch 67 Summary | Train MSE (x10^-2): 114.1472 | Val MSE (x10^-2): 53.2787 | Time: 34.66s
2025-07-18 08:39:21,638 - logger.py:50 - Epoch: [68][0/6]	Total Loss: 1.13453	Main MSE (x10^-2): 113.4526	LR: 3.83e-04	EMPP_Raw: 1.50834
2025-07-18 08:39:35,446 - logger.py:50 - Epoch: [68][5/6]	Total Loss: 1.13997	Main MSE (x10^-2): 113.9974	LR: 3.83e-04	EMPP_Raw: 1.48864
2025-07-18 08:39:35,489 - logger.py:50 - Epoch 68 Training Summary: Avg Total Loss: 1.13997, Avg Main MSE: 1.13997, Time: 16.99s
2025-07-18 08:39:53,397 - logger.py:50 - Epoch 68 Summary | Train MSE (x10^-2): 113.9974 | Val MSE (x10^-2): 55.3459 | Time: 34.90s
2025-07-18 08:39:56,566 - logger.py:50 - Epoch: [69][0/6]	Total Loss: 1.13856	Main MSE (x10^-2): 113.8561	LR: 3.82e-04	EMPP_Raw: 1.53201
2025-07-18 08:40:10,287 - logger.py:50 - Epoch: [69][5/6]	Total Loss: 1.13957	Main MSE (x10^-2): 113.9574	LR: 3.82e-04	EMPP_Raw: 1.50612
2025-07-18 08:40:10,328 - logger.py:50 - Epoch 69 Training Summary: Avg Total Loss: 1.13957, Avg Main MSE: 1.13957, Time: 16.92s
2025-07-18 08:40:28,245 - logger.py:50 - Epoch 69 Summary | Train MSE (x10^-2): 113.9574 | Val MSE (x10^-2): 54.8680 | Time: 34.84s
2025-07-18 08:40:31,246 - logger.py:50 - Epoch: [70][0/6]	Total Loss: 1.10867	Main MSE (x10^-2): 110.8668	LR: 3.82e-04	EMPP_Raw: 1.47481
2025-07-18 08:40:45,234 - logger.py:50 - Epoch: [70][5/6]	Total Loss: 1.12023	Main MSE (x10^-2): 112.0233	LR: 3.82e-04	EMPP_Raw: 1.50493
2025-07-18 08:40:45,285 - logger.py:50 - Epoch 70 Training Summary: Avg Total Loss: 1.12023, Avg Main MSE: 1.12023, Time: 17.03s
2025-07-18 08:41:03,267 - logger.py:50 - Epoch 70 Summary | Train MSE (x10^-2): 112.0233 | Val MSE (x10^-2): 55.1510 | Time: 35.02s
2025-07-18 08:41:06,272 - logger.py:50 - Epoch: [71][0/6]	Total Loss: 1.10040	Main MSE (x10^-2): 110.0403	LR: 3.81e-04	EMPP_Raw: 1.51613
2025-07-18 08:41:20,037 - logger.py:50 - Epoch: [71][5/6]	Total Loss: 1.11013	Main MSE (x10^-2): 111.0129	LR: 3.81e-04	EMPP_Raw: 1.50804
2025-07-18 08:41:20,080 - logger.py:50 - Epoch 71 Training Summary: Avg Total Loss: 1.11013, Avg Main MSE: 1.11013, Time: 16.80s
2025-07-18 08:41:38,143 - logger.py:50 - Epoch 71 Summary | Train MSE (x10^-2): 111.0129 | Val MSE (x10^-2): 56.4020 | Time: 34.87s
2025-07-18 08:41:41,161 - logger.py:50 - Epoch: [72][0/6]	Total Loss: 1.10535	Main MSE (x10^-2): 110.5347	LR: 3.80e-04	EMPP_Raw: 1.51049
2025-07-18 08:41:54,957 - logger.py:50 - Epoch: [72][5/6]	Total Loss: 1.10989	Main MSE (x10^-2): 110.9889	LR: 3.80e-04	EMPP_Raw: 1.48841
2025-07-18 08:41:54,994 - logger.py:50 - Epoch 72 Training Summary: Avg Total Loss: 1.10989, Avg Main MSE: 1.10989, Time: 16.84s
2025-07-18 08:42:13,014 - logger.py:50 - Epoch 72 Summary | Train MSE (x10^-2): 110.9889 | Val MSE (x10^-2): 55.1243 | Time: 34.86s
2025-07-18 08:42:16,193 - logger.py:50 - Epoch: [73][0/6]	Total Loss: 1.09665	Main MSE (x10^-2): 109.6652	LR: 3.80e-04	EMPP_Raw: 1.47979
2025-07-18 08:42:30,003 - logger.py:50 - Epoch: [73][5/6]	Total Loss: 1.13311	Main MSE (x10^-2): 113.3107	LR: 3.80e-04	EMPP_Raw: 1.50848
2025-07-18 08:42:30,044 - logger.py:50 - Epoch 73 Training Summary: Avg Total Loss: 1.13311, Avg Main MSE: 1.13311, Time: 17.02s
2025-07-18 08:42:47,985 - logger.py:50 - Epoch 73 Summary | Train MSE (x10^-2): 113.3107 | Val MSE (x10^-2): 58.3874 | Time: 34.96s
2025-07-18 08:42:50,997 - logger.py:50 - Epoch: [74][0/6]	Total Loss: 1.09385	Main MSE (x10^-2): 109.3854	LR: 3.79e-04	EMPP_Raw: 1.49223
2025-07-18 08:43:04,967 - logger.py:50 - Epoch: [74][5/6]	Total Loss: 1.12268	Main MSE (x10^-2): 112.2683	LR: 3.79e-04	EMPP_Raw: 1.50457
2025-07-18 08:43:05,019 - logger.py:50 - Epoch 74 Training Summary: Avg Total Loss: 1.12268, Avg Main MSE: 1.12268, Time: 17.02s
2025-07-18 08:43:22,976 - logger.py:50 - Epoch 74 Summary | Train MSE (x10^-2): 112.2683 | Val MSE (x10^-2): 57.1661 | Time: 34.99s
2025-07-18 08:43:25,994 - logger.py:50 - Epoch: [75][0/6]	Total Loss: 1.09868	Main MSE (x10^-2): 109.8682	LR: 3.79e-04	EMPP_Raw: 1.46338
2025-07-18 08:43:39,825 - logger.py:50 - Epoch: [75][5/6]	Total Loss: 1.09782	Main MSE (x10^-2): 109.7823	LR: 3.79e-04	EMPP_Raw: 1.50213
2025-07-18 08:43:39,865 - logger.py:50 - Epoch 75 Training Summary: Avg Total Loss: 1.09782, Avg Main MSE: 1.09782, Time: 16.88s
2025-07-18 08:43:57,965 - logger.py:50 - Epoch 75 Summary | Train MSE (x10^-2): 109.7823 | Val MSE (x10^-2): 56.1533 | Time: 34.98s
2025-07-18 08:44:01,022 - logger.py:50 - Epoch: [76][0/6]	Total Loss: 1.06581	Main MSE (x10^-2): 106.5812	LR: 3.78e-04	EMPP_Raw: 1.49717
2025-07-18 08:44:14,796 - logger.py:50 - Epoch: [76][5/6]	Total Loss: 1.07683	Main MSE (x10^-2): 107.6831	LR: 3.78e-04	EMPP_Raw: 1.48887
2025-07-18 08:44:14,841 - logger.py:50 - Epoch 76 Training Summary: Avg Total Loss: 1.07683, Avg Main MSE: 1.07683, Time: 16.87s
2025-07-18 08:44:33,046 - logger.py:50 - Epoch 76 Summary | Train MSE (x10^-2): 107.6831 | Val MSE (x10^-2): 59.6013 | Time: 35.07s
2025-07-18 08:44:36,073 - logger.py:50 - Epoch: [77][0/6]	Total Loss: 1.08296	Main MSE (x10^-2): 108.2956	LR: 3.78e-04	EMPP_Raw: 1.52911
2025-07-18 08:44:49,877 - logger.py:50 - Epoch: [77][5/6]	Total Loss: 1.08861	Main MSE (x10^-2): 108.8613	LR: 3.78e-04	EMPP_Raw: 1.50939
2025-07-18 08:44:49,919 - logger.py:50 - Epoch 77 Training Summary: Avg Total Loss: 1.08861, Avg Main MSE: 1.08861, Time: 16.86s
2025-07-18 08:45:07,940 - logger.py:50 - Epoch 77 Summary | Train MSE (x10^-2): 108.8613 | Val MSE (x10^-2): 57.4561 | Time: 34.89s
2025-07-18 08:45:11,283 - logger.py:50 - Epoch: [78][0/6]	Total Loss: 1.00995	Main MSE (x10^-2): 100.9948	LR: 3.77e-04	EMPP_Raw: 1.45005
2025-07-18 08:45:25,006 - logger.py:50 - Epoch: [78][5/6]	Total Loss: 1.04547	Main MSE (x10^-2): 104.5471	LR: 3.77e-04	EMPP_Raw: 1.47564
2025-07-18 08:45:25,058 - logger.py:50 - Epoch 78 Training Summary: Avg Total Loss: 1.04547, Avg Main MSE: 1.04547, Time: 17.11s
2025-07-18 08:45:43,074 - logger.py:50 - Epoch 78 Summary | Train MSE (x10^-2): 104.5471 | Val MSE (x10^-2): 59.5556 | Time: 35.13s
2025-07-18 08:45:46,232 - logger.py:50 - Epoch: [79][0/6]	Total Loss: 1.02475	Main MSE (x10^-2): 102.4748	LR: 3.77e-04	EMPP_Raw: 1.48770
2025-07-18 08:45:59,928 - logger.py:50 - Epoch: [79][5/6]	Total Loss: 1.05445	Main MSE (x10^-2): 105.4453	LR: 3.77e-04	EMPP_Raw: 1.49198
2025-07-18 08:45:59,976 - logger.py:50 - Epoch 79 Training Summary: Avg Total Loss: 1.05445, Avg Main MSE: 1.05445, Time: 16.89s
2025-07-18 08:46:17,902 - logger.py:50 - Epoch 79 Summary | Train MSE (x10^-2): 105.4453 | Val MSE (x10^-2): 61.8732 | Time: 34.82s
2025-07-18 08:46:20,911 - logger.py:50 - Epoch: [80][0/6]	Total Loss: 1.03419	Main MSE (x10^-2): 103.4186	LR: 3.76e-04	EMPP_Raw: 1.49988
2025-07-18 08:46:34,859 - logger.py:50 - Epoch: [80][5/6]	Total Loss: 1.04582	Main MSE (x10^-2): 104.5823	LR: 3.76e-04	EMPP_Raw: 1.52226
2025-07-18 08:46:34,900 - logger.py:50 - Epoch 80 Training Summary: Avg Total Loss: 1.04582, Avg Main MSE: 1.04582, Time: 16.99s
2025-07-18 08:46:52,794 - logger.py:50 - Epoch 80 Summary | Train MSE (x10^-2): 104.5823 | Val MSE (x10^-2): 61.3738 | Time: 34.89s
2025-07-18 08:46:55,797 - logger.py:50 - Epoch: [81][0/6]	Total Loss: 1.01038	Main MSE (x10^-2): 101.0377	LR: 3.75e-04	EMPP_Raw: 1.53269
2025-07-18 08:47:09,594 - logger.py:50 - Epoch: [81][5/6]	Total Loss: 1.01463	Main MSE (x10^-2): 101.4628	LR: 3.75e-04	EMPP_Raw: 1.48618
2025-07-18 08:47:09,640 - logger.py:50 - Epoch 81 Training Summary: Avg Total Loss: 1.01463, Avg Main MSE: 1.01463, Time: 16.84s
2025-07-18 08:47:27,655 - logger.py:50 - Epoch 81 Summary | Train MSE (x10^-2): 101.4628 | Val MSE (x10^-2): 62.1568 | Time: 34.85s
2025-07-18 08:47:30,672 - logger.py:50 - Epoch: [82][0/6]	Total Loss: 1.01129	Main MSE (x10^-2): 101.1292	LR: 3.75e-04	EMPP_Raw: 1.46308
2025-07-18 08:47:44,461 - logger.py:50 - Epoch: [82][5/6]	Total Loss: 1.00008	Main MSE (x10^-2): 100.0076	LR: 3.75e-04	EMPP_Raw: 1.47978
2025-07-18 08:47:44,504 - logger.py:50 - Epoch 82 Training Summary: Avg Total Loss: 1.00008, Avg Main MSE: 1.00008, Time: 16.84s
2025-07-18 08:48:02,569 - logger.py:50 - Epoch 82 Summary | Train MSE (x10^-2): 100.0076 | Val MSE (x10^-2): 62.4841 | Time: 34.91s
2025-07-18 08:48:05,571 - logger.py:50 - Epoch: [83][0/6]	Total Loss: 1.01445	Main MSE (x10^-2): 101.4453	LR: 3.74e-04	EMPP_Raw: 1.56245
2025-07-18 08:48:19,363 - logger.py:50 - Epoch: [83][5/6]	Total Loss: 1.00113	Main MSE (x10^-2): 100.1134	LR: 3.74e-04	EMPP_Raw: 1.51453
2025-07-18 08:48:19,414 - logger.py:50 - Epoch 83 Training Summary: Avg Total Loss: 1.00113, Avg Main MSE: 1.00113, Time: 16.84s
2025-07-18 08:48:37,305 - logger.py:50 - Epoch 83 Summary | Train MSE (x10^-2): 100.1134 | Val MSE (x10^-2): 63.6415 | Time: 34.73s
2025-07-18 08:48:40,477 - logger.py:50 - Epoch: [84][0/6]	Total Loss: 0.98340	Main MSE (x10^-2): 98.3396	LR: 3.73e-04	EMPP_Raw: 1.47856
2025-07-18 08:48:54,215 - logger.py:50 - Epoch: [84][5/6]	Total Loss: 0.98046	Main MSE (x10^-2): 98.0464	LR: 3.73e-04	EMPP_Raw: 1.48695
2025-07-18 08:48:54,262 - logger.py:50 - Epoch 84 Training Summary: Avg Total Loss: 0.98046, Avg Main MSE: 0.98046, Time: 16.95s
2025-07-18 08:49:12,138 - logger.py:50 - Epoch 84 Summary | Train MSE (x10^-2): 98.0464 | Val MSE (x10^-2): 66.2028 | Time: 34.83s
2025-07-18 08:49:15,148 - logger.py:50 - Epoch: [85][0/6]	Total Loss: 0.98307	Main MSE (x10^-2): 98.3072	LR: 3.73e-04	EMPP_Raw: 1.52414
2025-07-18 08:49:29,055 - logger.py:50 - Epoch: [85][5/6]	Total Loss: 0.96922	Main MSE (x10^-2): 96.9215	LR: 3.73e-04	EMPP_Raw: 1.49471
2025-07-18 08:49:29,100 - logger.py:50 - Epoch 85 Training Summary: Avg Total Loss: 0.96922, Avg Main MSE: 0.96922, Time: 16.95s
2025-07-18 08:49:47,027 - logger.py:50 - Epoch 85 Summary | Train MSE (x10^-2): 96.9215 | Val MSE (x10^-2): 64.0295 | Time: 34.88s
2025-07-18 08:49:50,072 - logger.py:50 - Epoch: [86][0/6]	Total Loss: 0.97439	Main MSE (x10^-2): 97.4391	LR: 3.72e-04	EMPP_Raw: 1.52142
2025-07-18 08:50:03,991 - logger.py:50 - Epoch: [86][5/6]	Total Loss: 0.97336	Main MSE (x10^-2): 97.3355	LR: 3.72e-04	EMPP_Raw: 1.50391
2025-07-18 08:50:04,037 - logger.py:50 - Epoch 86 Training Summary: Avg Total Loss: 0.97336, Avg Main MSE: 0.97336, Time: 17.00s
2025-07-18 08:50:21,997 - logger.py:50 - Epoch 86 Summary | Train MSE (x10^-2): 97.3355 | Val MSE (x10^-2): 67.1947 | Time: 34.96s
2025-07-18 08:50:25,043 - logger.py:50 - Epoch: [87][0/6]	Total Loss: 0.99881	Main MSE (x10^-2): 99.8807	LR: 3.72e-04	EMPP_Raw: 1.58777
2025-07-18 08:50:38,857 - logger.py:50 - Epoch: [87][5/6]	Total Loss: 0.96608	Main MSE (x10^-2): 96.6083	LR: 3.72e-04	EMPP_Raw: 1.51039
2025-07-18 08:50:38,897 - logger.py:50 - Epoch 87 Training Summary: Avg Total Loss: 0.96608, Avg Main MSE: 0.96608, Time: 16.89s
2025-07-18 08:50:56,777 - logger.py:50 - Epoch 87 Summary | Train MSE (x10^-2): 96.6083 | Val MSE (x10^-2): 66.3243 | Time: 34.77s
2025-07-18 08:50:59,929 - logger.py:50 - Epoch: [88][0/6]	Total Loss: 0.93058	Main MSE (x10^-2): 93.0577	LR: 3.71e-04	EMPP_Raw: 1.48040
2025-07-18 08:51:13,660 - logger.py:50 - Epoch: [88][5/6]	Total Loss: 0.93608	Main MSE (x10^-2): 93.6082	LR: 3.71e-04	EMPP_Raw: 1.48046
2025-07-18 08:51:13,715 - logger.py:50 - Epoch 88 Training Summary: Avg Total Loss: 0.93608, Avg Main MSE: 0.93608, Time: 16.93s
2025-07-18 08:51:31,736 - logger.py:50 - Epoch 88 Summary | Train MSE (x10^-2): 93.6082 | Val MSE (x10^-2): 66.2719 | Time: 34.95s
2025-07-18 08:51:34,912 - logger.py:50 - Epoch: [89][0/6]	Total Loss: 0.91396	Main MSE (x10^-2): 91.3964	LR: 3.70e-04	EMPP_Raw: 1.50356
2025-07-18 08:51:48,675 - logger.py:50 - Epoch: [89][5/6]	Total Loss: 0.93514	Main MSE (x10^-2): 93.5145	LR: 3.70e-04	EMPP_Raw: 1.51059
2025-07-18 08:51:48,714 - logger.py:50 - Epoch 89 Training Summary: Avg Total Loss: 0.93514, Avg Main MSE: 0.93514, Time: 16.97s
2025-07-18 08:52:06,755 - logger.py:50 - Epoch 89 Summary | Train MSE (x10^-2): 93.5145 | Val MSE (x10^-2): 68.4491 | Time: 35.01s
2025-07-18 08:52:09,761 - logger.py:50 - Epoch: [90][0/6]	Total Loss: 0.93114	Main MSE (x10^-2): 93.1144	LR: 3.70e-04	EMPP_Raw: 1.49627
2025-07-18 08:52:23,676 - logger.py:50 - Epoch: [90][5/6]	Total Loss: 0.93039	Main MSE (x10^-2): 93.0391	LR: 3.70e-04	EMPP_Raw: 1.50816
2025-07-18 08:52:23,718 - logger.py:50 - Epoch 90 Training Summary: Avg Total Loss: 0.93039, Avg Main MSE: 0.93039, Time: 16.95s
2025-07-18 08:52:41,576 - logger.py:50 - Epoch 90 Summary | Train MSE (x10^-2): 93.0391 | Val MSE (x10^-2): 69.3404 | Time: 34.82s
2025-07-18 08:52:44,574 - logger.py:50 - Epoch: [91][0/6]	Total Loss: 0.90595	Main MSE (x10^-2): 90.5954	LR: 3.69e-04	EMPP_Raw: 1.49018
2025-07-18 08:52:58,345 - logger.py:50 - Epoch: [91][5/6]	Total Loss: 0.91968	Main MSE (x10^-2): 91.9677	LR: 3.69e-04	EMPP_Raw: 1.50525
2025-07-18 08:52:58,389 - logger.py:50 - Epoch 91 Training Summary: Avg Total Loss: 0.91968, Avg Main MSE: 0.91968, Time: 16.80s
2025-07-18 08:53:16,576 - logger.py:50 - Epoch 91 Summary | Train MSE (x10^-2): 91.9677 | Val MSE (x10^-2): 66.9889 | Time: 34.99s
2025-07-18 08:53:19,593 - logger.py:50 - Epoch: [92][0/6]	Total Loss: 0.90815	Main MSE (x10^-2): 90.8150	LR: 3.68e-04	EMPP_Raw: 1.46716
2025-07-18 08:53:33,407 - logger.py:50 - Epoch: [92][5/6]	Total Loss: 0.90902	Main MSE (x10^-2): 90.9021	LR: 3.68e-04	EMPP_Raw: 1.49984
2025-07-18 08:53:33,447 - logger.py:50 - Epoch 92 Training Summary: Avg Total Loss: 0.90902, Avg Main MSE: 0.90902, Time: 16.86s
2025-07-18 08:53:51,412 - logger.py:50 - Epoch 92 Summary | Train MSE (x10^-2): 90.9021 | Val MSE (x10^-2): 72.0703 | Time: 34.83s
2025-07-18 08:53:54,596 - logger.py:50 - Epoch: [93][0/6]	Total Loss: 0.91714	Main MSE (x10^-2): 91.7142	LR: 3.68e-04	EMPP_Raw: 1.52648
2025-07-18 08:54:08,444 - logger.py:50 - Epoch: [93][5/6]	Total Loss: 0.91466	Main MSE (x10^-2): 91.4658	LR: 3.68e-04	EMPP_Raw: 1.52238
2025-07-18 08:54:08,488 - logger.py:50 - Epoch 93 Training Summary: Avg Total Loss: 0.91466, Avg Main MSE: 0.91466, Time: 17.07s
2025-07-18 08:54:26,542 - logger.py:50 - Epoch 93 Summary | Train MSE (x10^-2): 91.4658 | Val MSE (x10^-2): 72.8516 | Time: 35.12s
2025-07-18 08:54:29,642 - logger.py:50 - Epoch: [94][0/6]	Total Loss: 0.90692	Main MSE (x10^-2): 90.6919	LR: 3.67e-04	EMPP_Raw: 1.49380
2025-07-18 08:54:43,610 - logger.py:50 - Epoch: [94][5/6]	Total Loss: 0.91000	Main MSE (x10^-2): 90.9996	LR: 3.67e-04	EMPP_Raw: 1.51130
2025-07-18 08:54:43,657 - logger.py:50 - Epoch 94 Training Summary: Avg Total Loss: 0.91000, Avg Main MSE: 0.91000, Time: 17.10s
2025-07-18 08:55:01,550 - logger.py:50 - Epoch 94 Summary | Train MSE (x10^-2): 90.9996 | Val MSE (x10^-2): 71.6574 | Time: 35.00s
2025-07-18 08:55:04,600 - logger.py:50 - Epoch: [95][0/6]	Total Loss: 0.88457	Main MSE (x10^-2): 88.4566	LR: 3.66e-04	EMPP_Raw: 1.47679
2025-07-18 08:55:18,399 - logger.py:50 - Epoch: [95][5/6]	Total Loss: 0.89084	Main MSE (x10^-2): 89.0835	LR: 3.66e-04	EMPP_Raw: 1.50143
2025-07-18 08:55:18,443 - logger.py:50 - Epoch 95 Training Summary: Avg Total Loss: 0.89084, Avg Main MSE: 0.89084, Time: 16.88s
2025-07-18 08:55:36,467 - logger.py:50 - Epoch 95 Summary | Train MSE (x10^-2): 89.0835 | Val MSE (x10^-2): 75.0643 | Time: 34.91s
2025-07-18 08:55:39,552 - logger.py:50 - Epoch: [96][0/6]	Total Loss: 0.93260	Main MSE (x10^-2): 93.2596	LR: 3.66e-04	EMPP_Raw: 1.52572
2025-07-18 08:55:53,288 - logger.py:50 - Epoch: [96][5/6]	Total Loss: 0.91116	Main MSE (x10^-2): 91.1161	LR: 3.66e-04	EMPP_Raw: 1.51827
2025-07-18 08:55:53,335 - logger.py:50 - Epoch 96 Training Summary: Avg Total Loss: 0.91116, Avg Main MSE: 0.91116, Time: 16.86s
2025-07-18 08:56:11,404 - logger.py:50 - Epoch 96 Summary | Train MSE (x10^-2): 91.1161 | Val MSE (x10^-2): 74.0429 | Time: 34.93s
2025-07-18 08:56:14,412 - logger.py:50 - Epoch: [97][0/6]	Total Loss: 0.86778	Main MSE (x10^-2): 86.7775	LR: 3.65e-04	EMPP_Raw: 1.45726
2025-07-18 08:56:28,231 - logger.py:50 - Epoch: [97][5/6]	Total Loss: 0.88276	Main MSE (x10^-2): 88.2759	LR: 3.65e-04	EMPP_Raw: 1.49466
2025-07-18 08:56:28,272 - logger.py:50 - Epoch 97 Training Summary: Avg Total Loss: 0.88276, Avg Main MSE: 0.88276, Time: 16.86s
2025-07-18 08:56:46,289 - logger.py:50 - Epoch 97 Summary | Train MSE (x10^-2): 88.2759 | Val MSE (x10^-2): 69.7461 | Time: 34.88s
2025-07-18 08:56:49,716 - logger.py:50 - Epoch: [98][0/6]	Total Loss: 0.86611	Main MSE (x10^-2): 86.6112	LR: 3.64e-04	EMPP_Raw: 1.50189
2025-07-18 08:57:03,529 - logger.py:50 - Epoch: [98][5/6]	Total Loss: 0.87239	Main MSE (x10^-2): 87.2389	LR: 3.64e-04	EMPP_Raw: 1.47824
2025-07-18 08:57:03,581 - logger.py:50 - Epoch 98 Training Summary: Avg Total Loss: 0.87239, Avg Main MSE: 0.87239, Time: 17.28s
2025-07-18 08:57:21,388 - logger.py:50 - Epoch 98 Summary | Train MSE (x10^-2): 87.2389 | Val MSE (x10^-2): 71.9081 | Time: 35.09s
2025-07-18 08:57:24,559 - logger.py:50 - Epoch: [99][0/6]	Total Loss: 0.88914	Main MSE (x10^-2): 88.9140	LR: 3.63e-04	EMPP_Raw: 1.53643
2025-07-18 08:57:38,303 - logger.py:50 - Epoch: [99][5/6]	Total Loss: 0.89240	Main MSE (x10^-2): 89.2405	LR: 3.63e-04	EMPP_Raw: 1.51147
2025-07-18 08:57:38,348 - logger.py:50 - Epoch 99 Training Summary: Avg Total Loss: 0.89240, Avg Main MSE: 0.89240, Time: 16.95s
2025-07-18 08:57:56,223 - logger.py:50 - Epoch 99 Summary | Train MSE (x10^-2): 89.2405 | Val MSE (x10^-2): 71.1804 | Time: 34.83s
2025-07-18 08:57:59,250 - logger.py:50 - Epoch: [100][0/6]	Total Loss: 0.86662	Main MSE (x10^-2): 86.6622	LR: 3.63e-04	EMPP_Raw: 1.50704
2025-07-18 08:58:13,163 - logger.py:50 - Epoch: [100][5/6]	Total Loss: 0.87098	Main MSE (x10^-2): 87.0985	LR: 3.63e-04	EMPP_Raw: 1.48135
2025-07-18 08:58:13,218 - logger.py:50 - Epoch 100 Training Summary: Avg Total Loss: 0.87098, Avg Main MSE: 0.87098, Time: 16.99s
2025-07-18 08:58:31,127 - logger.py:50 - Epoch 100 Summary | Train MSE (x10^-2): 87.0985 | Val MSE (x10^-2): 69.2805 | Time: 34.90s
2025-07-18 08:58:34,130 - logger.py:50 - Epoch: [101][0/6]	Total Loss: 0.87022	Main MSE (x10^-2): 87.0217	LR: 3.62e-04	EMPP_Raw: 1.48781
2025-07-18 08:58:47,905 - logger.py:50 - Epoch: [101][5/6]	Total Loss: 0.86973	Main MSE (x10^-2): 86.9728	LR: 3.62e-04	EMPP_Raw: 1.49986
2025-07-18 08:58:47,959 - logger.py:50 - Epoch 101 Training Summary: Avg Total Loss: 0.86973, Avg Main MSE: 0.86973, Time: 16.82s
2025-07-18 08:59:05,942 - logger.py:50 - Epoch 101 Summary | Train MSE (x10^-2): 86.9728 | Val MSE (x10^-2): 73.3948 | Time: 34.81s
2025-07-18 08:59:08,992 - logger.py:50 - Epoch: [102][0/6]	Total Loss: 0.87612	Main MSE (x10^-2): 87.6125	LR: 3.61e-04	EMPP_Raw: 1.52982
2025-07-18 08:59:22,831 - logger.py:50 - Epoch: [102][5/6]	Total Loss: 0.86421	Main MSE (x10^-2): 86.4211	LR: 3.61e-04	EMPP_Raw: 1.50866
2025-07-18 08:59:22,875 - logger.py:50 - Epoch 102 Training Summary: Avg Total Loss: 0.86421, Avg Main MSE: 0.86421, Time: 16.92s
2025-07-18 08:59:40,947 - logger.py:50 - Epoch 102 Summary | Train MSE (x10^-2): 86.4211 | Val MSE (x10^-2): 71.7391 | Time: 35.00s
2025-07-18 08:59:43,962 - logger.py:50 - Epoch: [103][0/6]	Total Loss: 0.85208	Main MSE (x10^-2): 85.2082	LR: 3.60e-04	EMPP_Raw: 1.50145
2025-07-18 08:59:57,738 - logger.py:50 - Epoch: [103][5/6]	Total Loss: 0.85206	Main MSE (x10^-2): 85.2065	LR: 3.60e-04	EMPP_Raw: 1.48532
2025-07-18 08:59:57,780 - logger.py:50 - Epoch 103 Training Summary: Avg Total Loss: 0.85206, Avg Main MSE: 0.85206, Time: 16.82s
2025-07-18 09:00:15,689 - logger.py:50 - Epoch 103 Summary | Train MSE (x10^-2): 85.2065 | Val MSE (x10^-2): 73.1308 | Time: 34.74s
2025-07-18 09:00:18,844 - logger.py:50 - Epoch: [104][0/6]	Total Loss: 0.83201	Main MSE (x10^-2): 83.2012	LR: 3.60e-04	EMPP_Raw: 1.48700
2025-07-18 09:00:32,590 - logger.py:50 - Epoch: [104][5/6]	Total Loss: 0.84674	Main MSE (x10^-2): 84.6739	LR: 3.60e-04	EMPP_Raw: 1.48886
2025-07-18 09:00:32,631 - logger.py:50 - Epoch 104 Training Summary: Avg Total Loss: 0.84674, Avg Main MSE: 0.84674, Time: 16.93s
2025-07-18 09:00:50,740 - logger.py:50 - Epoch 104 Summary | Train MSE (x10^-2): 84.6739 | Val MSE (x10^-2): 69.9080 | Time: 35.04s
2025-07-18 09:00:53,789 - logger.py:50 - Epoch: [105][0/6]	Total Loss: 0.87201	Main MSE (x10^-2): 87.2008	LR: 3.59e-04	EMPP_Raw: 1.54657
2025-07-18 09:01:07,778 - logger.py:50 - Epoch: [105][5/6]	Total Loss: 0.86143	Main MSE (x10^-2): 86.1427	LR: 3.59e-04	EMPP_Raw: 1.51696
2025-07-18 09:01:07,823 - logger.py:50 - Epoch 105 Training Summary: Avg Total Loss: 0.86143, Avg Main MSE: 0.86143, Time: 17.07s
2025-07-18 09:01:25,790 - logger.py:50 - Epoch 105 Summary | Train MSE (x10^-2): 86.1427 | Val MSE (x10^-2): 73.3176 | Time: 35.04s
2025-07-18 09:01:28,828 - logger.py:50 - Epoch: [106][0/6]	Total Loss: 0.83544	Main MSE (x10^-2): 83.5439	LR: 3.58e-04	EMPP_Raw: 1.46880
2025-07-18 09:01:42,727 - logger.py:50 - Epoch: [106][5/6]	Total Loss: 0.83673	Main MSE (x10^-2): 83.6734	LR: 3.58e-04	EMPP_Raw: 1.48013
2025-07-18 09:01:42,777 - logger.py:50 - Epoch 106 Training Summary: Avg Total Loss: 0.83673, Avg Main MSE: 0.83673, Time: 16.98s
2025-07-18 09:02:00,703 - logger.py:50 - Epoch 106 Summary | Train MSE (x10^-2): 83.6734 | Val MSE (x10^-2): 76.5341 | Time: 34.91s
2025-07-18 09:02:03,755 - logger.py:50 - Epoch: [107][0/6]	Total Loss: 0.84401	Main MSE (x10^-2): 84.4008	LR: 3.57e-04	EMPP_Raw: 1.50681
2025-07-18 09:02:17,643 - logger.py:50 - Epoch: [107][5/6]	Total Loss: 0.84356	Main MSE (x10^-2): 84.3560	LR: 3.57e-04	EMPP_Raw: 1.50126
2025-07-18 09:02:17,683 - logger.py:50 - Epoch 107 Training Summary: Avg Total Loss: 0.84356, Avg Main MSE: 0.84356, Time: 16.97s
2025-07-18 09:02:35,572 - logger.py:50 - Epoch 107 Summary | Train MSE (x10^-2): 84.3560 | Val MSE (x10^-2): 77.6777 | Time: 34.86s
2025-07-18 09:02:38,727 - logger.py:50 - Epoch: [108][0/6]	Total Loss: 0.82643	Main MSE (x10^-2): 82.6429	LR: 3.57e-04	EMPP_Raw: 1.46645
2025-07-18 09:02:52,431 - logger.py:50 - Epoch: [108][5/6]	Total Loss: 0.84064	Main MSE (x10^-2): 84.0639	LR: 3.57e-04	EMPP_Raw: 1.49118
2025-07-18 09:02:52,477 - logger.py:50 - Epoch 108 Training Summary: Avg Total Loss: 0.84064, Avg Main MSE: 0.84064, Time: 16.90s
2025-07-18 09:03:10,353 - logger.py:50 - Epoch 108 Summary | Train MSE (x10^-2): 84.0639 | Val MSE (x10^-2): 76.2803 | Time: 34.78s
2025-07-18 09:03:13,533 - logger.py:50 - Epoch: [109][0/6]	Total Loss: 0.83428	Main MSE (x10^-2): 83.4283	LR: 3.56e-04	EMPP_Raw: 1.50267
2025-07-18 09:03:27,270 - logger.py:50 - Epoch: [109][5/6]	Total Loss: 0.84486	Main MSE (x10^-2): 84.4859	LR: 3.56e-04	EMPP_Raw: 1.50591
2025-07-18 09:03:27,310 - logger.py:50 - Epoch 109 Training Summary: Avg Total Loss: 0.84486, Avg Main MSE: 0.84486, Time: 16.95s
2025-07-18 09:03:45,357 - logger.py:50 - Epoch 109 Summary | Train MSE (x10^-2): 84.4859 | Val MSE (x10^-2): 73.6319 | Time: 35.00s
2025-07-18 09:03:48,421 - logger.py:50 - Epoch: [110][0/6]	Total Loss: 0.83025	Main MSE (x10^-2): 83.0246	LR: 3.55e-04	EMPP_Raw: 1.48148
2025-07-18 09:04:02,347 - logger.py:50 - Epoch: [110][5/6]	Total Loss: 0.82794	Main MSE (x10^-2): 82.7944	LR: 3.55e-04	EMPP_Raw: 1.47645
2025-07-18 09:04:02,388 - logger.py:50 - Epoch 110 Training Summary: Avg Total Loss: 0.82794, Avg Main MSE: 0.82794, Time: 17.02s
2025-07-18 09:04:20,264 - logger.py:50 - Epoch 110 Summary | Train MSE (x10^-2): 82.7944 | Val MSE (x10^-2): 74.8707 | Time: 34.90s
2025-07-18 09:04:23,269 - logger.py:50 - Epoch: [111][0/6]	Total Loss: 0.85976	Main MSE (x10^-2): 85.9756	LR: 3.54e-04	EMPP_Raw: 1.52672
2025-07-18 09:04:37,051 - logger.py:50 - Epoch: [111][5/6]	Total Loss: 0.84274	Main MSE (x10^-2): 84.2738	LR: 3.54e-04	EMPP_Raw: 1.50500
2025-07-18 09:04:37,092 - logger.py:50 - Epoch 111 Training Summary: Avg Total Loss: 0.84274, Avg Main MSE: 0.84274, Time: 16.82s
2025-07-18 09:04:55,138 - logger.py:50 - Epoch 111 Summary | Train MSE (x10^-2): 84.2738 | Val MSE (x10^-2): 76.3916 | Time: 34.87s
2025-07-18 09:04:58,148 - logger.py:50 - Epoch: [112][0/6]	Total Loss: 0.82595	Main MSE (x10^-2): 82.5952	LR: 3.53e-04	EMPP_Raw: 1.46249
2025-07-18 09:05:11,950 - logger.py:50 - Epoch: [112][5/6]	Total Loss: 0.81670	Main MSE (x10^-2): 81.6702	LR: 3.53e-04	EMPP_Raw: 1.45873
2025-07-18 09:05:11,994 - logger.py:50 - Epoch 112 Training Summary: Avg Total Loss: 0.81670, Avg Main MSE: 0.81670, Time: 16.85s
2025-07-18 09:05:29,978 - logger.py:50 - Epoch 112 Summary | Train MSE (x10^-2): 81.6702 | Val MSE (x10^-2): 74.0373 | Time: 34.83s
2025-07-18 09:05:33,179 - logger.py:50 - Epoch: [113][0/6]	Total Loss: 0.84331	Main MSE (x10^-2): 84.3315	LR: 3.53e-04	EMPP_Raw: 1.50763
2025-07-18 09:05:46,995 - logger.py:50 - Epoch: [113][5/6]	Total Loss: 0.83329	Main MSE (x10^-2): 83.3294	LR: 3.53e-04	EMPP_Raw: 1.49594
2025-07-18 09:05:47,039 - logger.py:50 - Epoch 113 Training Summary: Avg Total Loss: 0.83329, Avg Main MSE: 0.83329, Time: 17.05s
2025-07-18 09:06:04,959 - logger.py:50 - Epoch 113 Summary | Train MSE (x10^-2): 83.3294 | Val MSE (x10^-2): 76.4869 | Time: 34.98s
2025-07-18 09:06:07,960 - logger.py:50 - Epoch: [114][0/6]	Total Loss: 0.83550	Main MSE (x10^-2): 83.5504	LR: 3.52e-04	EMPP_Raw: 1.49312
2025-07-18 09:06:21,859 - logger.py:50 - Epoch: [114][5/6]	Total Loss: 0.82820	Main MSE (x10^-2): 82.8202	LR: 3.52e-04	EMPP_Raw: 1.49794
2025-07-18 09:06:21,923 - logger.py:50 - Epoch 114 Training Summary: Avg Total Loss: 0.82820, Avg Main MSE: 0.82820, Time: 16.95s
2025-07-18 09:06:39,735 - logger.py:50 - Epoch 114 Summary | Train MSE (x10^-2): 82.8202 | Val MSE (x10^-2): 73.9965 | Time: 34.77s
2025-07-18 09:06:42,755 - logger.py:50 - Epoch: [115][0/6]	Total Loss: 0.82598	Main MSE (x10^-2): 82.5975	LR: 3.51e-04	EMPP_Raw: 1.50585
2025-07-18 09:06:56,627 - logger.py:50 - Epoch: [115][5/6]	Total Loss: 0.82023	Main MSE (x10^-2): 82.0230	LR: 3.51e-04	EMPP_Raw: 1.49139
2025-07-18 09:06:56,673 - logger.py:50 - Epoch 115 Training Summary: Avg Total Loss: 0.82023, Avg Main MSE: 0.82023, Time: 16.93s
2025-07-18 09:07:14,769 - logger.py:50 - Epoch 115 Summary | Train MSE (x10^-2): 82.0230 | Val MSE (x10^-2): 74.8546 | Time: 35.02s
2025-07-18 09:07:17,824 - logger.py:50 - Epoch: [116][0/6]	Total Loss: 0.81843	Main MSE (x10^-2): 81.8429	LR: 3.50e-04	EMPP_Raw: 1.46356
2025-07-18 09:07:31,643 - logger.py:50 - Epoch: [116][5/6]	Total Loss: 0.82919	Main MSE (x10^-2): 82.9185	LR: 3.50e-04	EMPP_Raw: 1.50007
2025-07-18 09:07:31,693 - logger.py:50 - Epoch 116 Training Summary: Avg Total Loss: 0.82919, Avg Main MSE: 0.82919, Time: 16.92s
2025-07-18 09:07:49,779 - logger.py:50 - Epoch 116 Summary | Train MSE (x10^-2): 82.9185 | Val MSE (x10^-2): 72.2515 | Time: 35.00s
2025-07-18 09:07:52,788 - logger.py:50 - Epoch: [117][0/6]	Total Loss: 0.83297	Main MSE (x10^-2): 83.2970	LR: 3.49e-04	EMPP_Raw: 1.51939
2025-07-18 09:08:06,621 - logger.py:50 - Epoch: [117][5/6]	Total Loss: 0.81794	Main MSE (x10^-2): 81.7940	LR: 3.49e-04	EMPP_Raw: 1.48440
2025-07-18 09:08:06,662 - logger.py:50 - Epoch 117 Training Summary: Avg Total Loss: 0.81794, Avg Main MSE: 0.81794, Time: 16.87s
2025-07-18 09:08:24,676 - logger.py:50 - Epoch 117 Summary | Train MSE (x10^-2): 81.7940 | Val MSE (x10^-2): 75.1317 | Time: 34.89s
2025-07-18 09:08:28,045 - logger.py:50 - Epoch: [118][0/6]	Total Loss: 0.81305	Main MSE (x10^-2): 81.3049	LR: 3.48e-04	EMPP_Raw: 1.49632
2025-07-18 09:08:41,828 - logger.py:50 - Epoch: [118][5/6]	Total Loss: 0.81321	Main MSE (x10^-2): 81.3213	LR: 3.48e-04	EMPP_Raw: 1.47881
2025-07-18 09:08:41,895 - logger.py:50 - Epoch 118 Training Summary: Avg Total Loss: 0.81321, Avg Main MSE: 0.81321, Time: 17.21s
2025-07-18 09:08:59,809 - logger.py:50 - Epoch 118 Summary | Train MSE (x10^-2): 81.3213 | Val MSE (x10^-2): 71.0964 | Time: 35.13s
2025-07-18 09:09:02,982 - logger.py:50 - Epoch: [119][0/6]	Total Loss: 0.83362	Main MSE (x10^-2): 83.3622	LR: 3.48e-04	EMPP_Raw: 1.51284
2025-07-18 09:09:16,911 - logger.py:50 - Epoch: [119][5/6]	Total Loss: 0.82028	Main MSE (x10^-2): 82.0282	LR: 3.48e-04	EMPP_Raw: 1.49913
2025-07-18 09:09:16,971 - logger.py:50 - Epoch 119 Training Summary: Avg Total Loss: 0.82028, Avg Main MSE: 0.82028, Time: 17.15s
2025-07-18 09:09:34,996 - logger.py:50 - Epoch 119 Summary | Train MSE (x10^-2): 82.0282 | Val MSE (x10^-2): 74.2542 | Time: 35.18s
2025-07-18 09:09:38,011 - logger.py:50 - Epoch: [120][0/6]	Total Loss: 0.81935	Main MSE (x10^-2): 81.9349	LR: 3.47e-04	EMPP_Raw: 1.52066
2025-07-18 09:09:51,905 - logger.py:50 - Epoch: [120][5/6]	Total Loss: 0.80547	Main MSE (x10^-2): 80.5468	LR: 3.47e-04	EMPP_Raw: 1.47791
2025-07-18 09:09:51,949 - logger.py:50 - Epoch 120 Training Summary: Avg Total Loss: 0.80547, Avg Main MSE: 0.80547, Time: 16.94s
2025-07-18 09:10:09,760 - logger.py:50 - Epoch 120 Summary | Train MSE (x10^-2): 80.5468 | Val MSE (x10^-2): 75.7532 | Time: 34.76s
2025-07-18 09:10:12,806 - logger.py:50 - Epoch: [121][0/6]	Total Loss: 0.81309	Main MSE (x10^-2): 81.3092	LR: 3.46e-04	EMPP_Raw: 1.48748
2025-07-18 09:10:26,566 - logger.py:50 - Epoch: [121][5/6]	Total Loss: 0.80737	Main MSE (x10^-2): 80.7367	LR: 3.46e-04	EMPP_Raw: 1.48626
2025-07-18 09:10:26,612 - logger.py:50 - Epoch 121 Training Summary: Avg Total Loss: 0.80737, Avg Main MSE: 0.80737, Time: 16.84s
2025-07-18 09:10:44,740 - logger.py:50 - Epoch 121 Summary | Train MSE (x10^-2): 80.7367 | Val MSE (x10^-2): 74.9176 | Time: 34.98s
2025-07-18 09:10:47,757 - logger.py:50 - Epoch: [122][0/6]	Total Loss: 0.81216	Main MSE (x10^-2): 81.2156	LR: 3.45e-04	EMPP_Raw: 1.49823
2025-07-18 09:11:01,571 - logger.py:50 - Epoch: [122][5/6]	Total Loss: 0.80955	Main MSE (x10^-2): 80.9552	LR: 3.45e-04	EMPP_Raw: 1.48561
2025-07-18 09:11:01,619 - logger.py:50 - Epoch 122 Training Summary: Avg Total Loss: 0.80955, Avg Main MSE: 0.80955, Time: 16.87s
2025-07-18 09:11:19,586 - logger.py:50 - Epoch 122 Summary | Train MSE (x10^-2): 80.9552 | Val MSE (x10^-2): 75.2911 | Time: 34.84s
2025-07-18 09:11:22,669 - logger.py:50 - Epoch: [123][0/6]	Total Loss: 0.81695	Main MSE (x10^-2): 81.6954	LR: 3.44e-04	EMPP_Raw: 1.49406
2025-07-18 09:11:36,498 - logger.py:50 - Epoch: [123][5/6]	Total Loss: 0.81208	Main MSE (x10^-2): 81.2076	LR: 3.44e-04	EMPP_Raw: 1.49805
2025-07-18 09:11:36,542 - logger.py:50 - Epoch 123 Training Summary: Avg Total Loss: 0.81208, Avg Main MSE: 0.81208, Time: 16.95s
2025-07-18 09:11:54,519 - logger.py:50 - Epoch 123 Summary | Train MSE (x10^-2): 81.2076 | Val MSE (x10^-2): 78.3822 | Time: 34.93s
2025-07-18 09:11:57,699 - logger.py:50 - Epoch: [124][0/6]	Total Loss: 0.81416	Main MSE (x10^-2): 81.4156	LR: 3.43e-04	EMPP_Raw: 1.47115
2025-07-18 09:12:11,454 - logger.py:50 - Epoch: [124][5/6]	Total Loss: 0.80305	Main MSE (x10^-2): 80.3049	LR: 3.43e-04	EMPP_Raw: 1.47706
2025-07-18 09:12:11,503 - logger.py:50 - Epoch 124 Training Summary: Avg Total Loss: 0.80305, Avg Main MSE: 0.80305, Time: 16.97s
2025-07-18 09:12:29,379 - logger.py:50 - Epoch 124 Summary | Train MSE (x10^-2): 80.3049 | Val MSE (x10^-2): 75.0798 | Time: 34.85s
2025-07-18 09:12:32,417 - logger.py:50 - Epoch: [125][0/6]	Total Loss: 0.83390	Main MSE (x10^-2): 83.3898	LR: 3.42e-04	EMPP_Raw: 1.52989
2025-07-18 09:12:46,390 - logger.py:50 - Epoch: [125][5/6]	Total Loss: 0.81120	Main MSE (x10^-2): 81.1203	LR: 3.42e-04	EMPP_Raw: 1.49428
2025-07-18 09:12:46,441 - logger.py:50 - Epoch 125 Training Summary: Avg Total Loss: 0.81120, Avg Main MSE: 0.81120, Time: 17.05s
2025-07-18 09:13:04,496 - logger.py:50 - Epoch 125 Summary | Train MSE (x10^-2): 81.1203 | Val MSE (x10^-2): 74.4420 | Time: 35.11s
2025-07-18 09:13:07,512 - logger.py:50 - Epoch: [126][0/6]	Total Loss: 0.79538	Main MSE (x10^-2): 79.5376	LR: 3.42e-04	EMPP_Raw: 1.46285
2025-07-18 09:13:21,448 - logger.py:50 - Epoch: [126][5/6]	Total Loss: 0.79592	Main MSE (x10^-2): 79.5925	LR: 3.42e-04	EMPP_Raw: 1.46236
2025-07-18 09:13:21,495 - logger.py:50 - Epoch 126 Training Summary: Avg Total Loss: 0.79592, Avg Main MSE: 0.79592, Time: 16.99s
2025-07-18 09:13:39,335 - logger.py:50 - Epoch 126 Summary | Train MSE (x10^-2): 79.5925 | Val MSE (x10^-2): 80.3136 | Time: 34.83s
2025-07-18 09:13:42,385 - logger.py:50 - Epoch: [127][0/6]	Total Loss: 0.81435	Main MSE (x10^-2): 81.4345	LR: 3.41e-04	EMPP_Raw: 1.49232
2025-07-18 09:13:56,233 - logger.py:50 - Epoch: [127][5/6]	Total Loss: 0.79460	Main MSE (x10^-2): 79.4598	LR: 3.41e-04	EMPP_Raw: 1.47045
2025-07-18 09:13:56,279 - logger.py:50 - Epoch 127 Training Summary: Avg Total Loss: 0.79460, Avg Main MSE: 0.79460, Time: 16.93s
2025-07-18 09:14:14,206 - logger.py:50 - Epoch 127 Summary | Train MSE (x10^-2): 79.4598 | Val MSE (x10^-2): 79.6167 | Time: 34.86s
2025-07-18 09:14:17,378 - logger.py:50 - Epoch: [128][0/6]	Total Loss: 0.79398	Main MSE (x10^-2): 79.3977	LR: 3.40e-04	EMPP_Raw: 1.48366
2025-07-18 09:14:31,196 - logger.py:50 - Epoch: [128][5/6]	Total Loss: 0.79945	Main MSE (x10^-2): 79.9446	LR: 3.40e-04	EMPP_Raw: 1.47815
2025-07-18 09:14:31,245 - logger.py:50 - Epoch 128 Training Summary: Avg Total Loss: 0.79945, Avg Main MSE: 0.79945, Time: 17.03s
2025-07-18 09:14:49,257 - logger.py:50 - Epoch 128 Summary | Train MSE (x10^-2): 79.9446 | Val MSE (x10^-2): 79.0765 | Time: 35.05s
2025-07-18 09:14:52,422 - logger.py:50 - Epoch: [129][0/6]	Total Loss: 0.81128	Main MSE (x10^-2): 81.1282	LR: 3.39e-04	EMPP_Raw: 1.51161
2025-07-18 09:15:06,189 - logger.py:50 - Epoch: [129][5/6]	Total Loss: 0.79154	Main MSE (x10^-2): 79.1542	LR: 3.39e-04	EMPP_Raw: 1.47453
2025-07-18 09:15:06,232 - logger.py:50 - Epoch 129 Training Summary: Avg Total Loss: 0.79154, Avg Main MSE: 0.79154, Time: 16.97s
2025-07-18 09:15:24,319 - logger.py:50 - Epoch 129 Summary | Train MSE (x10^-2): 79.1542 | Val MSE (x10^-2): 78.0367 | Time: 35.06s
2025-07-18 09:15:27,320 - logger.py:50 - Epoch: [130][0/6]	Total Loss: 0.78462	Main MSE (x10^-2): 78.4625	LR: 3.38e-04	EMPP_Raw: 1.46404
2025-07-18 09:15:41,350 - logger.py:50 - Epoch: [130][5/6]	Total Loss: 0.79671	Main MSE (x10^-2): 79.6711	LR: 3.38e-04	EMPP_Raw: 1.47809
2025-07-18 09:15:41,395 - logger.py:50 - Epoch 130 Training Summary: Avg Total Loss: 0.79671, Avg Main MSE: 0.79671, Time: 17.07s
2025-07-18 09:15:59,305 - logger.py:50 - Epoch 130 Summary | Train MSE (x10^-2): 79.6711 | Val MSE (x10^-2): 76.8275 | Time: 34.98s
2025-07-18 09:16:02,307 - logger.py:50 - Epoch: [131][0/6]	Total Loss: 0.77003	Main MSE (x10^-2): 77.0026	LR: 3.37e-04	EMPP_Raw: 1.43077
2025-07-18 09:16:16,100 - logger.py:50 - Epoch: [131][5/6]	Total Loss: 0.79420	Main MSE (x10^-2): 79.4197	LR: 3.37e-04	EMPP_Raw: 1.48136
2025-07-18 09:16:16,143 - logger.py:50 - Epoch 131 Training Summary: Avg Total Loss: 0.79420, Avg Main MSE: 0.79420, Time: 16.83s
2025-07-18 09:16:34,166 - logger.py:50 - Epoch 131 Summary | Train MSE (x10^-2): 79.4197 | Val MSE (x10^-2): 75.5154 | Time: 34.86s
2025-07-18 09:16:37,217 - logger.py:50 - Epoch: [132][0/6]	Total Loss: 0.78036	Main MSE (x10^-2): 78.0362	LR: 3.36e-04	EMPP_Raw: 1.44888
2025-07-18 09:16:51,030 - logger.py:50 - Epoch: [132][5/6]	Total Loss: 0.79402	Main MSE (x10^-2): 79.4015	LR: 3.36e-04	EMPP_Raw: 1.47410
2025-07-18 09:16:51,070 - logger.py:50 - Epoch 132 Training Summary: Avg Total Loss: 0.79402, Avg Main MSE: 0.79402, Time: 16.89s
2025-07-18 09:17:09,009 - logger.py:50 - Epoch 132 Summary | Train MSE (x10^-2): 79.4015 | Val MSE (x10^-2): 76.3497 | Time: 34.84s
2025-07-18 09:17:12,213 - logger.py:50 - Epoch: [133][0/6]	Total Loss: 0.79377	Main MSE (x10^-2): 79.3767	LR: 3.35e-04	EMPP_Raw: 1.48398
2025-07-18 09:17:25,972 - logger.py:50 - Epoch: [133][5/6]	Total Loss: 0.80560	Main MSE (x10^-2): 80.5598	LR: 3.35e-04	EMPP_Raw: 1.50130
2025-07-18 09:17:26,016 - logger.py:50 - Epoch 133 Training Summary: Avg Total Loss: 0.80560, Avg Main MSE: 0.80560, Time: 17.00s
2025-07-18 09:17:43,947 - logger.py:50 - Epoch 133 Summary | Train MSE (x10^-2): 80.5598 | Val MSE (x10^-2): 81.5819 | Time: 34.93s
2025-07-18 09:17:46,984 - logger.py:50 - Epoch: [134][0/6]	Total Loss: 0.78425	Main MSE (x10^-2): 78.4249	LR: 3.34e-04	EMPP_Raw: 1.47234
2025-07-18 09:18:00,924 - logger.py:50 - Epoch: [134][5/6]	Total Loss: 0.79810	Main MSE (x10^-2): 79.8095	LR: 3.34e-04	EMPP_Raw: 1.49903
2025-07-18 09:18:00,973 - logger.py:50 - Epoch 134 Training Summary: Avg Total Loss: 0.79810, Avg Main MSE: 0.79810, Time: 17.02s
2025-07-18 09:18:18,909 - logger.py:50 - Epoch 134 Summary | Train MSE (x10^-2): 79.8095 | Val MSE (x10^-2): 81.7919 | Time: 34.96s
2025-07-18 09:18:21,909 - logger.py:50 - Epoch: [135][0/6]	Total Loss: 0.78631	Main MSE (x10^-2): 78.6307	LR: 3.33e-04	EMPP_Raw: 1.47368
2025-07-18 09:18:35,700 - logger.py:50 - Epoch: [135][5/6]	Total Loss: 0.79104	Main MSE (x10^-2): 79.1037	LR: 3.33e-04	EMPP_Raw: 1.47699
2025-07-18 09:18:35,742 - logger.py:50 - Epoch 135 Training Summary: Avg Total Loss: 0.79104, Avg Main MSE: 0.79104, Time: 16.82s
2025-07-18 09:18:53,797 - logger.py:50 - Epoch 135 Summary | Train MSE (x10^-2): 79.1037 | Val MSE (x10^-2): 79.6839 | Time: 34.88s
2025-07-18 09:18:56,801 - logger.py:50 - Epoch: [136][0/6]	Total Loss: 0.79277	Main MSE (x10^-2): 79.2773	LR: 3.32e-04	EMPP_Raw: 1.47813
2025-07-18 09:19:10,593 - logger.py:50 - Epoch: [136][5/6]	Total Loss: 0.80333	Main MSE (x10^-2): 80.3332	LR: 3.32e-04	EMPP_Raw: 1.50822
2025-07-18 09:19:10,634 - logger.py:50 - Epoch 136 Training Summary: Avg Total Loss: 0.80333, Avg Main MSE: 0.80333, Time: 16.83s
2025-07-18 09:19:28,705 - logger.py:50 - Epoch 136 Summary | Train MSE (x10^-2): 80.3332 | Val MSE (x10^-2): 77.0857 | Time: 34.90s
2025-07-18 09:19:31,760 - logger.py:50 - Epoch: [137][0/6]	Total Loss: 0.77546	Main MSE (x10^-2): 77.5458	LR: 3.31e-04	EMPP_Raw: 1.45598
2025-07-18 09:19:45,579 - logger.py:50 - Epoch: [137][5/6]	Total Loss: 0.78506	Main MSE (x10^-2): 78.5060	LR: 3.31e-04	EMPP_Raw: 1.47375
2025-07-18 09:19:45,628 - logger.py:50 - Epoch 137 Training Summary: Avg Total Loss: 0.78506, Avg Main MSE: 0.78506, Time: 16.91s
2025-07-18 09:20:03,601 - logger.py:50 - Epoch 137 Summary | Train MSE (x10^-2): 78.5060 | Val MSE (x10^-2): 77.9146 | Time: 34.89s
2025-07-18 09:20:06,993 - logger.py:50 - Epoch: [138][0/6]	Total Loss: 0.79174	Main MSE (x10^-2): 79.1741	LR: 3.31e-04	EMPP_Raw: 1.48675
2025-07-18 09:20:20,818 - logger.py:50 - Epoch: [138][5/6]	Total Loss: 0.78933	Main MSE (x10^-2): 78.9327	LR: 3.31e-04	EMPP_Raw: 1.47333
2025-07-18 09:20:20,870 - logger.py:50 - Epoch 138 Training Summary: Avg Total Loss: 0.78933, Avg Main MSE: 0.78933, Time: 17.26s
2025-07-18 09:20:38,802 - logger.py:50 - Epoch 138 Summary | Train MSE (x10^-2): 78.9327 | Val MSE (x10^-2): 77.4351 | Time: 35.19s
2025-07-18 09:20:41,988 - logger.py:50 - Epoch: [139][0/6]	Total Loss: 0.80283	Main MSE (x10^-2): 80.2832	LR: 3.30e-04	EMPP_Raw: 1.50338
2025-07-18 09:20:55,739 - logger.py:50 - Epoch: [139][5/6]	Total Loss: 0.80017	Main MSE (x10^-2): 80.0167	LR: 3.30e-04	EMPP_Raw: 1.49427
2025-07-18 09:20:55,787 - logger.py:50 - Epoch 139 Training Summary: Avg Total Loss: 0.80017, Avg Main MSE: 0.80017, Time: 16.98s
2025-07-18 09:21:13,657 - logger.py:50 - Epoch 139 Summary | Train MSE (x10^-2): 80.0167 | Val MSE (x10^-2): 77.3507 | Time: 34.85s
2025-07-18 09:21:16,660 - logger.py:50 - Epoch: [140][0/6]	Total Loss: 0.78202	Main MSE (x10^-2): 78.2023	LR: 3.29e-04	EMPP_Raw: 1.47085
2025-07-18 09:21:30,594 - logger.py:50 - Epoch: [140][5/6]	Total Loss: 0.78384	Main MSE (x10^-2): 78.3836	LR: 3.29e-04	EMPP_Raw: 1.47511
2025-07-18 09:21:30,638 - logger.py:50 - Epoch 140 Training Summary: Avg Total Loss: 0.78384, Avg Main MSE: 0.78384, Time: 16.97s
2025-07-18 09:21:48,552 - logger.py:50 - Epoch 140 Summary | Train MSE (x10^-2): 78.3836 | Val MSE (x10^-2): 76.8198 | Time: 34.89s
2025-07-18 09:21:51,575 - logger.py:50 - Epoch: [141][0/6]	Total Loss: 0.78207	Main MSE (x10^-2): 78.2066	LR: 3.28e-04	EMPP_Raw: 1.48215
2025-07-18 09:22:05,388 - logger.py:50 - Epoch: [141][5/6]	Total Loss: 0.79138	Main MSE (x10^-2): 79.1375	LR: 3.28e-04	EMPP_Raw: 1.49164
2025-07-18 09:22:05,430 - logger.py:50 - Epoch 141 Training Summary: Avg Total Loss: 0.79138, Avg Main MSE: 0.79138, Time: 16.87s
2025-07-18 09:22:23,398 - logger.py:50 - Epoch 141 Summary | Train MSE (x10^-2): 79.1375 | Val MSE (x10^-2): 76.2368 | Time: 34.84s
2025-07-18 09:22:26,394 - logger.py:50 - Epoch: [142][0/6]	Total Loss: 0.78265	Main MSE (x10^-2): 78.2649	LR: 3.27e-04	EMPP_Raw: 1.46657
2025-07-18 09:22:40,161 - logger.py:50 - Epoch: [142][5/6]	Total Loss: 0.78144	Main MSE (x10^-2): 78.1444	LR: 3.27e-04	EMPP_Raw: 1.46878
2025-07-18 09:22:40,202 - logger.py:50 - Epoch 142 Training Summary: Avg Total Loss: 0.78144, Avg Main MSE: 0.78144, Time: 16.79s
2025-07-18 09:22:58,193 - logger.py:50 - Epoch 142 Summary | Train MSE (x10^-2): 78.1444 | Val MSE (x10^-2): 75.9258 | Time: 34.79s
2025-07-18 09:23:01,205 - logger.py:50 - Epoch: [143][0/6]	Total Loss: 0.78352	Main MSE (x10^-2): 78.3516	LR: 3.26e-04	EMPP_Raw: 1.46421
2025-07-18 09:23:15,030 - logger.py:50 - Epoch: [143][5/6]	Total Loss: 0.78507	Main MSE (x10^-2): 78.5070	LR: 3.26e-04	EMPP_Raw: 1.46933
2025-07-18 09:23:15,075 - logger.py:50 - Epoch 143 Training Summary: Avg Total Loss: 0.78507, Avg Main MSE: 0.78507, Time: 16.87s
2025-07-18 09:23:33,052 - logger.py:50 - Epoch 143 Summary | Train MSE (x10^-2): 78.5070 | Val MSE (x10^-2): 76.4036 | Time: 34.85s
2025-07-18 09:23:36,250 - logger.py:50 - Epoch: [144][0/6]	Total Loss: 0.79452	Main MSE (x10^-2): 79.4521	LR: 3.25e-04	EMPP_Raw: 1.49144
2025-07-18 09:23:50,027 - logger.py:50 - Epoch: [144][5/6]	Total Loss: 0.78450	Main MSE (x10^-2): 78.4504	LR: 3.25e-04	EMPP_Raw: 1.47457
2025-07-18 09:23:50,072 - logger.py:50 - Epoch 144 Training Summary: Avg Total Loss: 0.78450, Avg Main MSE: 0.78450, Time: 17.01s
2025-07-18 09:24:08,085 - logger.py:50 - Epoch 144 Summary | Train MSE (x10^-2): 78.4504 | Val MSE (x10^-2): 77.3235 | Time: 35.03s
2025-07-18 09:24:11,082 - logger.py:50 - Epoch: [145][0/6]	Total Loss: 0.80639	Main MSE (x10^-2): 80.6392	LR: 3.24e-04	EMPP_Raw: 1.51270
2025-07-18 09:24:25,009 - logger.py:50 - Epoch: [145][5/6]	Total Loss: 0.78177	Main MSE (x10^-2): 78.1766	LR: 3.24e-04	EMPP_Raw: 1.46438
2025-07-18 09:24:25,056 - logger.py:50 - Epoch 145 Training Summary: Avg Total Loss: 0.78177, Avg Main MSE: 0.78177, Time: 16.96s
2025-07-18 09:24:43,114 - logger.py:50 - Epoch 145 Summary | Train MSE (x10^-2): 78.1766 | Val MSE (x10^-2): 80.2253 | Time: 35.02s
2025-07-18 09:24:46,114 - logger.py:50 - Epoch: [146][0/6]	Total Loss: 0.78188	Main MSE (x10^-2): 78.1882	LR: 3.23e-04	EMPP_Raw: 1.47083
2025-07-18 09:25:00,051 - logger.py:50 - Epoch: [146][5/6]	Total Loss: 0.77559	Main MSE (x10^-2): 77.5586	LR: 3.23e-04	EMPP_Raw: 1.46432
2025-07-18 09:25:00,098 - logger.py:50 - Epoch 146 Training Summary: Avg Total Loss: 0.77559, Avg Main MSE: 0.77559, Time: 16.97s
2025-07-18 09:25:18,102 - logger.py:50 - Epoch 146 Summary | Train MSE (x10^-2): 77.5586 | Val MSE (x10^-2): 79.2555 | Time: 34.98s
2025-07-18 09:25:21,156 - logger.py:50 - Epoch: [147][0/6]	Total Loss: 0.76669	Main MSE (x10^-2): 76.6686	LR: 3.22e-04	EMPP_Raw: 1.45435
2025-07-18 09:25:34,937 - logger.py:50 - Epoch: [147][5/6]	Total Loss: 0.77212	Main MSE (x10^-2): 77.2118	LR: 3.22e-04	EMPP_Raw: 1.46417
2025-07-18 09:25:34,982 - logger.py:50 - Epoch 147 Training Summary: Avg Total Loss: 0.77212, Avg Main MSE: 0.77212, Time: 16.87s
2025-07-18 09:25:52,945 - logger.py:50 - Epoch 147 Summary | Train MSE (x10^-2): 77.2118 | Val MSE (x10^-2): 79.1070 | Time: 34.84s
2025-07-18 09:25:56,154 - logger.py:50 - Epoch: [148][0/6]	Total Loss: 0.78366	Main MSE (x10^-2): 78.3664	LR: 3.21e-04	EMPP_Raw: 1.49718
2025-07-18 09:26:09,910 - logger.py:50 - Epoch: [148][5/6]	Total Loss: 0.77362	Main MSE (x10^-2): 77.3619	LR: 3.21e-04	EMPP_Raw: 1.46657
2025-07-18 09:26:09,950 - logger.py:50 - Epoch 148 Training Summary: Avg Total Loss: 0.77362, Avg Main MSE: 0.77362, Time: 17.00s
2025-07-18 09:26:27,800 - logger.py:50 - Epoch 148 Summary | Train MSE (x10^-2): 77.3619 | Val MSE (x10^-2): 79.7618 | Time: 34.85s
2025-07-18 09:26:30,966 - logger.py:50 - Epoch: [149][0/6]	Total Loss: 0.75516	Main MSE (x10^-2): 75.5157	LR: 3.20e-04	EMPP_Raw: 1.43387
2025-07-18 09:26:44,776 - logger.py:50 - Epoch: [149][5/6]	Total Loss: 0.77824	Main MSE (x10^-2): 77.8244	LR: 3.20e-04	EMPP_Raw: 1.47874
2025-07-18 09:26:44,822 - logger.py:50 - Epoch 149 Training Summary: Avg Total Loss: 0.77824, Avg Main MSE: 0.77824, Time: 17.01s
2025-07-18 09:27:02,737 - logger.py:50 - Epoch 149 Summary | Train MSE (x10^-2): 77.8244 | Val MSE (x10^-2): 78.6867 | Time: 34.93s
2025-07-18 09:27:05,750 - logger.py:50 - Epoch: [150][0/6]	Total Loss: 0.80017	Main MSE (x10^-2): 80.0168	LR: 3.19e-04	EMPP_Raw: 1.51660
2025-07-18 09:27:19,716 - logger.py:50 - Epoch: [150][5/6]	Total Loss: 0.77931	Main MSE (x10^-2): 77.9306	LR: 3.19e-04	EMPP_Raw: 1.47508
2025-07-18 09:27:19,762 - logger.py:50 - Epoch 150 Training Summary: Avg Total Loss: 0.77931, Avg Main MSE: 0.77931, Time: 17.02s
2025-07-18 09:27:37,620 - logger.py:50 - Epoch 150 Summary | Train MSE (x10^-2): 77.9306 | Val MSE (x10^-2): 76.6247 | Time: 34.88s
2025-07-18 09:27:40,622 - logger.py:50 - Epoch: [151][0/6]	Total Loss: 0.76217	Main MSE (x10^-2): 76.2171	LR: 3.18e-04	EMPP_Raw: 1.43854
2025-07-18 09:27:54,391 - logger.py:50 - Epoch: [151][5/6]	Total Loss: 0.77665	Main MSE (x10^-2): 77.6654	LR: 3.18e-04	EMPP_Raw: 1.46920
2025-07-18 09:27:54,439 - logger.py:50 - Epoch 151 Training Summary: Avg Total Loss: 0.77665, Avg Main MSE: 0.77665, Time: 16.81s
2025-07-18 09:28:12,500 - logger.py:50 - Epoch 151 Summary | Train MSE (x10^-2): 77.6654 | Val MSE (x10^-2): 75.2884 | Time: 34.87s
2025-07-18 09:28:15,514 - logger.py:50 - Epoch: [152][0/6]	Total Loss: 0.77585	Main MSE (x10^-2): 77.5848	LR: 3.17e-04	EMPP_Raw: 1.47064
2025-07-18 09:28:29,335 - logger.py:50 - Epoch: [152][5/6]	Total Loss: 0.77086	Main MSE (x10^-2): 77.0859	LR: 3.17e-04	EMPP_Raw: 1.45991
2025-07-18 09:28:29,381 - logger.py:50 - Epoch 152 Training Summary: Avg Total Loss: 0.77086, Avg Main MSE: 0.77086, Time: 16.87s
2025-07-18 09:28:47,349 - logger.py:50 - Epoch 152 Summary | Train MSE (x10^-2): 77.0859 | Val MSE (x10^-2): 75.6213 | Time: 34.84s
2025-07-18 09:28:50,513 - logger.py:50 - Epoch: [153][0/6]	Total Loss: 0.77383	Main MSE (x10^-2): 77.3829	LR: 3.16e-04	EMPP_Raw: 1.46006
2025-07-18 09:29:04,298 - logger.py:50 - Epoch: [153][5/6]	Total Loss: 0.77684	Main MSE (x10^-2): 77.6837	LR: 3.16e-04	EMPP_Raw: 1.46929
2025-07-18 09:29:04,342 - logger.py:50 - Epoch 153 Training Summary: Avg Total Loss: 0.77684, Avg Main MSE: 0.77684, Time: 16.98s
2025-07-18 09:29:22,354 - logger.py:50 - Epoch 153 Summary | Train MSE (x10^-2): 77.6837 | Val MSE (x10^-2): 76.9296 | Time: 35.00s
2025-07-18 09:29:25,361 - logger.py:50 - Epoch: [154][0/6]	Total Loss: 0.77414	Main MSE (x10^-2): 77.4135	LR: 3.15e-04	EMPP_Raw: 1.46343
2025-07-18 09:29:39,313 - logger.py:50 - Epoch: [154][5/6]	Total Loss: 0.78927	Main MSE (x10^-2): 78.9272	LR: 3.15e-04	EMPP_Raw: 1.49072
2025-07-18 09:29:39,360 - logger.py:50 - Epoch 154 Training Summary: Avg Total Loss: 0.78927, Avg Main MSE: 0.78927, Time: 17.00s
2025-07-18 09:29:57,236 - logger.py:50 - Epoch 154 Summary | Train MSE (x10^-2): 78.9272 | Val MSE (x10^-2): 76.3507 | Time: 34.88s
2025-07-18 09:30:00,239 - logger.py:50 - Epoch: [155][0/6]	Total Loss: 0.79631	Main MSE (x10^-2): 79.6313	LR: 3.14e-04	EMPP_Raw: 1.51508
2025-07-18 09:30:14,050 - logger.py:50 - Epoch: [155][5/6]	Total Loss: 0.78073	Main MSE (x10^-2): 78.0733	LR: 3.14e-04	EMPP_Raw: 1.48439
2025-07-18 09:30:14,097 - logger.py:50 - Epoch 155 Training Summary: Avg Total Loss: 0.78073, Avg Main MSE: 0.78073, Time: 16.85s
2025-07-18 09:30:32,112 - logger.py:50 - Epoch 155 Summary | Train MSE (x10^-2): 78.0733 | Val MSE (x10^-2): 78.7624 | Time: 34.87s
2025-07-18 09:30:35,138 - logger.py:50 - Epoch: [156][0/6]	Total Loss: 0.77377	Main MSE (x10^-2): 77.3771	LR: 3.13e-04	EMPP_Raw: 1.47617
2025-07-18 09:30:48,987 - logger.py:50 - Epoch: [156][5/6]	Total Loss: 0.77911	Main MSE (x10^-2): 77.9106	LR: 3.13e-04	EMPP_Raw: 1.47807
2025-07-18 09:30:49,034 - logger.py:50 - Epoch 156 Training Summary: Avg Total Loss: 0.77911, Avg Main MSE: 0.77911, Time: 16.91s
2025-07-18 09:31:07,050 - logger.py:50 - Epoch 156 Summary | Train MSE (x10^-2): 77.9106 | Val MSE (x10^-2): 75.4181 | Time: 34.93s
2025-07-18 09:31:10,070 - logger.py:50 - Epoch: [157][0/6]	Total Loss: 0.76296	Main MSE (x10^-2): 76.2964	LR: 3.12e-04	EMPP_Raw: 1.45791
2025-07-18 09:31:23,907 - logger.py:50 - Epoch: [157][5/6]	Total Loss: 0.78584	Main MSE (x10^-2): 78.5842	LR: 3.12e-04	EMPP_Raw: 1.49696
2025-07-18 09:31:23,952 - logger.py:50 - Epoch 157 Training Summary: Avg Total Loss: 0.78584, Avg Main MSE: 0.78584, Time: 16.89s
2025-07-18 09:31:41,938 - logger.py:50 - Epoch 157 Summary | Train MSE (x10^-2): 78.5842 | Val MSE (x10^-2): 76.5151 | Time: 34.88s
2025-07-18 09:31:45,341 - logger.py:50 - Epoch: [158][0/6]	Total Loss: 0.76858	Main MSE (x10^-2): 76.8580	LR: 3.11e-04	EMPP_Raw: 1.46947
2025-07-18 09:31:59,169 - logger.py:50 - Epoch: [158][5/6]	Total Loss: 0.76771	Main MSE (x10^-2): 76.7710	LR: 3.11e-04	EMPP_Raw: 1.45676
2025-07-18 09:31:59,234 - logger.py:50 - Epoch 158 Training Summary: Avg Total Loss: 0.76771, Avg Main MSE: 0.76771, Time: 17.29s
2025-07-18 09:32:17,204 - logger.py:50 - Epoch 158 Summary | Train MSE (x10^-2): 76.7710 | Val MSE (x10^-2): 77.7811 | Time: 35.26s
2025-07-18 09:32:20,361 - logger.py:50 - Epoch: [159][0/6]	Total Loss: 0.75439	Main MSE (x10^-2): 75.4393	LR: 3.10e-04	EMPP_Raw: 1.43564
2025-07-18 09:32:34,101 - logger.py:50 - Epoch: [159][5/6]	Total Loss: 0.77139	Main MSE (x10^-2): 77.1394	LR: 3.10e-04	EMPP_Raw: 1.46700
2025-07-18 09:32:34,142 - logger.py:50 - Epoch 159 Training Summary: Avg Total Loss: 0.77139, Avg Main MSE: 0.77139, Time: 16.93s
2025-07-18 09:32:52,199 - logger.py:50 - Epoch 159 Summary | Train MSE (x10^-2): 77.1394 | Val MSE (x10^-2): 73.6458 | Time: 34.99s
2025-07-18 09:32:55,214 - logger.py:50 - Epoch: [160][0/6]	Total Loss: 0.75767	Main MSE (x10^-2): 75.7672	LR: 3.08e-04	EMPP_Raw: 1.43923
2025-07-18 09:33:09,190 - logger.py:50 - Epoch: [160][5/6]	Total Loss: 0.78018	Main MSE (x10^-2): 78.0181	LR: 3.08e-04	EMPP_Raw: 1.49080
2025-07-18 09:33:09,236 - logger.py:50 - Epoch 160 Training Summary: Avg Total Loss: 0.78018, Avg Main MSE: 0.78018, Time: 17.03s
2025-07-18 09:33:27,140 - logger.py:50 - Epoch 160 Summary | Train MSE (x10^-2): 78.0181 | Val MSE (x10^-2): 77.1322 | Time: 34.93s
2025-07-18 09:33:30,142 - logger.py:50 - Epoch: [161][0/6]	Total Loss: 0.79723	Main MSE (x10^-2): 79.7227	LR: 3.07e-04	EMPP_Raw: 1.52432
2025-07-18 09:33:43,913 - logger.py:50 - Epoch: [161][5/6]	Total Loss: 0.77712	Main MSE (x10^-2): 77.7124	LR: 3.07e-04	EMPP_Raw: 1.47979
2025-07-18 09:33:43,953 - logger.py:50 - Epoch 161 Training Summary: Avg Total Loss: 0.77712, Avg Main MSE: 0.77712, Time: 16.80s
2025-07-18 09:34:02,062 - logger.py:50 - Epoch 161 Summary | Train MSE (x10^-2): 77.7124 | Val MSE (x10^-2): 78.4113 | Time: 34.92s
2025-07-18 09:34:05,062 - logger.py:50 - Epoch: [162][0/6]	Total Loss: 0.76009	Main MSE (x10^-2): 76.0090	LR: 3.06e-04	EMPP_Raw: 1.44229
2025-07-18 09:34:18,855 - logger.py:50 - Epoch: [162][5/6]	Total Loss: 0.76391	Main MSE (x10^-2): 76.3906	LR: 3.06e-04	EMPP_Raw: 1.45442
2025-07-18 09:34:18,896 - logger.py:50 - Epoch 162 Training Summary: Avg Total Loss: 0.76391, Avg Main MSE: 0.76391, Time: 16.82s
2025-07-18 09:34:36,985 - logger.py:50 - Epoch 162 Summary | Train MSE (x10^-2): 76.3906 | Val MSE (x10^-2): 79.0437 | Time: 34.92s
2025-07-18 09:34:39,988 - logger.py:50 - Epoch: [163][0/6]	Total Loss: 0.77977	Main MSE (x10^-2): 77.9772	LR: 3.05e-04	EMPP_Raw: 1.49153
2025-07-18 09:34:53,776 - logger.py:50 - Epoch: [163][5/6]	Total Loss: 0.77180	Main MSE (x10^-2): 77.1796	LR: 3.05e-04	EMPP_Raw: 1.47219
2025-07-18 09:34:53,814 - logger.py:50 - Epoch 163 Training Summary: Avg Total Loss: 0.77180, Avg Main MSE: 0.77180, Time: 16.82s
2025-07-18 09:35:11,697 - logger.py:50 - Epoch 163 Summary | Train MSE (x10^-2): 77.1796 | Val MSE (x10^-2): 77.7561 | Time: 34.70s
2025-07-18 09:35:14,865 - logger.py:50 - Epoch: [164][0/6]	Total Loss: 0.79128	Main MSE (x10^-2): 79.1283	LR: 3.04e-04	EMPP_Raw: 1.50352
2025-07-18 09:35:28,686 - logger.py:50 - Epoch: [164][5/6]	Total Loss: 0.77535	Main MSE (x10^-2): 77.5348	LR: 3.04e-04	EMPP_Raw: 1.48095
2025-07-18 09:35:28,734 - logger.py:50 - Epoch 164 Training Summary: Avg Total Loss: 0.77535, Avg Main MSE: 0.77535, Time: 17.03s
2025-07-18 09:35:46,640 - logger.py:50 - Epoch 164 Summary | Train MSE (x10^-2): 77.5348 | Val MSE (x10^-2): 77.7124 | Time: 34.94s
2025-07-18 09:35:49,664 - logger.py:50 - Epoch: [165][0/6]	Total Loss: 0.78315	Main MSE (x10^-2): 78.3147	LR: 3.03e-04	EMPP_Raw: 1.50742
2025-07-18 09:36:03,602 - logger.py:50 - Epoch: [165][5/6]	Total Loss: 0.77675	Main MSE (x10^-2): 77.6753	LR: 3.03e-04	EMPP_Raw: 1.48599
2025-07-18 09:36:03,649 - logger.py:50 - Epoch 165 Training Summary: Avg Total Loss: 0.77675, Avg Main MSE: 0.77675, Time: 17.00s
2025-07-18 09:36:21,565 - logger.py:50 - Epoch 165 Summary | Train MSE (x10^-2): 77.6753 | Val MSE (x10^-2): 78.4897 | Time: 34.92s
2025-07-18 09:36:24,574 - logger.py:50 - Epoch: [166][0/6]	Total Loss: 0.78420	Main MSE (x10^-2): 78.4203	LR: 3.02e-04	EMPP_Raw: 1.49885
2025-07-18 09:36:38,527 - logger.py:50 - Epoch: [166][5/6]	Total Loss: 0.77231	Main MSE (x10^-2): 77.2311	LR: 3.02e-04	EMPP_Raw: 1.48119
2025-07-18 09:36:38,567 - logger.py:50 - Epoch 166 Training Summary: Avg Total Loss: 0.77231, Avg Main MSE: 0.77231, Time: 16.99s
2025-07-18 09:36:56,470 - logger.py:50 - Epoch 166 Summary | Train MSE (x10^-2): 77.2311 | Val MSE (x10^-2): 77.7752 | Time: 34.90s
2025-07-18 09:36:59,487 - logger.py:50 - Epoch: [167][0/6]	Total Loss: 0.75713	Main MSE (x10^-2): 75.7132	LR: 3.01e-04	EMPP_Raw: 1.44804
2025-07-18 09:37:13,405 - logger.py:50 - Epoch: [167][5/6]	Total Loss: 0.76249	Main MSE (x10^-2): 76.2488	LR: 3.01e-04	EMPP_Raw: 1.44928
2025-07-18 09:37:13,446 - logger.py:50 - Epoch 167 Training Summary: Avg Total Loss: 0.76249, Avg Main MSE: 0.76249, Time: 16.97s
2025-07-18 09:37:31,416 - logger.py:50 - Epoch 167 Summary | Train MSE (x10^-2): 76.2488 | Val MSE (x10^-2): 77.6917 | Time: 34.94s
2025-07-18 09:37:34,596 - logger.py:50 - Epoch: [168][0/6]	Total Loss: 0.79030	Main MSE (x10^-2): 79.0303	LR: 3.00e-04	EMPP_Raw: 1.51858
2025-07-18 09:37:48,381 - logger.py:50 - Epoch: [168][5/6]	Total Loss: 0.78173	Main MSE (x10^-2): 78.1735	LR: 3.00e-04	EMPP_Raw: 1.48934
2025-07-18 09:37:48,421 - logger.py:50 - Epoch 168 Training Summary: Avg Total Loss: 0.78173, Avg Main MSE: 0.78173, Time: 16.99s
2025-07-18 09:38:06,448 - logger.py:50 - Epoch 168 Summary | Train MSE (x10^-2): 78.1735 | Val MSE (x10^-2): 82.0512 | Time: 35.03s
2025-07-18 09:38:09,666 - logger.py:50 - Epoch: [169][0/6]	Total Loss: 0.79331	Main MSE (x10^-2): 79.3313	LR: 2.99e-04	EMPP_Raw: 1.51024
2025-07-18 09:38:23,436 - logger.py:50 - Epoch: [169][5/6]	Total Loss: 0.76548	Main MSE (x10^-2): 76.5482	LR: 2.99e-04	EMPP_Raw: 1.45871
2025-07-18 09:38:23,480 - logger.py:50 - Epoch 169 Training Summary: Avg Total Loss: 0.76548, Avg Main MSE: 0.76548, Time: 17.02s
2025-07-18 09:38:41,442 - logger.py:50 - Epoch 169 Summary | Train MSE (x10^-2): 76.5482 | Val MSE (x10^-2): 79.6020 | Time: 34.99s
2025-07-18 09:38:44,500 - logger.py:50 - Epoch: [170][0/6]	Total Loss: 0.76720	Main MSE (x10^-2): 76.7195	LR: 2.98e-04	EMPP_Raw: 1.46859
2025-07-18 09:38:58,400 - logger.py:50 - Epoch: [170][5/6]	Total Loss: 0.77037	Main MSE (x10^-2): 77.0375	LR: 2.98e-04	EMPP_Raw: 1.47407
2025-07-18 09:38:58,442 - logger.py:50 - Epoch 170 Training Summary: Avg Total Loss: 0.77037, Avg Main MSE: 0.77037, Time: 16.99s
2025-07-18 09:39:16,488 - logger.py:50 - Epoch 170 Summary | Train MSE (x10^-2): 77.0375 | Val MSE (x10^-2): 80.0114 | Time: 35.04s
2025-07-18 09:39:19,483 - logger.py:50 - Epoch: [171][0/6]	Total Loss: 0.76659	Main MSE (x10^-2): 76.6592	LR: 2.97e-04	EMPP_Raw: 1.47393
2025-07-18 09:39:33,261 - logger.py:50 - Epoch: [171][5/6]	Total Loss: 0.78101	Main MSE (x10^-2): 78.1011	LR: 2.97e-04	EMPP_Raw: 1.49228
2025-07-18 09:39:33,306 - logger.py:50 - Epoch 171 Training Summary: Avg Total Loss: 0.78101, Avg Main MSE: 0.78101, Time: 16.81s
2025-07-18 09:39:51,399 - logger.py:50 - Epoch 171 Summary | Train MSE (x10^-2): 78.1011 | Val MSE (x10^-2): 82.1582 | Time: 34.90s
2025-07-18 09:39:54,472 - logger.py:50 - Epoch: [172][0/6]	Total Loss: 0.76082	Main MSE (x10^-2): 76.0817	LR: 2.96e-04	EMPP_Raw: 1.45281
2025-07-18 09:40:08,317 - logger.py:50 - Epoch: [172][5/6]	Total Loss: 0.77072	Main MSE (x10^-2): 77.0719	LR: 2.96e-04	EMPP_Raw: 1.47156
2025-07-18 09:40:08,362 - logger.py:50 - Epoch 172 Training Summary: Avg Total Loss: 0.77072, Avg Main MSE: 0.77072, Time: 16.95s
2025-07-18 09:40:26,299 - logger.py:50 - Epoch 172 Summary | Train MSE (x10^-2): 77.0719 | Val MSE (x10^-2): 77.2493 | Time: 34.89s
2025-07-18 09:40:29,450 - logger.py:50 - Epoch: [173][0/6]	Total Loss: 0.78520	Main MSE (x10^-2): 78.5202	LR: 2.94e-04	EMPP_Raw: 1.50523
2025-07-18 09:40:43,216 - logger.py:50 - Epoch: [173][5/6]	Total Loss: 0.76500	Main MSE (x10^-2): 76.5004	LR: 2.94e-04	EMPP_Raw: 1.46204
2025-07-18 09:40:43,256 - logger.py:50 - Epoch 173 Training Summary: Avg Total Loss: 0.76500, Avg Main MSE: 0.76500, Time: 16.95s
2025-07-18 09:41:01,150 - logger.py:50 - Epoch 173 Summary | Train MSE (x10^-2): 76.5004 | Val MSE (x10^-2): 75.6250 | Time: 34.85s
2025-07-18 09:41:04,149 - logger.py:50 - Epoch: [174][0/6]	Total Loss: 0.75998	Main MSE (x10^-2): 75.9984	LR: 2.93e-04	EMPP_Raw: 1.46356
2025-07-18 09:41:18,045 - logger.py:50 - Epoch: [174][5/6]	Total Loss: 0.75915	Main MSE (x10^-2): 75.9149	LR: 2.93e-04	EMPP_Raw: 1.45929
2025-07-18 09:41:18,088 - logger.py:50 - Epoch 174 Training Summary: Avg Total Loss: 0.75915, Avg Main MSE: 0.75915, Time: 16.93s
2025-07-18 09:41:36,015 - logger.py:50 - Epoch 174 Summary | Train MSE (x10^-2): 75.9149 | Val MSE (x10^-2): 78.0480 | Time: 34.86s
2025-07-18 09:41:39,029 - logger.py:50 - Epoch: [175][0/6]	Total Loss: 0.76452	Main MSE (x10^-2): 76.4522	LR: 2.92e-04	EMPP_Raw: 1.47075
2025-07-18 09:41:52,815 - logger.py:50 - Epoch: [175][5/6]	Total Loss: 0.77078	Main MSE (x10^-2): 77.0782	LR: 2.92e-04	EMPP_Raw: 1.47802
2025-07-18 09:41:52,865 - logger.py:50 - Epoch 175 Training Summary: Avg Total Loss: 0.77078, Avg Main MSE: 0.77078, Time: 16.84s
2025-07-18 09:42:10,909 - logger.py:50 - Epoch 175 Summary | Train MSE (x10^-2): 77.0782 | Val MSE (x10^-2): 77.7581 | Time: 34.89s
2025-07-18 09:42:13,908 - logger.py:50 - Epoch: [176][0/6]	Total Loss: 0.77675	Main MSE (x10^-2): 77.6753	LR: 2.91e-04	EMPP_Raw: 1.49797
2025-07-18 09:42:27,702 - logger.py:50 - Epoch: [176][5/6]	Total Loss: 0.77513	Main MSE (x10^-2): 77.5128	LR: 2.91e-04	EMPP_Raw: 1.48716
2025-07-18 09:42:27,742 - logger.py:50 - Epoch 176 Training Summary: Avg Total Loss: 0.77513, Avg Main MSE: 0.77513, Time: 16.82s
2025-07-18 09:42:45,705 - logger.py:50 - Epoch 176 Summary | Train MSE (x10^-2): 77.5128 | Val MSE (x10^-2): 76.8803 | Time: 34.79s
2025-07-18 09:42:48,715 - logger.py:50 - Epoch: [177][0/6]	Total Loss: 0.75323	Main MSE (x10^-2): 75.3230	LR: 2.90e-04	EMPP_Raw: 1.44113
2025-07-18 09:43:02,565 - logger.py:50 - Epoch: [177][5/6]	Total Loss: 0.76542	Main MSE (x10^-2): 76.5421	LR: 2.90e-04	EMPP_Raw: 1.46434
2025-07-18 09:43:02,615 - logger.py:50 - Epoch 177 Training Summary: Avg Total Loss: 0.76542, Avg Main MSE: 0.76542, Time: 16.90s
2025-07-18 09:43:20,506 - logger.py:50 - Epoch 177 Summary | Train MSE (x10^-2): 76.5421 | Val MSE (x10^-2): 77.2762 | Time: 34.80s
2025-07-18 09:43:23,846 - logger.py:50 - Epoch: [178][0/6]	Total Loss: 0.77366	Main MSE (x10^-2): 77.3657	LR: 2.89e-04	EMPP_Raw: 1.46903
2025-07-18 09:43:37,569 - logger.py:50 - Epoch: [178][5/6]	Total Loss: 0.78064	Main MSE (x10^-2): 78.0644	LR: 2.89e-04	EMPP_Raw: 1.49439
2025-07-18 09:43:37,643 - logger.py:50 - Epoch 178 Training Summary: Avg Total Loss: 0.78064, Avg Main MSE: 0.78064, Time: 17.13s
2025-07-18 09:43:55,518 - logger.py:50 - Epoch 178 Summary | Train MSE (x10^-2): 78.0644 | Val MSE (x10^-2): 76.7144 | Time: 35.01s
2025-07-18 09:43:58,682 - logger.py:50 - Epoch: [179][0/6]	Total Loss: 0.75978	Main MSE (x10^-2): 75.9779	LR: 2.88e-04	EMPP_Raw: 1.44776
2025-07-18 09:44:12,507 - logger.py:50 - Epoch: [179][5/6]	Total Loss: 0.76954	Main MSE (x10^-2): 76.9544	LR: 2.88e-04	EMPP_Raw: 1.46918
2025-07-18 09:44:12,554 - logger.py:50 - Epoch 179 Training Summary: Avg Total Loss: 0.76954, Avg Main MSE: 0.76954, Time: 17.03s
2025-07-18 09:44:30,506 - logger.py:50 - Epoch 179 Summary | Train MSE (x10^-2): 76.9544 | Val MSE (x10^-2): 74.2294 | Time: 34.98s
2025-07-18 09:44:33,522 - logger.py:50 - Epoch: [180][0/6]	Total Loss: 0.76161	Main MSE (x10^-2): 76.1609	LR: 2.87e-04	EMPP_Raw: 1.45702
2025-07-18 09:44:47,523 - logger.py:50 - Epoch: [180][5/6]	Total Loss: 0.76814	Main MSE (x10^-2): 76.8143	LR: 2.87e-04	EMPP_Raw: 1.47009
2025-07-18 09:44:47,569 - logger.py:50 - Epoch 180 Training Summary: Avg Total Loss: 0.76814, Avg Main MSE: 0.76814, Time: 17.05s
2025-07-18 09:45:05,512 - logger.py:50 - Epoch 180 Summary | Train MSE (x10^-2): 76.8143 | Val MSE (x10^-2): 74.6700 | Time: 35.00s
2025-07-18 09:45:08,513 - logger.py:50 - Epoch: [181][0/6]	Total Loss: 0.75511	Main MSE (x10^-2): 75.5110	LR: 2.85e-04	EMPP_Raw: 1.44525
2025-07-18 09:45:22,293 - logger.py:50 - Epoch: [181][5/6]	Total Loss: 0.77409	Main MSE (x10^-2): 77.4090	LR: 2.85e-04	EMPP_Raw: 1.48156
2025-07-18 09:45:22,335 - logger.py:50 - Epoch 181 Training Summary: Avg Total Loss: 0.77409, Avg Main MSE: 0.77409, Time: 16.82s
2025-07-18 09:45:40,359 - logger.py:50 - Epoch 181 Summary | Train MSE (x10^-2): 77.4090 | Val MSE (x10^-2): 76.8012 | Time: 34.84s
2025-07-18 09:45:43,363 - logger.py:50 - Epoch: [182][0/6]	Total Loss: 0.75209	Main MSE (x10^-2): 75.2088	LR: 2.84e-04	EMPP_Raw: 1.44267
2025-07-18 09:45:57,258 - logger.py:50 - Epoch: [182][5/6]	Total Loss: 0.76248	Main MSE (x10^-2): 76.2479	LR: 2.84e-04	EMPP_Raw: 1.46054
2025-07-18 09:45:57,303 - logger.py:50 - Epoch 182 Training Summary: Avg Total Loss: 0.76248, Avg Main MSE: 0.76248, Time: 16.94s
2025-07-18 09:46:15,335 - logger.py:50 - Epoch 182 Summary | Train MSE (x10^-2): 76.2479 | Val MSE (x10^-2): 77.8646 | Time: 34.97s
2025-07-18 09:46:18,335 - logger.py:50 - Epoch: [183][0/6]	Total Loss: 0.73992	Main MSE (x10^-2): 73.9916	LR: 2.83e-04	EMPP_Raw: 1.41662
2025-07-18 09:46:32,107 - logger.py:50 - Epoch: [183][5/6]	Total Loss: 0.76490	Main MSE (x10^-2): 76.4900	LR: 2.83e-04	EMPP_Raw: 1.46492
2025-07-18 09:46:32,150 - logger.py:50 - Epoch 183 Training Summary: Avg Total Loss: 0.76490, Avg Main MSE: 0.76490, Time: 16.80s
2025-07-18 09:46:50,160 - logger.py:50 - Epoch 183 Summary | Train MSE (x10^-2): 76.4900 | Val MSE (x10^-2): 77.0798 | Time: 34.82s
2025-07-18 09:46:53,329 - logger.py:50 - Epoch: [184][0/6]	Total Loss: 0.77239	Main MSE (x10^-2): 77.2394	LR: 2.82e-04	EMPP_Raw: 1.47544
2025-07-18 09:47:07,128 - logger.py:50 - Epoch: [184][5/6]	Total Loss: 0.76677	Main MSE (x10^-2): 76.6769	LR: 2.82e-04	EMPP_Raw: 1.46656
2025-07-18 09:47:07,175 - logger.py:50 - Epoch 184 Training Summary: Avg Total Loss: 0.76677, Avg Main MSE: 0.76677, Time: 17.01s
2025-07-18 09:47:25,060 - logger.py:50 - Epoch 184 Summary | Train MSE (x10^-2): 76.6769 | Val MSE (x10^-2): 80.1606 | Time: 34.90s
2025-07-18 09:47:28,112 - logger.py:50 - Epoch: [185][0/6]	Total Loss: 0.76944	Main MSE (x10^-2): 76.9439	LR: 2.81e-04	EMPP_Raw: 1.47287
2025-07-18 09:47:42,057 - logger.py:50 - Epoch: [185][5/6]	Total Loss: 0.77697	Main MSE (x10^-2): 77.6971	LR: 2.81e-04	EMPP_Raw: 1.48104
2025-07-18 09:47:42,097 - logger.py:50 - Epoch 185 Training Summary: Avg Total Loss: 0.77697, Avg Main MSE: 0.77697, Time: 17.03s
2025-07-18 09:48:00,022 - logger.py:50 - Epoch 185 Summary | Train MSE (x10^-2): 77.6971 | Val MSE (x10^-2): 75.0017 | Time: 34.96s
2025-07-18 09:48:03,092 - logger.py:50 - Epoch: [186][0/6]	Total Loss: 0.75689	Main MSE (x10^-2): 75.6887	LR: 2.80e-04	EMPP_Raw: 1.44398
2025-07-18 09:48:17,065 - logger.py:50 - Epoch: [186][5/6]	Total Loss: 0.76648	Main MSE (x10^-2): 76.6482	LR: 2.80e-04	EMPP_Raw: 1.46576
2025-07-18 09:48:17,116 - logger.py:50 - Epoch 186 Training Summary: Avg Total Loss: 0.76648, Avg Main MSE: 0.76648, Time: 17.09s
2025-07-18 09:48:34,955 - logger.py:50 - Epoch 186 Summary | Train MSE (x10^-2): 76.6482 | Val MSE (x10^-2): 77.6374 | Time: 34.93s
2025-07-18 09:48:37,992 - logger.py:50 - Epoch: [187][0/6]	Total Loss: 0.75635	Main MSE (x10^-2): 75.6345	LR: 2.79e-04	EMPP_Raw: 1.44759
2025-07-18 09:48:51,803 - logger.py:50 - Epoch: [187][5/6]	Total Loss: 0.77409	Main MSE (x10^-2): 77.4086	LR: 2.79e-04	EMPP_Raw: 1.48653
2025-07-18 09:48:51,847 - logger.py:50 - Epoch 187 Training Summary: Avg Total Loss: 0.77409, Avg Main MSE: 0.77409, Time: 16.88s
2025-07-18 09:49:09,743 - logger.py:50 - Epoch 187 Summary | Train MSE (x10^-2): 77.4086 | Val MSE (x10^-2): 80.4622 | Time: 34.78s
2025-07-18 09:49:12,921 - logger.py:50 - Epoch: [188][0/6]	Total Loss: 0.75511	Main MSE (x10^-2): 75.5111	LR: 2.77e-04	EMPP_Raw: 1.45519
2025-07-18 09:49:26,692 - logger.py:50 - Epoch: [188][5/6]	Total Loss: 0.75123	Main MSE (x10^-2): 75.1226	LR: 2.77e-04	EMPP_Raw: 1.44439
2025-07-18 09:49:26,732 - logger.py:50 - Epoch 188 Training Summary: Avg Total Loss: 0.75123, Avg Main MSE: 0.75123, Time: 16.98s
2025-07-18 09:49:44,660 - logger.py:50 - Epoch 188 Summary | Train MSE (x10^-2): 75.1226 | Val MSE (x10^-2): 79.8642 | Time: 34.91s
2025-07-18 09:49:47,844 - logger.py:50 - Epoch: [189][0/6]	Total Loss: 0.79051	Main MSE (x10^-2): 79.0509	LR: 2.76e-04	EMPP_Raw: 1.52484
2025-07-18 09:50:01,579 - logger.py:50 - Epoch: [189][5/6]	Total Loss: 0.75718	Main MSE (x10^-2): 75.7177	LR: 2.76e-04	EMPP_Raw: 1.45912
2025-07-18 09:50:01,627 - logger.py:50 - Epoch 189 Training Summary: Avg Total Loss: 0.75718, Avg Main MSE: 0.75718, Time: 16.96s
2025-07-18 09:50:19,635 - logger.py:50 - Epoch 189 Summary | Train MSE (x10^-2): 75.7177 | Val MSE (x10^-2): 81.5661 | Time: 34.97s
2025-07-18 09:50:22,685 - logger.py:50 - Epoch: [190][0/6]	Total Loss: 0.75932	Main MSE (x10^-2): 75.9322	LR: 2.75e-04	EMPP_Raw: 1.45739
2025-07-18 09:50:36,583 - logger.py:50 - Epoch: [190][5/6]	Total Loss: 0.76026	Main MSE (x10^-2): 76.0255	LR: 2.75e-04	EMPP_Raw: 1.46480
2025-07-18 09:50:36,628 - logger.py:50 - Epoch 190 Training Summary: Avg Total Loss: 0.76026, Avg Main MSE: 0.76026, Time: 16.98s
2025-07-18 09:50:54,428 - logger.py:50 - Epoch 190 Summary | Train MSE (x10^-2): 76.0255 | Val MSE (x10^-2): 79.1069 | Time: 34.79s
2025-07-18 09:50:57,488 - logger.py:50 - Epoch: [191][0/6]	Total Loss: 0.75891	Main MSE (x10^-2): 75.8914	LR: 2.74e-04	EMPP_Raw: 1.47137
2025-07-18 09:51:11,293 - logger.py:50 - Epoch: [191][5/6]	Total Loss: 0.75706	Main MSE (x10^-2): 75.7056	LR: 2.74e-04	EMPP_Raw: 1.45990
2025-07-18 09:51:11,335 - logger.py:50 - Epoch 191 Training Summary: Avg Total Loss: 0.75706, Avg Main MSE: 0.75706, Time: 16.90s
2025-07-18 09:51:29,511 - logger.py:50 - Epoch 191 Summary | Train MSE (x10^-2): 75.7056 | Val MSE (x10^-2): 79.8482 | Time: 35.08s
2025-07-18 09:51:32,503 - logger.py:50 - Epoch: [192][0/6]	Total Loss: 0.77938	Main MSE (x10^-2): 77.9377	LR: 2.73e-04	EMPP_Raw: 1.50330
2025-07-18 09:51:46,282 - logger.py:50 - Epoch: [192][5/6]	Total Loss: 0.76002	Main MSE (x10^-2): 76.0016	LR: 2.73e-04	EMPP_Raw: 1.46485
2025-07-18 09:51:46,323 - logger.py:50 - Epoch 192 Training Summary: Avg Total Loss: 0.76002, Avg Main MSE: 0.76002, Time: 16.80s
2025-07-18 09:52:04,193 - logger.py:50 - Epoch 192 Summary | Train MSE (x10^-2): 76.0016 | Val MSE (x10^-2): 79.9090 | Time: 34.68s
2025-07-18 09:52:07,344 - logger.py:50 - Epoch: [193][0/6]	Total Loss: 0.78167	Main MSE (x10^-2): 78.1674	LR: 2.72e-04	EMPP_Raw: 1.50541
2025-07-18 09:52:21,091 - logger.py:50 - Epoch: [193][5/6]	Total Loss: 0.76004	Main MSE (x10^-2): 76.0039	LR: 2.72e-04	EMPP_Raw: 1.46610
2025-07-18 09:52:21,129 - logger.py:50 - Epoch 193 Training Summary: Avg Total Loss: 0.76004, Avg Main MSE: 0.76004, Time: 16.93s
2025-07-18 09:52:39,106 - logger.py:50 - Epoch 193 Summary | Train MSE (x10^-2): 76.0039 | Val MSE (x10^-2): 78.5642 | Time: 34.91s
2025-07-18 09:52:42,112 - logger.py:50 - Epoch: [194][0/6]	Total Loss: 0.75101	Main MSE (x10^-2): 75.1012	LR: 2.70e-04	EMPP_Raw: 1.45306
2025-07-18 09:52:56,030 - logger.py:50 - Epoch: [194][5/6]	Total Loss: 0.75588	Main MSE (x10^-2): 75.5885	LR: 2.70e-04	EMPP_Raw: 1.45725
2025-07-18 09:52:56,074 - logger.py:50 - Epoch 194 Training Summary: Avg Total Loss: 0.75588, Avg Main MSE: 0.75588, Time: 16.96s
2025-07-18 09:53:13,989 - logger.py:50 - Epoch 194 Summary | Train MSE (x10^-2): 75.5885 | Val MSE (x10^-2): 77.8634 | Time: 34.88s
2025-07-18 09:53:17,050 - logger.py:50 - Epoch: [195][0/6]	Total Loss: 0.76809	Main MSE (x10^-2): 76.8087	LR: 2.69e-04	EMPP_Raw: 1.48366
2025-07-18 09:53:30,851 - logger.py:50 - Epoch: [195][5/6]	Total Loss: 0.76704	Main MSE (x10^-2): 76.7043	LR: 2.69e-04	EMPP_Raw: 1.47890
2025-07-18 09:53:30,900 - logger.py:50 - Epoch 195 Training Summary: Avg Total Loss: 0.76704, Avg Main MSE: 0.76704, Time: 16.90s
2025-07-18 09:53:48,918 - logger.py:50 - Epoch 195 Summary | Train MSE (x10^-2): 76.7043 | Val MSE (x10^-2): 80.0828 | Time: 34.92s
2025-07-18 09:53:51,923 - logger.py:50 - Epoch: [196][0/6]	Total Loss: 0.77215	Main MSE (x10^-2): 77.2151	LR: 2.68e-04	EMPP_Raw: 1.48767
2025-07-18 09:54:05,740 - logger.py:50 - Epoch: [196][5/6]	Total Loss: 0.77504	Main MSE (x10^-2): 77.5044	LR: 2.68e-04	EMPP_Raw: 1.48987
2025-07-18 09:54:05,780 - logger.py:50 - Epoch 196 Training Summary: Avg Total Loss: 0.77504, Avg Main MSE: 0.77504, Time: 16.85s
2025-07-18 09:54:23,811 - logger.py:50 - Epoch 196 Summary | Train MSE (x10^-2): 77.5044 | Val MSE (x10^-2): 80.7919 | Time: 34.89s
2025-07-18 09:54:26,809 - logger.py:50 - Epoch: [197][0/6]	Total Loss: 0.77749	Main MSE (x10^-2): 77.7489	LR: 2.67e-04	EMPP_Raw: 1.49921
2025-07-18 09:54:40,567 - logger.py:50 - Epoch: [197][5/6]	Total Loss: 0.76154	Main MSE (x10^-2): 76.1537	LR: 2.67e-04	EMPP_Raw: 1.46688
2025-07-18 09:54:40,618 - logger.py:50 - Epoch 197 Training Summary: Avg Total Loss: 0.76154, Avg Main MSE: 0.76154, Time: 16.80s
2025-07-18 09:54:58,565 - logger.py:50 - Epoch 197 Summary | Train MSE (x10^-2): 76.1537 | Val MSE (x10^-2): 83.0556 | Time: 34.75s
2025-07-18 09:55:01,914 - logger.py:50 - Epoch: [198][0/6]	Total Loss: 0.75223	Main MSE (x10^-2): 75.2229	LR: 2.66e-04	EMPP_Raw: 1.44450
2025-07-18 09:55:15,678 - logger.py:50 - Epoch: [198][5/6]	Total Loss: 0.75997	Main MSE (x10^-2): 75.9970	LR: 2.66e-04	EMPP_Raw: 1.46381
2025-07-18 09:55:15,732 - logger.py:50 - Epoch 198 Training Summary: Avg Total Loss: 0.75997, Avg Main MSE: 0.75997, Time: 17.16s
2025-07-18 09:55:33,731 - logger.py:50 - Epoch 198 Summary | Train MSE (x10^-2): 75.9970 | Val MSE (x10^-2): 78.8092 | Time: 35.16s
2025-07-18 09:55:36,929 - logger.py:50 - Epoch: [199][0/6]	Total Loss: 0.73378	Main MSE (x10^-2): 73.3785	LR: 2.65e-04	EMPP_Raw: 1.40839
2025-07-18 09:55:50,768 - logger.py:50 - Epoch: [199][5/6]	Total Loss: 0.74956	Main MSE (x10^-2): 74.9560	LR: 2.65e-04	EMPP_Raw: 1.44502
2025-07-18 09:55:50,816 - logger.py:50 - Epoch 199 Training Summary: Avg Total Loss: 0.74956, Avg Main MSE: 0.74956, Time: 17.08s
2025-07-18 09:56:08,825 - logger.py:50 - Epoch 199 Summary | Train MSE (x10^-2): 74.9560 | Val MSE (x10^-2): 79.8144 | Time: 35.09s
2025-07-18 09:56:11,845 - logger.py:50 - Epoch: [200][0/6]	Total Loss: 0.73955	Main MSE (x10^-2): 73.9546	LR: 2.63e-04	EMPP_Raw: 1.43183
2025-07-18 09:56:25,772 - logger.py:50 - Epoch: [200][5/6]	Total Loss: 0.75291	Main MSE (x10^-2): 75.2906	LR: 2.63e-04	EMPP_Raw: 1.45401
2025-07-18 09:56:25,813 - logger.py:50 - Epoch 200 Training Summary: Avg Total Loss: 0.75291, Avg Main MSE: 0.75291, Time: 16.98s
2025-07-18 09:56:43,780 - logger.py:50 - Epoch 200 Summary | Train MSE (x10^-2): 75.2906 | Val MSE (x10^-2): 78.1594 | Time: 34.95s
2025-07-18 09:56:46,785 - logger.py:50 - Epoch: [201][0/6]	Total Loss: 0.78619	Main MSE (x10^-2): 78.6189	LR: 2.62e-04	EMPP_Raw: 1.51997
2025-07-18 09:57:00,579 - logger.py:50 - Epoch: [201][5/6]	Total Loss: 0.76898	Main MSE (x10^-2): 76.8979	LR: 2.62e-04	EMPP_Raw: 1.48895
2025-07-18 09:57:00,624 - logger.py:50 - Epoch 201 Training Summary: Avg Total Loss: 0.76898, Avg Main MSE: 0.76898, Time: 16.83s
2025-07-18 09:57:18,648 - logger.py:50 - Epoch 201 Summary | Train MSE (x10^-2): 76.8979 | Val MSE (x10^-2): 76.9169 | Time: 34.86s
2025-07-18 09:57:21,651 - logger.py:50 - Epoch: [202][0/6]	Total Loss: 0.74736	Main MSE (x10^-2): 74.7357	LR: 2.61e-04	EMPP_Raw: 1.44196
2025-07-18 09:57:35,455 - logger.py:50 - Epoch: [202][5/6]	Total Loss: 0.74843	Main MSE (x10^-2): 74.8433	LR: 2.61e-04	EMPP_Raw: 1.44310
2025-07-18 09:57:35,507 - logger.py:50 - Epoch 202 Training Summary: Avg Total Loss: 0.74843, Avg Main MSE: 0.74843, Time: 16.85s
2025-07-18 09:57:53,564 - logger.py:50 - Epoch 202 Summary | Train MSE (x10^-2): 74.8433 | Val MSE (x10^-2): 75.2602 | Time: 34.91s
2025-07-18 09:57:56,619 - logger.py:50 - Epoch: [203][0/6]	Total Loss: 0.73464	Main MSE (x10^-2): 73.4637	LR: 2.60e-04	EMPP_Raw: 1.41364
2025-07-18 09:58:10,440 - logger.py:50 - Epoch: [203][5/6]	Total Loss: 0.75526	Main MSE (x10^-2): 75.5256	LR: 2.60e-04	EMPP_Raw: 1.45787
2025-07-18 09:58:10,480 - logger.py:50 - Epoch 203 Training Summary: Avg Total Loss: 0.75526, Avg Main MSE: 0.75526, Time: 16.91s
2025-07-18 09:58:28,420 - logger.py:50 - Epoch 203 Summary | Train MSE (x10^-2): 75.5256 | Val MSE (x10^-2): 75.6885 | Time: 34.85s
2025-07-18 09:58:31,586 - logger.py:50 - Epoch: [204][0/6]	Total Loss: 0.76268	Main MSE (x10^-2): 76.2685	LR: 2.59e-04	EMPP_Raw: 1.47457
2025-07-18 09:58:45,304 - logger.py:50 - Epoch: [204][5/6]	Total Loss: 0.75898	Main MSE (x10^-2): 75.8980	LR: 2.59e-04	EMPP_Raw: 1.47101
2025-07-18 09:58:45,346 - logger.py:50 - Epoch 204 Training Summary: Avg Total Loss: 0.75898, Avg Main MSE: 0.75898, Time: 16.92s
2025-07-18 09:59:03,230 - logger.py:50 - Epoch 204 Summary | Train MSE (x10^-2): 75.8980 | Val MSE (x10^-2): 76.5943 | Time: 34.80s
2025-07-18 09:59:06,233 - logger.py:50 - Epoch: [205][0/6]	Total Loss: 0.75076	Main MSE (x10^-2): 75.0756	LR: 2.57e-04	EMPP_Raw: 1.45365
2025-07-18 09:59:20,204 - logger.py:50 - Epoch: [205][5/6]	Total Loss: 0.75248	Main MSE (x10^-2): 75.2482	LR: 2.57e-04	EMPP_Raw: 1.45503
2025-07-18 09:59:20,246 - logger.py:50 - Epoch 205 Training Summary: Avg Total Loss: 0.75248, Avg Main MSE: 0.75248, Time: 17.01s
2025-07-18 09:59:38,086 - logger.py:50 - Epoch 205 Summary | Train MSE (x10^-2): 75.2482 | Val MSE (x10^-2): 78.2351 | Time: 34.85s
2025-07-18 09:59:41,085 - logger.py:50 - Epoch: [206][0/6]	Total Loss: 0.75666	Main MSE (x10^-2): 75.6664	LR: 2.56e-04	EMPP_Raw: 1.46443
2025-07-18 09:59:55,035 - logger.py:50 - Epoch: [206][5/6]	Total Loss: 0.75441	Main MSE (x10^-2): 75.4410	LR: 2.56e-04	EMPP_Raw: 1.45899
2025-07-18 09:59:55,080 - logger.py:50 - Epoch 206 Training Summary: Avg Total Loss: 0.75441, Avg Main MSE: 0.75441, Time: 16.98s
2025-07-18 10:00:13,083 - logger.py:50 - Epoch 206 Summary | Train MSE (x10^-2): 75.4410 | Val MSE (x10^-2): 76.1656 | Time: 34.99s
2025-07-18 10:00:16,078 - logger.py:50 - Epoch: [207][0/6]	Total Loss: 0.77689	Main MSE (x10^-2): 77.6886	LR: 2.55e-04	EMPP_Raw: 1.50408
2025-07-18 10:00:29,874 - logger.py:50 - Epoch: [207][5/6]	Total Loss: 0.76090	Main MSE (x10^-2): 76.0905	LR: 2.55e-04	EMPP_Raw: 1.47155
2025-07-18 10:00:29,915 - logger.py:50 - Epoch 207 Training Summary: Avg Total Loss: 0.76090, Avg Main MSE: 0.76090, Time: 16.82s
2025-07-18 10:00:47,792 - logger.py:50 - Epoch 207 Summary | Train MSE (x10^-2): 76.0905 | Val MSE (x10^-2): 76.4756 | Time: 34.70s
2025-07-18 10:00:50,988 - logger.py:50 - Epoch: [208][0/6]	Total Loss: 0.76572	Main MSE (x10^-2): 76.5719	LR: 2.54e-04	EMPP_Raw: 1.46037
2025-07-18 10:01:04,716 - logger.py:50 - Epoch: [208][5/6]	Total Loss: 0.75797	Main MSE (x10^-2): 75.7975	LR: 2.54e-04	EMPP_Raw: 1.46123
2025-07-18 10:01:04,764 - logger.py:50 - Epoch 208 Training Summary: Avg Total Loss: 0.75797, Avg Main MSE: 0.75797, Time: 16.97s
2025-07-18 10:01:22,659 - logger.py:50 - Epoch 208 Summary | Train MSE (x10^-2): 75.7975 | Val MSE (x10^-2): 79.8380 | Time: 34.86s
2025-07-18 10:01:25,836 - logger.py:50 - Epoch: [209][0/6]	Total Loss: 0.75539	Main MSE (x10^-2): 75.5386	LR: 2.53e-04	EMPP_Raw: 1.46426
2025-07-18 10:01:39,610 - logger.py:50 - Epoch: [209][5/6]	Total Loss: 0.75278	Main MSE (x10^-2): 75.2779	LR: 2.53e-04	EMPP_Raw: 1.45550
2025-07-18 10:01:39,654 - logger.py:50 - Epoch 209 Training Summary: Avg Total Loss: 0.75278, Avg Main MSE: 0.75278, Time: 16.99s
2025-07-18 10:01:57,508 - logger.py:50 - Epoch 209 Summary | Train MSE (x10^-2): 75.2779 | Val MSE (x10^-2): 80.1361 | Time: 34.84s
2025-07-18 10:02:00,537 - logger.py:50 - Epoch: [210][0/6]	Total Loss: 0.74497	Main MSE (x10^-2): 74.4972	LR: 2.51e-04	EMPP_Raw: 1.44138
2025-07-18 10:02:14,444 - logger.py:50 - Epoch: [210][5/6]	Total Loss: 0.75410	Main MSE (x10^-2): 75.4104	LR: 2.51e-04	EMPP_Raw: 1.46207
2025-07-18 10:02:14,485 - logger.py:50 - Epoch 210 Training Summary: Avg Total Loss: 0.75410, Avg Main MSE: 0.75410, Time: 16.97s
2025-07-18 10:02:32,303 - logger.py:50 - Epoch 210 Summary | Train MSE (x10^-2): 75.4104 | Val MSE (x10^-2): 79.7372 | Time: 34.79s
2025-07-18 10:02:35,294 - logger.py:50 - Epoch: [211][0/6]	Total Loss: 0.76215	Main MSE (x10^-2): 76.2150	LR: 2.50e-04	EMPP_Raw: 1.48039
2025-07-18 10:02:49,045 - logger.py:50 - Epoch: [211][5/6]	Total Loss: 0.74727	Main MSE (x10^-2): 74.7272	LR: 2.50e-04	EMPP_Raw: 1.45044
2025-07-18 10:02:49,086 - logger.py:50 - Epoch 211 Training Summary: Avg Total Loss: 0.74727, Avg Main MSE: 0.74727, Time: 16.77s
2025-07-18 10:03:07,185 - logger.py:50 - Epoch 211 Summary | Train MSE (x10^-2): 74.7272 | Val MSE (x10^-2): 79.4314 | Time: 34.88s
2025-07-18 10:03:10,210 - logger.py:50 - Epoch: [212][0/6]	Total Loss: 0.75113	Main MSE (x10^-2): 75.1131	LR: 2.49e-04	EMPP_Raw: 1.46054
2025-07-18 10:03:23,971 - logger.py:50 - Epoch: [212][5/6]	Total Loss: 0.75797	Main MSE (x10^-2): 75.7969	LR: 2.49e-04	EMPP_Raw: 1.46904
2025-07-18 10:03:24,018 - logger.py:50 - Epoch 212 Training Summary: Avg Total Loss: 0.75797, Avg Main MSE: 0.75797, Time: 16.82s
2025-07-18 10:03:42,011 - logger.py:50 - Epoch 212 Summary | Train MSE (x10^-2): 75.7969 | Val MSE (x10^-2): 78.4332 | Time: 34.82s
2025-07-18 10:03:45,201 - logger.py:50 - Epoch: [213][0/6]	Total Loss: 0.75998	Main MSE (x10^-2): 75.9975	LR: 2.48e-04	EMPP_Raw: 1.47253
2025-07-18 10:03:58,969 - logger.py:50 - Epoch: [213][5/6]	Total Loss: 0.76725	Main MSE (x10^-2): 76.7252	LR: 2.48e-04	EMPP_Raw: 1.48604
2025-07-18 10:03:59,017 - logger.py:50 - Epoch 213 Training Summary: Avg Total Loss: 0.76725, Avg Main MSE: 0.76725, Time: 17.00s
2025-07-18 10:04:17,018 - logger.py:50 - Epoch 213 Summary | Train MSE (x10^-2): 76.7252 | Val MSE (x10^-2): 76.5882 | Time: 35.00s
2025-07-18 10:04:20,054 - logger.py:50 - Epoch: [214][0/6]	Total Loss: 0.77303	Main MSE (x10^-2): 77.3027	LR: 2.46e-04	EMPP_Raw: 1.49609
2025-07-18 10:04:33,999 - logger.py:50 - Epoch: [214][5/6]	Total Loss: 0.75821	Main MSE (x10^-2): 75.8213	LR: 2.46e-04	EMPP_Raw: 1.46605
2025-07-18 10:04:34,041 - logger.py:50 - Epoch 214 Training Summary: Avg Total Loss: 0.75821, Avg Main MSE: 0.75821, Time: 17.01s
2025-07-18 10:04:51,935 - logger.py:50 - Epoch 214 Summary | Train MSE (x10^-2): 75.8213 | Val MSE (x10^-2): 78.0690 | Time: 34.91s
2025-07-18 10:04:54,978 - logger.py:50 - Epoch: [215][0/6]	Total Loss: 0.75700	Main MSE (x10^-2): 75.6997	LR: 2.45e-04	EMPP_Raw: 1.46715
2025-07-18 10:05:08,739 - logger.py:50 - Epoch: [215][5/6]	Total Loss: 0.75495	Main MSE (x10^-2): 75.4951	LR: 2.45e-04	EMPP_Raw: 1.46147
2025-07-18 10:05:08,780 - logger.py:50 - Epoch 215 Training Summary: Avg Total Loss: 0.75495, Avg Main MSE: 0.75495, Time: 16.84s
2025-07-18 10:05:26,804 - logger.py:50 - Epoch 215 Summary | Train MSE (x10^-2): 75.4951 | Val MSE (x10^-2): 78.7561 | Time: 34.86s
2025-07-18 10:05:29,799 - logger.py:50 - Epoch: [216][0/6]	Total Loss: 0.76762	Main MSE (x10^-2): 76.7618	LR: 2.44e-04	EMPP_Raw: 1.48133
2025-07-18 10:05:43,634 - logger.py:50 - Epoch: [216][5/6]	Total Loss: 0.76441	Main MSE (x10^-2): 76.4407	LR: 2.44e-04	EMPP_Raw: 1.47856
2025-07-18 10:05:43,676 - logger.py:50 - Epoch 216 Training Summary: Avg Total Loss: 0.76441, Avg Main MSE: 0.76441, Time: 16.86s
2025-07-18 10:06:01,688 - logger.py:50 - Epoch 216 Summary | Train MSE (x10^-2): 76.4407 | Val MSE (x10^-2): 79.1216 | Time: 34.88s
2025-07-18 10:06:04,683 - logger.py:50 - Epoch: [217][0/6]	Total Loss: 0.75782	Main MSE (x10^-2): 75.7817	LR: 2.43e-04	EMPP_Raw: 1.46768
2025-07-18 10:06:18,429 - logger.py:50 - Epoch: [217][5/6]	Total Loss: 0.76021	Main MSE (x10^-2): 76.0214	LR: 2.43e-04	EMPP_Raw: 1.47237
2025-07-18 10:06:18,469 - logger.py:50 - Epoch 217 Training Summary: Avg Total Loss: 0.76021, Avg Main MSE: 0.76021, Time: 16.77s
2025-07-18 10:06:36,354 - logger.py:50 - Epoch 217 Summary | Train MSE (x10^-2): 76.0214 | Val MSE (x10^-2): 76.6808 | Time: 34.66s
2025-07-18 10:06:39,736 - logger.py:50 - Epoch: [218][0/6]	Total Loss: 0.76418	Main MSE (x10^-2): 76.4181	LR: 2.42e-04	EMPP_Raw: 1.48462
2025-07-18 10:06:53,513 - logger.py:50 - Epoch: [218][5/6]	Total Loss: 0.75899	Main MSE (x10^-2): 75.8991	LR: 2.42e-04	EMPP_Raw: 1.47328
2025-07-18 10:06:53,563 - logger.py:50 - Epoch 218 Training Summary: Avg Total Loss: 0.75899, Avg Main MSE: 0.75899, Time: 17.20s
2025-07-18 10:07:11,502 - logger.py:50 - Epoch 218 Summary | Train MSE (x10^-2): 75.8991 | Val MSE (x10^-2): 77.9069 | Time: 35.14s
2025-07-18 10:07:14,710 - logger.py:50 - Epoch: [219][0/6]	Total Loss: 0.77336	Main MSE (x10^-2): 77.3362	LR: 2.40e-04	EMPP_Raw: 1.49652
2025-07-18 10:07:28,503 - logger.py:50 - Epoch: [219][5/6]	Total Loss: 0.74647	Main MSE (x10^-2): 74.6475	LR: 2.40e-04	EMPP_Raw: 1.44734
2025-07-18 10:07:28,549 - logger.py:50 - Epoch 219 Training Summary: Avg Total Loss: 0.74647, Avg Main MSE: 0.74647, Time: 17.04s
2025-07-18 10:07:46,477 - logger.py:50 - Epoch 219 Summary | Train MSE (x10^-2): 74.6475 | Val MSE (x10^-2): 77.5155 | Time: 34.97s
2025-07-18 10:07:49,469 - logger.py:50 - Epoch: [220][0/6]	Total Loss: 0.73919	Main MSE (x10^-2): 73.9193	LR: 2.39e-04	EMPP_Raw: 1.43531
2025-07-18 10:08:03,416 - logger.py:50 - Epoch: [220][5/6]	Total Loss: 0.74567	Main MSE (x10^-2): 74.5671	LR: 2.39e-04	EMPP_Raw: 1.44789
2025-07-18 10:08:03,456 - logger.py:50 - Epoch 220 Training Summary: Avg Total Loss: 0.74567, Avg Main MSE: 0.74567, Time: 16.97s
2025-07-18 10:08:21,704 - logger.py:50 - Epoch 220 Summary | Train MSE (x10^-2): 74.5671 | Val MSE (x10^-2): 77.4723 | Time: 35.22s
2025-07-18 10:08:24,709 - logger.py:50 - Epoch: [221][0/6]	Total Loss: 0.74428	Main MSE (x10^-2): 74.4275	LR: 2.38e-04	EMPP_Raw: 1.44710
2025-07-18 10:08:38,613 - logger.py:50 - Epoch: [221][5/6]	Total Loss: 0.75226	Main MSE (x10^-2): 75.2261	LR: 2.38e-04	EMPP_Raw: 1.46016
2025-07-18 10:08:38,657 - logger.py:50 - Epoch 221 Training Summary: Avg Total Loss: 0.75226, Avg Main MSE: 0.75226, Time: 16.94s
2025-07-18 10:08:56,807 - logger.py:50 - Epoch 221 Summary | Train MSE (x10^-2): 75.2261 | Val MSE (x10^-2): 78.2757 | Time: 35.10s
2025-07-18 10:08:59,856 - logger.py:50 - Epoch: [222][0/6]	Total Loss: 0.75810	Main MSE (x10^-2): 75.8099	LR: 2.37e-04	EMPP_Raw: 1.47368
2025-07-18 10:09:13,612 - logger.py:50 - Epoch: [222][5/6]	Total Loss: 0.75807	Main MSE (x10^-2): 75.8067	LR: 2.37e-04	EMPP_Raw: 1.47199
2025-07-18 10:09:13,658 - logger.py:50 - Epoch 222 Training Summary: Avg Total Loss: 0.75807, Avg Main MSE: 0.75807, Time: 16.84s
2025-07-18 10:09:31,809 - logger.py:50 - Epoch 222 Summary | Train MSE (x10^-2): 75.8067 | Val MSE (x10^-2): 76.9092 | Time: 35.00s
2025-07-18 10:09:34,815 - logger.py:50 - Epoch: [223][0/6]	Total Loss: 0.72594	Main MSE (x10^-2): 72.5941	LR: 2.35e-04	EMPP_Raw: 1.41329
2025-07-18 10:09:48,654 - logger.py:50 - Epoch: [223][5/6]	Total Loss: 0.73887	Main MSE (x10^-2): 73.8869	LR: 2.35e-04	EMPP_Raw: 1.43703
2025-07-18 10:09:48,698 - logger.py:50 - Epoch 223 Training Summary: Avg Total Loss: 0.73887, Avg Main MSE: 0.73887, Time: 16.88s
2025-07-18 10:10:06,620 - logger.py:50 - Epoch 223 Summary | Train MSE (x10^-2): 73.8869 | Val MSE (x10^-2): 75.9419 | Time: 34.80s
2025-07-18 10:10:09,792 - logger.py:50 - Epoch: [224][0/6]	Total Loss: 0.74581	Main MSE (x10^-2): 74.5807	LR: 2.34e-04	EMPP_Raw: 1.45136
2025-07-18 10:10:23,540 - logger.py:50 - Epoch: [224][5/6]	Total Loss: 0.74417	Main MSE (x10^-2): 74.4170	LR: 2.34e-04	EMPP_Raw: 1.44814
2025-07-18 10:10:23,586 - logger.py:50 - Epoch 224 Training Summary: Avg Total Loss: 0.74417, Avg Main MSE: 0.74417, Time: 16.96s
2025-07-18 10:10:41,719 - logger.py:50 - Epoch 224 Summary | Train MSE (x10^-2): 74.4170 | Val MSE (x10^-2): 78.0168 | Time: 35.09s
2025-07-18 10:10:44,737 - logger.py:50 - Epoch: [225][0/6]	Total Loss: 0.73416	Main MSE (x10^-2): 73.4165	LR: 2.33e-04	EMPP_Raw: 1.43068
2025-07-18 10:10:58,667 - logger.py:50 - Epoch: [225][5/6]	Total Loss: 0.75903	Main MSE (x10^-2): 75.9033	LR: 2.33e-04	EMPP_Raw: 1.47734
2025-07-18 10:10:58,710 - logger.py:50 - Epoch 225 Training Summary: Avg Total Loss: 0.75903, Avg Main MSE: 0.75903, Time: 16.98s
2025-07-18 10:11:16,708 - logger.py:50 - Epoch 225 Summary | Train MSE (x10^-2): 75.9033 | Val MSE (x10^-2): 78.3690 | Time: 34.98s
2025-07-18 10:11:19,711 - logger.py:50 - Epoch: [226][0/6]	Total Loss: 0.77276	Main MSE (x10^-2): 77.2763	LR: 2.32e-04	EMPP_Raw: 1.50890
2025-07-18 10:11:33,661 - logger.py:50 - Epoch: [226][5/6]	Total Loss: 0.75122	Main MSE (x10^-2): 75.1219	LR: 2.32e-04	EMPP_Raw: 1.46320
2025-07-18 10:11:33,708 - logger.py:50 - Epoch 226 Training Summary: Avg Total Loss: 0.75122, Avg Main MSE: 0.75122, Time: 16.99s
2025-07-18 10:11:51,635 - logger.py:50 - Epoch 226 Summary | Train MSE (x10^-2): 75.1219 | Val MSE (x10^-2): 77.3474 | Time: 34.92s
2025-07-18 10:11:54,667 - logger.py:50 - Epoch: [227][0/6]	Total Loss: 0.76860	Main MSE (x10^-2): 76.8596	LR: 2.30e-04	EMPP_Raw: 1.49173
2025-07-18 10:12:08,497 - logger.py:50 - Epoch: [227][5/6]	Total Loss: 0.75306	Main MSE (x10^-2): 75.3061	LR: 2.30e-04	EMPP_Raw: 1.45946
2025-07-18 10:12:08,542 - logger.py:50 - Epoch 227 Training Summary: Avg Total Loss: 0.75306, Avg Main MSE: 0.75306, Time: 16.90s
2025-07-18 10:12:26,504 - logger.py:50 - Epoch 227 Summary | Train MSE (x10^-2): 75.3061 | Val MSE (x10^-2): 77.5849 | Time: 34.86s
2025-07-18 10:12:29,678 - logger.py:50 - Epoch: [228][0/6]	Total Loss: 0.77392	Main MSE (x10^-2): 77.3922	LR: 2.29e-04	EMPP_Raw: 1.50134
2025-07-18 10:12:43,457 - logger.py:50 - Epoch: [228][5/6]	Total Loss: 0.75422	Main MSE (x10^-2): 75.4221	LR: 2.29e-04	EMPP_Raw: 1.46637
2025-07-18 10:12:43,504 - logger.py:50 - Epoch 228 Training Summary: Avg Total Loss: 0.75422, Avg Main MSE: 0.75422, Time: 16.99s
2025-07-18 10:13:01,436 - logger.py:50 - Epoch 228 Summary | Train MSE (x10^-2): 75.4221 | Val MSE (x10^-2): 78.1778 | Time: 34.93s
2025-07-18 10:13:04,610 - logger.py:50 - Epoch: [229][0/6]	Total Loss: 0.76594	Main MSE (x10^-2): 76.5944	LR: 2.28e-04	EMPP_Raw: 1.49279
2025-07-18 10:13:18,406 - logger.py:50 - Epoch: [229][5/6]	Total Loss: 0.75189	Main MSE (x10^-2): 75.1887	LR: 2.28e-04	EMPP_Raw: 1.46146
2025-07-18 10:13:18,443 - logger.py:50 - Epoch 229 Training Summary: Avg Total Loss: 0.75189, Avg Main MSE: 0.75189, Time: 17.00s
2025-07-18 10:13:36,368 - logger.py:50 - Epoch 229 Summary | Train MSE (x10^-2): 75.1887 | Val MSE (x10^-2): 77.0689 | Time: 34.93s
2025-07-18 10:13:39,381 - logger.py:50 - Epoch: [230][0/6]	Total Loss: 0.74893	Main MSE (x10^-2): 74.8925	LR: 2.27e-04	EMPP_Raw: 1.45164
2025-07-18 10:13:53,414 - logger.py:50 - Epoch: [230][5/6]	Total Loss: 0.75368	Main MSE (x10^-2): 75.3683	LR: 2.27e-04	EMPP_Raw: 1.46434
2025-07-18 10:13:53,456 - logger.py:50 - Epoch 230 Training Summary: Avg Total Loss: 0.75368, Avg Main MSE: 0.75368, Time: 17.08s
2025-07-18 10:14:11,333 - logger.py:50 - Epoch 230 Summary | Train MSE (x10^-2): 75.3683 | Val MSE (x10^-2): 80.3722 | Time: 34.96s
2025-07-18 10:14:14,340 - logger.py:50 - Epoch: [231][0/6]	Total Loss: 0.76476	Main MSE (x10^-2): 76.4758	LR: 2.26e-04	EMPP_Raw: 1.48771
2025-07-18 10:14:28,122 - logger.py:50 - Epoch: [231][5/6]	Total Loss: 0.75063	Main MSE (x10^-2): 75.0633	LR: 2.26e-04	EMPP_Raw: 1.46067
2025-07-18 10:14:28,167 - logger.py:50 - Epoch 231 Training Summary: Avg Total Loss: 0.75063, Avg Main MSE: 0.75063, Time: 16.82s
2025-07-18 10:14:46,351 - logger.py:50 - Epoch 231 Summary | Train MSE (x10^-2): 75.0633 | Val MSE (x10^-2): 79.0793 | Time: 35.01s
2025-07-18 10:14:49,352 - logger.py:50 - Epoch: [232][0/6]	Total Loss: 0.75151	Main MSE (x10^-2): 75.1515	LR: 2.24e-04	EMPP_Raw: 1.46638
2025-07-18 10:15:03,222 - logger.py:50 - Epoch: [232][5/6]	Total Loss: 0.75041	Main MSE (x10^-2): 75.0414	LR: 2.24e-04	EMPP_Raw: 1.46007
2025-07-18 10:15:03,265 - logger.py:50 - Epoch 232 Training Summary: Avg Total Loss: 0.75041, Avg Main MSE: 0.75041, Time: 16.90s
2025-07-18 10:15:21,302 - logger.py:50 - Epoch 232 Summary | Train MSE (x10^-2): 75.0414 | Val MSE (x10^-2): 78.7210 | Time: 34.94s
2025-07-18 10:15:24,474 - logger.py:50 - Epoch: [233][0/6]	Total Loss: 0.75983	Main MSE (x10^-2): 75.9830	LR: 2.23e-04	EMPP_Raw: 1.47934
2025-07-18 10:15:38,325 - logger.py:50 - Epoch: [233][5/6]	Total Loss: 0.75046	Main MSE (x10^-2): 75.0458	LR: 2.23e-04	EMPP_Raw: 1.45907
2025-07-18 10:15:38,376 - logger.py:50 - Epoch 233 Training Summary: Avg Total Loss: 0.75046, Avg Main MSE: 0.75046, Time: 17.06s
2025-07-18 10:15:56,289 - logger.py:50 - Epoch 233 Summary | Train MSE (x10^-2): 75.0458 | Val MSE (x10^-2): 77.2242 | Time: 34.98s
2025-07-18 10:15:59,296 - logger.py:50 - Epoch: [234][0/6]	Total Loss: 0.74374	Main MSE (x10^-2): 74.3743	LR: 2.22e-04	EMPP_Raw: 1.44279
2025-07-18 10:16:13,262 - logger.py:50 - Epoch: [234][5/6]	Total Loss: 0.74820	Main MSE (x10^-2): 74.8198	LR: 2.22e-04	EMPP_Raw: 1.45147
2025-07-18 10:16:13,306 - logger.py:50 - Epoch 234 Training Summary: Avg Total Loss: 0.74820, Avg Main MSE: 0.74820, Time: 17.01s
2025-07-18 10:16:31,287 - logger.py:50 - Epoch 234 Summary | Train MSE (x10^-2): 74.8198 | Val MSE (x10^-2): 78.2915 | Time: 34.99s
2025-07-18 10:16:34,367 - logger.py:50 - Epoch: [235][0/6]	Total Loss: 0.72850	Main MSE (x10^-2): 72.8501	LR: 2.21e-04	EMPP_Raw: 1.41597
2025-07-18 10:16:48,197 - logger.py:50 - Epoch: [235][5/6]	Total Loss: 0.75078	Main MSE (x10^-2): 75.0778	LR: 2.21e-04	EMPP_Raw: 1.46011
2025-07-18 10:16:48,240 - logger.py:50 - Epoch 235 Training Summary: Avg Total Loss: 0.75078, Avg Main MSE: 0.75078, Time: 16.94s
2025-07-18 10:17:06,379 - logger.py:50 - Epoch 235 Summary | Train MSE (x10^-2): 75.0778 | Val MSE (x10^-2): 80.6926 | Time: 35.09s
2025-07-18 10:17:09,380 - logger.py:50 - Epoch: [236][0/6]	Total Loss: 0.77965	Main MSE (x10^-2): 77.9651	LR: 2.19e-04	EMPP_Raw: 1.51969
2025-07-18 10:17:23,200 - logger.py:50 - Epoch: [236][5/6]	Total Loss: 0.76240	Main MSE (x10^-2): 76.2398	LR: 2.19e-04	EMPP_Raw: 1.48423
2025-07-18 10:17:23,240 - logger.py:50 - Epoch 236 Training Summary: Avg Total Loss: 0.76240, Avg Main MSE: 0.76240, Time: 16.85s
2025-07-18 10:17:41,345 - logger.py:50 - Epoch 236 Summary | Train MSE (x10^-2): 76.2398 | Val MSE (x10^-2): 79.7855 | Time: 34.96s
2025-07-18 10:17:44,352 - logger.py:50 - Epoch: [237][0/6]	Total Loss: 0.75708	Main MSE (x10^-2): 75.7078	LR: 2.18e-04	EMPP_Raw: 1.47774
2025-07-18 10:17:58,136 - logger.py:50 - Epoch: [237][5/6]	Total Loss: 0.75355	Main MSE (x10^-2): 75.3547	LR: 2.18e-04	EMPP_Raw: 1.46931
2025-07-18 10:17:58,183 - logger.py:50 - Epoch 237 Training Summary: Avg Total Loss: 0.75355, Avg Main MSE: 0.75355, Time: 16.83s
2025-07-18 10:18:16,085 - logger.py:50 - Epoch 237 Summary | Train MSE (x10^-2): 75.3547 | Val MSE (x10^-2): 80.7790 | Time: 34.73s
2025-07-18 10:18:19,545 - logger.py:50 - Epoch: [238][0/6]	Total Loss: 0.75360	Main MSE (x10^-2): 75.3600	LR: 2.17e-04	EMPP_Raw: 1.46911
2025-07-18 10:18:33,319 - logger.py:50 - Epoch: [238][5/6]	Total Loss: 0.75914	Main MSE (x10^-2): 75.9144	LR: 2.17e-04	EMPP_Raw: 1.47970
2025-07-18 10:18:33,369 - logger.py:50 - Epoch 238 Training Summary: Avg Total Loss: 0.75914, Avg Main MSE: 0.75914, Time: 17.27s
2025-07-18 10:18:51,722 - logger.py:50 - Epoch 238 Summary | Train MSE (x10^-2): 75.9144 | Val MSE (x10^-2): 80.2579 | Time: 35.63s
2025-07-18 10:18:54,968 - logger.py:50 - Epoch: [239][0/6]	Total Loss: 0.77603	Main MSE (x10^-2): 77.6033	LR: 2.16e-04	EMPP_Raw: 1.51063
2025-07-18 10:19:08,810 - logger.py:50 - Epoch: [239][5/6]	Total Loss: 0.75749	Main MSE (x10^-2): 75.7491	LR: 2.16e-04	EMPP_Raw: 1.47418
2025-07-18 10:19:08,859 - logger.py:50 - Epoch 239 Training Summary: Avg Total Loss: 0.75749, Avg Main MSE: 0.75749, Time: 17.13s
2025-07-18 10:19:26,838 - logger.py:50 - Epoch 239 Summary | Train MSE (x10^-2): 75.7491 | Val MSE (x10^-2): 78.8849 | Time: 35.11s
2025-07-18 10:19:29,892 - logger.py:50 - Epoch: [240][0/6]	Total Loss: 0.74246	Main MSE (x10^-2): 74.2457	LR: 2.14e-04	EMPP_Raw: 1.43773
2025-07-18 10:19:43,938 - logger.py:50 - Epoch: [240][5/6]	Total Loss: 0.75417	Main MSE (x10^-2): 75.4172	LR: 2.14e-04	EMPP_Raw: 1.46921
2025-07-18 10:19:43,977 - logger.py:50 - Epoch 240 Training Summary: Avg Total Loss: 0.75417, Avg Main MSE: 0.75417, Time: 17.13s
2025-07-18 10:20:01,893 - logger.py:50 - Epoch 240 Summary | Train MSE (x10^-2): 75.4172 | Val MSE (x10^-2): 79.2861 | Time: 35.05s
2025-07-18 10:20:04,898 - logger.py:50 - Epoch: [241][0/6]	Total Loss: 0.76245	Main MSE (x10^-2): 76.2451	LR: 2.13e-04	EMPP_Raw: 1.48356
2025-07-18 10:20:18,725 - logger.py:50 - Epoch: [241][5/6]	Total Loss: 0.75438	Main MSE (x10^-2): 75.4381	LR: 2.13e-04	EMPP_Raw: 1.47048
2025-07-18 10:20:18,766 - logger.py:50 - Epoch 241 Training Summary: Avg Total Loss: 0.75438, Avg Main MSE: 0.75438, Time: 16.86s
2025-07-18 10:20:36,870 - logger.py:50 - Epoch 241 Summary | Train MSE (x10^-2): 75.4381 | Val MSE (x10^-2): 79.8710 | Time: 34.97s
2025-07-18 10:20:39,902 - logger.py:50 - Epoch: [242][0/6]	Total Loss: 0.74896	Main MSE (x10^-2): 74.8962	LR: 2.12e-04	EMPP_Raw: 1.46111
2025-07-18 10:20:53,704 - logger.py:50 - Epoch: [242][5/6]	Total Loss: 0.74835	Main MSE (x10^-2): 74.8354	LR: 2.12e-04	EMPP_Raw: 1.45896
2025-07-18 10:20:53,741 - logger.py:50 - Epoch 242 Training Summary: Avg Total Loss: 0.74835, Avg Main MSE: 0.74835, Time: 16.86s
2025-07-18 10:21:11,848 - logger.py:50 - Epoch 242 Summary | Train MSE (x10^-2): 74.8354 | Val MSE (x10^-2): 80.4417 | Time: 34.97s
2025-07-18 10:21:14,866 - logger.py:50 - Epoch: [243][0/6]	Total Loss: 0.74252	Main MSE (x10^-2): 74.2516	LR: 2.11e-04	EMPP_Raw: 1.44162
2025-07-18 10:21:28,658 - logger.py:50 - Epoch: [243][5/6]	Total Loss: 0.75925	Main MSE (x10^-2): 75.9251	LR: 2.11e-04	EMPP_Raw: 1.47856
2025-07-18 10:21:28,700 - logger.py:50 - Epoch 243 Training Summary: Avg Total Loss: 0.75925, Avg Main MSE: 0.75925, Time: 16.84s
2025-07-18 10:21:46,606 - logger.py:50 - Epoch 243 Summary | Train MSE (x10^-2): 75.9251 | Val MSE (x10^-2): 79.2398 | Time: 34.75s
2025-07-18 10:21:49,798 - logger.py:50 - Epoch: [244][0/6]	Total Loss: 0.75992	Main MSE (x10^-2): 75.9916	LR: 2.09e-04	EMPP_Raw: 1.48233
2025-07-18 10:22:03,604 - logger.py:50 - Epoch: [244][5/6]	Total Loss: 0.74756	Main MSE (x10^-2): 74.7557	LR: 2.09e-04	EMPP_Raw: 1.45529
2025-07-18 10:22:03,649 - logger.py:50 - Epoch 244 Training Summary: Avg Total Loss: 0.74756, Avg Main MSE: 0.74756, Time: 17.03s
2025-07-18 10:22:21,545 - logger.py:50 - Epoch 244 Summary | Train MSE (x10^-2): 74.7557 | Val MSE (x10^-2): 77.5715 | Time: 34.93s
2025-07-18 10:22:24,600 - logger.py:50 - Epoch: [245][0/6]	Total Loss: 0.74966	Main MSE (x10^-2): 74.9661	LR: 2.08e-04	EMPP_Raw: 1.46602
2025-07-18 10:22:38,523 - logger.py:50 - Epoch: [245][5/6]	Total Loss: 0.74942	Main MSE (x10^-2): 74.9422	LR: 2.08e-04	EMPP_Raw: 1.46104
2025-07-18 10:22:38,570 - logger.py:50 - Epoch 245 Training Summary: Avg Total Loss: 0.74942, Avg Main MSE: 0.74942, Time: 17.01s
2025-07-18 10:22:56,533 - logger.py:50 - Epoch 245 Summary | Train MSE (x10^-2): 74.9422 | Val MSE (x10^-2): 77.7924 | Time: 34.98s
2025-07-18 10:22:59,580 - logger.py:50 - Epoch: [246][0/6]	Total Loss: 0.74947	Main MSE (x10^-2): 74.9469	LR: 2.07e-04	EMPP_Raw: 1.46397
2025-07-18 10:23:13,533 - logger.py:50 - Epoch: [246][5/6]	Total Loss: 0.74990	Main MSE (x10^-2): 74.9904	LR: 2.07e-04	EMPP_Raw: 1.46372
2025-07-18 10:23:13,579 - logger.py:50 - Epoch 246 Training Summary: Avg Total Loss: 0.74990, Avg Main MSE: 0.74990, Time: 17.04s
2025-07-18 10:23:31,479 - logger.py:50 - Epoch 246 Summary | Train MSE (x10^-2): 74.9904 | Val MSE (x10^-2): 77.6086 | Time: 34.94s
2025-07-18 10:23:34,485 - logger.py:50 - Epoch: [247][0/6]	Total Loss: 0.76892	Main MSE (x10^-2): 76.8916	LR: 2.06e-04	EMPP_Raw: 1.50563
2025-07-18 10:23:48,312 - logger.py:50 - Epoch: [247][5/6]	Total Loss: 0.75561	Main MSE (x10^-2): 75.5615	LR: 2.06e-04	EMPP_Raw: 1.47533
2025-07-18 10:23:48,356 - logger.py:50 - Epoch 247 Training Summary: Avg Total Loss: 0.75561, Avg Main MSE: 0.75561, Time: 16.87s
2025-07-18 10:24:06,245 - logger.py:50 - Epoch 247 Summary | Train MSE (x10^-2): 75.5615 | Val MSE (x10^-2): 78.2254 | Time: 34.76s
2025-07-18 10:24:09,457 - logger.py:50 - Epoch: [248][0/6]	Total Loss: 0.73224	Main MSE (x10^-2): 73.2240	LR: 2.04e-04	EMPP_Raw: 1.43051
2025-07-18 10:24:23,222 - logger.py:50 - Epoch: [248][5/6]	Total Loss: 0.74490	Main MSE (x10^-2): 74.4895	LR: 2.04e-04	EMPP_Raw: 1.45105
2025-07-18 10:24:23,262 - logger.py:50 - Epoch 248 Training Summary: Avg Total Loss: 0.74490, Avg Main MSE: 0.74490, Time: 17.01s
2025-07-18 10:24:41,124 - logger.py:50 - Epoch 248 Summary | Train MSE (x10^-2): 74.4895 | Val MSE (x10^-2): 76.9927 | Time: 34.87s
2025-07-18 10:24:44,312 - logger.py:50 - Epoch: [249][0/6]	Total Loss: 0.75010	Main MSE (x10^-2): 75.0100	LR: 2.03e-04	EMPP_Raw: 1.46307
2025-07-18 10:24:58,043 - logger.py:50 - Epoch: [249][5/6]	Total Loss: 0.75082	Main MSE (x10^-2): 75.0823	LR: 2.03e-04	EMPP_Raw: 1.46465
2025-07-18 10:24:58,088 - logger.py:50 - Epoch 249 Training Summary: Avg Total Loss: 0.75082, Avg Main MSE: 0.75082, Time: 16.96s
2025-07-18 10:25:15,947 - logger.py:50 - Epoch 249 Summary | Train MSE (x10^-2): 75.0823 | Val MSE (x10^-2): 77.4226 | Time: 34.82s
2025-07-18 10:25:18,956 - logger.py:50 - Epoch: [250][0/6]	Total Loss: 0.75331	Main MSE (x10^-2): 75.3309	LR: 2.02e-04	EMPP_Raw: 1.47312
2025-07-18 10:25:32,873 - logger.py:50 - Epoch: [250][5/6]	Total Loss: 0.75136	Main MSE (x10^-2): 75.1361	LR: 2.02e-04	EMPP_Raw: 1.46492
2025-07-18 10:25:32,917 - logger.py:50 - Epoch 250 Training Summary: Avg Total Loss: 0.75136, Avg Main MSE: 0.75136, Time: 16.96s
2025-07-18 10:25:50,913 - logger.py:50 - Epoch 250 Summary | Train MSE (x10^-2): 75.1361 | Val MSE (x10^-2): 80.0787 | Time: 34.96s
2025-07-18 10:25:53,921 - logger.py:50 - Epoch: [251][0/6]	Total Loss: 0.77233	Main MSE (x10^-2): 77.2328	LR: 2.00e-04	EMPP_Raw: 1.50978
2025-07-18 10:26:07,724 - logger.py:50 - Epoch: [251][5/6]	Total Loss: 0.75476	Main MSE (x10^-2): 75.4761	LR: 2.00e-04	EMPP_Raw: 1.47443
2025-07-18 10:26:07,766 - logger.py:50 - Epoch 251 Training Summary: Avg Total Loss: 0.75476, Avg Main MSE: 0.75476, Time: 16.84s
2025-07-18 10:26:25,858 - logger.py:50 - Epoch 251 Summary | Train MSE (x10^-2): 75.4761 | Val MSE (x10^-2): 79.5609 | Time: 34.94s
2025-07-18 10:26:28,859 - logger.py:50 - Epoch: [252][0/6]	Total Loss: 0.74627	Main MSE (x10^-2): 74.6265	LR: 1.99e-04	EMPP_Raw: 1.46046
2025-07-18 10:26:42,658 - logger.py:50 - Epoch: [252][5/6]	Total Loss: 0.74287	Main MSE (x10^-2): 74.2867	LR: 1.99e-04	EMPP_Raw: 1.45267
2025-07-18 10:26:42,699 - logger.py:50 - Epoch 252 Training Summary: Avg Total Loss: 0.74287, Avg Main MSE: 0.74287, Time: 16.83s
2025-07-18 10:27:00,642 - logger.py:50 - Epoch 252 Summary | Train MSE (x10^-2): 74.2867 | Val MSE (x10^-2): 80.4183 | Time: 34.78s
2025-07-18 10:27:03,843 - logger.py:50 - Epoch: [253][0/6]	Total Loss: 0.74109	Main MSE (x10^-2): 74.1094	LR: 1.98e-04	EMPP_Raw: 1.44492
2025-07-18 10:27:17,622 - logger.py:50 - Epoch: [253][5/6]	Total Loss: 0.75223	Main MSE (x10^-2): 75.2228	LR: 1.98e-04	EMPP_Raw: 1.47049
2025-07-18 10:27:17,666 - logger.py:50 - Epoch 253 Training Summary: Avg Total Loss: 0.75223, Avg Main MSE: 0.75223, Time: 17.02s
2025-07-18 10:27:35,598 - logger.py:50 - Epoch 253 Summary | Train MSE (x10^-2): 75.2228 | Val MSE (x10^-2): 78.6925 | Time: 34.95s
2025-07-18 10:27:38,591 - logger.py:50 - Epoch: [254][0/6]	Total Loss: 0.73535	Main MSE (x10^-2): 73.5346	LR: 1.97e-04	EMPP_Raw: 1.43584
2025-07-18 10:27:52,532 - logger.py:50 - Epoch: [254][5/6]	Total Loss: 0.75061	Main MSE (x10^-2): 75.0607	LR: 1.97e-04	EMPP_Raw: 1.46687
2025-07-18 10:27:52,577 - logger.py:50 - Epoch 254 Training Summary: Avg Total Loss: 0.75061, Avg Main MSE: 0.75061, Time: 16.97s
2025-07-18 10:28:10,451 - logger.py:50 - Epoch 254 Summary | Train MSE (x10^-2): 75.0607 | Val MSE (x10^-2): 79.0459 | Time: 34.85s
2025-07-18 10:28:13,483 - logger.py:50 - Epoch: [255][0/6]	Total Loss: 0.74083	Main MSE (x10^-2): 74.0830	LR: 1.95e-04	EMPP_Raw: 1.45172
2025-07-18 10:28:27,255 - logger.py:50 - Epoch: [255][5/6]	Total Loss: 0.73959	Main MSE (x10^-2): 73.9587	LR: 1.95e-04	EMPP_Raw: 1.44660
2025-07-18 10:28:27,300 - logger.py:50 - Epoch 255 Training Summary: Avg Total Loss: 0.73959, Avg Main MSE: 0.73959, Time: 16.84s
2025-07-18 10:28:45,368 - logger.py:50 - Epoch 255 Summary | Train MSE (x10^-2): 73.9587 | Val MSE (x10^-2): 78.8342 | Time: 34.91s
2025-07-18 10:28:48,434 - logger.py:50 - Epoch: [256][0/6]	Total Loss: 0.75390	Main MSE (x10^-2): 75.3900	LR: 1.94e-04	EMPP_Raw: 1.47760
2025-07-18 10:29:02,287 - logger.py:50 - Epoch: [256][5/6]	Total Loss: 0.73897	Main MSE (x10^-2): 73.8967	LR: 1.94e-04	EMPP_Raw: 1.44542
2025-07-18 10:29:02,334 - logger.py:50 - Epoch 256 Training Summary: Avg Total Loss: 0.73897, Avg Main MSE: 0.73897, Time: 16.96s
2025-07-18 10:29:20,407 - logger.py:50 - Epoch 256 Summary | Train MSE (x10^-2): 73.8967 | Val MSE (x10^-2): 77.7007 | Time: 35.03s
2025-07-18 10:29:23,413 - logger.py:50 - Epoch: [257][0/6]	Total Loss: 0.76381	Main MSE (x10^-2): 76.3806	LR: 1.93e-04	EMPP_Raw: 1.49246
2025-07-18 10:29:37,176 - logger.py:50 - Epoch: [257][5/6]	Total Loss: 0.75467	Main MSE (x10^-2): 75.4671	LR: 1.93e-04	EMPP_Raw: 1.47412
2025-07-18 10:29:37,220 - logger.py:50 - Epoch 257 Training Summary: Avg Total Loss: 0.75467, Avg Main MSE: 0.75467, Time: 16.80s
2025-07-18 10:29:55,065 - logger.py:50 - Epoch 257 Summary | Train MSE (x10^-2): 75.4671 | Val MSE (x10^-2): 79.4513 | Time: 34.65s
2025-07-18 10:29:58,389 - logger.py:50 - Epoch: [258][0/6]	Total Loss: 0.74667	Main MSE (x10^-2): 74.6667	LR: 1.92e-04	EMPP_Raw: 1.46349
2025-07-18 10:30:12,120 - logger.py:50 - Epoch: [258][5/6]	Total Loss: 0.74720	Main MSE (x10^-2): 74.7200	LR: 1.92e-04	EMPP_Raw: 1.45976
2025-07-18 10:30:12,172 - logger.py:50 - Epoch 258 Training Summary: Avg Total Loss: 0.74720, Avg Main MSE: 0.74720, Time: 17.10s
2025-07-18 10:30:30,114 - logger.py:50 - Epoch 258 Summary | Train MSE (x10^-2): 74.7200 | Val MSE (x10^-2): 77.4514 | Time: 35.05s
2025-07-18 10:30:33,324 - logger.py:50 - Epoch: [259][0/6]	Total Loss: 0.75982	Main MSE (x10^-2): 75.9817	LR: 1.90e-04	EMPP_Raw: 1.48636
2025-07-18 10:30:47,083 - logger.py:50 - Epoch: [259][5/6]	Total Loss: 0.75016	Main MSE (x10^-2): 75.0164	LR: 1.90e-04	EMPP_Raw: 1.46637
2025-07-18 10:30:47,127 - logger.py:50 - Epoch 259 Training Summary: Avg Total Loss: 0.75016, Avg Main MSE: 0.75016, Time: 17.00s
2025-07-18 10:31:05,014 - logger.py:50 - Epoch 259 Summary | Train MSE (x10^-2): 75.0164 | Val MSE (x10^-2): 78.1367 | Time: 34.89s
2025-07-18 10:31:08,049 - logger.py:50 - Epoch: [260][0/6]	Total Loss: 0.73546	Main MSE (x10^-2): 73.5462	LR: 1.89e-04	EMPP_Raw: 1.43709
2025-07-18 10:31:21,996 - logger.py:50 - Epoch: [260][5/6]	Total Loss: 0.74973	Main MSE (x10^-2): 74.9734	LR: 1.89e-04	EMPP_Raw: 1.46498
2025-07-18 10:31:22,038 - logger.py:50 - Epoch 260 Training Summary: Avg Total Loss: 0.74973, Avg Main MSE: 0.74973, Time: 17.01s
2025-07-18 10:31:39,845 - logger.py:50 - Epoch 260 Summary | Train MSE (x10^-2): 74.9734 | Val MSE (x10^-2): 78.9318 | Time: 34.82s
2025-07-18 10:31:42,831 - logger.py:50 - Epoch: [261][0/6]	Total Loss: 0.74127	Main MSE (x10^-2): 74.1269	LR: 1.88e-04	EMPP_Raw: 1.44682
2025-07-18 10:31:56,608 - logger.py:50 - Epoch: [261][5/6]	Total Loss: 0.73863	Main MSE (x10^-2): 73.8633	LR: 1.88e-04	EMPP_Raw: 1.44285
2025-07-18 10:31:56,656 - logger.py:50 - Epoch 261 Training Summary: Avg Total Loss: 0.73863, Avg Main MSE: 0.73863, Time: 16.80s
2025-07-18 10:32:14,739 - logger.py:50 - Epoch 261 Summary | Train MSE (x10^-2): 73.8633 | Val MSE (x10^-2): 79.0449 | Time: 34.89s
2025-07-18 10:32:17,742 - logger.py:50 - Epoch: [262][0/6]	Total Loss: 0.74799	Main MSE (x10^-2): 74.7987	LR: 1.87e-04	EMPP_Raw: 1.46488
2025-07-18 10:32:31,567 - logger.py:50 - Epoch: [262][5/6]	Total Loss: 0.75714	Main MSE (x10^-2): 75.7142	LR: 1.87e-04	EMPP_Raw: 1.48174
2025-07-18 10:32:31,613 - logger.py:50 - Epoch 262 Training Summary: Avg Total Loss: 0.75714, Avg Main MSE: 0.75714, Time: 16.87s
2025-07-18 10:32:49,664 - logger.py:50 - Epoch 262 Summary | Train MSE (x10^-2): 75.7142 | Val MSE (x10^-2): 79.7043 | Time: 34.92s
2025-07-18 10:32:52,678 - logger.py:50 - Epoch: [263][0/6]	Total Loss: 0.75399	Main MSE (x10^-2): 75.3989	LR: 1.85e-04	EMPP_Raw: 1.47543
2025-07-18 10:33:06,417 - logger.py:50 - Epoch: [263][5/6]	Total Loss: 0.74467	Main MSE (x10^-2): 74.4665	LR: 1.85e-04	EMPP_Raw: 1.45581
2025-07-18 10:33:06,467 - logger.py:50 - Epoch 263 Training Summary: Avg Total Loss: 0.74467, Avg Main MSE: 0.74467, Time: 16.79s
2025-07-18 10:33:24,315 - logger.py:50 - Epoch 263 Summary | Train MSE (x10^-2): 74.4665 | Val MSE (x10^-2): 79.6800 | Time: 34.64s
2025-07-18 10:33:27,529 - logger.py:50 - Epoch: [264][0/6]	Total Loss: 0.73755	Main MSE (x10^-2): 73.7554	LR: 1.84e-04	EMPP_Raw: 1.44016
2025-07-18 10:33:41,233 - logger.py:50 - Epoch: [264][5/6]	Total Loss: 0.74559	Main MSE (x10^-2): 74.5587	LR: 1.84e-04	EMPP_Raw: 1.45762
2025-07-18 10:33:41,278 - logger.py:50 - Epoch 264 Training Summary: Avg Total Loss: 0.74559, Avg Main MSE: 0.74559, Time: 16.96s
2025-07-18 10:33:59,185 - logger.py:50 - Epoch 264 Summary | Train MSE (x10^-2): 74.5587 | Val MSE (x10^-2): 79.3293 | Time: 34.87s
2025-07-18 10:34:02,224 - logger.py:50 - Epoch: [265][0/6]	Total Loss: 0.74102	Main MSE (x10^-2): 74.1023	LR: 1.83e-04	EMPP_Raw: 1.44591
2025-07-18 10:34:16,118 - logger.py:50 - Epoch: [265][5/6]	Total Loss: 0.74556	Main MSE (x10^-2): 74.5563	LR: 1.83e-04	EMPP_Raw: 1.45728
2025-07-18 10:34:16,160 - logger.py:50 - Epoch 265 Training Summary: Avg Total Loss: 0.74556, Avg Main MSE: 0.74556, Time: 16.96s
2025-07-18 10:34:34,068 - logger.py:50 - Epoch 265 Summary | Train MSE (x10^-2): 74.5563 | Val MSE (x10^-2): 79.3941 | Time: 34.88s
2025-07-18 10:34:37,066 - logger.py:50 - Epoch: [266][0/6]	Total Loss: 0.74771	Main MSE (x10^-2): 74.7707	LR: 1.82e-04	EMPP_Raw: 1.45551
2025-07-18 10:34:50,997 - logger.py:50 - Epoch: [266][5/6]	Total Loss: 0.74107	Main MSE (x10^-2): 74.1068	LR: 1.82e-04	EMPP_Raw: 1.44696
2025-07-18 10:34:51,039 - logger.py:50 - Epoch 266 Training Summary: Avg Total Loss: 0.74107, Avg Main MSE: 0.74107, Time: 16.96s
2025-07-18 10:35:09,067 - logger.py:50 - Epoch 266 Summary | Train MSE (x10^-2): 74.1068 | Val MSE (x10^-2): 78.9648 | Time: 34.99s
2025-07-18 10:35:12,086 - logger.py:50 - Epoch: [267][0/6]	Total Loss: 0.73856	Main MSE (x10^-2): 73.8556	LR: 1.80e-04	EMPP_Raw: 1.43894
2025-07-18 10:35:26,052 - logger.py:50 - Epoch: [267][5/6]	Total Loss: 0.74749	Main MSE (x10^-2): 74.7488	LR: 1.80e-04	EMPP_Raw: 1.46087
2025-07-18 10:35:26,092 - logger.py:50 - Epoch 267 Training Summary: Avg Total Loss: 0.74749, Avg Main MSE: 0.74749, Time: 17.02s
2025-07-18 10:35:44,060 - logger.py:50 - Epoch 267 Summary | Train MSE (x10^-2): 74.7488 | Val MSE (x10^-2): 79.2963 | Time: 34.99s
2025-07-18 10:35:47,209 - logger.py:50 - Epoch: [268][0/6]	Total Loss: 0.74448	Main MSE (x10^-2): 74.4483	LR: 1.79e-04	EMPP_Raw: 1.45428
2025-07-18 10:36:00,959 - logger.py:50 - Epoch: [268][5/6]	Total Loss: 0.74213	Main MSE (x10^-2): 74.2134	LR: 1.79e-04	EMPP_Raw: 1.45237
2025-07-18 10:36:00,998 - logger.py:50 - Epoch 268 Training Summary: Avg Total Loss: 0.74213, Avg Main MSE: 0.74213, Time: 16.93s
2025-07-18 10:36:19,055 - logger.py:50 - Epoch 268 Summary | Train MSE (x10^-2): 74.2134 | Val MSE (x10^-2): 79.6849 | Time: 34.99s
2025-07-18 10:36:22,277 - logger.py:50 - Epoch: [269][0/6]	Total Loss: 0.74535	Main MSE (x10^-2): 74.5351	LR: 1.78e-04	EMPP_Raw: 1.45623
2025-07-18 10:36:36,038 - logger.py:50 - Epoch: [269][5/6]	Total Loss: 0.73759	Main MSE (x10^-2): 73.7592	LR: 1.78e-04	EMPP_Raw: 1.44169
2025-07-18 10:36:36,078 - logger.py:50 - Epoch 269 Training Summary: Avg Total Loss: 0.73759, Avg Main MSE: 0.73759, Time: 17.01s
2025-07-18 10:36:54,015 - logger.py:50 - Epoch 269 Summary | Train MSE (x10^-2): 73.7592 | Val MSE (x10^-2): 77.9010 | Time: 34.95s
2025-07-18 10:36:57,068 - logger.py:50 - Epoch: [270][0/6]	Total Loss: 0.74364	Main MSE (x10^-2): 74.3635	LR: 1.77e-04	EMPP_Raw: 1.45378
2025-07-18 10:37:11,015 - logger.py:50 - Epoch: [270][5/6]	Total Loss: 0.73945	Main MSE (x10^-2): 73.9453	LR: 1.77e-04	EMPP_Raw: 1.44577
2025-07-18 10:37:11,058 - logger.py:50 - Epoch 270 Training Summary: Avg Total Loss: 0.73945, Avg Main MSE: 0.73945, Time: 17.03s
2025-07-18 10:37:29,137 - logger.py:50 - Epoch 270 Summary | Train MSE (x10^-2): 73.9453 | Val MSE (x10^-2): 79.0878 | Time: 35.12s
2025-07-18 10:37:32,143 - logger.py:50 - Epoch: [271][0/6]	Total Loss: 0.72010	Main MSE (x10^-2): 72.0097	LR: 1.75e-04	EMPP_Raw: 1.40924
2025-07-18 10:37:45,957 - logger.py:50 - Epoch: [271][5/6]	Total Loss: 0.74418	Main MSE (x10^-2): 74.4177	LR: 1.75e-04	EMPP_Raw: 1.45425
2025-07-18 10:37:46,000 - logger.py:50 - Epoch 271 Training Summary: Avg Total Loss: 0.74418, Avg Main MSE: 0.74418, Time: 16.85s
2025-07-18 10:38:04,027 - logger.py:50 - Epoch 271 Summary | Train MSE (x10^-2): 74.4177 | Val MSE (x10^-2): 79.8852 | Time: 34.88s
2025-07-18 10:38:07,024 - logger.py:50 - Epoch: [272][0/6]	Total Loss: 0.74066	Main MSE (x10^-2): 74.0655	LR: 1.74e-04	EMPP_Raw: 1.44606
2025-07-18 10:38:20,778 - logger.py:50 - Epoch: [272][5/6]	Total Loss: 0.75575	Main MSE (x10^-2): 75.5750	LR: 1.74e-04	EMPP_Raw: 1.47558
2025-07-18 10:38:20,823 - logger.py:50 - Epoch 272 Training Summary: Avg Total Loss: 0.75575, Avg Main MSE: 0.75575, Time: 16.79s
2025-07-18 10:38:38,723 - logger.py:50 - Epoch 272 Summary | Train MSE (x10^-2): 75.5750 | Val MSE (x10^-2): 76.9283 | Time: 34.69s
2025-07-18 10:38:41,869 - logger.py:50 - Epoch: [273][0/6]	Total Loss: 0.75319	Main MSE (x10^-2): 75.3188	LR: 1.73e-04	EMPP_Raw: 1.46913
2025-07-18 10:38:55,650 - logger.py:50 - Epoch: [273][5/6]	Total Loss: 0.74745	Main MSE (x10^-2): 74.7448	LR: 1.73e-04	EMPP_Raw: 1.46072
2025-07-18 10:38:55,692 - logger.py:50 - Epoch 273 Training Summary: Avg Total Loss: 0.74745, Avg Main MSE: 0.74745, Time: 16.96s
2025-07-18 10:39:13,577 - logger.py:50 - Epoch 273 Summary | Train MSE (x10^-2): 74.7448 | Val MSE (x10^-2): 80.2179 | Time: 34.85s
2025-07-18 10:39:16,590 - logger.py:50 - Epoch: [274][0/6]	Total Loss: 0.72920	Main MSE (x10^-2): 72.9197	LR: 1.72e-04	EMPP_Raw: 1.42284
2025-07-18 10:39:30,522 - logger.py:50 - Epoch: [274][5/6]	Total Loss: 0.74281	Main MSE (x10^-2): 74.2806	LR: 1.72e-04	EMPP_Raw: 1.45233
2025-07-18 10:39:30,563 - logger.py:50 - Epoch 274 Training Summary: Avg Total Loss: 0.74281, Avg Main MSE: 0.74281, Time: 16.98s
2025-07-18 10:39:48,458 - logger.py:50 - Epoch 274 Summary | Train MSE (x10^-2): 74.2806 | Val MSE (x10^-2): 80.3646 | Time: 34.88s
2025-07-18 10:39:51,462 - logger.py:50 - Epoch: [275][0/6]	Total Loss: 0.74666	Main MSE (x10^-2): 74.6661	LR: 1.71e-04	EMPP_Raw: 1.46549
2025-07-18 10:40:05,249 - logger.py:50 - Epoch: [275][5/6]	Total Loss: 0.74354	Main MSE (x10^-2): 74.3540	LR: 1.71e-04	EMPP_Raw: 1.45671
2025-07-18 10:40:05,289 - logger.py:50 - Epoch 275 Training Summary: Avg Total Loss: 0.74354, Avg Main MSE: 0.74354, Time: 16.82s
2025-07-18 10:40:23,309 - logger.py:50 - Epoch 275 Summary | Train MSE (x10^-2): 74.3540 | Val MSE (x10^-2): 79.9440 | Time: 34.84s
2025-07-18 10:40:26,294 - logger.py:50 - Epoch: [276][0/6]	Total Loss: 0.73928	Main MSE (x10^-2): 73.9281	LR: 1.69e-04	EMPP_Raw: 1.45015
2025-07-18 10:40:40,077 - logger.py:50 - Epoch: [276][5/6]	Total Loss: 0.74717	Main MSE (x10^-2): 74.7169	LR: 1.69e-04	EMPP_Raw: 1.46421
2025-07-18 10:40:40,117 - logger.py:50 - Epoch 276 Training Summary: Avg Total Loss: 0.74717, Avg Main MSE: 0.74717, Time: 16.80s
2025-07-18 10:40:58,134 - logger.py:50 - Epoch 276 Summary | Train MSE (x10^-2): 74.7169 | Val MSE (x10^-2): 79.4622 | Time: 34.82s
2025-07-18 10:41:01,175 - logger.py:50 - Epoch: [277][0/6]	Total Loss: 0.75535	Main MSE (x10^-2): 75.5352	LR: 1.68e-04	EMPP_Raw: 1.48164
2025-07-18 10:41:14,920 - logger.py:50 - Epoch: [277][5/6]	Total Loss: 0.74447	Main MSE (x10^-2): 74.4473	LR: 1.68e-04	EMPP_Raw: 1.45837
2025-07-18 10:41:14,961 - logger.py:50 - Epoch 277 Training Summary: Avg Total Loss: 0.74447, Avg Main MSE: 0.74447, Time: 16.82s
2025-07-18 10:41:32,914 - logger.py:50 - Epoch 277 Summary | Train MSE (x10^-2): 74.4473 | Val MSE (x10^-2): 79.9456 | Time: 34.77s
2025-07-18 10:41:36,285 - logger.py:50 - Epoch: [278][0/6]	Total Loss: 0.77218	Main MSE (x10^-2): 77.2180	LR: 1.67e-04	EMPP_Raw: 1.51154
2025-07-18 10:41:50,003 - logger.py:50 - Epoch: [278][5/6]	Total Loss: 0.73947	Main MSE (x10^-2): 73.9467	LR: 1.67e-04	EMPP_Raw: 1.44784
2025-07-18 10:41:50,055 - logger.py:50 - Epoch 278 Training Summary: Avg Total Loss: 0.73947, Avg Main MSE: 0.73947, Time: 17.13s
2025-07-18 10:42:08,015 - logger.py:50 - Epoch 278 Summary | Train MSE (x10^-2): 73.9467 | Val MSE (x10^-2): 79.5348 | Time: 35.09s
2025-07-18 10:42:11,254 - logger.py:50 - Epoch: [279][0/6]	Total Loss: 0.76243	Main MSE (x10^-2): 76.2432	LR: 1.66e-04	EMPP_Raw: 1.49232
2025-07-18 10:42:25,088 - logger.py:50 - Epoch: [279][5/6]	Total Loss: 0.74460	Main MSE (x10^-2): 74.4599	LR: 1.66e-04	EMPP_Raw: 1.45665
2025-07-18 10:42:25,129 - logger.py:50 - Epoch 279 Training Summary: Avg Total Loss: 0.74460, Avg Main MSE: 0.74460, Time: 17.10s
2025-07-18 10:42:43,024 - logger.py:50 - Epoch 279 Summary | Train MSE (x10^-2): 74.4599 | Val MSE (x10^-2): 77.9814 | Time: 35.00s
2025-07-18 10:42:46,017 - logger.py:50 - Epoch: [280][0/6]	Total Loss: 0.74843	Main MSE (x10^-2): 74.8433	LR: 1.64e-04	EMPP_Raw: 1.46682
2025-07-18 10:42:59,969 - logger.py:50 - Epoch: [280][5/6]	Total Loss: 0.74959	Main MSE (x10^-2): 74.9588	LR: 1.64e-04	EMPP_Raw: 1.46694
2025-07-18 10:43:00,013 - logger.py:50 - Epoch 280 Training Summary: Avg Total Loss: 0.74959, Avg Main MSE: 0.74959, Time: 16.98s
2025-07-18 10:43:17,938 - logger.py:50 - Epoch 280 Summary | Train MSE (x10^-2): 74.9588 | Val MSE (x10^-2): 79.0793 | Time: 34.91s
2025-07-18 10:43:20,939 - logger.py:50 - Epoch: [281][0/6]	Total Loss: 0.74384	Main MSE (x10^-2): 74.3838	LR: 1.63e-04	EMPP_Raw: 1.45527
2025-07-18 10:43:34,721 - logger.py:50 - Epoch: [281][5/6]	Total Loss: 0.73738	Main MSE (x10^-2): 73.7380	LR: 1.63e-04	EMPP_Raw: 1.44309
2025-07-18 10:43:34,767 - logger.py:50 - Epoch 281 Training Summary: Avg Total Loss: 0.73738, Avg Main MSE: 0.73738, Time: 16.82s
2025-07-18 10:43:52,769 - logger.py:50 - Epoch 281 Summary | Train MSE (x10^-2): 73.7380 | Val MSE (x10^-2): 79.7701 | Time: 34.83s
2025-07-18 10:43:55,764 - logger.py:50 - Epoch: [282][0/6]	Total Loss: 0.72692	Main MSE (x10^-2): 72.6922	LR: 1.62e-04	EMPP_Raw: 1.42385
2025-07-18 10:44:09,522 - logger.py:50 - Epoch: [282][5/6]	Total Loss: 0.74317	Main MSE (x10^-2): 74.3165	LR: 1.62e-04	EMPP_Raw: 1.45562
2025-07-18 10:44:09,565 - logger.py:50 - Epoch 282 Training Summary: Avg Total Loss: 0.74317, Avg Main MSE: 0.74317, Time: 16.79s
2025-07-18 10:44:27,683 - logger.py:50 - Epoch 282 Summary | Train MSE (x10^-2): 74.3165 | Val MSE (x10^-2): 77.8911 | Time: 34.91s
2025-07-18 10:44:30,733 - logger.py:50 - Epoch: [283][0/6]	Total Loss: 0.75811	Main MSE (x10^-2): 75.8111	LR: 1.61e-04	EMPP_Raw: 1.48491
2025-07-18 10:44:44,485 - logger.py:50 - Epoch: [283][5/6]	Total Loss: 0.74743	Main MSE (x10^-2): 74.7433	LR: 1.61e-04	EMPP_Raw: 1.46160
2025-07-18 10:44:44,529 - logger.py:50 - Epoch 283 Training Summary: Avg Total Loss: 0.74743, Avg Main MSE: 0.74743, Time: 16.84s
2025-07-18 10:45:02,636 - logger.py:50 - Epoch 283 Summary | Train MSE (x10^-2): 74.7433 | Val MSE (x10^-2): 81.2184 | Time: 34.95s
2025-07-18 10:45:05,809 - logger.py:50 - Epoch: [284][0/6]	Total Loss: 0.75701	Main MSE (x10^-2): 75.7015	LR: 1.59e-04	EMPP_Raw: 1.48221
2025-07-18 10:45:19,533 - logger.py:50 - Epoch: [284][5/6]	Total Loss: 0.75269	Main MSE (x10^-2): 75.2693	LR: 1.59e-04	EMPP_Raw: 1.47453
2025-07-18 10:45:19,591 - logger.py:50 - Epoch 284 Training Summary: Avg Total Loss: 0.75269, Avg Main MSE: 0.75269, Time: 16.94s
2025-07-18 10:45:37,550 - logger.py:50 - Epoch 284 Summary | Train MSE (x10^-2): 75.2693 | Val MSE (x10^-2): 79.7386 | Time: 34.91s
2025-07-18 10:45:40,584 - logger.py:50 - Epoch: [285][0/6]	Total Loss: 0.75725	Main MSE (x10^-2): 75.7246	LR: 1.58e-04	EMPP_Raw: 1.48694
2025-07-18 10:45:54,479 - logger.py:50 - Epoch: [285][5/6]	Total Loss: 0.74162	Main MSE (x10^-2): 74.1625	LR: 1.58e-04	EMPP_Raw: 1.45373
2025-07-18 10:45:54,525 - logger.py:50 - Epoch 285 Training Summary: Avg Total Loss: 0.74162, Avg Main MSE: 0.74162, Time: 16.97s
2025-07-18 10:46:12,500 - logger.py:50 - Epoch 285 Summary | Train MSE (x10^-2): 74.1625 | Val MSE (x10^-2): 79.0757 | Time: 34.94s
2025-07-18 10:46:15,534 - logger.py:50 - Epoch: [286][0/6]	Total Loss: 0.75196	Main MSE (x10^-2): 75.1964	LR: 1.57e-04	EMPP_Raw: 1.47357
2025-07-18 10:46:29,472 - logger.py:50 - Epoch: [286][5/6]	Total Loss: 0.75425	Main MSE (x10^-2): 75.4252	LR: 1.57e-04	EMPP_Raw: 1.47931
2025-07-18 10:46:29,512 - logger.py:50 - Epoch 286 Training Summary: Avg Total Loss: 0.75425, Avg Main MSE: 0.75425, Time: 17.00s
2025-07-18 10:46:47,380 - logger.py:50 - Epoch 286 Summary | Train MSE (x10^-2): 75.4252 | Val MSE (x10^-2): 79.2218 | Time: 34.87s
2025-07-18 10:46:50,373 - logger.py:50 - Epoch: [287][0/6]	Total Loss: 0.78118	Main MSE (x10^-2): 78.1176	LR: 1.56e-04	EMPP_Raw: 1.53151
2025-07-18 10:47:04,171 - logger.py:50 - Epoch: [287][5/6]	Total Loss: 0.73724	Main MSE (x10^-2): 73.7244	LR: 1.56e-04	EMPP_Raw: 1.44357
2025-07-18 10:47:04,212 - logger.py:50 - Epoch 287 Training Summary: Avg Total Loss: 0.73724, Avg Main MSE: 0.73724, Time: 16.83s
2025-07-18 10:47:22,121 - logger.py:50 - Epoch 287 Summary | Train MSE (x10^-2): 73.7244 | Val MSE (x10^-2): 79.1557 | Time: 34.74s
2025-07-18 10:47:25,277 - logger.py:50 - Epoch: [288][0/6]	Total Loss: 0.72724	Main MSE (x10^-2): 72.7241	LR: 1.55e-04	EMPP_Raw: 1.42455
2025-07-18 10:47:39,096 - logger.py:50 - Epoch: [288][5/6]	Total Loss: 0.74681	Main MSE (x10^-2): 74.6810	LR: 1.55e-04	EMPP_Raw: 1.46466
2025-07-18 10:47:39,139 - logger.py:50 - Epoch 288 Training Summary: Avg Total Loss: 0.74681, Avg Main MSE: 0.74681, Time: 17.01s
2025-07-18 10:47:57,082 - logger.py:50 - Epoch 288 Summary | Train MSE (x10^-2): 74.6810 | Val MSE (x10^-2): 78.8293 | Time: 34.96s
2025-07-18 10:48:00,239 - logger.py:50 - Epoch: [289][0/6]	Total Loss: 0.72881	Main MSE (x10^-2): 72.8813	LR: 1.53e-04	EMPP_Raw: 1.43041
2025-07-18 10:48:14,007 - logger.py:50 - Epoch: [289][5/6]	Total Loss: 0.74334	Main MSE (x10^-2): 74.3340	LR: 1.53e-04	EMPP_Raw: 1.45522
2025-07-18 10:48:14,051 - logger.py:50 - Epoch 289 Training Summary: Avg Total Loss: 0.74334, Avg Main MSE: 0.74334, Time: 16.96s
2025-07-18 10:48:31,925 - logger.py:50 - Epoch 289 Summary | Train MSE (x10^-2): 74.3340 | Val MSE (x10^-2): 82.2844 | Time: 34.84s
2025-07-18 10:48:34,917 - logger.py:50 - Epoch: [290][0/6]	Total Loss: 0.75582	Main MSE (x10^-2): 75.5823	LR: 1.52e-04	EMPP_Raw: 1.47145
2025-07-18 10:48:48,863 - logger.py:50 - Epoch: [290][5/6]	Total Loss: 0.74050	Main MSE (x10^-2): 74.0495	LR: 1.52e-04	EMPP_Raw: 1.44618
2025-07-18 10:48:48,907 - logger.py:50 - Epoch 290 Training Summary: Avg Total Loss: 0.74050, Avg Main MSE: 0.74050, Time: 16.97s
2025-07-18 10:49:06,823 - logger.py:50 - Epoch 290 Summary | Train MSE (x10^-2): 74.0495 | Val MSE (x10^-2): 76.2399 | Time: 34.89s
2025-07-18 10:49:09,826 - logger.py:50 - Epoch: [291][0/6]	Total Loss: 0.76589	Main MSE (x10^-2): 76.5893	LR: 1.51e-04	EMPP_Raw: 1.50131
2025-07-18 10:49:23,628 - logger.py:50 - Epoch: [291][5/6]	Total Loss: 0.74916	Main MSE (x10^-2): 74.9160	LR: 1.51e-04	EMPP_Raw: 1.46770
2025-07-18 10:49:23,670 - logger.py:50 - Epoch 291 Training Summary: Avg Total Loss: 0.74916, Avg Main MSE: 0.74916, Time: 16.84s
2025-07-18 10:49:41,772 - logger.py:50 - Epoch 291 Summary | Train MSE (x10^-2): 74.9160 | Val MSE (x10^-2): 82.5924 | Time: 34.94s
2025-07-18 10:49:44,765 - logger.py:50 - Epoch: [292][0/6]	Total Loss: 0.75466	Main MSE (x10^-2): 75.4655	LR: 1.50e-04	EMPP_Raw: 1.47829
2025-07-18 10:49:58,511 - logger.py:50 - Epoch: [292][5/6]	Total Loss: 0.74719	Main MSE (x10^-2): 74.7188	LR: 1.50e-04	EMPP_Raw: 1.46476
2025-07-18 10:49:58,556 - logger.py:50 - Epoch 292 Training Summary: Avg Total Loss: 0.74719, Avg Main MSE: 0.74719, Time: 16.77s
2025-07-18 10:50:16,455 - logger.py:50 - Epoch 292 Summary | Train MSE (x10^-2): 74.7188 | Val MSE (x10^-2): 78.1300 | Time: 34.68s
2025-07-18 10:50:19,660 - logger.py:50 - Epoch: [293][0/6]	Total Loss: 0.75821	Main MSE (x10^-2): 75.8214	LR: 1.48e-04	EMPP_Raw: 1.48938
2025-07-18 10:50:33,412 - logger.py:50 - Epoch: [293][5/6]	Total Loss: 0.74956	Main MSE (x10^-2): 74.9564	LR: 1.48e-04	EMPP_Raw: 1.47205
2025-07-18 10:50:33,456 - logger.py:50 - Epoch 293 Training Summary: Avg Total Loss: 0.74956, Avg Main MSE: 0.74956, Time: 16.99s
2025-07-18 10:50:51,311 - logger.py:50 - Epoch 293 Summary | Train MSE (x10^-2): 74.9564 | Val MSE (x10^-2): 78.6851 | Time: 34.85s
2025-07-18 10:50:54,306 - logger.py:50 - Epoch: [294][0/6]	Total Loss: 0.74735	Main MSE (x10^-2): 74.7353	LR: 1.47e-04	EMPP_Raw: 1.46679
2025-07-18 10:51:08,216 - logger.py:50 - Epoch: [294][5/6]	Total Loss: 0.73097	Main MSE (x10^-2): 73.0972	LR: 1.47e-04	EMPP_Raw: 1.43343
2025-07-18 10:51:08,257 - logger.py:50 - Epoch 294 Training Summary: Avg Total Loss: 0.73097, Avg Main MSE: 0.73097, Time: 16.94s
2025-07-18 10:51:26,196 - logger.py:50 - Epoch 294 Summary | Train MSE (x10^-2): 73.0972 | Val MSE (x10^-2): 78.8765 | Time: 34.88s
2025-07-18 10:51:29,187 - logger.py:50 - Epoch: [295][0/6]	Total Loss: 0.75127	Main MSE (x10^-2): 75.1271	LR: 1.46e-04	EMPP_Raw: 1.47733
2025-07-18 10:51:42,933 - logger.py:50 - Epoch: [295][5/6]	Total Loss: 0.74372	Main MSE (x10^-2): 74.3721	LR: 1.46e-04	EMPP_Raw: 1.46075
2025-07-18 10:51:42,978 - logger.py:50 - Epoch 295 Training Summary: Avg Total Loss: 0.74372, Avg Main MSE: 0.74372, Time: 16.77s
2025-07-18 10:52:01,013 - logger.py:50 - Epoch 295 Summary | Train MSE (x10^-2): 74.3721 | Val MSE (x10^-2): 79.0606 | Time: 34.81s
2025-07-18 10:52:04,018 - logger.py:50 - Epoch: [296][0/6]	Total Loss: 0.75047	Main MSE (x10^-2): 75.0475	LR: 1.45e-04	EMPP_Raw: 1.47529
2025-07-18 10:52:17,771 - logger.py:50 - Epoch: [296][5/6]	Total Loss: 0.74426	Main MSE (x10^-2): 74.4258	LR: 1.45e-04	EMPP_Raw: 1.45927
2025-07-18 10:52:17,816 - logger.py:50 - Epoch 296 Training Summary: Avg Total Loss: 0.74426, Avg Main MSE: 0.74426, Time: 16.79s
2025-07-18 10:52:35,797 - logger.py:50 - Epoch 296 Summary | Train MSE (x10^-2): 74.4258 | Val MSE (x10^-2): 78.9022 | Time: 34.78s
2025-07-18 10:52:38,799 - logger.py:50 - Epoch: [297][0/6]	Total Loss: 0.74841	Main MSE (x10^-2): 74.8410	LR: 1.44e-04	EMPP_Raw: 1.47153
2025-07-18 10:52:52,585 - logger.py:50 - Epoch: [297][5/6]	Total Loss: 0.73436	Main MSE (x10^-2): 73.4360	LR: 1.44e-04	EMPP_Raw: 1.44121
2025-07-18 10:52:52,634 - logger.py:50 - Epoch 297 Training Summary: Avg Total Loss: 0.73436, Avg Main MSE: 0.73436, Time: 16.83s
2025-07-18 10:53:10,643 - logger.py:50 - Epoch 297 Summary | Train MSE (x10^-2): 73.4360 | Val MSE (x10^-2): 79.2160 | Time: 34.84s
2025-07-18 10:53:14,041 - logger.py:50 - Epoch: [298][0/6]	Total Loss: 0.74913	Main MSE (x10^-2): 74.9129	LR: 1.42e-04	EMPP_Raw: 1.46736
2025-07-18 10:53:27,851 - logger.py:50 - Epoch: [298][5/6]	Total Loss: 0.74789	Main MSE (x10^-2): 74.7890	LR: 1.42e-04	EMPP_Raw: 1.46644
2025-07-18 10:53:27,912 - logger.py:50 - Epoch 298 Training Summary: Avg Total Loss: 0.74789, Avg Main MSE: 0.74789, Time: 17.26s
2025-07-18 10:53:45,953 - logger.py:50 - Epoch 298 Summary | Train MSE (x10^-2): 74.7890 | Val MSE (x10^-2): 79.5707 | Time: 35.30s
2025-07-18 10:53:49,165 - logger.py:50 - Epoch: [299][0/6]	Total Loss: 0.73136	Main MSE (x10^-2): 73.1358	LR: 1.41e-04	EMPP_Raw: 1.43541
2025-07-18 10:54:02,986 - logger.py:50 - Epoch: [299][5/6]	Total Loss: 0.75154	Main MSE (x10^-2): 75.1542	LR: 1.41e-04	EMPP_Raw: 1.47518
2025-07-18 10:54:03,032 - logger.py:50 - Epoch 299 Training Summary: Avg Total Loss: 0.75154, Avg Main MSE: 0.75154, Time: 17.07s
2025-07-18 10:54:21,025 - logger.py:50 - Epoch 299 Summary | Train MSE (x10^-2): 75.1542 | Val MSE (x10^-2): 79.4406 | Time: 35.07s
2025-07-18 10:54:24,062 - logger.py:50 - Epoch: [300][0/6]	Total Loss: 0.73873	Main MSE (x10^-2): 73.8733	LR: 1.40e-04	EMPP_Raw: 1.45032
2025-07-18 10:54:37,987 - logger.py:50 - Epoch: [300][5/6]	Total Loss: 0.73653	Main MSE (x10^-2): 73.6529	LR: 1.40e-04	EMPP_Raw: 1.44493
2025-07-18 10:54:38,028 - logger.py:50 - Epoch 300 Training Summary: Avg Total Loss: 0.73653, Avg Main MSE: 0.73653, Time: 16.99s
2025-07-18 10:54:55,878 - logger.py:50 - Epoch 300 Summary | Train MSE (x10^-2): 73.6529 | Val MSE (x10^-2): 79.0547 | Time: 34.85s
2025-07-18 10:54:58,932 - logger.py:50 - Epoch: [301][0/6]	Total Loss: 0.75031	Main MSE (x10^-2): 75.0311	LR: 1.39e-04	EMPP_Raw: 1.47374
2025-07-18 10:55:12,758 - logger.py:50 - Epoch: [301][5/6]	Total Loss: 0.74254	Main MSE (x10^-2): 74.2543	LR: 1.39e-04	EMPP_Raw: 1.45605
2025-07-18 10:55:12,812 - logger.py:50 - Epoch 301 Training Summary: Avg Total Loss: 0.74254, Avg Main MSE: 0.74254, Time: 16.93s
2025-07-18 10:55:30,804 - logger.py:50 - Epoch 301 Summary | Train MSE (x10^-2): 74.2543 | Val MSE (x10^-2): 78.7687 | Time: 34.92s
2025-07-18 10:55:33,812 - logger.py:50 - Epoch: [302][0/6]	Total Loss: 0.72865	Main MSE (x10^-2): 72.8652	LR: 1.38e-04	EMPP_Raw: 1.42781
2025-07-18 10:55:47,587 - logger.py:50 - Epoch: [302][5/6]	Total Loss: 0.74141	Main MSE (x10^-2): 74.1412	LR: 1.38e-04	EMPP_Raw: 1.45337
2025-07-18 10:55:47,633 - logger.py:50 - Epoch 302 Training Summary: Avg Total Loss: 0.74141, Avg Main MSE: 0.74141, Time: 16.82s
2025-07-18 10:56:05,645 - logger.py:50 - Epoch 302 Summary | Train MSE (x10^-2): 74.1412 | Val MSE (x10^-2): 78.2020 | Time: 34.83s
2025-07-18 10:56:08,687 - logger.py:50 - Epoch: [303][0/6]	Total Loss: 0.76612	Main MSE (x10^-2): 76.6121	LR: 1.36e-04	EMPP_Raw: 1.50364
2025-07-18 10:56:22,530 - logger.py:50 - Epoch: [303][5/6]	Total Loss: 0.74507	Main MSE (x10^-2): 74.5075	LR: 1.36e-04	EMPP_Raw: 1.46200
2025-07-18 10:56:22,569 - logger.py:50 - Epoch 303 Training Summary: Avg Total Loss: 0.74507, Avg Main MSE: 0.74507, Time: 16.92s
2025-07-18 10:56:40,527 - logger.py:50 - Epoch 303 Summary | Train MSE (x10^-2): 74.5075 | Val MSE (x10^-2): 78.8878 | Time: 34.88s
2025-07-18 10:56:43,708 - logger.py:50 - Epoch: [304][0/6]	Total Loss: 0.73797	Main MSE (x10^-2): 73.7973	LR: 1.35e-04	EMPP_Raw: 1.45040
2025-07-18 10:56:57,455 - logger.py:50 - Epoch: [304][5/6]	Total Loss: 0.74862	Main MSE (x10^-2): 74.8619	LR: 1.35e-04	EMPP_Raw: 1.46881
2025-07-18 10:56:57,505 - logger.py:50 - Epoch 304 Training Summary: Avg Total Loss: 0.74862, Avg Main MSE: 0.74862, Time: 16.97s
2025-07-18 10:57:15,299 - logger.py:50 - Epoch 304 Summary | Train MSE (x10^-2): 74.8619 | Val MSE (x10^-2): 77.5263 | Time: 34.77s
2025-07-18 10:57:18,295 - logger.py:50 - Epoch: [305][0/6]	Total Loss: 0.72085	Main MSE (x10^-2): 72.0846	LR: 1.34e-04	EMPP_Raw: 1.41436
2025-07-18 10:57:32,202 - logger.py:50 - Epoch: [305][5/6]	Total Loss: 0.73525	Main MSE (x10^-2): 73.5249	LR: 1.34e-04	EMPP_Raw: 1.44020
2025-07-18 10:57:32,249 - logger.py:50 - Epoch 305 Training Summary: Avg Total Loss: 0.73525, Avg Main MSE: 0.73525, Time: 16.94s
2025-07-18 10:57:50,143 - logger.py:50 - Epoch 305 Summary | Train MSE (x10^-2): 73.5249 | Val MSE (x10^-2): 77.6879 | Time: 34.84s
2025-07-18 10:57:53,140 - logger.py:50 - Epoch: [306][0/6]	Total Loss: 0.75145	Main MSE (x10^-2): 75.1455	LR: 1.33e-04	EMPP_Raw: 1.47517
2025-07-18 10:58:07,065 - logger.py:50 - Epoch: [306][5/6]	Total Loss: 0.74107	Main MSE (x10^-2): 74.1065	LR: 1.33e-04	EMPP_Raw: 1.45516
2025-07-18 10:58:07,111 - logger.py:50 - Epoch 306 Training Summary: Avg Total Loss: 0.74107, Avg Main MSE: 0.74107, Time: 16.96s
2025-07-18 10:58:25,011 - logger.py:50 - Epoch 306 Summary | Train MSE (x10^-2): 74.1065 | Val MSE (x10^-2): 79.3471 | Time: 34.86s
2025-07-18 10:58:28,008 - logger.py:50 - Epoch: [307][0/6]	Total Loss: 0.74857	Main MSE (x10^-2): 74.8569	LR: 1.32e-04	EMPP_Raw: 1.47178
2025-07-18 10:58:41,785 - logger.py:50 - Epoch: [307][5/6]	Total Loss: 0.74303	Main MSE (x10^-2): 74.3033	LR: 1.32e-04	EMPP_Raw: 1.46029
2025-07-18 10:58:41,826 - logger.py:50 - Epoch 307 Training Summary: Avg Total Loss: 0.74303, Avg Main MSE: 0.74303, Time: 16.81s
2025-07-18 10:58:59,795 - logger.py:50 - Epoch 307 Summary | Train MSE (x10^-2): 74.3033 | Val MSE (x10^-2): 79.8363 | Time: 34.78s
2025-07-18 10:59:03,023 - logger.py:50 - Epoch: [308][0/6]	Total Loss: 0.74054	Main MSE (x10^-2): 74.0541	LR: 1.31e-04	EMPP_Raw: 1.45356
2025-07-18 10:59:16,816 - logger.py:50 - Epoch: [308][5/6]	Total Loss: 0.75312	Main MSE (x10^-2): 75.3117	LR: 1.31e-04	EMPP_Raw: 1.47998
2025-07-18 10:59:16,862 - logger.py:50 - Epoch 308 Training Summary: Avg Total Loss: 0.75312, Avg Main MSE: 0.75312, Time: 17.06s
2025-07-18 10:59:34,705 - logger.py:50 - Epoch 308 Summary | Train MSE (x10^-2): 75.3117 | Val MSE (x10^-2): 79.3549 | Time: 34.90s
2025-07-18 10:59:37,866 - logger.py:50 - Epoch: [309][0/6]	Total Loss: 0.72779	Main MSE (x10^-2): 72.7791	LR: 1.29e-04	EMPP_Raw: 1.43297
2025-07-18 10:59:51,634 - logger.py:50 - Epoch: [309][5/6]	Total Loss: 0.73923	Main MSE (x10^-2): 73.9232	LR: 1.29e-04	EMPP_Raw: 1.45174
2025-07-18 10:59:51,682 - logger.py:50 - Epoch 309 Training Summary: Avg Total Loss: 0.73923, Avg Main MSE: 0.73923, Time: 16.97s
2025-07-18 11:00:09,703 - logger.py:50 - Epoch 309 Summary | Train MSE (x10^-2): 73.9232 | Val MSE (x10^-2): 79.1363 | Time: 34.99s
2025-07-18 11:00:12,720 - logger.py:50 - Epoch: [310][0/6]	Total Loss: 0.72371	Main MSE (x10^-2): 72.3713	LR: 1.28e-04	EMPP_Raw: 1.41661
2025-07-18 11:00:26,709 - logger.py:50 - Epoch: [310][5/6]	Total Loss: 0.73507	Main MSE (x10^-2): 73.5070	LR: 1.28e-04	EMPP_Raw: 1.44130
2025-07-18 11:00:26,750 - logger.py:50 - Epoch 310 Training Summary: Avg Total Loss: 0.73507, Avg Main MSE: 0.73507, Time: 17.04s
2025-07-18 11:00:44,652 - logger.py:50 - Epoch 310 Summary | Train MSE (x10^-2): 73.5070 | Val MSE (x10^-2): 79.6483 | Time: 34.94s
2025-07-18 11:00:47,656 - logger.py:50 - Epoch: [311][0/6]	Total Loss: 0.72296	Main MSE (x10^-2): 72.2964	LR: 1.27e-04	EMPP_Raw: 1.41823
2025-07-18 11:01:01,529 - logger.py:50 - Epoch: [311][5/6]	Total Loss: 0.73715	Main MSE (x10^-2): 73.7149	LR: 1.27e-04	EMPP_Raw: 1.44724
2025-07-18 11:01:01,585 - logger.py:50 - Epoch 311 Training Summary: Avg Total Loss: 0.73715, Avg Main MSE: 0.73715, Time: 16.92s
2025-07-18 11:01:19,674 - logger.py:50 - Epoch 311 Summary | Train MSE (x10^-2): 73.7149 | Val MSE (x10^-2): 79.9549 | Time: 35.02s
2025-07-18 11:01:22,712 - logger.py:50 - Epoch: [312][0/6]	Total Loss: 0.75606	Main MSE (x10^-2): 75.6057	LR: 1.26e-04	EMPP_Raw: 1.48504
2025-07-18 11:01:36,491 - logger.py:50 - Epoch: [312][5/6]	Total Loss: 0.74618	Main MSE (x10^-2): 74.6175	LR: 1.26e-04	EMPP_Raw: 1.46557
2025-07-18 11:01:36,537 - logger.py:50 - Epoch 312 Training Summary: Avg Total Loss: 0.74618, Avg Main MSE: 0.74618, Time: 16.85s
2025-07-18 11:01:54,472 - logger.py:50 - Epoch 312 Summary | Train MSE (x10^-2): 74.6175 | Val MSE (x10^-2): 78.6781 | Time: 34.79s
2025-07-18 11:01:57,630 - logger.py:50 - Epoch: [313][0/6]	Total Loss: 0.74248	Main MSE (x10^-2): 74.2480	LR: 1.25e-04	EMPP_Raw: 1.45834
2025-07-18 11:02:11,396 - logger.py:50 - Epoch: [313][5/6]	Total Loss: 0.73773	Main MSE (x10^-2): 73.7726	LR: 1.25e-04	EMPP_Raw: 1.44934
2025-07-18 11:02:11,437 - logger.py:50 - Epoch 313 Training Summary: Avg Total Loss: 0.73773, Avg Main MSE: 0.73773, Time: 16.95s
2025-07-18 11:02:29,418 - logger.py:50 - Epoch 313 Summary | Train MSE (x10^-2): 73.7726 | Val MSE (x10^-2): 78.5839 | Time: 34.94s
2025-07-18 11:02:32,419 - logger.py:50 - Epoch: [314][0/6]	Total Loss: 0.72003	Main MSE (x10^-2): 72.0031	LR: 1.24e-04	EMPP_Raw: 1.41481
2025-07-18 11:02:46,354 - logger.py:50 - Epoch: [314][5/6]	Total Loss: 0.73578	Main MSE (x10^-2): 73.5779	LR: 1.24e-04	EMPP_Raw: 1.44622
2025-07-18 11:02:46,404 - logger.py:50 - Epoch 314 Training Summary: Avg Total Loss: 0.73578, Avg Main MSE: 0.73578, Time: 16.98s
2025-07-18 11:03:04,421 - logger.py:50 - Epoch 314 Summary | Train MSE (x10^-2): 73.5779 | Val MSE (x10^-2): 78.9721 | Time: 35.00s
2025-07-18 11:03:07,420 - logger.py:50 - Epoch: [315][0/6]	Total Loss: 0.73743	Main MSE (x10^-2): 73.7433	LR: 1.22e-04	EMPP_Raw: 1.45062
2025-07-18 11:03:21,199 - logger.py:50 - Epoch: [315][5/6]	Total Loss: 0.74339	Main MSE (x10^-2): 74.3393	LR: 1.22e-04	EMPP_Raw: 1.46134
2025-07-18 11:03:21,244 - logger.py:50 - Epoch 315 Training Summary: Avg Total Loss: 0.74339, Avg Main MSE: 0.74339, Time: 16.81s
2025-07-18 11:03:39,382 - logger.py:50 - Epoch 315 Summary | Train MSE (x10^-2): 74.3393 | Val MSE (x10^-2): 79.1063 | Time: 34.96s
2025-07-18 11:03:42,438 - logger.py:50 - Epoch: [316][0/6]	Total Loss: 0.73675	Main MSE (x10^-2): 73.6749	LR: 1.21e-04	EMPP_Raw: 1.44240
2025-07-18 11:03:56,211 - logger.py:50 - Epoch: [316][5/6]	Total Loss: 0.74689	Main MSE (x10^-2): 74.6890	LR: 1.21e-04	EMPP_Raw: 1.46741
2025-07-18 11:03:56,251 - logger.py:50 - Epoch 316 Training Summary: Avg Total Loss: 0.74689, Avg Main MSE: 0.74689, Time: 16.86s
2025-07-18 11:04:14,272 - logger.py:50 - Epoch 316 Summary | Train MSE (x10^-2): 74.6890 | Val MSE (x10^-2): 78.8723 | Time: 34.88s
2025-07-18 11:04:17,285 - logger.py:50 - Epoch: [317][0/6]	Total Loss: 0.74125	Main MSE (x10^-2): 74.1253	LR: 1.20e-04	EMPP_Raw: 1.45476
2025-07-18 11:04:31,342 - logger.py:50 - Epoch: [317][5/6]	Total Loss: 0.72963	Main MSE (x10^-2): 72.9630	LR: 1.20e-04	EMPP_Raw: 1.43347
2025-07-18 11:04:31,387 - logger.py:50 - Epoch 317 Training Summary: Avg Total Loss: 0.72963, Avg Main MSE: 0.72963, Time: 17.11s
2025-07-18 11:04:49,408 - logger.py:50 - Epoch 317 Summary | Train MSE (x10^-2): 72.9630 | Val MSE (x10^-2): 78.8804 | Time: 35.13s
2025-07-18 11:04:52,848 - logger.py:50 - Epoch: [318][0/6]	Total Loss: 0.72627	Main MSE (x10^-2): 72.6269	LR: 1.19e-04	EMPP_Raw: 1.42846
2025-07-18 11:05:06,703 - logger.py:50 - Epoch: [318][5/6]	Total Loss: 0.74706	Main MSE (x10^-2): 74.7064	LR: 1.19e-04	EMPP_Raw: 1.46858
2025-07-18 11:05:06,760 - logger.py:50 - Epoch 318 Training Summary: Avg Total Loss: 0.74706, Avg Main MSE: 0.74706, Time: 17.34s
2025-07-18 11:05:24,852 - logger.py:50 - Epoch 318 Summary | Train MSE (x10^-2): 74.7064 | Val MSE (x10^-2): 78.1196 | Time: 35.44s
2025-07-18 11:05:28,019 - logger.py:50 - Epoch: [319][0/6]	Total Loss: 0.72770	Main MSE (x10^-2): 72.7696	LR: 1.18e-04	EMPP_Raw: 1.43034
2025-07-18 11:05:41,739 - logger.py:50 - Epoch: [319][5/6]	Total Loss: 0.73520	Main MSE (x10^-2): 73.5203	LR: 1.18e-04	EMPP_Raw: 1.44502
2025-07-18 11:05:41,786 - logger.py:50 - Epoch 319 Training Summary: Avg Total Loss: 0.73520, Avg Main MSE: 0.73520, Time: 16.92s
2025-07-18 11:05:59,743 - logger.py:50 - Epoch 319 Summary | Train MSE (x10^-2): 73.5203 | Val MSE (x10^-2): 78.9831 | Time: 34.89s
2025-07-18 11:06:02,750 - logger.py:50 - Epoch: [320][0/6]	Total Loss: 0.74737	Main MSE (x10^-2): 74.7373	LR: 1.17e-04	EMPP_Raw: 1.47040
2025-07-18 11:06:16,772 - logger.py:50 - Epoch: [320][5/6]	Total Loss: 0.73464	Main MSE (x10^-2): 73.4644	LR: 1.17e-04	EMPP_Raw: 1.44446
2025-07-18 11:06:16,822 - logger.py:50 - Epoch 320 Training Summary: Avg Total Loss: 0.73464, Avg Main MSE: 0.73464, Time: 17.07s
2025-07-18 11:06:34,873 - logger.py:50 - Epoch 320 Summary | Train MSE (x10^-2): 73.4644 | Val MSE (x10^-2): 79.3289 | Time: 35.12s
2025-07-18 11:06:37,876 - logger.py:50 - Epoch: [321][0/6]	Total Loss: 0.74727	Main MSE (x10^-2): 74.7271	LR: 1.16e-04	EMPP_Raw: 1.46671
2025-07-18 11:06:51,700 - logger.py:50 - Epoch: [321][5/6]	Total Loss: 0.74027	Main MSE (x10^-2): 74.0268	LR: 1.16e-04	EMPP_Raw: 1.45395
2025-07-18 11:06:51,741 - logger.py:50 - Epoch 321 Training Summary: Avg Total Loss: 0.74027, Avg Main MSE: 0.74027, Time: 16.86s
2025-07-18 11:07:09,769 - logger.py:50 - Epoch 321 Summary | Train MSE (x10^-2): 74.0268 | Val MSE (x10^-2): 80.2456 | Time: 34.89s
2025-07-18 11:07:12,774 - logger.py:50 - Epoch: [322][0/6]	Total Loss: 0.76391	Main MSE (x10^-2): 76.3913	LR: 1.14e-04	EMPP_Raw: 1.50364
2025-07-18 11:07:26,559 - logger.py:50 - Epoch: [322][5/6]	Total Loss: 0.74138	Main MSE (x10^-2): 74.1382	LR: 1.14e-04	EMPP_Raw: 1.45632
2025-07-18 11:07:26,600 - logger.py:50 - Epoch 322 Training Summary: Avg Total Loss: 0.74138, Avg Main MSE: 0.74138, Time: 16.82s
2025-07-18 11:07:44,660 - logger.py:50 - Epoch 322 Summary | Train MSE (x10^-2): 74.1382 | Val MSE (x10^-2): 78.8808 | Time: 34.88s
2025-07-18 11:07:47,687 - logger.py:50 - Epoch: [323][0/6]	Total Loss: 0.74707	Main MSE (x10^-2): 74.7074	LR: 1.13e-04	EMPP_Raw: 1.46746
2025-07-18 11:08:01,436 - logger.py:50 - Epoch: [323][5/6]	Total Loss: 0.75396	Main MSE (x10^-2): 75.3958	LR: 1.13e-04	EMPP_Raw: 1.48200
2025-07-18 11:08:01,484 - logger.py:50 - Epoch 323 Training Summary: Avg Total Loss: 0.75396, Avg Main MSE: 0.75396, Time: 16.81s
2025-07-18 11:08:19,320 - logger.py:50 - Epoch 323 Summary | Train MSE (x10^-2): 75.3958 | Val MSE (x10^-2): 79.6379 | Time: 34.65s
2025-07-18 11:08:22,513 - logger.py:50 - Epoch: [324][0/6]	Total Loss: 0.74411	Main MSE (x10^-2): 74.4114	LR: 1.12e-04	EMPP_Raw: 1.45896
2025-07-18 11:08:36,299 - logger.py:50 - Epoch: [324][5/6]	Total Loss: 0.75524	Main MSE (x10^-2): 75.5241	LR: 1.12e-04	EMPP_Raw: 1.48452
2025-07-18 11:08:36,365 - logger.py:50 - Epoch 324 Training Summary: Avg Total Loss: 0.75524, Avg Main MSE: 0.75524, Time: 17.04s
2025-07-18 11:08:54,202 - logger.py:50 - Epoch 324 Summary | Train MSE (x10^-2): 75.5241 | Val MSE (x10^-2): 79.8904 | Time: 34.88s
2025-07-18 11:08:57,197 - logger.py:50 - Epoch: [325][0/6]	Total Loss: 0.74509	Main MSE (x10^-2): 74.5086	LR: 1.11e-04	EMPP_Raw: 1.46736
2025-07-18 11:09:11,086 - logger.py:50 - Epoch: [325][5/6]	Total Loss: 0.74983	Main MSE (x10^-2): 74.9828	LR: 1.11e-04	EMPP_Raw: 1.47589
2025-07-18 11:09:11,128 - logger.py:50 - Epoch 325 Training Summary: Avg Total Loss: 0.74983, Avg Main MSE: 0.74983, Time: 16.91s
2025-07-18 11:09:29,084 - logger.py:50 - Epoch 325 Summary | Train MSE (x10^-2): 74.9828 | Val MSE (x10^-2): 79.8000 | Time: 34.87s
2025-07-18 11:09:32,136 - logger.py:50 - Epoch: [326][0/6]	Total Loss: 0.72583	Main MSE (x10^-2): 72.5830	LR: 1.10e-04	EMPP_Raw: 1.42866
2025-07-18 11:09:46,082 - logger.py:50 - Epoch: [326][5/6]	Total Loss: 0.74142	Main MSE (x10^-2): 74.1416	LR: 1.10e-04	EMPP_Raw: 1.45911
2025-07-18 11:09:46,128 - logger.py:50 - Epoch 326 Training Summary: Avg Total Loss: 0.74142, Avg Main MSE: 0.74142, Time: 17.03s
2025-07-18 11:10:04,124 - logger.py:50 - Epoch 326 Summary | Train MSE (x10^-2): 74.1416 | Val MSE (x10^-2): 79.7717 | Time: 35.03s
2025-07-18 11:10:07,185 - logger.py:50 - Epoch: [327][0/6]	Total Loss: 0.76635	Main MSE (x10^-2): 76.6349	LR: 1.09e-04	EMPP_Raw: 1.50921
2025-07-18 11:10:20,990 - logger.py:50 - Epoch: [327][5/6]	Total Loss: 0.74151	Main MSE (x10^-2): 74.1505	LR: 1.09e-04	EMPP_Raw: 1.45847
2025-07-18 11:10:21,032 - logger.py:50 - Epoch 327 Training Summary: Avg Total Loss: 0.74151, Avg Main MSE: 0.74151, Time: 16.90s
2025-07-18 11:10:38,875 - logger.py:50 - Epoch 327 Summary | Train MSE (x10^-2): 74.1505 | Val MSE (x10^-2): 78.3053 | Time: 34.75s
2025-07-18 11:10:42,039 - logger.py:50 - Epoch: [328][0/6]	Total Loss: 0.71734	Main MSE (x10^-2): 71.7337	LR: 1.08e-04	EMPP_Raw: 1.41195
2025-07-18 11:10:55,820 - logger.py:50 - Epoch: [328][5/6]	Total Loss: 0.74121	Main MSE (x10^-2): 74.1206	LR: 1.08e-04	EMPP_Raw: 1.45747
2025-07-18 11:10:55,860 - logger.py:50 - Epoch 328 Training Summary: Avg Total Loss: 0.74121, Avg Main MSE: 0.74121, Time: 16.97s
2025-07-18 11:11:13,813 - logger.py:50 - Epoch 328 Summary | Train MSE (x10^-2): 74.1206 | Val MSE (x10^-2): 78.3543 | Time: 34.93s
2025-07-18 11:11:16,986 - logger.py:50 - Epoch: [329][0/6]	Total Loss: 0.72056	Main MSE (x10^-2): 72.0560	LR: 1.07e-04	EMPP_Raw: 1.41615
2025-07-18 11:11:30,763 - logger.py:50 - Epoch: [329][5/6]	Total Loss: 0.73747	Main MSE (x10^-2): 73.7467	LR: 1.07e-04	EMPP_Raw: 1.45055
2025-07-18 11:11:30,807 - logger.py:50 - Epoch 329 Training Summary: Avg Total Loss: 0.73747, Avg Main MSE: 0.73747, Time: 16.99s
2025-07-18 11:11:48,740 - logger.py:50 - Epoch 329 Summary | Train MSE (x10^-2): 73.7467 | Val MSE (x10^-2): 78.0858 | Time: 34.92s
2025-07-18 11:11:51,747 - logger.py:50 - Epoch: [330][0/6]	Total Loss: 0.75389	Main MSE (x10^-2): 75.3892	LR: 1.05e-04	EMPP_Raw: 1.47934
2025-07-18 11:12:05,737 - logger.py:50 - Epoch: [330][5/6]	Total Loss: 0.73964	Main MSE (x10^-2): 73.9644	LR: 1.05e-04	EMPP_Raw: 1.45311
2025-07-18 11:12:05,781 - logger.py:50 - Epoch 330 Training Summary: Avg Total Loss: 0.73964, Avg Main MSE: 0.73964, Time: 17.03s
2025-07-18 11:12:23,686 - logger.py:50 - Epoch 330 Summary | Train MSE (x10^-2): 73.9644 | Val MSE (x10^-2): 79.9870 | Time: 34.94s
2025-07-18 11:12:26,720 - logger.py:50 - Epoch: [331][0/6]	Total Loss: 0.73375	Main MSE (x10^-2): 73.3747	LR: 1.04e-04	EMPP_Raw: 1.44233
2025-07-18 11:12:40,473 - logger.py:50 - Epoch: [331][5/6]	Total Loss: 0.74229	Main MSE (x10^-2): 74.2295	LR: 1.04e-04	EMPP_Raw: 1.46015
2025-07-18 11:12:40,515 - logger.py:50 - Epoch 331 Training Summary: Avg Total Loss: 0.74229, Avg Main MSE: 0.74229, Time: 16.82s
2025-07-18 11:12:58,599 - logger.py:50 - Epoch 331 Summary | Train MSE (x10^-2): 74.2295 | Val MSE (x10^-2): 79.9344 | Time: 34.91s
2025-07-18 11:13:01,591 - logger.py:50 - Epoch: [332][0/6]	Total Loss: 0.74481	Main MSE (x10^-2): 74.4812	LR: 1.03e-04	EMPP_Raw: 1.46698
2025-07-18 11:13:15,365 - logger.py:50 - Epoch: [332][5/6]	Total Loss: 0.74861	Main MSE (x10^-2): 74.8612	LR: 1.03e-04	EMPP_Raw: 1.47315
2025-07-18 11:13:15,405 - logger.py:50 - Epoch 332 Training Summary: Avg Total Loss: 0.74861, Avg Main MSE: 0.74861, Time: 16.80s
2025-07-18 11:13:33,376 - logger.py:50 - Epoch 332 Summary | Train MSE (x10^-2): 74.8612 | Val MSE (x10^-2): 78.0311 | Time: 34.77s
2025-07-18 11:13:36,549 - logger.py:50 - Epoch: [333][0/6]	Total Loss: 0.76371	Main MSE (x10^-2): 76.3706	LR: 1.02e-04	EMPP_Raw: 1.50392
2025-07-18 11:13:50,328 - logger.py:50 - Epoch: [333][5/6]	Total Loss: 0.74776	Main MSE (x10^-2): 74.7760	LR: 1.02e-04	EMPP_Raw: 1.47189
2025-07-18 11:13:50,369 - logger.py:50 - Epoch 333 Training Summary: Avg Total Loss: 0.74776, Avg Main MSE: 0.74776, Time: 16.98s
2025-07-18 11:14:08,414 - logger.py:50 - Epoch 333 Summary | Train MSE (x10^-2): 74.7760 | Val MSE (x10^-2): 78.3638 | Time: 35.03s
2025-07-18 11:14:11,427 - logger.py:50 - Epoch: [334][0/6]	Total Loss: 0.74712	Main MSE (x10^-2): 74.7124	LR: 1.01e-04	EMPP_Raw: 1.47107
2025-07-18 11:14:25,396 - logger.py:50 - Epoch: [334][5/6]	Total Loss: 0.73688	Main MSE (x10^-2): 73.6881	LR: 1.01e-04	EMPP_Raw: 1.45090
2025-07-18 11:14:25,438 - logger.py:50 - Epoch 334 Training Summary: Avg Total Loss: 0.73688, Avg Main MSE: 0.73688, Time: 17.01s
2025-07-18 11:14:43,350 - logger.py:50 - Epoch 334 Summary | Train MSE (x10^-2): 73.6881 | Val MSE (x10^-2): 78.8051 | Time: 34.93s
2025-07-18 11:14:46,351 - logger.py:50 - Epoch: [335][0/6]	Total Loss: 0.75386	Main MSE (x10^-2): 75.3862	LR: 1.00e-04	EMPP_Raw: 1.48420
2025-07-18 11:15:00,185 - logger.py:50 - Epoch: [335][5/6]	Total Loss: 0.74044	Main MSE (x10^-2): 74.0442	LR: 1.00e-04	EMPP_Raw: 1.45682
2025-07-18 11:15:00,228 - logger.py:50 - Epoch 335 Training Summary: Avg Total Loss: 0.74044, Avg Main MSE: 0.74044, Time: 16.87s
2025-07-18 11:15:18,286 - logger.py:50 - Epoch 335 Summary | Train MSE (x10^-2): 74.0442 | Val MSE (x10^-2): 79.0259 | Time: 34.93s
2025-07-18 11:15:21,285 - logger.py:50 - Epoch: [336][0/6]	Total Loss: 0.75221	Main MSE (x10^-2): 75.2206	LR: 9.89e-05	EMPP_Raw: 1.47769
2025-07-18 11:15:35,121 - logger.py:50 - Epoch: [336][5/6]	Total Loss: 0.74682	Main MSE (x10^-2): 74.6822	LR: 9.89e-05	EMPP_Raw: 1.46881
2025-07-18 11:15:35,162 - logger.py:50 - Epoch 336 Training Summary: Avg Total Loss: 0.74682, Avg Main MSE: 0.74682, Time: 16.87s
2025-07-18 11:15:53,232 - logger.py:50 - Epoch 336 Summary | Train MSE (x10^-2): 74.6822 | Val MSE (x10^-2): 79.5520 | Time: 34.94s
2025-07-18 11:15:56,257 - logger.py:50 - Epoch: [337][0/6]	Total Loss: 0.75000	Main MSE (x10^-2): 74.9996	LR: 9.79e-05	EMPP_Raw: 1.47622
2025-07-18 11:16:10,096 - logger.py:50 - Epoch: [337][5/6]	Total Loss: 0.73246	Main MSE (x10^-2): 73.2464	LR: 9.79e-05	EMPP_Raw: 1.44067
2025-07-18 11:16:10,137 - logger.py:50 - Epoch 337 Training Summary: Avg Total Loss: 0.73246, Avg Main MSE: 0.73246, Time: 16.89s
2025-07-18 11:16:28,093 - logger.py:50 - Epoch 337 Summary | Train MSE (x10^-2): 73.2464 | Val MSE (x10^-2): 78.5957 | Time: 34.85s
2025-07-18 11:16:31,475 - logger.py:50 - Epoch: [338][0/6]	Total Loss: 0.73829	Main MSE (x10^-2): 73.8288	LR: 9.68e-05	EMPP_Raw: 1.45340
2025-07-18 11:16:45,234 - logger.py:50 - Epoch: [338][5/6]	Total Loss: 0.73530	Main MSE (x10^-2): 73.5300	LR: 9.68e-05	EMPP_Raw: 1.44644
2025-07-18 11:16:45,286 - logger.py:50 - Epoch 338 Training Summary: Avg Total Loss: 0.73530, Avg Main MSE: 0.73530, Time: 17.18s
2025-07-18 11:17:03,225 - logger.py:50 - Epoch 338 Summary | Train MSE (x10^-2): 73.5300 | Val MSE (x10^-2): 78.9518 | Time: 35.13s
2025-07-18 11:17:06,406 - logger.py:50 - Epoch: [339][0/6]	Total Loss: 0.73744	Main MSE (x10^-2): 73.7443	LR: 9.57e-05	EMPP_Raw: 1.45382
2025-07-18 11:17:20,222 - logger.py:50 - Epoch: [339][5/6]	Total Loss: 0.74232	Main MSE (x10^-2): 74.2322	LR: 9.57e-05	EMPP_Raw: 1.46117
2025-07-18 11:17:20,263 - logger.py:50 - Epoch 339 Training Summary: Avg Total Loss: 0.74232, Avg Main MSE: 0.74232, Time: 17.03s
2025-07-18 11:17:38,251 - logger.py:50 - Epoch 339 Summary | Train MSE (x10^-2): 74.2322 | Val MSE (x10^-2): 79.3941 | Time: 35.02s
2025-07-18 11:17:41,258 - logger.py:50 - Epoch: [340][0/6]	Total Loss: 0.72656	Main MSE (x10^-2): 72.6559	LR: 9.47e-05	EMPP_Raw: 1.42938
2025-07-18 11:17:55,163 - logger.py:50 - Epoch: [340][5/6]	Total Loss: 0.72354	Main MSE (x10^-2): 72.3539	LR: 9.47e-05	EMPP_Raw: 1.42333
2025-07-18 11:17:55,210 - logger.py:50 - Epoch 340 Training Summary: Avg Total Loss: 0.72354, Avg Main MSE: 0.72354, Time: 16.95s
2025-07-18 11:18:13,213 - logger.py:50 - Epoch 340 Summary | Train MSE (x10^-2): 72.3539 | Val MSE (x10^-2): 79.5822 | Time: 34.96s
2025-07-18 11:18:16,223 - logger.py:50 - Epoch: [341][0/6]	Total Loss: 0.74647	Main MSE (x10^-2): 74.6468	LR: 9.36e-05	EMPP_Raw: 1.47000
2025-07-18 11:18:30,000 - logger.py:50 - Epoch: [341][5/6]	Total Loss: 0.73693	Main MSE (x10^-2): 73.6928	LR: 9.36e-05	EMPP_Raw: 1.45036
2025-07-18 11:18:30,048 - logger.py:50 - Epoch 341 Training Summary: Avg Total Loss: 0.73693, Avg Main MSE: 0.73693, Time: 16.83s
2025-07-18 11:18:48,032 - logger.py:50 - Epoch 341 Summary | Train MSE (x10^-2): 73.6928 | Val MSE (x10^-2): 79.9054 | Time: 34.81s
2025-07-18 11:18:51,079 - logger.py:50 - Epoch: [342][0/6]	Total Loss: 0.74375	Main MSE (x10^-2): 74.3748	LR: 9.25e-05	EMPP_Raw: 1.46462
2025-07-18 11:19:04,849 - logger.py:50 - Epoch: [342][5/6]	Total Loss: 0.73888	Main MSE (x10^-2): 73.8882	LR: 9.25e-05	EMPP_Raw: 1.45391
2025-07-18 11:19:04,894 - logger.py:50 - Epoch 342 Training Summary: Avg Total Loss: 0.73888, Avg Main MSE: 0.73888, Time: 16.85s
2025-07-18 11:19:22,973 - logger.py:50 - Epoch 342 Summary | Train MSE (x10^-2): 73.8882 | Val MSE (x10^-2): 78.6901 | Time: 34.94s
2025-07-18 11:19:26,020 - logger.py:50 - Epoch: [343][0/6]	Total Loss: 0.71954	Main MSE (x10^-2): 71.9539	LR: 9.15e-05	EMPP_Raw: 1.41751
2025-07-18 11:19:39,814 - logger.py:50 - Epoch: [343][5/6]	Total Loss: 0.73135	Main MSE (x10^-2): 73.1352	LR: 9.15e-05	EMPP_Raw: 1.43932
2025-07-18 11:19:39,854 - logger.py:50 - Epoch 343 Training Summary: Avg Total Loss: 0.73135, Avg Main MSE: 0.73135, Time: 16.87s
2025-07-18 11:19:57,727 - logger.py:50 - Epoch 343 Summary | Train MSE (x10^-2): 73.1352 | Val MSE (x10^-2): 78.8502 | Time: 34.75s
2025-07-18 11:20:00,891 - logger.py:50 - Epoch: [344][0/6]	Total Loss: 0.75589	Main MSE (x10^-2): 75.5888	LR: 9.04e-05	EMPP_Raw: 1.48878
2025-07-18 11:20:14,643 - logger.py:50 - Epoch: [344][5/6]	Total Loss: 0.74368	Main MSE (x10^-2): 74.3683	LR: 9.04e-05	EMPP_Raw: 1.46383
2025-07-18 11:20:14,687 - logger.py:50 - Epoch 344 Training Summary: Avg Total Loss: 0.74368, Avg Main MSE: 0.74368, Time: 16.95s
2025-07-18 11:20:32,513 - logger.py:50 - Epoch 344 Summary | Train MSE (x10^-2): 74.3683 | Val MSE (x10^-2): 79.5807 | Time: 34.78s
2025-07-18 11:20:35,557 - logger.py:50 - Epoch: [345][0/6]	Total Loss: 0.75003	Main MSE (x10^-2): 75.0031	LR: 8.94e-05	EMPP_Raw: 1.47792
2025-07-18 11:20:49,460 - logger.py:50 - Epoch: [345][5/6]	Total Loss: 0.73511	Main MSE (x10^-2): 73.5107	LR: 8.94e-05	EMPP_Raw: 1.44708
2025-07-18 11:20:49,509 - logger.py:50 - Epoch 345 Training Summary: Avg Total Loss: 0.73511, Avg Main MSE: 0.73511, Time: 16.99s
2025-07-18 11:21:07,465 - logger.py:50 - Epoch 345 Summary | Train MSE (x10^-2): 73.5107 | Val MSE (x10^-2): 79.2413 | Time: 34.95s
2025-07-18 11:21:10,469 - logger.py:50 - Epoch: [346][0/6]	Total Loss: 0.74978	Main MSE (x10^-2): 74.9783	LR: 8.84e-05	EMPP_Raw: 1.47704
2025-07-18 11:21:24,384 - logger.py:50 - Epoch: [346][5/6]	Total Loss: 0.75148	Main MSE (x10^-2): 75.1476	LR: 8.84e-05	EMPP_Raw: 1.47945
2025-07-18 11:21:24,426 - logger.py:50 - Epoch 346 Training Summary: Avg Total Loss: 0.75148, Avg Main MSE: 0.75148, Time: 16.95s
2025-07-18 11:21:42,333 - logger.py:50 - Epoch 346 Summary | Train MSE (x10^-2): 75.1476 | Val MSE (x10^-2): 79.5903 | Time: 34.86s
2025-07-18 11:21:45,377 - logger.py:50 - Epoch: [347][0/6]	Total Loss: 0.75625	Main MSE (x10^-2): 75.6247	LR: 8.73e-05	EMPP_Raw: 1.49153
2025-07-18 11:21:59,128 - logger.py:50 - Epoch: [347][5/6]	Total Loss: 0.74581	Main MSE (x10^-2): 74.5811	LR: 8.73e-05	EMPP_Raw: 1.46779
2025-07-18 11:21:59,168 - logger.py:50 - Epoch 347 Training Summary: Avg Total Loss: 0.74581, Avg Main MSE: 0.74581, Time: 16.82s
2025-07-18 11:22:17,146 - logger.py:50 - Epoch 347 Summary | Train MSE (x10^-2): 74.5811 | Val MSE (x10^-2): 79.5019 | Time: 34.81s
2025-07-18 11:22:20,338 - logger.py:50 - Epoch: [348][0/6]	Total Loss: 0.75233	Main MSE (x10^-2): 75.2333	LR: 8.63e-05	EMPP_Raw: 1.47756
2025-07-18 11:22:34,085 - logger.py:50 - Epoch: [348][5/6]	Total Loss: 0.74548	Main MSE (x10^-2): 74.5476	LR: 8.63e-05	EMPP_Raw: 1.46725
2025-07-18 11:22:34,132 - logger.py:50 - Epoch 348 Training Summary: Avg Total Loss: 0.74548, Avg Main MSE: 0.74548, Time: 16.98s
2025-07-18 11:22:52,098 - logger.py:50 - Epoch 348 Summary | Train MSE (x10^-2): 74.5476 | Val MSE (x10^-2): 78.9244 | Time: 34.95s
2025-07-18 11:22:55,269 - logger.py:50 - Epoch: [349][0/6]	Total Loss: 0.74666	Main MSE (x10^-2): 74.6658	LR: 8.53e-05	EMPP_Raw: 1.47172
2025-07-18 11:23:09,017 - logger.py:50 - Epoch: [349][5/6]	Total Loss: 0.73791	Main MSE (x10^-2): 73.7906	LR: 8.53e-05	EMPP_Raw: 1.45198
2025-07-18 11:23:09,060 - logger.py:50 - Epoch 349 Training Summary: Avg Total Loss: 0.73791, Avg Main MSE: 0.73791, Time: 16.95s
2025-07-18 11:23:26,978 - logger.py:50 - Epoch 349 Summary | Train MSE (x10^-2): 73.7906 | Val MSE (x10^-2): 80.0014 | Time: 34.87s
2025-07-18 11:23:30,015 - logger.py:50 - Epoch: [350][0/6]	Total Loss: 0.75370	Main MSE (x10^-2): 75.3704	LR: 8.43e-05	EMPP_Raw: 1.48685
2025-07-18 11:23:43,919 - logger.py:50 - Epoch: [350][5/6]	Total Loss: 0.74538	Main MSE (x10^-2): 74.5384	LR: 8.43e-05	EMPP_Raw: 1.46775
2025-07-18 11:23:43,964 - logger.py:50 - Epoch 350 Training Summary: Avg Total Loss: 0.74538, Avg Main MSE: 0.74538, Time: 16.97s
2025-07-18 11:24:01,843 - logger.py:50 - Epoch 350 Summary | Train MSE (x10^-2): 74.5384 | Val MSE (x10^-2): 80.6157 | Time: 34.86s
2025-07-18 11:24:04,857 - logger.py:50 - Epoch: [351][0/6]	Total Loss: 0.72611	Main MSE (x10^-2): 72.6112	LR: 8.32e-05	EMPP_Raw: 1.42833
2025-07-18 11:24:18,749 - logger.py:50 - Epoch: [351][5/6]	Total Loss: 0.72678	Main MSE (x10^-2): 72.6780	LR: 8.32e-05	EMPP_Raw: 1.42921
2025-07-18 11:24:18,797 - logger.py:50 - Epoch 351 Training Summary: Avg Total Loss: 0.72678, Avg Main MSE: 0.72678, Time: 16.95s
2025-07-18 11:24:37,079 - logger.py:50 - Epoch 351 Summary | Train MSE (x10^-2): 72.6780 | Val MSE (x10^-2): 80.5779 | Time: 35.23s
2025-07-18 11:24:40,107 - logger.py:50 - Epoch: [352][0/6]	Total Loss: 0.74400	Main MSE (x10^-2): 74.3997	LR: 8.22e-05	EMPP_Raw: 1.46455
2025-07-18 11:24:54,002 - logger.py:50 - Epoch: [352][5/6]	Total Loss: 0.73369	Main MSE (x10^-2): 73.3694	LR: 8.22e-05	EMPP_Raw: 1.44411
2025-07-18 11:24:54,057 - logger.py:50 - Epoch 352 Training Summary: Avg Total Loss: 0.73369, Avg Main MSE: 0.73369, Time: 16.97s
2025-07-18 11:25:12,104 - logger.py:50 - Epoch 352 Summary | Train MSE (x10^-2): 73.3694 | Val MSE (x10^-2): 80.0894 | Time: 35.02s
2025-07-18 11:25:15,326 - logger.py:50 - Epoch: [353][0/6]	Total Loss: 0.75182	Main MSE (x10^-2): 75.1822	LR: 8.12e-05	EMPP_Raw: 1.47832
2025-07-18 11:25:29,329 - logger.py:50 - Epoch: [353][5/6]	Total Loss: 0.74152	Main MSE (x10^-2): 74.1515	LR: 8.12e-05	EMPP_Raw: 1.45997
2025-07-18 11:25:29,378 - logger.py:50 - Epoch 353 Training Summary: Avg Total Loss: 0.74152, Avg Main MSE: 0.74152, Time: 17.26s
2025-07-18 11:25:47,659 - logger.py:50 - Epoch 353 Summary | Train MSE (x10^-2): 74.1515 | Val MSE (x10^-2): 79.2707 | Time: 35.55s
2025-07-18 11:25:50,681 - logger.py:50 - Epoch: [354][0/6]	Total Loss: 0.74672	Main MSE (x10^-2): 74.6715	LR: 8.02e-05	EMPP_Raw: 1.47076
2025-07-18 11:26:04,716 - logger.py:50 - Epoch: [354][5/6]	Total Loss: 0.73333	Main MSE (x10^-2): 73.3335	LR: 8.02e-05	EMPP_Raw: 1.44318
2025-07-18 11:26:04,780 - logger.py:50 - Epoch 354 Training Summary: Avg Total Loss: 0.73333, Avg Main MSE: 0.73333, Time: 17.11s
2025-07-18 11:26:22,898 - logger.py:50 - Epoch 354 Summary | Train MSE (x10^-2): 73.3335 | Val MSE (x10^-2): 79.0721 | Time: 35.23s
2025-07-18 11:26:25,935 - logger.py:50 - Epoch: [355][0/6]	Total Loss: 0.75103	Main MSE (x10^-2): 75.1031	LR: 7.92e-05	EMPP_Raw: 1.48006
2025-07-18 11:26:39,816 - logger.py:50 - Epoch: [355][5/6]	Total Loss: 0.73755	Main MSE (x10^-2): 73.7549	LR: 7.92e-05	EMPP_Raw: 1.45255
2025-07-18 11:26:39,860 - logger.py:50 - Epoch 355 Training Summary: Avg Total Loss: 0.73755, Avg Main MSE: 0.73755, Time: 16.95s
2025-07-18 11:26:57,959 - logger.py:50 - Epoch 355 Summary | Train MSE (x10^-2): 73.7549 | Val MSE (x10^-2): 80.2255 | Time: 35.05s
2025-07-18 11:27:00,972 - logger.py:50 - Epoch: [356][0/6]	Total Loss: 0.74049	Main MSE (x10^-2): 74.0494	LR: 7.82e-05	EMPP_Raw: 1.45815
2025-07-18 11:27:14,817 - logger.py:50 - Epoch: [356][5/6]	Total Loss: 0.73432	Main MSE (x10^-2): 73.4319	LR: 7.82e-05	EMPP_Raw: 1.44545
2025-07-18 11:27:14,860 - logger.py:50 - Epoch 356 Training Summary: Avg Total Loss: 0.73432, Avg Main MSE: 0.73432, Time: 16.90s
2025-07-18 11:27:33,013 - logger.py:50 - Epoch 356 Summary | Train MSE (x10^-2): 73.4319 | Val MSE (x10^-2): 79.9363 | Time: 35.05s
2025-07-18 11:27:36,016 - logger.py:50 - Epoch: [357][0/6]	Total Loss: 0.75452	Main MSE (x10^-2): 75.4519	LR: 7.72e-05	EMPP_Raw: 1.48613
2025-07-18 11:27:49,809 - logger.py:50 - Epoch: [357][5/6]	Total Loss: 0.73219	Main MSE (x10^-2): 73.2194	LR: 7.72e-05	EMPP_Raw: 1.44145
2025-07-18 11:27:49,856 - logger.py:50 - Epoch 357 Training Summary: Avg Total Loss: 0.73219, Avg Main MSE: 0.73219, Time: 16.83s
2025-07-18 11:28:07,835 - logger.py:50 - Epoch 357 Summary | Train MSE (x10^-2): 73.2194 | Val MSE (x10^-2): 77.7408 | Time: 34.82s
2025-07-18 11:28:11,211 - logger.py:50 - Epoch: [358][0/6]	Total Loss: 0.73982	Main MSE (x10^-2): 73.9817	LR: 7.63e-05	EMPP_Raw: 1.45520
2025-07-18 11:28:25,009 - logger.py:50 - Epoch: [358][5/6]	Total Loss: 0.73886	Main MSE (x10^-2): 73.8859	LR: 7.63e-05	EMPP_Raw: 1.45521
2025-07-18 11:28:25,065 - logger.py:50 - Epoch 358 Training Summary: Avg Total Loss: 0.73886, Avg Main MSE: 0.73886, Time: 17.22s
2025-07-18 11:28:42,925 - logger.py:50 - Epoch 358 Summary | Train MSE (x10^-2): 73.8859 | Val MSE (x10^-2): 79.4896 | Time: 35.08s
2025-07-18 11:28:46,090 - logger.py:50 - Epoch: [359][0/6]	Total Loss: 0.71260	Main MSE (x10^-2): 71.2602	LR: 7.53e-05	EMPP_Raw: 1.40383
2025-07-18 11:28:59,859 - logger.py:50 - Epoch: [359][5/6]	Total Loss: 0.74142	Main MSE (x10^-2): 74.1416	LR: 7.53e-05	EMPP_Raw: 1.46118
2025-07-18 11:28:59,904 - logger.py:50 - Epoch 359 Training Summary: Avg Total Loss: 0.74142, Avg Main MSE: 0.74142, Time: 16.97s
2025-07-18 11:29:17,850 - logger.py:50 - Epoch 359 Summary | Train MSE (x10^-2): 74.1416 | Val MSE (x10^-2): 79.5124 | Time: 34.92s
2025-07-18 11:29:20,858 - logger.py:50 - Epoch: [360][0/6]	Total Loss: 0.74418	Main MSE (x10^-2): 74.4177	LR: 7.43e-05	EMPP_Raw: 1.46391
2025-07-18 11:29:34,825 - logger.py:50 - Epoch: [360][5/6]	Total Loss: 0.74017	Main MSE (x10^-2): 74.0171	LR: 7.43e-05	EMPP_Raw: 1.45719
2025-07-18 11:29:34,866 - logger.py:50 - Epoch 360 Training Summary: Avg Total Loss: 0.74017, Avg Main MSE: 0.74017, Time: 17.01s
2025-07-18 11:29:52,711 - logger.py:50 - Epoch 360 Summary | Train MSE (x10^-2): 74.0171 | Val MSE (x10^-2): 78.8095 | Time: 34.85s
2025-07-18 11:29:55,784 - logger.py:50 - Epoch: [361][0/6]	Total Loss: 0.73449	Main MSE (x10^-2): 73.4489	LR: 7.33e-05	EMPP_Raw: 1.44672
2025-07-18 11:30:09,565 - logger.py:50 - Epoch: [361][5/6]	Total Loss: 0.72706	Main MSE (x10^-2): 72.7063	LR: 7.33e-05	EMPP_Raw: 1.43226
2025-07-18 11:30:09,606 - logger.py:50 - Epoch 361 Training Summary: Avg Total Loss: 0.72706, Avg Main MSE: 0.72706, Time: 16.89s
2025-07-18 11:30:27,713 - logger.py:50 - Epoch 361 Summary | Train MSE (x10^-2): 72.7063 | Val MSE (x10^-2): 79.3652 | Time: 35.00s
2025-07-18 11:30:30,773 - logger.py:50 - Epoch: [362][0/6]	Total Loss: 0.73091	Main MSE (x10^-2): 73.0914	LR: 7.24e-05	EMPP_Raw: 1.43957
2025-07-18 11:30:44,701 - logger.py:50 - Epoch: [362][5/6]	Total Loss: 0.73208	Main MSE (x10^-2): 73.2085	LR: 7.24e-05	EMPP_Raw: 1.44251
2025-07-18 11:30:44,753 - logger.py:50 - Epoch 362 Training Summary: Avg Total Loss: 0.73208, Avg Main MSE: 0.73208, Time: 17.03s
2025-07-18 11:31:02,844 - logger.py:50 - Epoch 362 Summary | Train MSE (x10^-2): 73.2085 | Val MSE (x10^-2): 79.1548 | Time: 35.13s
2025-07-18 11:31:05,853 - logger.py:50 - Epoch: [363][0/6]	Total Loss: 0.73432	Main MSE (x10^-2): 73.4318	LR: 7.14e-05	EMPP_Raw: 1.44554
2025-07-18 11:31:19,671 - logger.py:50 - Epoch: [363][5/6]	Total Loss: 0.73652	Main MSE (x10^-2): 73.6525	LR: 7.14e-05	EMPP_Raw: 1.45085
2025-07-18 11:31:19,712 - logger.py:50 - Epoch 363 Training Summary: Avg Total Loss: 0.73652, Avg Main MSE: 0.73652, Time: 16.86s
2025-07-18 11:31:37,613 - logger.py:50 - Epoch 363 Summary | Train MSE (x10^-2): 73.6525 | Val MSE (x10^-2): 78.6324 | Time: 34.76s
2025-07-18 11:31:40,794 - logger.py:50 - Epoch: [364][0/6]	Total Loss: 0.75236	Main MSE (x10^-2): 75.2358	LR: 7.05e-05	EMPP_Raw: 1.48059
2025-07-18 11:31:54,636 - logger.py:50 - Epoch: [364][5/6]	Total Loss: 0.74179	Main MSE (x10^-2): 74.1792	LR: 7.05e-05	EMPP_Raw: 1.46199
2025-07-18 11:31:54,684 - logger.py:50 - Epoch 364 Training Summary: Avg Total Loss: 0.74179, Avg Main MSE: 0.74179, Time: 17.06s
2025-07-18 11:32:12,614 - logger.py:50 - Epoch 364 Summary | Train MSE (x10^-2): 74.1792 | Val MSE (x10^-2): 79.6096 | Time: 34.99s
2025-07-18 11:32:15,653 - logger.py:50 - Epoch: [365][0/6]	Total Loss: 0.72786	Main MSE (x10^-2): 72.7863	LR: 6.95e-05	EMPP_Raw: 1.43406
2025-07-18 11:32:29,647 - logger.py:50 - Epoch: [365][5/6]	Total Loss: 0.73917	Main MSE (x10^-2): 73.9168	LR: 6.95e-05	EMPP_Raw: 1.45654
2025-07-18 11:32:29,691 - logger.py:50 - Epoch 365 Training Summary: Avg Total Loss: 0.73917, Avg Main MSE: 0.73917, Time: 17.07s
2025-07-18 11:32:47,613 - logger.py:50 - Epoch 365 Summary | Train MSE (x10^-2): 73.9168 | Val MSE (x10^-2): 79.0819 | Time: 34.99s
2025-07-18 11:32:50,623 - logger.py:50 - Epoch: [366][0/6]	Total Loss: 0.72954	Main MSE (x10^-2): 72.9537	LR: 6.86e-05	EMPP_Raw: 1.43753
2025-07-18 11:33:04,598 - logger.py:50 - Epoch: [366][5/6]	Total Loss: 0.73901	Main MSE (x10^-2): 73.9007	LR: 6.86e-05	EMPP_Raw: 1.45614
2025-07-18 11:33:04,642 - logger.py:50 - Epoch 366 Training Summary: Avg Total Loss: 0.73901, Avg Main MSE: 0.73901, Time: 17.02s
2025-07-18 11:33:22,552 - logger.py:50 - Epoch 366 Summary | Train MSE (x10^-2): 73.9007 | Val MSE (x10^-2): 79.0996 | Time: 34.93s
2025-07-18 11:33:25,563 - logger.py:50 - Epoch: [367][0/6]	Total Loss: 0.73353	Main MSE (x10^-2): 73.3525	LR: 6.76e-05	EMPP_Raw: 1.44590
2025-07-18 11:33:39,378 - logger.py:50 - Epoch: [367][5/6]	Total Loss: 0.74925	Main MSE (x10^-2): 74.9254	LR: 6.76e-05	EMPP_Raw: 1.47673
2025-07-18 11:33:39,424 - logger.py:50 - Epoch 367 Training Summary: Avg Total Loss: 0.74925, Avg Main MSE: 0.74925, Time: 16.86s
2025-07-18 11:33:57,418 - logger.py:50 - Epoch 367 Summary | Train MSE (x10^-2): 74.9254 | Val MSE (x10^-2): 79.1763 | Time: 34.86s
2025-07-18 11:34:00,615 - logger.py:50 - Epoch: [368][0/6]	Total Loss: 0.74068	Main MSE (x10^-2): 74.0675	LR: 6.67e-05	EMPP_Raw: 1.45796
2025-07-18 11:34:14,421 - logger.py:50 - Epoch: [368][5/6]	Total Loss: 0.72503	Main MSE (x10^-2): 72.5027	LR: 6.67e-05	EMPP_Raw: 1.42819
2025-07-18 11:34:14,464 - logger.py:50 - Epoch 368 Training Summary: Avg Total Loss: 0.72503, Avg Main MSE: 0.72503, Time: 17.04s
2025-07-18 11:34:32,502 - logger.py:50 - Epoch 368 Summary | Train MSE (x10^-2): 72.5027 | Val MSE (x10^-2): 78.9564 | Time: 35.08s
2025-07-18 11:34:35,729 - logger.py:50 - Epoch: [369][0/6]	Total Loss: 0.72127	Main MSE (x10^-2): 72.1270	LR: 6.58e-05	EMPP_Raw: 1.42209
2025-07-18 11:34:49,498 - logger.py:50 - Epoch: [369][5/6]	Total Loss: 0.73621	Main MSE (x10^-2): 73.6208	LR: 6.58e-05	EMPP_Raw: 1.45142
2025-07-18 11:34:49,543 - logger.py:50 - Epoch 369 Training Summary: Avg Total Loss: 0.73621, Avg Main MSE: 0.73621, Time: 17.03s
2025-07-18 11:35:07,470 - logger.py:50 - Epoch 369 Summary | Train MSE (x10^-2): 73.6208 | Val MSE (x10^-2): 78.8825 | Time: 34.96s
2025-07-18 11:35:10,474 - logger.py:50 - Epoch: [370][0/6]	Total Loss: 0.73570	Main MSE (x10^-2): 73.5703	LR: 6.48e-05	EMPP_Raw: 1.44917
2025-07-18 11:35:24,436 - logger.py:50 - Epoch: [370][5/6]	Total Loss: 0.72906	Main MSE (x10^-2): 72.9063	LR: 6.48e-05	EMPP_Raw: 1.43626
2025-07-18 11:35:24,483 - logger.py:50 - Epoch 370 Training Summary: Avg Total Loss: 0.72906, Avg Main MSE: 0.72906, Time: 17.00s
2025-07-18 11:35:42,451 - logger.py:50 - Epoch 370 Summary | Train MSE (x10^-2): 72.9063 | Val MSE (x10^-2): 79.9313 | Time: 34.97s
2025-07-18 11:35:45,452 - logger.py:50 - Epoch: [371][0/6]	Total Loss: 0.73792	Main MSE (x10^-2): 73.7919	LR: 6.39e-05	EMPP_Raw: 1.45712
2025-07-18 11:35:59,261 - logger.py:50 - Epoch: [371][5/6]	Total Loss: 0.74876	Main MSE (x10^-2): 74.8762	LR: 6.39e-05	EMPP_Raw: 1.47621
2025-07-18 11:35:59,302 - logger.py:50 - Epoch 371 Training Summary: Avg Total Loss: 0.74876, Avg Main MSE: 0.74876, Time: 16.84s
2025-07-18 11:36:17,357 - logger.py:50 - Epoch 371 Summary | Train MSE (x10^-2): 74.8762 | Val MSE (x10^-2): 79.6283 | Time: 34.90s
2025-07-18 11:36:20,400 - logger.py:50 - Epoch: [372][0/6]	Total Loss: 0.71575	Main MSE (x10^-2): 71.5748	LR: 6.30e-05	EMPP_Raw: 1.40913
2025-07-18 11:36:34,220 - logger.py:50 - Epoch: [372][5/6]	Total Loss: 0.73191	Main MSE (x10^-2): 73.1909	LR: 6.30e-05	EMPP_Raw: 1.44213
2025-07-18 11:36:34,262 - logger.py:50 - Epoch 372 Training Summary: Avg Total Loss: 0.73191, Avg Main MSE: 0.73191, Time: 16.90s
2025-07-18 11:36:52,072 - logger.py:50 - Epoch 372 Summary | Train MSE (x10^-2): 73.1909 | Val MSE (x10^-2): 79.4320 | Time: 34.71s
2025-07-18 11:36:55,231 - logger.py:50 - Epoch: [373][0/6]	Total Loss: 0.73542	Main MSE (x10^-2): 73.5416	LR: 6.21e-05	EMPP_Raw: 1.44901
2025-07-18 11:37:09,020 - logger.py:50 - Epoch: [373][5/6]	Total Loss: 0.73165	Main MSE (x10^-2): 73.1655	LR: 6.21e-05	EMPP_Raw: 1.44148
2025-07-18 11:37:09,067 - logger.py:50 - Epoch 373 Training Summary: Avg Total Loss: 0.73165, Avg Main MSE: 0.73165, Time: 16.99s
2025-07-18 11:37:26,956 - logger.py:50 - Epoch 373 Summary | Train MSE (x10^-2): 73.1655 | Val MSE (x10^-2): 79.6401 | Time: 34.88s
2025-07-18 11:37:29,967 - logger.py:50 - Epoch: [374][0/6]	Total Loss: 0.73432	Main MSE (x10^-2): 73.4322	LR: 6.12e-05	EMPP_Raw: 1.44858
2025-07-18 11:37:43,917 - logger.py:50 - Epoch: [374][5/6]	Total Loss: 0.74289	Main MSE (x10^-2): 74.2890	LR: 6.12e-05	EMPP_Raw: 1.46483
2025-07-18 11:37:43,958 - logger.py:50 - Epoch 374 Training Summary: Avg Total Loss: 0.74289, Avg Main MSE: 0.74289, Time: 17.00s
2025-07-18 11:38:01,906 - logger.py:50 - Epoch 374 Summary | Train MSE (x10^-2): 74.2890 | Val MSE (x10^-2): 79.7970 | Time: 34.95s
2025-07-18 11:38:04,959 - logger.py:50 - Epoch: [375][0/6]	Total Loss: 0.71937	Main MSE (x10^-2): 71.9369	LR: 6.03e-05	EMPP_Raw: 1.42094
2025-07-18 11:38:18,842 - logger.py:50 - Epoch: [375][5/6]	Total Loss: 0.73350	Main MSE (x10^-2): 73.3501	LR: 6.03e-05	EMPP_Raw: 1.44622
2025-07-18 11:38:18,883 - logger.py:50 - Epoch 375 Training Summary: Avg Total Loss: 0.73350, Avg Main MSE: 0.73350, Time: 16.97s
2025-07-18 11:38:36,948 - logger.py:50 - Epoch 375 Summary | Train MSE (x10^-2): 73.3501 | Val MSE (x10^-2): 79.8350 | Time: 35.04s
2025-07-18 11:38:39,999 - logger.py:50 - Epoch: [376][0/6]	Total Loss: 0.73952	Main MSE (x10^-2): 73.9515	LR: 5.94e-05	EMPP_Raw: 1.46032
2025-07-18 11:38:53,776 - logger.py:50 - Epoch: [376][5/6]	Total Loss: 0.74486	Main MSE (x10^-2): 74.4856	LR: 5.94e-05	EMPP_Raw: 1.46846
2025-07-18 11:38:53,820 - logger.py:50 - Epoch 376 Training Summary: Avg Total Loss: 0.74486, Avg Main MSE: 0.74486, Time: 16.86s
2025-07-18 11:39:11,813 - logger.py:50 - Epoch 376 Summary | Train MSE (x10^-2): 74.4856 | Val MSE (x10^-2): 79.8298 | Time: 34.86s
2025-07-18 11:39:14,847 - logger.py:50 - Epoch: [377][0/6]	Total Loss: 0.74430	Main MSE (x10^-2): 74.4297	LR: 5.85e-05	EMPP_Raw: 1.46820
2025-07-18 11:39:28,647 - logger.py:50 - Epoch: [377][5/6]	Total Loss: 0.74139	Main MSE (x10^-2): 74.1388	LR: 5.85e-05	EMPP_Raw: 1.46199
2025-07-18 11:39:28,688 - logger.py:50 - Epoch 377 Training Summary: Avg Total Loss: 0.74139, Avg Main MSE: 0.74139, Time: 16.87s
2025-07-18 11:39:46,513 - logger.py:50 - Epoch 377 Summary | Train MSE (x10^-2): 74.1388 | Val MSE (x10^-2): 78.9860 | Time: 34.69s
2025-07-18 11:39:49,885 - logger.py:50 - Epoch: [378][0/6]	Total Loss: 0.73552	Main MSE (x10^-2): 73.5524	LR: 5.77e-05	EMPP_Raw: 1.45059
2025-07-18 11:40:03,714 - logger.py:50 - Epoch: [378][5/6]	Total Loss: 0.72300	Main MSE (x10^-2): 72.2998	LR: 5.77e-05	EMPP_Raw: 1.42540
2025-07-18 11:40:03,768 - logger.py:50 - Epoch 378 Training Summary: Avg Total Loss: 0.72300, Avg Main MSE: 0.72300, Time: 17.25s
2025-07-18 11:40:21,691 - logger.py:50 - Epoch 378 Summary | Train MSE (x10^-2): 72.2998 | Val MSE (x10^-2): 79.7336 | Time: 35.17s
2025-07-18 11:40:24,853 - logger.py:50 - Epoch: [379][0/6]	Total Loss: 0.74465	Main MSE (x10^-2): 74.4652	LR: 5.68e-05	EMPP_Raw: 1.47050
2025-07-18 11:40:38,566 - logger.py:50 - Epoch: [379][5/6]	Total Loss: 0.74025	Main MSE (x10^-2): 74.0252	LR: 5.68e-05	EMPP_Raw: 1.45993
2025-07-18 11:40:38,615 - logger.py:50 - Epoch 379 Training Summary: Avg Total Loss: 0.74025, Avg Main MSE: 0.74025, Time: 16.91s
2025-07-18 11:40:56,576 - logger.py:50 - Epoch 379 Summary | Train MSE (x10^-2): 74.0252 | Val MSE (x10^-2): 79.8004 | Time: 34.88s
2025-07-18 11:40:59,599 - logger.py:50 - Epoch: [380][0/6]	Total Loss: 0.72630	Main MSE (x10^-2): 72.6303	LR: 5.59e-05	EMPP_Raw: 1.43117
2025-07-18 11:41:13,511 - logger.py:50 - Epoch: [380][5/6]	Total Loss: 0.73333	Main MSE (x10^-2): 73.3330	LR: 5.59e-05	EMPP_Raw: 1.44567
2025-07-18 11:41:13,557 - logger.py:50 - Epoch 380 Training Summary: Avg Total Loss: 0.73333, Avg Main MSE: 0.73333, Time: 16.97s
2025-07-18 11:41:31,482 - logger.py:50 - Epoch 380 Summary | Train MSE (x10^-2): 73.3330 | Val MSE (x10^-2): 79.1547 | Time: 34.90s
2025-07-18 11:41:34,480 - logger.py:50 - Epoch: [381][0/6]	Total Loss: 0.73011	Main MSE (x10^-2): 73.0105	LR: 5.51e-05	EMPP_Raw: 1.44017
2025-07-18 11:41:48,253 - logger.py:50 - Epoch: [381][5/6]	Total Loss: 0.74200	Main MSE (x10^-2): 74.2002	LR: 5.51e-05	EMPP_Raw: 1.46267
2025-07-18 11:41:48,296 - logger.py:50 - Epoch 381 Training Summary: Avg Total Loss: 0.74200, Avg Main MSE: 0.74200, Time: 16.81s
2025-07-18 11:42:06,347 - logger.py:50 - Epoch 381 Summary | Train MSE (x10^-2): 74.2002 | Val MSE (x10^-2): 79.1294 | Time: 34.86s
2025-07-18 11:42:09,343 - logger.py:50 - Epoch: [382][0/6]	Total Loss: 0.72571	Main MSE (x10^-2): 72.5713	LR: 5.42e-05	EMPP_Raw: 1.43177
2025-07-18 11:42:23,136 - logger.py:50 - Epoch: [382][5/6]	Total Loss: 0.73345	Main MSE (x10^-2): 73.3453	LR: 5.42e-05	EMPP_Raw: 1.44542
2025-07-18 11:42:23,178 - logger.py:50 - Epoch 382 Training Summary: Avg Total Loss: 0.73345, Avg Main MSE: 0.73345, Time: 16.82s
2025-07-18 11:42:41,289 - logger.py:50 - Epoch 382 Summary | Train MSE (x10^-2): 73.3453 | Val MSE (x10^-2): 79.0855 | Time: 34.94s
2025-07-18 11:42:44,335 - logger.py:50 - Epoch: [383][0/6]	Total Loss: 0.73465	Main MSE (x10^-2): 73.4648	LR: 5.34e-05	EMPP_Raw: 1.44995
2025-07-18 11:42:58,158 - logger.py:50 - Epoch: [383][5/6]	Total Loss: 0.73943	Main MSE (x10^-2): 73.9433	LR: 5.34e-05	EMPP_Raw: 1.45865
2025-07-18 11:42:58,201 - logger.py:50 - Epoch 383 Training Summary: Avg Total Loss: 0.73943, Avg Main MSE: 0.73943, Time: 16.91s
2025-07-18 11:43:16,110 - logger.py:50 - Epoch 383 Summary | Train MSE (x10^-2): 73.9433 | Val MSE (x10^-2): 79.8454 | Time: 34.82s
2025-07-18 11:43:19,272 - logger.py:50 - Epoch: [384][0/6]	Total Loss: 0.74097	Main MSE (x10^-2): 74.0971	LR: 5.25e-05	EMPP_Raw: 1.46168
2025-07-18 11:43:32,965 - logger.py:50 - Epoch: [384][5/6]	Total Loss: 0.74605	Main MSE (x10^-2): 74.6051	LR: 5.25e-05	EMPP_Raw: 1.47140
2025-07-18 11:43:33,009 - logger.py:50 - Epoch 384 Training Summary: Avg Total Loss: 0.74605, Avg Main MSE: 0.74605, Time: 16.89s
2025-07-18 11:43:50,951 - logger.py:50 - Epoch 384 Summary | Train MSE (x10^-2): 74.6051 | Val MSE (x10^-2): 79.0576 | Time: 34.84s
2025-07-18 11:43:53,982 - logger.py:50 - Epoch: [385][0/6]	Total Loss: 0.71952	Main MSE (x10^-2): 71.9523	LR: 5.17e-05	EMPP_Raw: 1.41963
2025-07-18 11:44:07,888 - logger.py:50 - Epoch: [385][5/6]	Total Loss: 0.73679	Main MSE (x10^-2): 73.6789	LR: 5.17e-05	EMPP_Raw: 1.45344
2025-07-18 11:44:07,928 - logger.py:50 - Epoch 385 Training Summary: Avg Total Loss: 0.73679, Avg Main MSE: 0.73679, Time: 16.97s
2025-07-18 11:44:25,973 - logger.py:50 - Epoch 385 Summary | Train MSE (x10^-2): 73.6789 | Val MSE (x10^-2): 79.4674 | Time: 35.02s
2025-07-18 11:44:28,996 - logger.py:50 - Epoch: [386][0/6]	Total Loss: 0.74528	Main MSE (x10^-2): 74.5279	LR: 5.09e-05	EMPP_Raw: 1.46550
2025-07-18 11:44:42,954 - logger.py:50 - Epoch: [386][5/6]	Total Loss: 0.73765	Main MSE (x10^-2): 73.7653	LR: 5.09e-05	EMPP_Raw: 1.45416
2025-07-18 11:44:43,000 - logger.py:50 - Epoch 386 Training Summary: Avg Total Loss: 0.73765, Avg Main MSE: 0.73765, Time: 17.02s
2025-07-18 11:45:00,976 - logger.py:50 - Epoch 386 Summary | Train MSE (x10^-2): 73.7653 | Val MSE (x10^-2): 79.2911 | Time: 35.00s
2025-07-18 11:45:03,976 - logger.py:50 - Epoch: [387][0/6]	Total Loss: 0.71090	Main MSE (x10^-2): 71.0901	LR: 5.00e-05	EMPP_Raw: 1.40199
2025-07-18 11:45:17,799 - logger.py:50 - Epoch: [387][5/6]	Total Loss: 0.72814	Main MSE (x10^-2): 72.8138	LR: 5.00e-05	EMPP_Raw: 1.43613
2025-07-18 11:45:17,844 - logger.py:50 - Epoch 387 Training Summary: Avg Total Loss: 0.72814, Avg Main MSE: 0.72814, Time: 16.86s
2025-07-18 11:45:35,873 - logger.py:50 - Epoch 387 Summary | Train MSE (x10^-2): 72.8138 | Val MSE (x10^-2): 79.2779 | Time: 34.89s
2025-07-18 11:45:39,043 - logger.py:50 - Epoch: [388][0/6]	Total Loss: 0.73814	Main MSE (x10^-2): 73.8141	LR: 4.92e-05	EMPP_Raw: 1.45542
2025-07-18 11:45:52,817 - logger.py:50 - Epoch: [388][5/6]	Total Loss: 0.74154	Main MSE (x10^-2): 74.1543	LR: 4.92e-05	EMPP_Raw: 1.46219
2025-07-18 11:45:52,858 - logger.py:50 - Epoch 388 Training Summary: Avg Total Loss: 0.74154, Avg Main MSE: 0.74154, Time: 16.98s
2025-07-18 11:46:10,788 - logger.py:50 - Epoch 388 Summary | Train MSE (x10^-2): 74.1543 | Val MSE (x10^-2): 78.7847 | Time: 34.91s
2025-07-18 11:46:13,956 - logger.py:50 - Epoch: [389][0/6]	Total Loss: 0.74073	Main MSE (x10^-2): 74.0733	LR: 4.84e-05	EMPP_Raw: 1.45897
2025-07-18 11:46:27,739 - logger.py:50 - Epoch: [389][5/6]	Total Loss: 0.73186	Main MSE (x10^-2): 73.1861	LR: 4.84e-05	EMPP_Raw: 1.44383
2025-07-18 11:46:27,785 - logger.py:50 - Epoch 389 Training Summary: Avg Total Loss: 0.73186, Avg Main MSE: 0.73186, Time: 16.99s
2025-07-18 11:46:45,647 - logger.py:50 - Epoch 389 Summary | Train MSE (x10^-2): 73.1861 | Val MSE (x10^-2): 79.5464 | Time: 34.85s
2025-07-18 11:46:48,657 - logger.py:50 - Epoch: [390][0/6]	Total Loss: 0.73992	Main MSE (x10^-2): 73.9915	LR: 4.76e-05	EMPP_Raw: 1.46062
2025-07-18 11:47:02,633 - logger.py:50 - Epoch: [390][5/6]	Total Loss: 0.73300	Main MSE (x10^-2): 73.3002	LR: 4.76e-05	EMPP_Raw: 1.44614
2025-07-18 11:47:02,678 - logger.py:50 - Epoch 390 Training Summary: Avg Total Loss: 0.73300, Avg Main MSE: 0.73300, Time: 17.02s
2025-07-18 11:47:20,630 - logger.py:50 - Epoch 390 Summary | Train MSE (x10^-2): 73.3002 | Val MSE (x10^-2): 79.3031 | Time: 34.98s
2025-07-18 11:47:23,650 - logger.py:50 - Epoch: [391][0/6]	Total Loss: 0.75427	Main MSE (x10^-2): 75.4268	LR: 4.68e-05	EMPP_Raw: 1.48938
2025-07-18 11:47:37,492 - logger.py:50 - Epoch: [391][5/6]	Total Loss: 0.74009	Main MSE (x10^-2): 74.0090	LR: 4.68e-05	EMPP_Raw: 1.46027
2025-07-18 11:47:37,531 - logger.py:50 - Epoch 391 Training Summary: Avg Total Loss: 0.74009, Avg Main MSE: 0.74009, Time: 16.89s
2025-07-18 11:47:55,697 - logger.py:50 - Epoch 391 Summary | Train MSE (x10^-2): 74.0090 | Val MSE (x10^-2): 78.9402 | Time: 35.06s
2025-07-18 11:47:58,760 - logger.py:50 - Epoch: [392][0/6]	Total Loss: 0.72972	Main MSE (x10^-2): 72.9717	LR: 4.60e-05	EMPP_Raw: 1.44002
2025-07-18 11:48:12,623 - logger.py:50 - Epoch: [392][5/6]	Total Loss: 0.73493	Main MSE (x10^-2): 73.4927	LR: 4.60e-05	EMPP_Raw: 1.44991
2025-07-18 11:48:12,669 - logger.py:50 - Epoch 392 Training Summary: Avg Total Loss: 0.73493, Avg Main MSE: 0.73493, Time: 16.96s
2025-07-18 11:48:30,558 - logger.py:50 - Epoch 392 Summary | Train MSE (x10^-2): 73.4927 | Val MSE (x10^-2): 79.3144 | Time: 34.85s
2025-07-18 11:48:33,722 - logger.py:50 - Epoch: [393][0/6]	Total Loss: 0.72994	Main MSE (x10^-2): 72.9941	LR: 4.52e-05	EMPP_Raw: 1.44033
2025-07-18 11:48:47,525 - logger.py:50 - Epoch: [393][5/6]	Total Loss: 0.74729	Main MSE (x10^-2): 74.7289	LR: 4.52e-05	EMPP_Raw: 1.47479
2025-07-18 11:48:47,570 - logger.py:50 - Epoch 393 Training Summary: Avg Total Loss: 0.74729, Avg Main MSE: 0.74729, Time: 17.00s
2025-07-18 11:49:05,453 - logger.py:50 - Epoch 393 Summary | Train MSE (x10^-2): 74.7289 | Val MSE (x10^-2): 79.4582 | Time: 34.89s
2025-07-18 11:49:08,461 - logger.py:50 - Epoch: [394][0/6]	Total Loss: 0.72817	Main MSE (x10^-2): 72.8165	LR: 4.44e-05	EMPP_Raw: 1.43524
2025-07-18 11:49:22,430 - logger.py:50 - Epoch: [394][5/6]	Total Loss: 0.73288	Main MSE (x10^-2): 73.2879	LR: 4.44e-05	EMPP_Raw: 1.44536
2025-07-18 11:49:22,472 - logger.py:50 - Epoch 394 Training Summary: Avg Total Loss: 0.73288, Avg Main MSE: 0.73288, Time: 17.01s
2025-07-18 11:49:40,364 - logger.py:50 - Epoch 394 Summary | Train MSE (x10^-2): 73.2879 | Val MSE (x10^-2): 79.0780 | Time: 34.91s
2025-07-18 11:49:43,404 - logger.py:50 - Epoch: [395][0/6]	Total Loss: 0.72797	Main MSE (x10^-2): 72.7971	LR: 4.36e-05	EMPP_Raw: 1.43520
2025-07-18 11:49:57,170 - logger.py:50 - Epoch: [395][5/6]	Total Loss: 0.73196	Main MSE (x10^-2): 73.1957	LR: 4.36e-05	EMPP_Raw: 1.44435
2025-07-18 11:49:57,212 - logger.py:50 - Epoch 395 Training Summary: Avg Total Loss: 0.73196, Avg Main MSE: 0.73196, Time: 16.84s
2025-07-18 11:50:15,297 - logger.py:50 - Epoch 395 Summary | Train MSE (x10^-2): 73.1957 | Val MSE (x10^-2): 80.1120 | Time: 34.93s
2025-07-18 11:50:18,301 - logger.py:50 - Epoch: [396][0/6]	Total Loss: 0.72471	Main MSE (x10^-2): 72.4708	LR: 4.29e-05	EMPP_Raw: 1.42749
2025-07-18 11:50:32,102 - logger.py:50 - Epoch: [396][5/6]	Total Loss: 0.73891	Main MSE (x10^-2): 73.8913	LR: 4.29e-05	EMPP_Raw: 1.45732
2025-07-18 11:50:32,143 - logger.py:50 - Epoch 396 Training Summary: Avg Total Loss: 0.73891, Avg Main MSE: 0.73891, Time: 16.84s
2025-07-18 11:50:50,111 - logger.py:50 - Epoch 396 Summary | Train MSE (x10^-2): 73.8913 | Val MSE (x10^-2): 78.8086 | Time: 34.81s
2025-07-18 11:50:53,109 - logger.py:50 - Epoch: [397][0/6]	Total Loss: 0.73582	Main MSE (x10^-2): 73.5824	LR: 4.21e-05	EMPP_Raw: 1.45202
2025-07-18 11:51:06,862 - logger.py:50 - Epoch: [397][5/6]	Total Loss: 0.72941	Main MSE (x10^-2): 72.9407	LR: 4.21e-05	EMPP_Raw: 1.43978
2025-07-18 11:51:06,908 - logger.py:50 - Epoch 397 Training Summary: Avg Total Loss: 0.72941, Avg Main MSE: 0.72941, Time: 16.79s
2025-07-18 11:51:24,829 - logger.py:50 - Epoch 397 Summary | Train MSE (x10^-2): 72.9407 | Val MSE (x10^-2): 79.5824 | Time: 34.71s
2025-07-18 11:51:28,195 - logger.py:50 - Epoch: [398][0/6]	Total Loss: 0.74677	Main MSE (x10^-2): 74.6768	LR: 4.13e-05	EMPP_Raw: 1.47495
2025-07-18 11:51:41,995 - logger.py:50 - Epoch: [398][5/6]	Total Loss: 0.74617	Main MSE (x10^-2): 74.6172	LR: 4.13e-05	EMPP_Raw: 1.47260
2025-07-18 11:51:42,047 - logger.py:50 - Epoch 398 Training Summary: Avg Total Loss: 0.74617, Avg Main MSE: 0.74617, Time: 17.21s
2025-07-18 11:51:59,916 - logger.py:50 - Epoch 398 Summary | Train MSE (x10^-2): 74.6172 | Val MSE (x10^-2): 79.2304 | Time: 35.08s
2025-07-18 11:52:03,089 - logger.py:50 - Epoch: [399][0/6]	Total Loss: 0.72495	Main MSE (x10^-2): 72.4953	LR: 4.06e-05	EMPP_Raw: 1.43120
2025-07-18 11:52:16,900 - logger.py:50 - Epoch: [399][5/6]	Total Loss: 0.72895	Main MSE (x10^-2): 72.8952	LR: 4.06e-05	EMPP_Raw: 1.43806
2025-07-18 11:52:16,945 - logger.py:50 - Epoch 399 Training Summary: Avg Total Loss: 0.72895, Avg Main MSE: 0.72895, Time: 17.02s
2025-07-18 11:52:34,840 - logger.py:50 - Epoch 399 Summary | Train MSE (x10^-2): 72.8952 | Val MSE (x10^-2): 79.8393 | Time: 34.92s
2025-07-18 11:52:37,858 - logger.py:50 - Epoch: [400][0/6]	Total Loss: 0.72453	Main MSE (x10^-2): 72.4528	LR: 3.98e-05	EMPP_Raw: 1.42840
2025-07-18 11:52:51,768 - logger.py:50 - Epoch: [400][5/6]	Total Loss: 0.72885	Main MSE (x10^-2): 72.8851	LR: 3.98e-05	EMPP_Raw: 1.43807
2025-07-18 11:52:51,813 - logger.py:50 - Epoch 400 Training Summary: Avg Total Loss: 0.72885, Avg Main MSE: 0.72885, Time: 16.96s
2025-07-18 11:53:09,732 - logger.py:50 - Epoch 400 Summary | Train MSE (x10^-2): 72.8851 | Val MSE (x10^-2): 78.9205 | Time: 34.89s
2025-07-18 11:53:12,791 - logger.py:50 - Epoch: [401][0/6]	Total Loss: 0.72935	Main MSE (x10^-2): 72.9347	LR: 3.91e-05	EMPP_Raw: 1.44163
2025-07-18 11:53:26,589 - logger.py:50 - Epoch: [401][5/6]	Total Loss: 0.73061	Main MSE (x10^-2): 73.0610	LR: 3.91e-05	EMPP_Raw: 1.44198
2025-07-18 11:53:26,627 - logger.py:50 - Epoch 401 Training Summary: Avg Total Loss: 0.73061, Avg Main MSE: 0.73061, Time: 16.88s
2025-07-18 11:53:44,650 - logger.py:50 - Epoch 401 Summary | Train MSE (x10^-2): 73.0610 | Val MSE (x10^-2): 78.9011 | Time: 34.91s
2025-07-18 11:53:47,664 - logger.py:50 - Epoch: [402][0/6]	Total Loss: 0.72112	Main MSE (x10^-2): 72.1122	LR: 3.84e-05	EMPP_Raw: 1.42115
2025-07-18 11:54:01,486 - logger.py:50 - Epoch: [402][5/6]	Total Loss: 0.73212	Main MSE (x10^-2): 73.2120	LR: 3.84e-05	EMPP_Raw: 1.44422
2025-07-18 11:54:01,531 - logger.py:50 - Epoch 402 Training Summary: Avg Total Loss: 0.73212, Avg Main MSE: 0.73212, Time: 16.87s
2025-07-18 11:54:19,573 - logger.py:50 - Epoch 402 Summary | Train MSE (x10^-2): 73.2120 | Val MSE (x10^-2): 79.3346 | Time: 34.92s
2025-07-18 11:54:22,579 - logger.py:50 - Epoch: [403][0/6]	Total Loss: 0.74014	Main MSE (x10^-2): 74.0143	LR: 3.76e-05	EMPP_Raw: 1.45960
2025-07-18 11:54:36,405 - logger.py:50 - Epoch: [403][5/6]	Total Loss: 0.74001	Main MSE (x10^-2): 74.0006	LR: 3.76e-05	EMPP_Raw: 1.46062
2025-07-18 11:54:36,452 - logger.py:50 - Epoch 403 Training Summary: Avg Total Loss: 0.74001, Avg Main MSE: 0.74001, Time: 16.87s
2025-07-18 11:54:54,330 - logger.py:50 - Epoch 403 Summary | Train MSE (x10^-2): 74.0006 | Val MSE (x10^-2): 79.3029 | Time: 34.75s
2025-07-18 11:54:57,512 - logger.py:50 - Epoch: [404][0/6]	Total Loss: 0.71890	Main MSE (x10^-2): 71.8899	LR: 3.69e-05	EMPP_Raw: 1.41606
2025-07-18 11:55:11,289 - logger.py:50 - Epoch: [404][5/6]	Total Loss: 0.73696	Main MSE (x10^-2): 73.6955	LR: 3.69e-05	EMPP_Raw: 1.45257
2025-07-18 11:55:11,336 - logger.py:50 - Epoch 404 Training Summary: Avg Total Loss: 0.73696, Avg Main MSE: 0.73696, Time: 17.00s
2025-07-18 11:55:29,313 - logger.py:50 - Epoch 404 Summary | Train MSE (x10^-2): 73.6955 | Val MSE (x10^-2): 79.2748 | Time: 34.98s
2025-07-18 11:55:32,343 - logger.py:50 - Epoch: [405][0/6]	Total Loss: 0.74488	Main MSE (x10^-2): 74.4879	LR: 3.62e-05	EMPP_Raw: 1.46758
2025-07-18 11:55:46,241 - logger.py:50 - Epoch: [405][5/6]	Total Loss: 0.73555	Main MSE (x10^-2): 73.5547	LR: 3.62e-05	EMPP_Raw: 1.45041
2025-07-18 11:55:46,286 - logger.py:50 - Epoch 405 Training Summary: Avg Total Loss: 0.73555, Avg Main MSE: 0.73555, Time: 16.96s
2025-07-18 11:56:04,282 - logger.py:50 - Epoch 405 Summary | Train MSE (x10^-2): 73.5547 | Val MSE (x10^-2): 79.3015 | Time: 34.96s
2025-07-18 11:56:07,291 - logger.py:50 - Epoch: [406][0/6]	Total Loss: 0.71518	Main MSE (x10^-2): 71.5177	LR: 3.55e-05	EMPP_Raw: 1.41107
2025-07-18 11:56:21,270 - logger.py:50 - Epoch: [406][5/6]	Total Loss: 0.73004	Main MSE (x10^-2): 73.0043	LR: 3.55e-05	EMPP_Raw: 1.44052
2025-07-18 11:56:21,309 - logger.py:50 - Epoch 406 Training Summary: Avg Total Loss: 0.73004, Avg Main MSE: 0.73004, Time: 17.02s
2025-07-18 11:56:39,257 - logger.py:50 - Epoch 406 Summary | Train MSE (x10^-2): 73.0043 | Val MSE (x10^-2): 79.2749 | Time: 34.97s
2025-07-18 11:56:42,261 - logger.py:50 - Epoch: [407][0/6]	Total Loss: 0.71652	Main MSE (x10^-2): 71.6517	LR: 3.48e-05	EMPP_Raw: 1.41002
2025-07-18 11:56:56,068 - logger.py:50 - Epoch: [407][5/6]	Total Loss: 0.73801	Main MSE (x10^-2): 73.8014	LR: 3.48e-05	EMPP_Raw: 1.45575
2025-07-18 11:56:56,113 - logger.py:50 - Epoch 407 Training Summary: Avg Total Loss: 0.73801, Avg Main MSE: 0.73801, Time: 16.85s
2025-07-18 11:57:13,975 - logger.py:50 - Epoch 407 Summary | Train MSE (x10^-2): 73.8014 | Val MSE (x10^-2): 79.2183 | Time: 34.71s
2025-07-18 11:57:17,148 - logger.py:50 - Epoch: [408][0/6]	Total Loss: 0.73323	Main MSE (x10^-2): 73.3234	LR: 3.41e-05	EMPP_Raw: 1.44530
2025-07-18 11:57:30,920 - logger.py:50 - Epoch: [408][5/6]	Total Loss: 0.73118	Main MSE (x10^-2): 73.1178	LR: 3.41e-05	EMPP_Raw: 1.44284
2025-07-18 11:57:30,965 - logger.py:50 - Epoch 408 Training Summary: Avg Total Loss: 0.73118, Avg Main MSE: 0.73118, Time: 16.98s
2025-07-18 11:57:48,960 - logger.py:50 - Epoch 408 Summary | Train MSE (x10^-2): 73.1178 | Val MSE (x10^-2): 79.0750 | Time: 34.98s
2025-07-18 11:57:52,137 - logger.py:50 - Epoch: [409][0/6]	Total Loss: 0.73537	Main MSE (x10^-2): 73.5367	LR: 3.34e-05	EMPP_Raw: 1.45345
2025-07-18 11:58:05,898 - logger.py:50 - Epoch: [409][5/6]	Total Loss: 0.73795	Main MSE (x10^-2): 73.7953	LR: 3.34e-05	EMPP_Raw: 1.45677
2025-07-18 11:58:05,943 - logger.py:50 - Epoch 409 Training Summary: Avg Total Loss: 0.73795, Avg Main MSE: 0.73795, Time: 16.97s
2025-07-18 11:58:23,845 - logger.py:50 - Epoch 409 Summary | Train MSE (x10^-2): 73.7953 | Val MSE (x10^-2): 79.0912 | Time: 34.88s
2025-07-18 11:58:26,854 - logger.py:50 - Epoch: [410][0/6]	Total Loss: 0.77501	Main MSE (x10^-2): 77.5009	LR: 3.27e-05	EMPP_Raw: 1.53224
2025-07-18 11:58:40,797 - logger.py:50 - Epoch: [410][5/6]	Total Loss: 0.74787	Main MSE (x10^-2): 74.7868	LR: 3.27e-05	EMPP_Raw: 1.47668
2025-07-18 11:58:40,844 - logger.py:50 - Epoch 410 Training Summary: Avg Total Loss: 0.74787, Avg Main MSE: 0.74787, Time: 16.99s
2025-07-18 11:58:58,821 - logger.py:50 - Epoch 410 Summary | Train MSE (x10^-2): 74.7868 | Val MSE (x10^-2): 79.6748 | Time: 34.97s
2025-07-18 11:59:01,845 - logger.py:50 - Epoch: [411][0/6]	Total Loss: 0.75157	Main MSE (x10^-2): 75.1573	LR: 3.21e-05	EMPP_Raw: 1.48471
2025-07-18 11:59:15,678 - logger.py:50 - Epoch: [411][5/6]	Total Loss: 0.73258	Main MSE (x10^-2): 73.2583	LR: 3.21e-05	EMPP_Raw: 1.44629
2025-07-18 11:59:15,724 - logger.py:50 - Epoch 411 Training Summary: Avg Total Loss: 0.73258, Avg Main MSE: 0.73258, Time: 16.89s
2025-07-18 11:59:33,820 - logger.py:50 - Epoch 411 Summary | Train MSE (x10^-2): 73.2583 | Val MSE (x10^-2): 78.8386 | Time: 34.99s
2025-07-18 11:59:36,823 - logger.py:50 - Epoch: [412][0/6]	Total Loss: 0.73486	Main MSE (x10^-2): 73.4857	LR: 3.14e-05	EMPP_Raw: 1.45097
2025-07-18 11:59:50,597 - logger.py:50 - Epoch: [412][5/6]	Total Loss: 0.72968	Main MSE (x10^-2): 72.9681	LR: 3.14e-05	EMPP_Raw: 1.44045
2025-07-18 11:59:50,640 - logger.py:50 - Epoch 412 Training Summary: Avg Total Loss: 0.72968, Avg Main MSE: 0.72968, Time: 16.81s
2025-07-18 12:00:08,516 - logger.py:50 - Epoch 412 Summary | Train MSE (x10^-2): 72.9681 | Val MSE (x10^-2): 80.0206 | Time: 34.69s
2025-07-18 12:00:11,674 - logger.py:50 - Epoch: [413][0/6]	Total Loss: 0.74403	Main MSE (x10^-2): 74.4028	LR: 3.07e-05	EMPP_Raw: 1.46798
2025-07-18 12:00:25,419 - logger.py:50 - Epoch: [413][5/6]	Total Loss: 0.74275	Main MSE (x10^-2): 74.2748	LR: 3.07e-05	EMPP_Raw: 1.46657
2025-07-18 12:00:25,462 - logger.py:50 - Epoch 413 Training Summary: Avg Total Loss: 0.74275, Avg Main MSE: 0.74275, Time: 16.94s
2025-07-18 12:00:43,336 - logger.py:50 - Epoch 413 Summary | Train MSE (x10^-2): 74.2748 | Val MSE (x10^-2): 78.8020 | Time: 34.81s
2025-07-18 12:00:46,367 - logger.py:50 - Epoch: [414][0/6]	Total Loss: 0.75853	Main MSE (x10^-2): 75.8534	LR: 3.01e-05	EMPP_Raw: 1.49913
2025-07-18 12:01:00,269 - logger.py:50 - Epoch: [414][5/6]	Total Loss: 0.73638	Main MSE (x10^-2): 73.6381	LR: 3.01e-05	EMPP_Raw: 1.45445
2025-07-18 12:01:00,308 - logger.py:50 - Epoch 414 Training Summary: Avg Total Loss: 0.73638, Avg Main MSE: 0.73638, Time: 16.96s
2025-07-18 12:01:18,193 - logger.py:50 - Epoch 414 Summary | Train MSE (x10^-2): 73.6381 | Val MSE (x10^-2): 79.3323 | Time: 34.85s
2025-07-18 12:01:21,187 - logger.py:50 - Epoch: [415][0/6]	Total Loss: 0.72006	Main MSE (x10^-2): 72.0063	LR: 2.94e-05	EMPP_Raw: 1.41887
2025-07-18 12:01:34,963 - logger.py:50 - Epoch: [415][5/6]	Total Loss: 0.73491	Main MSE (x10^-2): 73.4911	LR: 2.94e-05	EMPP_Raw: 1.45014
2025-07-18 12:01:35,010 - logger.py:50 - Epoch 415 Training Summary: Avg Total Loss: 0.73491, Avg Main MSE: 0.73491, Time: 16.81s
2025-07-18 12:01:53,025 - logger.py:50 - Epoch 415 Summary | Train MSE (x10^-2): 73.4911 | Val MSE (x10^-2): 79.2914 | Time: 34.83s
2025-07-18 12:01:56,038 - logger.py:50 - Epoch: [416][0/6]	Total Loss: 0.75112	Main MSE (x10^-2): 75.1123	LR: 2.88e-05	EMPP_Raw: 1.48244
2025-07-18 12:02:09,890 - logger.py:50 - Epoch: [416][5/6]	Total Loss: 0.74398	Main MSE (x10^-2): 74.3979	LR: 2.88e-05	EMPP_Raw: 1.46884
2025-07-18 12:02:09,930 - logger.py:50 - Epoch 416 Training Summary: Avg Total Loss: 0.74398, Avg Main MSE: 0.74398, Time: 16.89s
2025-07-18 12:02:27,936 - logger.py:50 - Epoch 416 Summary | Train MSE (x10^-2): 74.3979 | Val MSE (x10^-2): 79.0110 | Time: 34.90s
2025-07-18 12:02:30,943 - logger.py:50 - Epoch: [417][0/6]	Total Loss: 0.75526	Main MSE (x10^-2): 75.5262	LR: 2.81e-05	EMPP_Raw: 1.48960
2025-07-18 12:02:44,699 - logger.py:50 - Epoch: [417][5/6]	Total Loss: 0.74082	Main MSE (x10^-2): 74.0824	LR: 2.81e-05	EMPP_Raw: 1.46189
2025-07-18 12:02:44,748 - logger.py:50 - Epoch 417 Training Summary: Avg Total Loss: 0.74082, Avg Main MSE: 0.74082, Time: 16.80s
2025-07-18 12:03:02,698 - logger.py:50 - Epoch 417 Summary | Train MSE (x10^-2): 74.0824 | Val MSE (x10^-2): 79.4686 | Time: 34.76s
2025-07-18 12:03:06,062 - logger.py:50 - Epoch: [418][0/6]	Total Loss: 0.73146	Main MSE (x10^-2): 73.1460	LR: 2.75e-05	EMPP_Raw: 1.44169
2025-07-18 12:03:19,892 - logger.py:50 - Epoch: [418][5/6]	Total Loss: 0.73491	Main MSE (x10^-2): 73.4908	LR: 2.75e-05	EMPP_Raw: 1.45054
2025-07-18 12:03:19,944 - logger.py:50 - Epoch 418 Training Summary: Avg Total Loss: 0.73491, Avg Main MSE: 0.73491, Time: 17.24s
2025-07-18 12:03:37,889 - logger.py:50 - Epoch 418 Summary | Train MSE (x10^-2): 73.4908 | Val MSE (x10^-2): 79.1452 | Time: 35.18s
2025-07-18 12:03:41,052 - logger.py:50 - Epoch: [419][0/6]	Total Loss: 0.74118	Main MSE (x10^-2): 74.1182	LR: 2.69e-05	EMPP_Raw: 1.46525
2025-07-18 12:03:54,840 - logger.py:50 - Epoch: [419][5/6]	Total Loss: 0.73218	Main MSE (x10^-2): 73.2183	LR: 2.69e-05	EMPP_Raw: 1.44621
2025-07-18 12:03:54,884 - logger.py:50 - Epoch 419 Training Summary: Avg Total Loss: 0.73218, Avg Main MSE: 0.73218, Time: 16.99s
2025-07-18 12:04:12,895 - logger.py:50 - Epoch 419 Summary | Train MSE (x10^-2): 73.2183 | Val MSE (x10^-2): 79.4795 | Time: 35.00s
2025-07-18 12:04:15,960 - logger.py:50 - Epoch: [420][0/6]	Total Loss: 0.72798	Main MSE (x10^-2): 72.7979	LR: 2.63e-05	EMPP_Raw: 1.43701
2025-07-18 12:04:29,969 - logger.py:50 - Epoch: [420][5/6]	Total Loss: 0.74562	Main MSE (x10^-2): 74.5619	LR: 2.63e-05	EMPP_Raw: 1.47293
2025-07-18 12:04:30,014 - logger.py:50 - Epoch 420 Training Summary: Avg Total Loss: 0.74562, Avg Main MSE: 0.74562, Time: 17.11s
2025-07-18 12:04:47,858 - logger.py:50 - Epoch 420 Summary | Train MSE (x10^-2): 74.5619 | Val MSE (x10^-2): 78.7990 | Time: 34.96s
2025-07-18 12:04:50,868 - logger.py:50 - Epoch: [421][0/6]	Total Loss: 0.72627	Main MSE (x10^-2): 72.6265	LR: 2.57e-05	EMPP_Raw: 1.43159
2025-07-18 12:05:04,659 - logger.py:50 - Epoch: [421][5/6]	Total Loss: 0.72663	Main MSE (x10^-2): 72.6633	LR: 2.57e-05	EMPP_Raw: 1.43398
2025-07-18 12:05:04,698 - logger.py:50 - Epoch 421 Training Summary: Avg Total Loss: 0.72663, Avg Main MSE: 0.72663, Time: 16.83s
2025-07-18 12:05:22,787 - logger.py:50 - Epoch 421 Summary | Train MSE (x10^-2): 72.6633 | Val MSE (x10^-2): 79.5577 | Time: 34.92s
2025-07-18 12:05:25,794 - logger.py:50 - Epoch: [422][0/6]	Total Loss: 0.72204	Main MSE (x10^-2): 72.2041	LR: 2.51e-05	EMPP_Raw: 1.42673
2025-07-18 12:05:39,671 - logger.py:50 - Epoch: [422][5/6]	Total Loss: 0.72668	Main MSE (x10^-2): 72.6685	LR: 2.51e-05	EMPP_Raw: 1.43535
2025-07-18 12:05:39,716 - logger.py:50 - Epoch 422 Training Summary: Avg Total Loss: 0.72668, Avg Main MSE: 0.72668, Time: 16.92s
2025-07-18 12:05:57,832 - logger.py:50 - Epoch 422 Summary | Train MSE (x10^-2): 72.6685 | Val MSE (x10^-2): 78.5704 | Time: 35.04s
2025-07-18 12:06:00,879 - logger.py:50 - Epoch: [423][0/6]	Total Loss: 0.72405	Main MSE (x10^-2): 72.4046	LR: 2.45e-05	EMPP_Raw: 1.42981
2025-07-18 12:06:14,652 - logger.py:50 - Epoch: [423][5/6]	Total Loss: 0.73135	Main MSE (x10^-2): 73.1348	LR: 2.45e-05	EMPP_Raw: 1.44424
2025-07-18 12:06:14,697 - logger.py:50 - Epoch 423 Training Summary: Avg Total Loss: 0.73135, Avg Main MSE: 0.73135, Time: 16.86s
2025-07-18 12:06:32,612 - logger.py:50 - Epoch 423 Summary | Train MSE (x10^-2): 73.1348 | Val MSE (x10^-2): 79.4931 | Time: 34.77s
2025-07-18 12:06:35,832 - logger.py:50 - Epoch: [424][0/6]	Total Loss: 0.72156	Main MSE (x10^-2): 72.1557	LR: 2.39e-05	EMPP_Raw: 1.42419
2025-07-18 12:06:49,581 - logger.py:50 - Epoch: [424][5/6]	Total Loss: 0.74425	Main MSE (x10^-2): 74.4255	LR: 2.39e-05	EMPP_Raw: 1.46971
2025-07-18 12:06:49,624 - logger.py:50 - Epoch 424 Training Summary: Avg Total Loss: 0.74425, Avg Main MSE: 0.74425, Time: 17.00s
2025-07-18 12:07:07,593 - logger.py:50 - Epoch 424 Summary | Train MSE (x10^-2): 74.4255 | Val MSE (x10^-2): 78.9182 | Time: 34.98s
2025-07-18 12:07:10,607 - logger.py:50 - Epoch: [425][0/6]	Total Loss: 0.74516	Main MSE (x10^-2): 74.5158	LR: 2.33e-05	EMPP_Raw: 1.47128
2025-07-18 12:07:24,504 - logger.py:50 - Epoch: [425][5/6]	Total Loss: 0.72805	Main MSE (x10^-2): 72.8050	LR: 2.33e-05	EMPP_Raw: 1.43807
2025-07-18 12:07:24,546 - logger.py:50 - Epoch 425 Training Summary: Avg Total Loss: 0.72805, Avg Main MSE: 0.72805, Time: 16.94s
2025-07-18 12:07:42,396 - logger.py:50 - Epoch 425 Summary | Train MSE (x10^-2): 72.8050 | Val MSE (x10^-2): 79.2323 | Time: 34.80s
2025-07-18 12:07:45,397 - logger.py:50 - Epoch: [426][0/6]	Total Loss: 0.70729	Main MSE (x10^-2): 70.7289	LR: 2.27e-05	EMPP_Raw: 1.39762
2025-07-18 12:07:59,373 - logger.py:50 - Epoch: [426][5/6]	Total Loss: 0.72259	Main MSE (x10^-2): 72.2585	LR: 2.27e-05	EMPP_Raw: 1.42696
2025-07-18 12:07:59,421 - logger.py:50 - Epoch 426 Training Summary: Avg Total Loss: 0.72259, Avg Main MSE: 0.72259, Time: 17.02s
2025-07-18 12:08:17,396 - logger.py:50 - Epoch 426 Summary | Train MSE (x10^-2): 72.2585 | Val MSE (x10^-2): 79.2983 | Time: 34.99s
2025-07-18 12:08:20,391 - logger.py:50 - Epoch: [427][0/6]	Total Loss: 0.73399	Main MSE (x10^-2): 73.3989	LR: 2.22e-05	EMPP_Raw: 1.44787
2025-07-18 12:08:34,195 - logger.py:50 - Epoch: [427][5/6]	Total Loss: 0.73321	Main MSE (x10^-2): 73.3211	LR: 2.22e-05	EMPP_Raw: 1.44726
2025-07-18 12:08:34,240 - logger.py:50 - Epoch 427 Training Summary: Avg Total Loss: 0.73321, Avg Main MSE: 0.73321, Time: 16.83s
2025-07-18 12:08:52,102 - logger.py:50 - Epoch 427 Summary | Train MSE (x10^-2): 73.3211 | Val MSE (x10^-2): 79.0299 | Time: 34.70s
2025-07-18 12:08:55,291 - logger.py:50 - Epoch: [428][0/6]	Total Loss: 0.75624	Main MSE (x10^-2): 75.6243	LR: 2.16e-05	EMPP_Raw: 1.49476
2025-07-18 12:09:09,054 - logger.py:50 - Epoch: [428][5/6]	Total Loss: 0.73602	Main MSE (x10^-2): 73.6015	LR: 2.16e-05	EMPP_Raw: 1.45337
2025-07-18 12:09:09,102 - logger.py:50 - Epoch 428 Training Summary: Avg Total Loss: 0.73602, Avg Main MSE: 0.73602, Time: 16.99s
2025-07-18 12:09:27,039 - logger.py:50 - Epoch 428 Summary | Train MSE (x10^-2): 73.6015 | Val MSE (x10^-2): 79.3889 | Time: 34.93s
2025-07-18 12:09:30,233 - logger.py:50 - Epoch: [429][0/6]	Total Loss: 0.72837	Main MSE (x10^-2): 72.8367	LR: 2.11e-05	EMPP_Raw: 1.43819
2025-07-18 12:09:44,073 - logger.py:50 - Epoch: [429][5/6]	Total Loss: 0.72172	Main MSE (x10^-2): 72.1721	LR: 2.11e-05	EMPP_Raw: 1.42444
2025-07-18 12:09:44,113 - logger.py:50 - Epoch 429 Training Summary: Avg Total Loss: 0.72172, Avg Main MSE: 0.72172, Time: 17.06s
2025-07-18 12:10:01,962 - logger.py:50 - Epoch 429 Summary | Train MSE (x10^-2): 72.1721 | Val MSE (x10^-2): 79.0013 | Time: 34.92s
2025-07-18 12:10:04,961 - logger.py:50 - Epoch: [430][0/6]	Total Loss: 0.74347	Main MSE (x10^-2): 74.3467	LR: 2.05e-05	EMPP_Raw: 1.46959
2025-07-18 12:10:18,844 - logger.py:50 - Epoch: [430][5/6]	Total Loss: 0.72416	Main MSE (x10^-2): 72.4163	LR: 2.05e-05	EMPP_Raw: 1.42951
2025-07-18 12:10:18,891 - logger.py:50 - Epoch 430 Training Summary: Avg Total Loss: 0.72416, Avg Main MSE: 0.72416, Time: 16.92s
2025-07-18 12:10:36,822 - logger.py:50 - Epoch 430 Summary | Train MSE (x10^-2): 72.4163 | Val MSE (x10^-2): 79.0829 | Time: 34.86s
2025-07-18 12:10:39,825 - logger.py:50 - Epoch: [431][0/6]	Total Loss: 0.73266	Main MSE (x10^-2): 73.2661	LR: 2.00e-05	EMPP_Raw: 1.44349
2025-07-18 12:10:53,640 - logger.py:50 - Epoch: [431][5/6]	Total Loss: 0.73696	Main MSE (x10^-2): 73.6958	LR: 2.00e-05	EMPP_Raw: 1.45528
2025-07-18 12:10:53,685 - logger.py:50 - Epoch 431 Training Summary: Avg Total Loss: 0.73696, Avg Main MSE: 0.73696, Time: 16.86s
2025-07-18 12:11:11,699 - logger.py:50 - Epoch 431 Summary | Train MSE (x10^-2): 73.6958 | Val MSE (x10^-2): 79.0807 | Time: 34.87s
2025-07-18 12:11:14,701 - logger.py:50 - Epoch: [432][0/6]	Total Loss: 0.75138	Main MSE (x10^-2): 75.1380	LR: 1.95e-05	EMPP_Raw: 1.48593
2025-07-18 12:11:28,543 - logger.py:50 - Epoch: [432][5/6]	Total Loss: 0.73034	Main MSE (x10^-2): 73.0344	LR: 1.95e-05	EMPP_Raw: 1.44193
2025-07-18 12:11:28,583 - logger.py:50 - Epoch 432 Training Summary: Avg Total Loss: 0.73034, Avg Main MSE: 0.73034, Time: 16.87s
2025-07-18 12:11:46,559 - logger.py:50 - Epoch 432 Summary | Train MSE (x10^-2): 73.0344 | Val MSE (x10^-2): 79.8122 | Time: 34.85s
2025-07-18 12:11:49,725 - logger.py:50 - Epoch: [433][0/6]	Total Loss: 0.74844	Main MSE (x10^-2): 74.8441	LR: 1.89e-05	EMPP_Raw: 1.47674
2025-07-18 12:12:03,472 - logger.py:50 - Epoch: [433][5/6]	Total Loss: 0.73923	Main MSE (x10^-2): 73.9225	LR: 1.89e-05	EMPP_Raw: 1.45901
2025-07-18 12:12:03,513 - logger.py:50 - Epoch 433 Training Summary: Avg Total Loss: 0.73923, Avg Main MSE: 0.73923, Time: 16.94s
2025-07-18 12:12:21,449 - logger.py:50 - Epoch 433 Summary | Train MSE (x10^-2): 73.9225 | Val MSE (x10^-2): 78.9779 | Time: 34.88s
2025-07-18 12:12:24,526 - logger.py:50 - Epoch: [434][0/6]	Total Loss: 0.72764	Main MSE (x10^-2): 72.7640	LR: 1.84e-05	EMPP_Raw: 1.43573
2025-07-18 12:12:38,535 - logger.py:50 - Epoch: [434][5/6]	Total Loss: 0.73655	Main MSE (x10^-2): 73.6552	LR: 1.84e-05	EMPP_Raw: 1.45395
2025-07-18 12:12:38,580 - logger.py:50 - Epoch 434 Training Summary: Avg Total Loss: 0.73655, Avg Main MSE: 0.73655, Time: 17.12s
2025-07-18 12:12:56,532 - logger.py:50 - Epoch 434 Summary | Train MSE (x10^-2): 73.6552 | Val MSE (x10^-2): 79.2454 | Time: 35.08s
2025-07-18 12:12:59,581 - logger.py:50 - Epoch: [435][0/6]	Total Loss: 0.73145	Main MSE (x10^-2): 73.1453	LR: 1.79e-05	EMPP_Raw: 1.44659
2025-07-18 12:13:13,369 - logger.py:50 - Epoch: [435][5/6]	Total Loss: 0.74133	Main MSE (x10^-2): 74.1329	LR: 1.79e-05	EMPP_Raw: 1.46544
2025-07-18 12:13:13,413 - logger.py:50 - Epoch 435 Training Summary: Avg Total Loss: 0.74133, Avg Main MSE: 0.74133, Time: 16.87s
2025-07-18 12:13:31,391 - logger.py:50 - Epoch 435 Summary | Train MSE (x10^-2): 74.1329 | Val MSE (x10^-2): 79.2944 | Time: 34.85s
2025-07-18 12:13:34,411 - logger.py:50 - Epoch: [436][0/6]	Total Loss: 0.71979	Main MSE (x10^-2): 71.9792	LR: 1.74e-05	EMPP_Raw: 1.42215
2025-07-18 12:13:48,248 - logger.py:50 - Epoch: [436][5/6]	Total Loss: 0.74053	Main MSE (x10^-2): 74.0528	LR: 1.74e-05	EMPP_Raw: 1.46278
2025-07-18 12:13:48,301 - logger.py:50 - Epoch 436 Training Summary: Avg Total Loss: 0.74053, Avg Main MSE: 0.74053, Time: 16.90s
2025-07-18 12:14:06,473 - logger.py:50 - Epoch 436 Summary | Train MSE (x10^-2): 74.0528 | Val MSE (x10^-2): 79.1879 | Time: 35.08s
2025-07-18 12:14:09,481 - logger.py:50 - Epoch: [437][0/6]	Total Loss: 0.72542	Main MSE (x10^-2): 72.5419	LR: 1.69e-05	EMPP_Raw: 1.43174
2025-07-18 12:14:23,284 - logger.py:50 - Epoch: [437][5/6]	Total Loss: 0.72981	Main MSE (x10^-2): 72.9810	LR: 1.69e-05	EMPP_Raw: 1.44129
2025-07-18 12:14:23,330 - logger.py:50 - Epoch 437 Training Summary: Avg Total Loss: 0.72981, Avg Main MSE: 0.72981, Time: 16.85s
2025-07-18 12:14:41,271 - logger.py:50 - Epoch 437 Summary | Train MSE (x10^-2): 72.9810 | Val MSE (x10^-2): 79.2394 | Time: 34.79s
2025-07-18 12:14:44,635 - logger.py:50 - Epoch: [438][0/6]	Total Loss: 0.73959	Main MSE (x10^-2): 73.9587	LR: 1.64e-05	EMPP_Raw: 1.46263
2025-07-18 12:14:58,385 - logger.py:50 - Epoch: [438][5/6]	Total Loss: 0.73632	Main MSE (x10^-2): 73.6323	LR: 1.64e-05	EMPP_Raw: 1.45371
2025-07-18 12:14:58,444 - logger.py:50 - Epoch 438 Training Summary: Avg Total Loss: 0.73632, Avg Main MSE: 0.73632, Time: 17.16s
2025-07-18 12:15:16,500 - logger.py:50 - Epoch 438 Summary | Train MSE (x10^-2): 73.6323 | Val MSE (x10^-2): 79.4408 | Time: 35.22s
2025-07-18 12:15:19,669 - logger.py:50 - Epoch: [439][0/6]	Total Loss: 0.72166	Main MSE (x10^-2): 72.1661	LR: 1.59e-05	EMPP_Raw: 1.42517
2025-07-18 12:15:33,395 - logger.py:50 - Epoch: [439][5/6]	Total Loss: 0.73893	Main MSE (x10^-2): 73.8929	LR: 1.59e-05	EMPP_Raw: 1.45950
2025-07-18 12:15:33,435 - logger.py:50 - Epoch 439 Training Summary: Avg Total Loss: 0.73893, Avg Main MSE: 0.73893, Time: 16.93s
2025-07-18 12:15:51,418 - logger.py:50 - Epoch 439 Summary | Train MSE (x10^-2): 73.8929 | Val MSE (x10^-2): 78.9405 | Time: 34.91s
2025-07-18 12:15:54,469 - logger.py:50 - Epoch: [440][0/6]	Total Loss: 0.74536	Main MSE (x10^-2): 74.5356	LR: 1.55e-05	EMPP_Raw: 1.47019
2025-07-18 12:16:08,403 - logger.py:50 - Epoch: [440][5/6]	Total Loss: 0.74174	Main MSE (x10^-2): 74.1739	LR: 1.55e-05	EMPP_Raw: 1.46472
2025-07-18 12:16:08,444 - logger.py:50 - Epoch 440 Training Summary: Avg Total Loss: 0.74174, Avg Main MSE: 0.74174, Time: 17.02s
2025-07-18 12:16:26,389 - logger.py:50 - Epoch 440 Summary | Train MSE (x10^-2): 74.1739 | Val MSE (x10^-2): 79.2937 | Time: 34.96s
2025-07-18 12:16:29,390 - logger.py:50 - Epoch: [441][0/6]	Total Loss: 0.71851	Main MSE (x10^-2): 71.8511	LR: 1.50e-05	EMPP_Raw: 1.41614
2025-07-18 12:16:43,242 - logger.py:50 - Epoch: [441][5/6]	Total Loss: 0.72857	Main MSE (x10^-2): 72.8566	LR: 1.50e-05	EMPP_Raw: 1.43807
2025-07-18 12:16:43,284 - logger.py:50 - Epoch 441 Training Summary: Avg Total Loss: 0.72857, Avg Main MSE: 0.72857, Time: 16.89s
2025-07-18 12:17:01,300 - logger.py:50 - Epoch 441 Summary | Train MSE (x10^-2): 72.8566 | Val MSE (x10^-2): 79.5080 | Time: 34.91s
2025-07-18 12:17:04,307 - logger.py:50 - Epoch: [442][0/6]	Total Loss: 0.74896	Main MSE (x10^-2): 74.8963	LR: 1.46e-05	EMPP_Raw: 1.48024
2025-07-18 12:17:18,112 - logger.py:50 - Epoch: [442][5/6]	Total Loss: 0.74039	Main MSE (x10^-2): 74.0385	LR: 1.46e-05	EMPP_Raw: 1.46257
2025-07-18 12:17:18,155 - logger.py:50 - Epoch 442 Training Summary: Avg Total Loss: 0.74039, Avg Main MSE: 0.74039, Time: 16.85s
2025-07-18 12:17:36,268 - logger.py:50 - Epoch 442 Summary | Train MSE (x10^-2): 74.0385 | Val MSE (x10^-2): 79.3093 | Time: 34.96s
2025-07-18 12:17:39,278 - logger.py:50 - Epoch: [443][0/6]	Total Loss: 0.73616	Main MSE (x10^-2): 73.6159	LR: 1.41e-05	EMPP_Raw: 1.45351
2025-07-18 12:17:53,124 - logger.py:50 - Epoch: [443][5/6]	Total Loss: 0.73836	Main MSE (x10^-2): 73.8361	LR: 1.41e-05	EMPP_Raw: 1.45859
2025-07-18 12:17:53,165 - logger.py:50 - Epoch 443 Training Summary: Avg Total Loss: 0.73836, Avg Main MSE: 0.73836, Time: 16.89s
2025-07-18 12:18:11,152 - logger.py:50 - Epoch 443 Summary | Train MSE (x10^-2): 73.8361 | Val MSE (x10^-2): 79.1797 | Time: 34.88s
2025-07-18 12:18:14,308 - logger.py:50 - Epoch: [444][0/6]	Total Loss: 0.73955	Main MSE (x10^-2): 73.9554	LR: 1.37e-05	EMPP_Raw: 1.46035
2025-07-18 12:18:28,029 - logger.py:50 - Epoch: [444][5/6]	Total Loss: 0.73354	Main MSE (x10^-2): 73.3535	LR: 1.37e-05	EMPP_Raw: 1.44832
2025-07-18 12:18:28,068 - logger.py:50 - Epoch 444 Training Summary: Avg Total Loss: 0.73354, Avg Main MSE: 0.73354, Time: 16.91s
2025-07-18 12:18:46,069 - logger.py:50 - Epoch 444 Summary | Train MSE (x10^-2): 73.3535 | Val MSE (x10^-2): 79.5185 | Time: 34.91s
2025-07-18 12:18:49,081 - logger.py:50 - Epoch: [445][0/6]	Total Loss: 0.73655	Main MSE (x10^-2): 73.6548	LR: 1.32e-05	EMPP_Raw: 1.45470
2025-07-18 12:19:03,037 - logger.py:50 - Epoch: [445][5/6]	Total Loss: 0.72583	Main MSE (x10^-2): 72.5828	LR: 1.32e-05	EMPP_Raw: 1.43351
2025-07-18 12:19:03,079 - logger.py:50 - Epoch 445 Training Summary: Avg Total Loss: 0.72583, Avg Main MSE: 0.72583, Time: 17.00s
2025-07-18 12:19:21,045 - logger.py:50 - Epoch 445 Summary | Train MSE (x10^-2): 72.5828 | Val MSE (x10^-2): 79.3230 | Time: 34.97s
2025-07-18 12:19:24,069 - logger.py:50 - Epoch: [446][0/6]	Total Loss: 0.71983	Main MSE (x10^-2): 71.9830	LR: 1.28e-05	EMPP_Raw: 1.42278
2025-07-18 12:19:38,053 - logger.py:50 - Epoch: [446][5/6]	Total Loss: 0.73749	Main MSE (x10^-2): 73.7491	LR: 1.28e-05	EMPP_Raw: 1.45661
2025-07-18 12:19:38,100 - logger.py:50 - Epoch 446 Training Summary: Avg Total Loss: 0.73749, Avg Main MSE: 0.73749, Time: 17.04s
2025-07-18 12:19:56,023 - logger.py:50 - Epoch 446 Summary | Train MSE (x10^-2): 73.7491 | Val MSE (x10^-2): 79.3766 | Time: 34.97s
2025-07-18 12:19:59,027 - logger.py:50 - Epoch: [447][0/6]	Total Loss: 0.72072	Main MSE (x10^-2): 72.0724	LR: 1.24e-05	EMPP_Raw: 1.42296
2025-07-18 12:20:12,814 - logger.py:50 - Epoch: [447][5/6]	Total Loss: 0.73538	Main MSE (x10^-2): 73.5379	LR: 1.24e-05	EMPP_Raw: 1.45289
2025-07-18 12:20:12,857 - logger.py:50 - Epoch 447 Training Summary: Avg Total Loss: 0.73538, Avg Main MSE: 0.73538, Time: 16.82s
2025-07-18 12:20:30,729 - logger.py:50 - Epoch 447 Summary | Train MSE (x10^-2): 73.5379 | Val MSE (x10^-2): 79.4391 | Time: 34.70s
2025-07-18 12:20:33,893 - logger.py:50 - Epoch: [448][0/6]	Total Loss: 0.73241	Main MSE (x10^-2): 73.2414	LR: 1.20e-05	EMPP_Raw: 1.44545
2025-07-18 12:20:47,639 - logger.py:50 - Epoch: [448][5/6]	Total Loss: 0.71786	Main MSE (x10^-2): 71.7855	LR: 1.20e-05	EMPP_Raw: 1.41693
2025-07-18 12:20:47,680 - logger.py:50 - Epoch 448 Training Summary: Avg Total Loss: 0.71786, Avg Main MSE: 0.71786, Time: 16.94s
2025-07-18 12:21:05,516 - logger.py:50 - Epoch 448 Summary | Train MSE (x10^-2): 71.7855 | Val MSE (x10^-2): 79.3695 | Time: 34.78s
2025-07-18 12:21:08,672 - logger.py:50 - Epoch: [449][0/6]	Total Loss: 0.72854	Main MSE (x10^-2): 72.8536	LR: 1.16e-05	EMPP_Raw: 1.43840
2025-07-18 12:21:22,443 - logger.py:50 - Epoch: [449][5/6]	Total Loss: 0.73254	Main MSE (x10^-2): 73.2544	LR: 1.16e-05	EMPP_Raw: 1.44653
2025-07-18 12:21:22,487 - logger.py:50 - Epoch 449 Training Summary: Avg Total Loss: 0.73254, Avg Main MSE: 0.73254, Time: 16.96s
2025-07-18 12:21:40,315 - logger.py:50 - Epoch 449 Summary | Train MSE (x10^-2): 73.2544 | Val MSE (x10^-2): 79.2355 | Time: 34.79s
2025-07-18 12:21:43,388 - logger.py:50 - Epoch: [450][0/6]	Total Loss: 0.75115	Main MSE (x10^-2): 75.1146	LR: 1.12e-05	EMPP_Raw: 1.48239
2025-07-18 12:21:57,337 - logger.py:50 - Epoch: [450][5/6]	Total Loss: 0.73537	Main MSE (x10^-2): 73.5372	LR: 1.12e-05	EMPP_Raw: 1.45256
2025-07-18 12:21:57,384 - logger.py:50 - Epoch 450 Training Summary: Avg Total Loss: 0.73537, Avg Main MSE: 0.73537, Time: 17.06s
2025-07-18 12:22:15,514 - logger.py:50 - Epoch 450 Summary | Train MSE (x10^-2): 73.5372 | Val MSE (x10^-2): 79.2560 | Time: 35.19s
2025-07-18 12:22:18,530 - logger.py:50 - Epoch: [451][0/6]	Total Loss: 0.74175	Main MSE (x10^-2): 74.1746	LR: 1.08e-05	EMPP_Raw: 1.46740
2025-07-18 12:22:32,431 - logger.py:50 - Epoch: [451][5/6]	Total Loss: 0.73565	Main MSE (x10^-2): 73.5649	LR: 1.08e-05	EMPP_Raw: 1.45326
2025-07-18 12:22:32,485 - logger.py:50 - Epoch 451 Training Summary: Avg Total Loss: 0.73565, Avg Main MSE: 0.73565, Time: 16.96s
2025-07-18 12:22:50,704 - logger.py:50 - Epoch 451 Summary | Train MSE (x10^-2): 73.5649 | Val MSE (x10^-2): 79.1807 | Time: 35.18s
2025-07-18 12:22:53,710 - logger.py:50 - Epoch: [452][0/6]	Total Loss: 0.74597	Main MSE (x10^-2): 74.5966	LR: 1.04e-05	EMPP_Raw: 1.47332
2025-07-18 12:23:07,569 - logger.py:50 - Epoch: [452][5/6]	Total Loss: 0.74219	Main MSE (x10^-2): 74.2192	LR: 1.04e-05	EMPP_Raw: 1.46669
2025-07-18 12:23:07,616 - logger.py:50 - Epoch 452 Training Summary: Avg Total Loss: 0.74219, Avg Main MSE: 0.74219, Time: 16.90s
2025-07-18 12:23:25,484 - logger.py:50 - Epoch 452 Summary | Train MSE (x10^-2): 74.2192 | Val MSE (x10^-2): 79.1998 | Time: 34.77s
2025-07-18 12:23:28,686 - logger.py:50 - Epoch: [453][0/6]	Total Loss: 0.74571	Main MSE (x10^-2): 74.5710	LR: 1.00e-05	EMPP_Raw: 1.47287
2025-07-18 12:23:42,450 - logger.py:50 - Epoch: [453][5/6]	Total Loss: 0.73587	Main MSE (x10^-2): 73.5869	LR: 1.00e-05	EMPP_Raw: 1.45339
2025-07-18 12:23:42,492 - logger.py:50 - Epoch 453 Training Summary: Avg Total Loss: 0.73587, Avg Main MSE: 0.73587, Time: 17.00s
2025-07-18 12:24:00,380 - logger.py:50 - Epoch 453 Summary | Train MSE (x10^-2): 73.5869 | Val MSE (x10^-2): 79.4695 | Time: 34.89s
2025-07-18 12:24:03,384 - logger.py:50 - Epoch: [454][0/6]	Total Loss: 0.72918	Main MSE (x10^-2): 72.9181	LR: 9.64e-06	EMPP_Raw: 1.44096
2025-07-18 12:24:17,344 - logger.py:50 - Epoch: [454][5/6]	Total Loss: 0.72496	Main MSE (x10^-2): 72.4959	LR: 9.64e-06	EMPP_Raw: 1.43182
2025-07-18 12:24:17,389 - logger.py:50 - Epoch 454 Training Summary: Avg Total Loss: 0.72496, Avg Main MSE: 0.72496, Time: 17.00s
2025-07-18 12:24:35,232 - logger.py:50 - Epoch 454 Summary | Train MSE (x10^-2): 72.4959 | Val MSE (x10^-2): 79.3028 | Time: 34.85s
2025-07-18 12:24:38,279 - logger.py:50 - Epoch: [455][0/6]	Total Loss: 0.72805	Main MSE (x10^-2): 72.8048	LR: 9.27e-06	EMPP_Raw: 1.43912
2025-07-18 12:24:52,044 - logger.py:50 - Epoch: [455][5/6]	Total Loss: 0.73331	Main MSE (x10^-2): 73.3310	LR: 9.27e-06	EMPP_Raw: 1.44848
2025-07-18 12:24:52,088 - logger.py:50 - Epoch 455 Training Summary: Avg Total Loss: 0.73331, Avg Main MSE: 0.73331, Time: 16.85s
2025-07-18 12:25:10,161 - logger.py:50 - Epoch 455 Summary | Train MSE (x10^-2): 73.3310 | Val MSE (x10^-2): 79.3401 | Time: 34.93s
2025-07-18 12:25:13,162 - logger.py:50 - Epoch: [456][0/6]	Total Loss: 0.73574	Main MSE (x10^-2): 73.5735	LR: 8.92e-06	EMPP_Raw: 1.45169
2025-07-18 12:25:27,027 - logger.py:50 - Epoch: [456][5/6]	Total Loss: 0.73451	Main MSE (x10^-2): 73.4513	LR: 8.92e-06	EMPP_Raw: 1.45057
2025-07-18 12:25:27,070 - logger.py:50 - Epoch 456 Training Summary: Avg Total Loss: 0.73451, Avg Main MSE: 0.73451, Time: 16.90s
2025-07-18 12:25:45,146 - logger.py:50 - Epoch 456 Summary | Train MSE (x10^-2): 73.4513 | Val MSE (x10^-2): 79.3169 | Time: 34.98s
2025-07-18 12:25:48,203 - logger.py:50 - Epoch: [457][0/6]	Total Loss: 0.75282	Main MSE (x10^-2): 75.2824	LR: 8.58e-06	EMPP_Raw: 1.48753
2025-07-18 12:26:02,008 - logger.py:50 - Epoch: [457][5/6]	Total Loss: 0.73560	Main MSE (x10^-2): 73.5599	LR: 8.58e-06	EMPP_Raw: 1.45314
2025-07-18 12:26:02,047 - logger.py:50 - Epoch 457 Training Summary: Avg Total Loss: 0.73560, Avg Main MSE: 0.73560, Time: 16.89s
2025-07-18 12:26:19,939 - logger.py:50 - Epoch 457 Summary | Train MSE (x10^-2): 73.5599 | Val MSE (x10^-2): 79.2757 | Time: 34.79s
2025-07-18 12:26:23,333 - logger.py:50 - Epoch: [458][0/6]	Total Loss: 0.72515	Main MSE (x10^-2): 72.5151	LR: 8.24e-06	EMPP_Raw: 1.43339
2025-07-18 12:26:37,133 - logger.py:50 - Epoch: [458][5/6]	Total Loss: 0.73183	Main MSE (x10^-2): 73.1828	LR: 8.24e-06	EMPP_Raw: 1.44622
2025-07-18 12:26:37,185 - logger.py:50 - Epoch 458 Training Summary: Avg Total Loss: 0.73183, Avg Main MSE: 0.73183, Time: 17.24s
2025-07-18 12:26:55,064 - logger.py:50 - Epoch 458 Summary | Train MSE (x10^-2): 73.1828 | Val MSE (x10^-2): 79.2507 | Time: 35.12s
2025-07-18 12:26:58,225 - logger.py:50 - Epoch: [459][0/6]	Total Loss: 0.72804	Main MSE (x10^-2): 72.8042	LR: 7.91e-06	EMPP_Raw: 1.43853
2025-07-18 12:27:11,983 - logger.py:50 - Epoch: [459][5/6]	Total Loss: 0.74181	Main MSE (x10^-2): 74.1810	LR: 7.91e-06	EMPP_Raw: 1.46608
2025-07-18 12:27:12,028 - logger.py:50 - Epoch 459 Training Summary: Avg Total Loss: 0.74181, Avg Main MSE: 0.74181, Time: 16.95s
2025-07-18 12:27:29,975 - logger.py:50 - Epoch 459 Summary | Train MSE (x10^-2): 74.1810 | Val MSE (x10^-2): 79.2033 | Time: 34.90s
2025-07-18 12:27:33,036 - logger.py:50 - Epoch: [460][0/6]	Total Loss: 0.74371	Main MSE (x10^-2): 74.3705	LR: 7.58e-06	EMPP_Raw: 1.46965
2025-07-18 12:27:46,989 - logger.py:50 - Epoch: [460][5/6]	Total Loss: 0.73892	Main MSE (x10^-2): 73.8919	LR: 7.58e-06	EMPP_Raw: 1.45973
2025-07-18 12:27:47,036 - logger.py:50 - Epoch 460 Training Summary: Avg Total Loss: 0.73892, Avg Main MSE: 0.73892, Time: 17.05s
2025-07-18 12:28:04,878 - logger.py:50 - Epoch 460 Summary | Train MSE (x10^-2): 73.8919 | Val MSE (x10^-2): 79.2242 | Time: 34.90s
2025-07-18 12:28:07,871 - logger.py:50 - Epoch: [461][0/6]	Total Loss: 0.74039	Main MSE (x10^-2): 74.0388	LR: 7.27e-06	EMPP_Raw: 1.46293
2025-07-18 12:28:21,623 - logger.py:50 - Epoch: [461][5/6]	Total Loss: 0.73124	Main MSE (x10^-2): 73.1236	LR: 7.27e-06	EMPP_Raw: 1.44444
2025-07-18 12:28:21,669 - logger.py:50 - Epoch 461 Training Summary: Avg Total Loss: 0.73124, Avg Main MSE: 0.73124, Time: 16.78s
2025-07-18 12:28:39,715 - logger.py:50 - Epoch 461 Summary | Train MSE (x10^-2): 73.1236 | Val MSE (x10^-2): 79.3898 | Time: 34.83s
2025-07-18 12:28:42,776 - logger.py:50 - Epoch: [462][0/6]	Total Loss: 0.71138	Main MSE (x10^-2): 71.1383	LR: 6.96e-06	EMPP_Raw: 1.40314
2025-07-18 12:28:56,586 - logger.py:50 - Epoch: [462][5/6]	Total Loss: 0.72989	Main MSE (x10^-2): 72.9890	LR: 6.96e-06	EMPP_Raw: 1.44167
2025-07-18 12:28:56,628 - logger.py:50 - Epoch 462 Training Summary: Avg Total Loss: 0.72989, Avg Main MSE: 0.72989, Time: 16.90s
2025-07-18 12:29:14,861 - logger.py:50 - Epoch 462 Summary | Train MSE (x10^-2): 72.9890 | Val MSE (x10^-2): 79.2583 | Time: 35.14s
2025-07-18 12:29:17,921 - logger.py:50 - Epoch: [463][0/6]	Total Loss: 0.74246	Main MSE (x10^-2): 74.2459	LR: 6.66e-06	EMPP_Raw: 1.46733
2025-07-18 12:29:31,724 - logger.py:50 - Epoch: [463][5/6]	Total Loss: 0.73357	Main MSE (x10^-2): 73.3570	LR: 6.66e-06	EMPP_Raw: 1.44936
2025-07-18 12:29:31,765 - logger.py:50 - Epoch 463 Training Summary: Avg Total Loss: 0.73357, Avg Main MSE: 0.73357, Time: 16.89s
2025-07-18 12:29:49,650 - logger.py:50 - Epoch 463 Summary | Train MSE (x10^-2): 73.3570 | Val MSE (x10^-2): 79.2756 | Time: 34.78s
2025-07-18 12:29:52,818 - logger.py:50 - Epoch: [464][0/6]	Total Loss: 0.72033	Main MSE (x10^-2): 72.0327	LR: 6.37e-06	EMPP_Raw: 1.42129
2025-07-18 12:30:06,551 - logger.py:50 - Epoch: [464][5/6]	Total Loss: 0.72966	Main MSE (x10^-2): 72.9663	LR: 6.37e-06	EMPP_Raw: 1.44136
2025-07-18 12:30:06,595 - logger.py:50 - Epoch 464 Training Summary: Avg Total Loss: 0.72966, Avg Main MSE: 0.72966, Time: 16.94s
2025-07-18 12:30:24,541 - logger.py:50 - Epoch 464 Summary | Train MSE (x10^-2): 72.9663 | Val MSE (x10^-2): 79.2703 | Time: 34.88s
2025-07-18 12:30:27,569 - logger.py:50 - Epoch: [465][0/6]	Total Loss: 0.73735	Main MSE (x10^-2): 73.7346	LR: 6.08e-06	EMPP_Raw: 1.45655
2025-07-18 12:30:41,531 - logger.py:50 - Epoch: [465][5/6]	Total Loss: 0.73533	Main MSE (x10^-2): 73.5332	LR: 6.08e-06	EMPP_Raw: 1.45282
2025-07-18 12:30:41,576 - logger.py:50 - Epoch 465 Training Summary: Avg Total Loss: 0.73533, Avg Main MSE: 0.73533, Time: 17.03s
2025-07-18 12:30:59,544 - logger.py:50 - Epoch 465 Summary | Train MSE (x10^-2): 73.5332 | Val MSE (x10^-2): 79.3640 | Time: 35.00s
2025-07-18 12:31:02,552 - logger.py:50 - Epoch: [466][0/6]	Total Loss: 0.75172	Main MSE (x10^-2): 75.1723	LR: 5.80e-06	EMPP_Raw: 1.48459
2025-07-18 12:31:16,517 - logger.py:50 - Epoch: [466][5/6]	Total Loss: 0.73251	Main MSE (x10^-2): 73.2505	LR: 5.80e-06	EMPP_Raw: 1.44669
2025-07-18 12:31:16,564 - logger.py:50 - Epoch 466 Training Summary: Avg Total Loss: 0.73251, Avg Main MSE: 0.73251, Time: 17.01s
2025-07-18 12:31:34,491 - logger.py:50 - Epoch 466 Summary | Train MSE (x10^-2): 73.2505 | Val MSE (x10^-2): 79.4879 | Time: 34.94s
2025-07-18 12:31:37,510 - logger.py:50 - Epoch: [467][0/6]	Total Loss: 0.76055	Main MSE (x10^-2): 76.0549	LR: 5.54e-06	EMPP_Raw: 1.50207
2025-07-18 12:31:51,291 - logger.py:50 - Epoch: [467][5/6]	Total Loss: 0.73989	Main MSE (x10^-2): 73.9887	LR: 5.54e-06	EMPP_Raw: 1.46247
2025-07-18 12:31:51,333 - logger.py:50 - Epoch 467 Training Summary: Avg Total Loss: 0.73989, Avg Main MSE: 0.73989, Time: 16.83s
2025-07-18 12:32:09,208 - logger.py:50 - Epoch 467 Summary | Train MSE (x10^-2): 73.9887 | Val MSE (x10^-2): 79.5349 | Time: 34.71s
2025-07-18 12:32:12,365 - logger.py:50 - Epoch: [468][0/6]	Total Loss: 0.72824	Main MSE (x10^-2): 72.8236	LR: 5.27e-06	EMPP_Raw: 1.43710
2025-07-18 12:32:26,110 - logger.py:50 - Epoch: [468][5/6]	Total Loss: 0.73596	Main MSE (x10^-2): 73.5961	LR: 5.27e-06	EMPP_Raw: 1.45374
2025-07-18 12:32:26,151 - logger.py:50 - Epoch 468 Training Summary: Avg Total Loss: 0.73596, Avg Main MSE: 0.73596, Time: 16.93s
2025-07-18 12:32:44,036 - logger.py:50 - Epoch 468 Summary | Train MSE (x10^-2): 73.5961 | Val MSE (x10^-2): 79.4504 | Time: 34.82s
2025-07-18 12:32:47,199 - logger.py:50 - Epoch: [469][0/6]	Total Loss: 0.74060	Main MSE (x10^-2): 74.0600	LR: 5.02e-06	EMPP_Raw: 1.46326
2025-07-18 12:33:00,948 - logger.py:50 - Epoch: [469][5/6]	Total Loss: 0.72996	Main MSE (x10^-2): 72.9965	LR: 5.02e-06	EMPP_Raw: 1.44184
2025-07-18 12:33:00,989 - logger.py:50 - Epoch 469 Training Summary: Avg Total Loss: 0.72996, Avg Main MSE: 0.72996, Time: 16.94s
2025-07-18 12:33:18,920 - logger.py:50 - Epoch 469 Summary | Train MSE (x10^-2): 72.9965 | Val MSE (x10^-2): 79.3833 | Time: 34.88s
2025-07-18 12:33:21,967 - logger.py:50 - Epoch: [470][0/6]	Total Loss: 0.72026	Main MSE (x10^-2): 72.0261	LR: 4.77e-06	EMPP_Raw: 1.42306
2025-07-18 12:33:35,866 - logger.py:50 - Epoch: [470][5/6]	Total Loss: 0.72947	Main MSE (x10^-2): 72.9470	LR: 4.77e-06	EMPP_Raw: 1.44084
2025-07-18 12:33:35,905 - logger.py:50 - Epoch 470 Training Summary: Avg Total Loss: 0.72947, Avg Main MSE: 0.72947, Time: 16.97s
2025-07-18 12:33:53,808 - logger.py:50 - Epoch 470 Summary | Train MSE (x10^-2): 72.9470 | Val MSE (x10^-2): 79.4188 | Time: 34.88s
2025-07-18 12:33:56,814 - logger.py:50 - Epoch: [471][0/6]	Total Loss: 0.75307	Main MSE (x10^-2): 75.3069	LR: 4.53e-06	EMPP_Raw: 1.48827
2025-07-18 12:34:10,687 - logger.py:50 - Epoch: [471][5/6]	Total Loss: 0.73652	Main MSE (x10^-2): 73.6519	LR: 4.53e-06	EMPP_Raw: 1.45499
2025-07-18 12:34:10,729 - logger.py:50 - Epoch 471 Training Summary: Avg Total Loss: 0.73652, Avg Main MSE: 0.73652, Time: 16.91s
2025-07-18 12:34:28,755 - logger.py:50 - Epoch 471 Summary | Train MSE (x10^-2): 73.6519 | Val MSE (x10^-2): 79.4452 | Time: 34.94s
2025-07-18 12:34:31,765 - logger.py:50 - Epoch: [472][0/6]	Total Loss: 0.73545	Main MSE (x10^-2): 73.5453	LR: 4.30e-06	EMPP_Raw: 1.45284
2025-07-18 12:34:45,576 - logger.py:50 - Epoch: [472][5/6]	Total Loss: 0.73690	Main MSE (x10^-2): 73.6903	LR: 4.30e-06	EMPP_Raw: 1.45628
2025-07-18 12:34:45,616 - logger.py:50 - Epoch 472 Training Summary: Avg Total Loss: 0.73690, Avg Main MSE: 0.73690, Time: 16.85s
2025-07-18 12:35:03,490 - logger.py:50 - Epoch 472 Summary | Train MSE (x10^-2): 73.6903 | Val MSE (x10^-2): 79.4332 | Time: 34.73s
2025-07-18 12:35:06,647 - logger.py:50 - Epoch: [473][0/6]	Total Loss: 0.73740	Main MSE (x10^-2): 73.7399	LR: 4.08e-06	EMPP_Raw: 1.45431
2025-07-18 12:35:20,402 - logger.py:50 - Epoch: [473][5/6]	Total Loss: 0.73308	Main MSE (x10^-2): 73.3083	LR: 4.08e-06	EMPP_Raw: 1.44790
2025-07-18 12:35:20,445 - logger.py:50 - Epoch 473 Training Summary: Avg Total Loss: 0.73308, Avg Main MSE: 0.73308, Time: 16.94s
2025-07-18 12:35:38,392 - logger.py:50 - Epoch 473 Summary | Train MSE (x10^-2): 73.3083 | Val MSE (x10^-2): 79.3207 | Time: 34.89s
2025-07-18 12:35:41,406 - logger.py:50 - Epoch: [474][0/6]	Total Loss: 0.73398	Main MSE (x10^-2): 73.3980	LR: 3.86e-06	EMPP_Raw: 1.45125
2025-07-18 12:35:55,364 - logger.py:50 - Epoch: [474][5/6]	Total Loss: 0.73200	Main MSE (x10^-2): 73.2005	LR: 3.86e-06	EMPP_Raw: 1.44661
2025-07-18 12:35:55,409 - logger.py:50 - Epoch 474 Training Summary: Avg Total Loss: 0.73200, Avg Main MSE: 0.73200, Time: 17.01s
2025-07-18 12:36:13,328 - logger.py:50 - Epoch 474 Summary | Train MSE (x10^-2): 73.2005 | Val MSE (x10^-2): 79.2822 | Time: 34.93s
2025-07-18 12:36:16,353 - logger.py:50 - Epoch: [475][0/6]	Total Loss: 0.71327	Main MSE (x10^-2): 71.3266	LR: 3.66e-06	EMPP_Raw: 1.40611
2025-07-18 12:36:30,093 - logger.py:50 - Epoch: [475][5/6]	Total Loss: 0.73022	Main MSE (x10^-2): 73.0221	LR: 3.66e-06	EMPP_Raw: 1.44258
2025-07-18 12:36:30,138 - logger.py:50 - Epoch 475 Training Summary: Avg Total Loss: 0.73022, Avg Main MSE: 0.73022, Time: 16.80s
2025-07-18 12:36:48,217 - logger.py:50 - Epoch 475 Summary | Train MSE (x10^-2): 73.0221 | Val MSE (x10^-2): 79.3517 | Time: 34.88s
2025-07-18 12:36:51,227 - logger.py:50 - Epoch: [476][0/6]	Total Loss: 0.70473	Main MSE (x10^-2): 70.4728	LR: 3.46e-06	EMPP_Raw: 1.39152
2025-07-18 12:37:05,043 - logger.py:50 - Epoch: [476][5/6]	Total Loss: 0.72758	Main MSE (x10^-2): 72.7580	LR: 3.46e-06	EMPP_Raw: 1.43796
2025-07-18 12:37:05,104 - logger.py:50 - Epoch 476 Training Summary: Avg Total Loss: 0.72758, Avg Main MSE: 0.72758, Time: 16.88s
2025-07-18 12:37:23,149 - logger.py:50 - Epoch 476 Summary | Train MSE (x10^-2): 72.7580 | Val MSE (x10^-2): 79.4615 | Time: 34.93s
2025-07-18 12:37:26,141 - logger.py:50 - Epoch: [477][0/6]	Total Loss: 0.75001	Main MSE (x10^-2): 75.0012	LR: 3.26e-06	EMPP_Raw: 1.48152
2025-07-18 12:37:39,923 - logger.py:50 - Epoch: [477][5/6]	Total Loss: 0.73483	Main MSE (x10^-2): 73.4830	LR: 3.26e-06	EMPP_Raw: 1.45196
2025-07-18 12:37:39,971 - logger.py:50 - Epoch 477 Training Summary: Avg Total Loss: 0.73483, Avg Main MSE: 0.73483, Time: 16.82s
2025-07-18 12:37:57,843 - logger.py:50 - Epoch 477 Summary | Train MSE (x10^-2): 73.4830 | Val MSE (x10^-2): 79.4471 | Time: 34.69s
2025-07-18 12:38:01,231 - logger.py:50 - Epoch: [478][0/6]	Total Loss: 0.74110	Main MSE (x10^-2): 74.1098	LR: 3.08e-06	EMPP_Raw: 1.46477
2025-07-18 12:38:14,983 - logger.py:50 - Epoch: [478][5/6]	Total Loss: 0.72694	Main MSE (x10^-2): 72.6940	LR: 3.08e-06	EMPP_Raw: 1.43596
2025-07-18 12:38:15,038 - logger.py:50 - Epoch 478 Training Summary: Avg Total Loss: 0.72694, Avg Main MSE: 0.72694, Time: 17.18s
2025-07-18 12:38:33,041 - logger.py:50 - Epoch 478 Summary | Train MSE (x10^-2): 72.6940 | Val MSE (x10^-2): 79.3065 | Time: 35.19s
2025-07-18 12:38:36,244 - logger.py:50 - Epoch: [479][0/6]	Total Loss: 0.72681	Main MSE (x10^-2): 72.6814	LR: 2.90e-06	EMPP_Raw: 1.43517
2025-07-18 12:38:50,007 - logger.py:50 - Epoch: [479][5/6]	Total Loss: 0.73290	Main MSE (x10^-2): 73.2901	LR: 2.90e-06	EMPP_Raw: 1.44763
2025-07-18 12:38:50,055 - logger.py:50 - Epoch 479 Training Summary: Avg Total Loss: 0.73290, Avg Main MSE: 0.73290, Time: 17.01s
2025-07-18 12:39:07,983 - logger.py:50 - Epoch 479 Summary | Train MSE (x10^-2): 73.2901 | Val MSE (x10^-2): 79.2503 | Time: 34.94s
2025-07-18 12:39:11,013 - logger.py:50 - Epoch: [480][0/6]	Total Loss: 0.74508	Main MSE (x10^-2): 74.5082	LR: 2.73e-06	EMPP_Raw: 1.47247
2025-07-18 12:39:24,957 - logger.py:50 - Epoch: [480][5/6]	Total Loss: 0.72595	Main MSE (x10^-2): 72.5951	LR: 2.73e-06	EMPP_Raw: 1.43399
2025-07-18 12:39:25,000 - logger.py:50 - Epoch 480 Training Summary: Avg Total Loss: 0.72595, Avg Main MSE: 0.72595, Time: 17.01s
2025-07-18 12:39:42,833 - logger.py:50 - Epoch 480 Summary | Train MSE (x10^-2): 72.5951 | Val MSE (x10^-2): 79.3031 | Time: 34.84s
2025-07-18 12:39:45,824 - logger.py:50 - Epoch: [481][0/6]	Total Loss: 0.73488	Main MSE (x10^-2): 73.4877	LR: 2.57e-06	EMPP_Raw: 1.45227
2025-07-18 12:39:59,637 - logger.py:50 - Epoch: [481][5/6]	Total Loss: 0.73453	Main MSE (x10^-2): 73.4532	LR: 2.57e-06	EMPP_Raw: 1.45153
2025-07-18 12:39:59,683 - logger.py:50 - Epoch 481 Training Summary: Avg Total Loss: 0.73453, Avg Main MSE: 0.73453, Time: 16.84s
2025-07-18 12:40:17,718 - logger.py:50 - Epoch 481 Summary | Train MSE (x10^-2): 73.4532 | Val MSE (x10^-2): 79.3977 | Time: 34.88s
2025-07-18 12:40:20,759 - logger.py:50 - Epoch: [482][0/6]	Total Loss: 0.73405	Main MSE (x10^-2): 73.4046	LR: 2.42e-06	EMPP_Raw: 1.44929
2025-07-18 12:40:34,547 - logger.py:50 - Epoch: [482][5/6]	Total Loss: 0.73843	Main MSE (x10^-2): 73.8426	LR: 2.42e-06	EMPP_Raw: 1.45884
2025-07-18 12:40:34,587 - logger.py:50 - Epoch 482 Training Summary: Avg Total Loss: 0.73843, Avg Main MSE: 0.73843, Time: 16.86s
2025-07-18 12:40:52,665 - logger.py:50 - Epoch 482 Summary | Train MSE (x10^-2): 73.8426 | Val MSE (x10^-2): 79.4340 | Time: 34.94s
2025-07-18 12:40:55,675 - logger.py:50 - Epoch: [483][0/6]	Total Loss: 0.72432	Main MSE (x10^-2): 72.4318	LR: 2.27e-06	EMPP_Raw: 1.43183
2025-07-18 12:41:09,479 - logger.py:50 - Epoch: [483][5/6]	Total Loss: 0.73508	Main MSE (x10^-2): 73.5080	LR: 2.27e-06	EMPP_Raw: 1.45230
2025-07-18 12:41:09,515 - logger.py:50 - Epoch 483 Training Summary: Avg Total Loss: 0.73508, Avg Main MSE: 0.73508, Time: 16.84s
2025-07-18 12:41:27,366 - logger.py:50 - Epoch 483 Summary | Train MSE (x10^-2): 73.5080 | Val MSE (x10^-2): 79.3395 | Time: 34.70s
2025-07-18 12:41:30,528 - logger.py:50 - Epoch: [484][0/6]	Total Loss: 0.73718	Main MSE (x10^-2): 73.7182	LR: 2.14e-06	EMPP_Raw: 1.45799
2025-07-18 12:41:44,281 - logger.py:50 - Epoch: [484][5/6]	Total Loss: 0.73242	Main MSE (x10^-2): 73.2421	LR: 2.14e-06	EMPP_Raw: 1.44764
2025-07-18 12:41:44,320 - logger.py:50 - Epoch 484 Training Summary: Avg Total Loss: 0.73242, Avg Main MSE: 0.73242, Time: 16.94s
2025-07-18 12:42:02,246 - logger.py:50 - Epoch 484 Summary | Train MSE (x10^-2): 73.2421 | Val MSE (x10^-2): 79.2590 | Time: 34.87s
2025-07-18 12:42:05,272 - logger.py:50 - Epoch: [485][0/6]	Total Loss: 0.72737	Main MSE (x10^-2): 72.7371	LR: 2.01e-06	EMPP_Raw: 1.43790
2025-07-18 12:42:19,227 - logger.py:50 - Epoch: [485][5/6]	Total Loss: 0.74174	Main MSE (x10^-2): 74.1745	LR: 2.01e-06	EMPP_Raw: 1.46584
2025-07-18 12:42:19,276 - logger.py:50 - Epoch 485 Training Summary: Avg Total Loss: 0.74174, Avg Main MSE: 0.74174, Time: 17.02s
2025-07-18 12:42:37,171 - logger.py:50 - Epoch 485 Summary | Train MSE (x10^-2): 74.1745 | Val MSE (x10^-2): 79.2732 | Time: 34.92s
2025-07-18 12:42:40,172 - logger.py:50 - Epoch: [486][0/6]	Total Loss: 0.73293	Main MSE (x10^-2): 73.2931	LR: 1.89e-06	EMPP_Raw: 1.44694
2025-07-18 12:42:54,087 - logger.py:50 - Epoch: [486][5/6]	Total Loss: 0.73000	Main MSE (x10^-2): 73.0002	LR: 1.89e-06	EMPP_Raw: 1.44186
2025-07-18 12:42:54,126 - logger.py:50 - Epoch 486 Training Summary: Avg Total Loss: 0.73000, Avg Main MSE: 0.73000, Time: 16.95s
2025-07-18 12:43:12,226 - logger.py:50 - Epoch 486 Summary | Train MSE (x10^-2): 73.0002 | Val MSE (x10^-2): 79.3334 | Time: 35.05s
2025-07-18 12:43:15,229 - logger.py:50 - Epoch: [487][0/6]	Total Loss: 0.75598	Main MSE (x10^-2): 75.5976	LR: 1.77e-06	EMPP_Raw: 1.49285
2025-07-18 12:43:29,000 - logger.py:50 - Epoch: [487][5/6]	Total Loss: 0.73799	Main MSE (x10^-2): 73.7989	LR: 1.77e-06	EMPP_Raw: 1.45764
2025-07-18 12:43:29,039 - logger.py:50 - Epoch 487 Training Summary: Avg Total Loss: 0.73799, Avg Main MSE: 0.73799, Time: 16.80s
2025-07-18 12:43:46,907 - logger.py:50 - Epoch 487 Summary | Train MSE (x10^-2): 73.7989 | Val MSE (x10^-2): 79.3765 | Time: 34.67s
2025-07-18 12:43:50,065 - logger.py:50 - Epoch: [488][0/6]	Total Loss: 0.72460	Main MSE (x10^-2): 72.4601	LR: 1.67e-06	EMPP_Raw: 1.43211
2025-07-18 12:44:03,822 - logger.py:50 - Epoch: [488][5/6]	Total Loss: 0.73709	Main MSE (x10^-2): 73.7090	LR: 1.67e-06	EMPP_Raw: 1.45594
2025-07-18 12:44:03,865 - logger.py:50 - Epoch 488 Training Summary: Avg Total Loss: 0.73709, Avg Main MSE: 0.73709, Time: 16.95s
2025-07-18 12:44:21,745 - logger.py:50 - Epoch 488 Summary | Train MSE (x10^-2): 73.7090 | Val MSE (x10^-2): 79.4013 | Time: 34.83s
2025-07-18 12:44:24,918 - logger.py:50 - Epoch: [489][0/6]	Total Loss: 0.73827	Main MSE (x10^-2): 73.8269	LR: 1.57e-06	EMPP_Raw: 1.45780
2025-07-18 12:44:38,667 - logger.py:50 - Epoch: [489][5/6]	Total Loss: 0.72823	Main MSE (x10^-2): 72.8231	LR: 1.57e-06	EMPP_Raw: 1.43889
2025-07-18 12:44:38,711 - logger.py:50 - Epoch 489 Training Summary: Avg Total Loss: 0.72823, Avg Main MSE: 0.72823, Time: 16.95s
2025-07-18 12:44:56,518 - logger.py:50 - Epoch 489 Summary | Train MSE (x10^-2): 72.8231 | Val MSE (x10^-2): 79.3933 | Time: 34.77s
2025-07-18 12:44:59,514 - logger.py:50 - Epoch: [490][0/6]	Total Loss: 0.75956	Main MSE (x10^-2): 75.9557	LR: 1.48e-06	EMPP_Raw: 1.49917
2025-07-18 12:45:13,428 - logger.py:50 - Epoch: [490][5/6]	Total Loss: 0.73996	Main MSE (x10^-2): 73.9964	LR: 1.48e-06	EMPP_Raw: 1.46201
2025-07-18 12:45:13,473 - logger.py:50 - Epoch 490 Training Summary: Avg Total Loss: 0.73996, Avg Main MSE: 0.73996, Time: 16.94s
2025-07-18 12:45:31,527 - logger.py:50 - Epoch 490 Summary | Train MSE (x10^-2): 73.9964 | Val MSE (x10^-2): 79.3805 | Time: 35.00s
2025-07-18 12:45:34,556 - logger.py:50 - Epoch: [491][0/6]	Total Loss: 0.71379	Main MSE (x10^-2): 71.3791	LR: 1.39e-06	EMPP_Raw: 1.40764
2025-07-18 12:45:48,369 - logger.py:50 - Epoch: [491][5/6]	Total Loss: 0.74582	Main MSE (x10^-2): 74.5818	LR: 1.39e-06	EMPP_Raw: 1.47325
2025-07-18 12:45:48,413 - logger.py:50 - Epoch 491 Training Summary: Avg Total Loss: 0.74582, Avg Main MSE: 0.74582, Time: 16.88s
2025-07-18 12:46:06,573 - logger.py:50 - Epoch 491 Summary | Train MSE (x10^-2): 74.5818 | Val MSE (x10^-2): 79.3442 | Time: 35.04s
2025-07-18 12:46:09,633 - logger.py:50 - Epoch: [492][0/6]	Total Loss: 0.72883	Main MSE (x10^-2): 72.8825	LR: 1.32e-06	EMPP_Raw: 1.44014
2025-07-18 12:46:23,392 - logger.py:50 - Epoch: [492][5/6]	Total Loss: 0.73866	Main MSE (x10^-2): 73.8659	LR: 1.32e-06	EMPP_Raw: 1.45970
2025-07-18 12:46:23,433 - logger.py:50 - Epoch 492 Training Summary: Avg Total Loss: 0.73866, Avg Main MSE: 0.73866, Time: 16.85s
2025-07-18 12:46:41,428 - logger.py:50 - Epoch 492 Summary | Train MSE (x10^-2): 73.8659 | Val MSE (x10^-2): 79.3101 | Time: 34.85s
2025-07-18 12:46:44,607 - logger.py:50 - Epoch: [493][0/6]	Total Loss: 0.72458	Main MSE (x10^-2): 72.4582	LR: 1.25e-06	EMPP_Raw: 1.43190
2025-07-18 12:46:58,347 - logger.py:50 - Epoch: [493][5/6]	Total Loss: 0.72346	Main MSE (x10^-2): 72.3461	LR: 1.25e-06	EMPP_Raw: 1.42907
2025-07-18 12:46:58,387 - logger.py:50 - Epoch 493 Training Summary: Avg Total Loss: 0.72346, Avg Main MSE: 0.72346, Time: 16.95s
2025-07-18 12:47:16,201 - logger.py:50 - Epoch 493 Summary | Train MSE (x10^-2): 72.3461 | Val MSE (x10^-2): 79.2749 | Time: 34.77s
2025-07-18 12:47:19,236 - logger.py:50 - Epoch: [494][0/6]	Total Loss: 0.70887	Main MSE (x10^-2): 70.8870	LR: 1.19e-06	EMPP_Raw: 1.40236
2025-07-18 12:47:33,141 - logger.py:50 - Epoch: [494][5/6]	Total Loss: 0.72410	Main MSE (x10^-2): 72.4098	LR: 1.19e-06	EMPP_Raw: 1.43121
2025-07-18 12:47:33,186 - logger.py:50 - Epoch 494 Training Summary: Avg Total Loss: 0.72410, Avg Main MSE: 0.72410, Time: 16.98s
2025-07-18 12:47:51,023 - logger.py:50 - Epoch 494 Summary | Train MSE (x10^-2): 72.4098 | Val MSE (x10^-2): 79.2948 | Time: 34.82s
2025-07-18 12:47:54,015 - logger.py:50 - Epoch: [495][0/6]	Total Loss: 0.75008	Main MSE (x10^-2): 75.0079	LR: 1.14e-06	EMPP_Raw: 1.48366
2025-07-18 12:48:07,757 - logger.py:50 - Epoch: [495][5/6]	Total Loss: 0.73431	Main MSE (x10^-2): 73.4313	LR: 1.14e-06	EMPP_Raw: 1.45095
2025-07-18 12:48:07,807 - logger.py:50 - Epoch 495 Training Summary: Avg Total Loss: 0.73431, Avg Main MSE: 0.73431, Time: 16.77s
2025-07-18 12:48:25,741 - logger.py:50 - Epoch 495 Summary | Train MSE (x10^-2): 73.4313 | Val MSE (x10^-2): 79.3189 | Time: 34.71s
2025-07-18 12:48:28,748 - logger.py:50 - Epoch: [496][0/6]	Total Loss: 0.73327	Main MSE (x10^-2): 73.3272	LR: 1.10e-06	EMPP_Raw: 1.44764
2025-07-18 12:48:42,617 - logger.py:50 - Epoch: [496][5/6]	Total Loss: 0.72999	Main MSE (x10^-2): 72.9993	LR: 1.10e-06	EMPP_Raw: 1.44162
2025-07-18 12:48:42,664 - logger.py:50 - Epoch 496 Training Summary: Avg Total Loss: 0.72999, Avg Main MSE: 0.72999, Time: 16.91s
2025-07-18 12:49:00,642 - logger.py:50 - Epoch 496 Summary | Train MSE (x10^-2): 72.9993 | Val MSE (x10^-2): 79.3356 | Time: 34.89s
2025-07-18 12:49:03,648 - logger.py:50 - Epoch: [497][0/6]	Total Loss: 0.72991	Main MSE (x10^-2): 72.9911	LR: 1.06e-06	EMPP_Raw: 1.44139
2025-07-18 12:49:17,424 - logger.py:50 - Epoch: [497][5/6]	Total Loss: 0.73860	Main MSE (x10^-2): 73.8604	LR: 1.06e-06	EMPP_Raw: 1.45934
2025-07-18 12:49:17,468 - logger.py:50 - Epoch 497 Training Summary: Avg Total Loss: 0.73860, Avg Main MSE: 0.73860, Time: 16.82s
2025-07-18 12:49:35,359 - logger.py:50 - Epoch 497 Summary | Train MSE (x10^-2): 73.8604 | Val MSE (x10^-2): 79.3402 | Time: 34.71s
2025-07-18 12:49:38,698 - logger.py:50 - Epoch: [498][0/6]	Total Loss: 0.72970	Main MSE (x10^-2): 72.9701	LR: 1.04e-06	EMPP_Raw: 1.44203
2025-07-18 12:49:52,490 - logger.py:50 - Epoch: [498][5/6]	Total Loss: 0.74001	Main MSE (x10^-2): 74.0011	LR: 1.04e-06	EMPP_Raw: 1.46225
2025-07-18 12:49:52,545 - logger.py:50 - Epoch 498 Training Summary: Avg Total Loss: 0.74001, Avg Main MSE: 0.74001, Time: 17.18s
2025-07-18 12:50:10,442 - logger.py:50 - Epoch 498 Summary | Train MSE (x10^-2): 74.0011 | Val MSE (x10^-2): 79.3286 | Time: 35.08s
2025-07-18 12:50:13,647 - logger.py:50 - Epoch: [499][0/6]	Total Loss: 0.73639	Main MSE (x10^-2): 73.6386	LR: 1.02e-06	EMPP_Raw: 1.45552
2025-07-18 12:50:27,399 - logger.py:50 - Epoch: [499][5/6]	Total Loss: 0.73108	Main MSE (x10^-2): 73.1076	LR: 1.02e-06	EMPP_Raw: 1.44458
2025-07-18 12:50:27,446 - logger.py:50 - Epoch 499 Training Summary: Avg Total Loss: 0.73108, Avg Main MSE: 0.73108, Time: 16.99s
2025-07-18 12:50:45,481 - logger.py:50 - Epoch 499 Summary | Train MSE (x10^-2): 73.1076 | Val MSE (x10^-2): 79.2887 | Time: 35.03s
2025-07-18 12:50:45,488 - logger.py:50 - --- Finished training for malonaldehyde ---
2025-07-18 12:50:45,488 - logger.py:50 - Final Best Val MSE (at Epoch 26): 0.469997 (x10^-2: 46.9997)
2025-07-18 12:50:45,488 - logger.py:50 - Final Test MSE (at Best Val Epoch): 0.472275 (x10^-2: 47.2275)
2025-07-18 12:50:45,523 - logger.py:50 - --- Starting training for naphthalene ---
2025-07-18 12:50:45,524 - logger.py:50 - Namespace(amp=False, batch_size=80, clip_grad=1.0, contrastive_aug_mask_ratio=0.15, contrastive_loss_weight=0.1, contrastive_mask_token_idx=0, contrastive_prioritize_heteroatoms=False, contrastive_projection_dim=128, contrastive_temp=0.1, cooldown_epochs=10, data_path='data/md17', decay_rate=0.1, delta_frame=3000, device='cuda:0', drop_path=0.0, empp_atom_type_embed_irreps='16x0e', empp_loss_weight=0.5, empp_num_mask=1, empp_pos_pred_num_s2_channels=32, empp_pos_pred_res_s2grid=100, empp_pos_pred_temp_label=0.1, empp_pos_pred_temp_softmax=0.1, empp_prioritize_heteroatoms=True, empp_ssp_feature_dim='16x0e', enable_contrastive=False, epochs=500, exp_name='md17_final_run_20250717_152800', logger=<logger.FileLogger object at 0x7f2569e9d8e0>, loss='l2', lr=0.0004, max_test_samples=2000, max_train_samples=500, max_val_samples=2000, min_lr=1e-06, model_name='graph_attention_transformer_nonlinear_l2', molecule_type='naphthalene', momentum=0.9, num_basis=128, opt='adamw', opt_betas=None, opt_eps=1e-08, output_dir='outputs/md17_final_run_20250717_152800', patience_epochs=10, pin_mem=True, print_freq=50, radius=5.0, sched='cosine', seed=42, ssp=True, warmup_epochs=10, warmup_lr=1e-06, weight_decay=1e-06, workers=8)
2025-07-18 12:50:45,525 - logger.py:50 - Loading datasets...
2025-07-18 12:50:47,878 - logger.py:50 - Creating model...
2025-07-18 12:50:56,242 - logger.py:50 - Number of params: 3,205,881
2025-07-18 12:51:00,957 - logger.py:50 - Epoch: [0][0/6]	Total Loss: 1.23303	Main MSE (x10^-2): 123.3028	LR: 1.00e-06	EMPP_Raw: 2.42879
2025-07-18 12:51:20,424 - logger.py:50 - Epoch: [0][5/6]	Total Loss: 1.22233	Main MSE (x10^-2): 122.2326	LR: 1.00e-06	EMPP_Raw: 2.40718
2025-07-18 12:51:20,469 - logger.py:50 - Epoch 0 Training Summary: Avg Total Loss: 1.22233, Avg Main MSE: 1.22233, Time: 24.22s
2025-07-18 12:51:59,151 - logger.py:50 - *** New Best Val MSE (x10^-2): 1.9050, Corresponding Test MSE (x10^-2): 1.9418 at Epoch 0 ***
2025-07-18 12:51:59,197 - logger.py:50 - Epoch 0 Summary | Train MSE (x10^-2): 122.2326 | Val MSE (x10^-2): 1.9050 | Time: 62.95s
2025-07-18 12:52:03,105 - logger.py:50 - Epoch: [1][0/6]	Total Loss: 1.18133	Main MSE (x10^-2): 118.1327	LR: 1.00e-06	EMPP_Raw: 2.32398
2025-07-18 12:52:20,462 - logger.py:50 - Epoch: [1][5/6]	Total Loss: 1.20642	Main MSE (x10^-2): 120.6417	LR: 1.00e-06	EMPP_Raw: 2.37543
2025-07-18 12:52:20,508 - logger.py:50 - Epoch 1 Training Summary: Avg Total Loss: 1.20642, Avg Main MSE: 1.20642, Time: 21.31s
2025-07-18 12:52:58,863 - logger.py:50 - *** New Best Val MSE (x10^-2): 1.9040, Corresponding Test MSE (x10^-2): 1.9408 at Epoch 1 ***
2025-07-18 12:52:58,911 - logger.py:50 - Epoch 1 Summary | Train MSE (x10^-2): 120.6417 | Val MSE (x10^-2): 1.9040 | Time: 59.71s
2025-07-18 12:53:02,805 - logger.py:50 - Epoch: [2][0/6]	Total Loss: 1.16694	Main MSE (x10^-2): 116.6937	LR: 4.09e-05	EMPP_Raw: 2.29505
2025-07-18 12:53:20,214 - logger.py:50 - Epoch: [2][5/6]	Total Loss: 1.03156	Main MSE (x10^-2): 103.1556	LR: 4.09e-05	EMPP_Raw: 2.02583
2025-07-18 12:53:20,255 - logger.py:50 - Epoch 2 Training Summary: Avg Total Loss: 1.03156, Avg Main MSE: 1.03156, Time: 21.34s
2025-07-18 12:53:58,632 - logger.py:50 - *** New Best Val MSE (x10^-2): 1.8962, Corresponding Test MSE (x10^-2): 1.9321 at Epoch 2 ***
2025-07-18 12:53:58,679 - logger.py:50 - Epoch 2 Summary | Train MSE (x10^-2): 103.1556 | Val MSE (x10^-2): 1.8962 | Time: 59.77s
2025-07-18 12:54:02,582 - logger.py:50 - Epoch: [3][0/6]	Total Loss: 0.92973	Main MSE (x10^-2): 92.9731	LR: 8.08e-05	EMPP_Raw: 1.81857
2025-07-18 12:54:19,973 - logger.py:50 - Epoch: [3][5/6]	Total Loss: 0.86889	Main MSE (x10^-2): 86.8891	LR: 8.08e-05	EMPP_Raw: 1.70050
2025-07-18 12:54:20,017 - logger.py:50 - Epoch 3 Training Summary: Avg Total Loss: 0.86889, Avg Main MSE: 0.86889, Time: 21.33s
2025-07-18 12:54:58,245 - logger.py:50 - *** New Best Val MSE (x10^-2): 1.8840, Corresponding Test MSE (x10^-2): 1.9200 at Epoch 3 ***
2025-07-18 12:54:58,294 - logger.py:50 - Epoch 3 Summary | Train MSE (x10^-2): 86.8891 | Val MSE (x10^-2): 1.8840 | Time: 59.61s
2025-07-18 12:55:02,207 - logger.py:50 - Epoch: [4][0/6]	Total Loss: 0.80949	Main MSE (x10^-2): 80.9495	LR: 1.21e-04	EMPP_Raw: 1.58451
2025-07-18 12:55:19,614 - logger.py:50 - Epoch: [4][5/6]	Total Loss: 0.80085	Main MSE (x10^-2): 80.0852	LR: 1.21e-04	EMPP_Raw: 1.56482
2025-07-18 12:55:19,661 - logger.py:50 - Epoch 4 Training Summary: Avg Total Loss: 0.80085, Avg Main MSE: 0.80085, Time: 21.36s
2025-07-18 12:55:57,807 - logger.py:50 - *** New Best Val MSE (x10^-2): 1.8729, Corresponding Test MSE (x10^-2): 1.9085 at Epoch 4 ***
2025-07-18 12:55:57,854 - logger.py:50 - Epoch 4 Summary | Train MSE (x10^-2): 80.0852 | Val MSE (x10^-2): 1.8729 | Time: 59.56s
2025-07-18 12:56:01,745 - logger.py:50 - Epoch: [5][0/6]	Total Loss: 0.77686	Main MSE (x10^-2): 77.6857	LR: 1.61e-04	EMPP_Raw: 1.51662
2025-07-18 12:56:19,044 - logger.py:50 - Epoch: [5][5/6]	Total Loss: 0.74819	Main MSE (x10^-2): 74.8186	LR: 1.61e-04	EMPP_Raw: 1.45953
2025-07-18 12:56:19,086 - logger.py:50 - Epoch 5 Training Summary: Avg Total Loss: 0.74819, Avg Main MSE: 0.74819, Time: 21.23s
2025-07-18 12:56:57,423 - logger.py:50 - *** New Best Val MSE (x10^-2): 1.8650, Corresponding Test MSE (x10^-2): 1.9001 at Epoch 5 ***
2025-07-18 12:56:57,473 - logger.py:50 - Epoch 5 Summary | Train MSE (x10^-2): 74.8186 | Val MSE (x10^-2): 1.8650 | Time: 59.62s
2025-07-18 12:57:01,345 - logger.py:50 - Epoch: [6][0/6]	Total Loss: 0.67736	Main MSE (x10^-2): 67.7359	LR: 2.00e-04	EMPP_Raw: 1.31885
2025-07-18 12:57:18,627 - logger.py:50 - Epoch: [6][5/6]	Total Loss: 0.70466	Main MSE (x10^-2): 70.4665	LR: 2.00e-04	EMPP_Raw: 1.37274
2025-07-18 12:57:18,676 - logger.py:50 - Epoch 6 Training Summary: Avg Total Loss: 0.70466, Avg Main MSE: 0.70466, Time: 21.20s
2025-07-18 12:57:57,025 - logger.py:50 - *** New Best Val MSE (x10^-2): 1.8525, Corresponding Test MSE (x10^-2): 1.8872 at Epoch 6 ***
2025-07-18 12:57:57,211 - logger.py:50 - Epoch 6 Summary | Train MSE (x10^-2): 70.4665 | Val MSE (x10^-2): 1.8525 | Time: 59.74s
2025-07-18 12:58:00,926 - logger.py:50 - Epoch: [7][0/6]	Total Loss: 0.76809	Main MSE (x10^-2): 76.8088	LR: 2.40e-04	EMPP_Raw: 1.50319
2025-07-18 12:58:18,235 - logger.py:50 - Epoch: [7][5/6]	Total Loss: 0.71985	Main MSE (x10^-2): 71.9848	LR: 2.40e-04	EMPP_Raw: 1.40355
2025-07-18 12:58:18,277 - logger.py:50 - Epoch 7 Training Summary: Avg Total Loss: 0.71985, Avg Main MSE: 0.71985, Time: 21.06s
2025-07-18 12:58:56,537 - logger.py:50 - *** New Best Val MSE (x10^-2): 1.8337, Corresponding Test MSE (x10^-2): 1.8681 at Epoch 7 ***
2025-07-18 12:58:56,585 - logger.py:50 - Epoch 7 Summary | Train MSE (x10^-2): 71.9848 | Val MSE (x10^-2): 1.8337 | Time: 59.37s
2025-07-18 12:59:00,291 - logger.py:50 - Epoch: [8][0/6]	Total Loss: 0.74911	Main MSE (x10^-2): 74.9110	LR: 2.80e-04	EMPP_Raw: 1.46287
2025-07-18 12:59:17,695 - logger.py:50 - Epoch: [8][5/6]	Total Loss: 0.71371	Main MSE (x10^-2): 71.3710	LR: 2.80e-04	EMPP_Raw: 1.39141
2025-07-18 12:59:17,735 - logger.py:50 - Epoch 8 Training Summary: Avg Total Loss: 0.71371, Avg Main MSE: 0.71371, Time: 21.15s
2025-07-18 12:59:56,344 - logger.py:50 - *** New Best Val MSE (x10^-2): 1.8032, Corresponding Test MSE (x10^-2): 1.8368 at Epoch 8 ***
2025-07-18 12:59:56,392 - logger.py:50 - Epoch 8 Summary | Train MSE (x10^-2): 71.3710 | Val MSE (x10^-2): 1.8032 | Time: 59.81s
2025-07-18 13:00:00,151 - logger.py:50 - Epoch: [9][0/6]	Total Loss: 0.64839	Main MSE (x10^-2): 64.8390	LR: 3.20e-04	EMPP_Raw: 1.26230
2025-07-18 13:00:17,488 - logger.py:50 - Epoch: [9][5/6]	Total Loss: 0.68441	Main MSE (x10^-2): 68.4408	LR: 3.20e-04	EMPP_Raw: 1.33333
2025-07-18 13:00:17,530 - logger.py:50 - Epoch 9 Training Summary: Avg Total Loss: 0.68441, Avg Main MSE: 0.68441, Time: 21.13s
2025-07-18 13:00:55,909 - logger.py:50 - *** New Best Val MSE (x10^-2): 1.7825, Corresponding Test MSE (x10^-2): 1.8164 at Epoch 9 ***
2025-07-18 13:00:55,957 - logger.py:50 - Epoch 9 Summary | Train MSE (x10^-2): 68.4408 | Val MSE (x10^-2): 1.7825 | Time: 59.56s
2025-07-18 13:00:59,698 - logger.py:50 - Epoch: [10][0/6]	Total Loss: 0.74103	Main MSE (x10^-2): 74.1026	LR: 3.60e-04	EMPP_Raw: 1.44590
2025-07-18 13:01:17,081 - logger.py:50 - Epoch: [10][5/6]	Total Loss: 0.71310	Main MSE (x10^-2): 71.3101	LR: 3.60e-04	EMPP_Raw: 1.39147
2025-07-18 13:01:17,124 - logger.py:50 - Epoch 10 Training Summary: Avg Total Loss: 0.71310, Avg Main MSE: 0.71310, Time: 21.16s
2025-07-18 13:01:55,573 - logger.py:50 - *** New Best Val MSE (x10^-2): 1.7181, Corresponding Test MSE (x10^-2): 1.7512 at Epoch 10 ***
2025-07-18 13:01:55,623 - logger.py:50 - Epoch 10 Summary | Train MSE (x10^-2): 71.3101 | Val MSE (x10^-2): 1.7181 | Time: 59.67s
2025-07-18 13:01:59,360 - logger.py:50 - Epoch: [11][0/6]	Total Loss: 0.71354	Main MSE (x10^-2): 71.3538	LR: 4.00e-04	EMPP_Raw: 1.39345
2025-07-18 13:02:16,686 - logger.py:50 - Epoch: [11][5/6]	Total Loss: 0.70534	Main MSE (x10^-2): 70.5342	LR: 4.00e-04	EMPP_Raw: 1.37709
2025-07-18 13:02:16,731 - logger.py:50 - Epoch 11 Training Summary: Avg Total Loss: 0.70534, Avg Main MSE: 0.70534, Time: 21.10s
2025-07-18 13:02:55,105 - logger.py:50 - *** New Best Val MSE (x10^-2): 1.6424, Corresponding Test MSE (x10^-2): 1.6748 at Epoch 11 ***
2025-07-18 13:02:55,152 - logger.py:50 - Epoch 11 Summary | Train MSE (x10^-2): 70.5342 | Val MSE (x10^-2): 1.6424 | Time: 59.53s
2025-07-18 13:02:58,864 - logger.py:50 - Epoch: [12][0/6]	Total Loss: 0.65377	Main MSE (x10^-2): 65.3766	LR: 4.00e-04	EMPP_Raw: 1.27333
2025-07-18 13:03:16,138 - logger.py:50 - Epoch: [12][5/6]	Total Loss: 0.67426	Main MSE (x10^-2): 67.4261	LR: 4.00e-04	EMPP_Raw: 1.31646
2025-07-18 13:03:16,187 - logger.py:50 - Epoch 12 Training Summary: Avg Total Loss: 0.67426, Avg Main MSE: 0.67426, Time: 21.03s
2025-07-18 13:03:54,712 - logger.py:50 - *** New Best Val MSE (x10^-2): 1.5514, Corresponding Test MSE (x10^-2): 1.5826 at Epoch 12 ***
2025-07-18 13:03:54,759 - logger.py:50 - Epoch 12 Summary | Train MSE (x10^-2): 67.4261 | Val MSE (x10^-2): 1.5514 | Time: 59.61s
2025-07-18 13:03:58,483 - logger.py:50 - Epoch: [13][0/6]	Total Loss: 0.73053	Main MSE (x10^-2): 73.0532	LR: 3.99e-04	EMPP_Raw: 1.42839
2025-07-18 13:04:15,697 - logger.py:50 - Epoch: [13][5/6]	Total Loss: 0.67923	Main MSE (x10^-2): 67.9234	LR: 3.99e-04	EMPP_Raw: 1.32806
2025-07-18 13:04:15,743 - logger.py:50 - Epoch 13 Training Summary: Avg Total Loss: 0.67923, Avg Main MSE: 0.67923, Time: 20.98s
2025-07-18 13:04:54,106 - logger.py:50 - *** New Best Val MSE (x10^-2): 1.4308, Corresponding Test MSE (x10^-2): 1.4597 at Epoch 13 ***
2025-07-18 13:04:54,157 - logger.py:50 - Epoch 13 Summary | Train MSE (x10^-2): 67.9234 | Val MSE (x10^-2): 1.4308 | Time: 59.40s
2025-07-18 13:04:57,875 - logger.py:50 - Epoch: [14][0/6]	Total Loss: 0.69610	Main MSE (x10^-2): 69.6097	LR: 3.99e-04	EMPP_Raw: 1.36345
2025-07-18 13:05:15,184 - logger.py:50 - Epoch: [14][5/6]	Total Loss: 0.66904	Main MSE (x10^-2): 66.9041	LR: 3.99e-04	EMPP_Raw: 1.30411
2025-07-18 13:05:15,225 - logger.py:50 - Epoch 14 Training Summary: Avg Total Loss: 0.66904, Avg Main MSE: 0.66904, Time: 21.06s
2025-07-18 13:05:34,324 - logger.py:50 - Epoch 14 Summary | Train MSE (x10^-2): 66.9041 | Val MSE (x10^-2): 1.5907 | Time: 40.17s
2025-07-18 13:05:38,224 - logger.py:50 - Epoch: [15][0/6]	Total Loss: 0.67316	Main MSE (x10^-2): 67.3157	LR: 3.99e-04	EMPP_Raw: 1.31328
2025-07-18 13:05:55,482 - logger.py:50 - Epoch: [15][5/6]	Total Loss: 0.66680	Main MSE (x10^-2): 66.6805	LR: 3.99e-04	EMPP_Raw: 1.30285
2025-07-18 13:05:55,525 - logger.py:50 - Epoch 15 Training Summary: Avg Total Loss: 0.66680, Avg Main MSE: 0.66680, Time: 21.19s
2025-07-18 13:06:33,564 - logger.py:50 - *** New Best Val MSE (x10^-2): 1.2872, Corresponding Test MSE (x10^-2): 1.3140 at Epoch 15 ***
2025-07-18 13:06:33,614 - logger.py:50 - Epoch 15 Summary | Train MSE (x10^-2): 66.6805 | Val MSE (x10^-2): 1.2872 | Time: 59.28s
2025-07-18 13:06:37,509 - logger.py:50 - Epoch: [16][0/6]	Total Loss: 0.66387	Main MSE (x10^-2): 66.3866	LR: 3.99e-04	EMPP_Raw: 1.30239
2025-07-18 13:06:54,820 - logger.py:50 - Epoch: [16][5/6]	Total Loss: 0.65360	Main MSE (x10^-2): 65.3598	LR: 3.99e-04	EMPP_Raw: 1.27424
2025-07-18 13:06:54,865 - logger.py:50 - Epoch 16 Training Summary: Avg Total Loss: 0.65360, Avg Main MSE: 0.65360, Time: 21.25s
2025-07-18 13:07:14,046 - logger.py:50 - Epoch 16 Summary | Train MSE (x10^-2): 65.3598 | Val MSE (x10^-2): 1.6435 | Time: 40.43s
2025-07-18 13:07:17,930 - logger.py:50 - Epoch: [17][0/6]	Total Loss: 0.68134	Main MSE (x10^-2): 68.1341	LR: 3.99e-04	EMPP_Raw: 1.33044
2025-07-18 13:07:35,220 - logger.py:50 - Epoch: [17][5/6]	Total Loss: 0.66047	Main MSE (x10^-2): 66.0469	LR: 3.99e-04	EMPP_Raw: 1.29215
2025-07-18 13:07:35,265 - logger.py:50 - Epoch 17 Training Summary: Avg Total Loss: 0.66047, Avg Main MSE: 0.66047, Time: 21.21s
2025-07-18 13:08:13,581 - logger.py:50 - *** New Best Val MSE (x10^-2): 1.2818, Corresponding Test MSE (x10^-2): 1.3102 at Epoch 17 ***
2025-07-18 13:08:13,629 - logger.py:50 - Epoch 17 Summary | Train MSE (x10^-2): 66.0469 | Val MSE (x10^-2): 1.2818 | Time: 59.58s
2025-07-18 13:08:17,492 - logger.py:50 - Epoch: [18][0/6]	Total Loss: 0.69210	Main MSE (x10^-2): 69.2096	LR: 3.99e-04	EMPP_Raw: 1.35781
2025-07-18 13:08:34,755 - logger.py:50 - Epoch: [18][5/6]	Total Loss: 0.66841	Main MSE (x10^-2): 66.8410	LR: 3.99e-04	EMPP_Raw: 1.30904
2025-07-18 13:08:34,796 - logger.py:50 - Epoch 18 Training Summary: Avg Total Loss: 0.66841, Avg Main MSE: 0.66841, Time: 21.16s
2025-07-18 13:08:54,023 - logger.py:50 - Epoch 18 Summary | Train MSE (x10^-2): 66.8410 | Val MSE (x10^-2): 1.3188 | Time: 40.39s
2025-07-18 13:08:57,735 - logger.py:50 - Epoch: [19][0/6]	Total Loss: 0.65833	Main MSE (x10^-2): 65.8333	LR: 3.99e-04	EMPP_Raw: 1.28887
2025-07-18 13:09:15,150 - logger.py:50 - Epoch: [19][5/6]	Total Loss: 0.66306	Main MSE (x10^-2): 66.3058	LR: 3.99e-04	EMPP_Raw: 1.29928
2025-07-18 13:09:15,196 - logger.py:50 - Epoch 19 Training Summary: Avg Total Loss: 0.66306, Avg Main MSE: 0.66306, Time: 21.16s
2025-07-18 13:09:53,582 - logger.py:50 - *** New Best Val MSE (x10^-2): 1.2503, Corresponding Test MSE (x10^-2): 1.2780 at Epoch 19 ***
2025-07-18 13:09:53,629 - logger.py:50 - Epoch 19 Summary | Train MSE (x10^-2): 66.3058 | Val MSE (x10^-2): 1.2503 | Time: 59.60s
2025-07-18 13:09:57,356 - logger.py:50 - Epoch: [20][0/6]	Total Loss: 0.65566	Main MSE (x10^-2): 65.5656	LR: 3.99e-04	EMPP_Raw: 1.28546
2025-07-18 13:10:14,775 - logger.py:50 - Epoch: [20][5/6]	Total Loss: 0.65970	Main MSE (x10^-2): 65.9698	LR: 3.99e-04	EMPP_Raw: 1.29234
2025-07-18 13:10:14,819 - logger.py:50 - Epoch 20 Training Summary: Avg Total Loss: 0.65970, Avg Main MSE: 0.65970, Time: 21.19s
2025-07-18 13:10:53,113 - logger.py:50 - *** New Best Val MSE (x10^-2): 1.2371, Corresponding Test MSE (x10^-2): 1.2636 at Epoch 20 ***
2025-07-18 13:10:53,161 - logger.py:50 - Epoch 20 Summary | Train MSE (x10^-2): 65.9698 | Val MSE (x10^-2): 1.2371 | Time: 59.53s
2025-07-18 13:10:56,864 - logger.py:50 - Epoch: [21][0/6]	Total Loss: 0.65942	Main MSE (x10^-2): 65.9423	LR: 3.98e-04	EMPP_Raw: 1.29362
2025-07-18 13:11:14,321 - logger.py:50 - Epoch: [21][5/6]	Total Loss: 0.65005	Main MSE (x10^-2): 65.0053	LR: 3.98e-04	EMPP_Raw: 1.27395
2025-07-18 13:11:14,367 - logger.py:50 - Epoch 21 Training Summary: Avg Total Loss: 0.65005, Avg Main MSE: 0.65005, Time: 21.20s
2025-07-18 13:11:33,584 - logger.py:50 - Epoch 21 Summary | Train MSE (x10^-2): 65.0053 | Val MSE (x10^-2): 1.2520 | Time: 40.42s
2025-07-18 13:11:37,329 - logger.py:50 - Epoch: [22][0/6]	Total Loss: 0.63844	Main MSE (x10^-2): 63.8440	LR: 3.98e-04	EMPP_Raw: 1.25362
2025-07-18 13:11:54,542 - logger.py:50 - Epoch: [22][5/6]	Total Loss: 0.64576	Main MSE (x10^-2): 64.5758	LR: 3.98e-04	EMPP_Raw: 1.26575
2025-07-18 13:11:54,587 - logger.py:50 - Epoch 22 Training Summary: Avg Total Loss: 0.64576, Avg Main MSE: 0.64576, Time: 20.99s
2025-07-18 13:12:32,906 - logger.py:50 - *** New Best Val MSE (x10^-2): 1.2307, Corresponding Test MSE (x10^-2): 1.2546 at Epoch 22 ***
2025-07-18 13:12:32,953 - logger.py:50 - Epoch 22 Summary | Train MSE (x10^-2): 64.5758 | Val MSE (x10^-2): 1.2307 | Time: 59.36s
2025-07-18 13:12:36,672 - logger.py:50 - Epoch: [23][0/6]	Total Loss: 0.64929	Main MSE (x10^-2): 64.9294	LR: 3.98e-04	EMPP_Raw: 1.27391
2025-07-18 13:12:53,935 - logger.py:50 - Epoch: [23][5/6]	Total Loss: 0.64494	Main MSE (x10^-2): 64.4938	LR: 3.98e-04	EMPP_Raw: 1.26398
2025-07-18 13:12:53,980 - logger.py:50 - Epoch 23 Training Summary: Avg Total Loss: 0.64494, Avg Main MSE: 0.64494, Time: 21.02s
2025-07-18 13:13:13,205 - logger.py:50 - Epoch 23 Summary | Train MSE (x10^-2): 64.4938 | Val MSE (x10^-2): 1.4929 | Time: 40.25s
2025-07-18 13:13:16,962 - logger.py:50 - Epoch: [24][0/6]	Total Loss: 0.69200	Main MSE (x10^-2): 69.1999	LR: 3.98e-04	EMPP_Raw: 1.35254
2025-07-18 13:13:34,294 - logger.py:50 - Epoch: [24][5/6]	Total Loss: 0.66755	Main MSE (x10^-2): 66.7548	LR: 3.98e-04	EMPP_Raw: 1.30662
2025-07-18 13:13:34,341 - logger.py:50 - Epoch 24 Training Summary: Avg Total Loss: 0.66755, Avg Main MSE: 0.66755, Time: 21.13s
2025-07-18 13:13:53,492 - logger.py:50 - Epoch 24 Summary | Train MSE (x10^-2): 66.7548 | Val MSE (x10^-2): 1.4574 | Time: 40.28s
2025-07-18 13:13:57,409 - logger.py:50 - Epoch: [25][0/6]	Total Loss: 0.63923	Main MSE (x10^-2): 63.9229	LR: 3.98e-04	EMPP_Raw: 1.24952
2025-07-18 13:14:14,643 - logger.py:50 - Epoch: [25][5/6]	Total Loss: 0.65958	Main MSE (x10^-2): 65.9583	LR: 3.98e-04	EMPP_Raw: 1.29097
2025-07-18 13:14:14,687 - logger.py:50 - Epoch 25 Training Summary: Avg Total Loss: 0.65958, Avg Main MSE: 0.65958, Time: 21.19s
2025-07-18 13:14:33,832 - logger.py:50 - Epoch 25 Summary | Train MSE (x10^-2): 65.9583 | Val MSE (x10^-2): 1.3046 | Time: 40.33s
2025-07-18 13:14:37,555 - logger.py:50 - Epoch: [26][0/6]	Total Loss: 0.70613	Main MSE (x10^-2): 70.6134	LR: 3.98e-04	EMPP_Raw: 1.38473
2025-07-18 13:14:55,188 - logger.py:50 - Epoch: [26][5/6]	Total Loss: 0.66214	Main MSE (x10^-2): 66.2143	LR: 3.98e-04	EMPP_Raw: 1.29748
2025-07-18 13:14:55,241 - logger.py:50 - Epoch 26 Training Summary: Avg Total Loss: 0.66214, Avg Main MSE: 0.66214, Time: 21.40s
2025-07-18 13:15:14,379 - logger.py:50 - Epoch 26 Summary | Train MSE (x10^-2): 66.2143 | Val MSE (x10^-2): 1.5323 | Time: 40.54s
2025-07-18 13:15:18,076 - logger.py:50 - Epoch: [27][0/6]	Total Loss: 0.66549	Main MSE (x10^-2): 66.5493	LR: 3.97e-04	EMPP_Raw: 1.29892
2025-07-18 13:15:35,376 - logger.py:50 - Epoch: [27][5/6]	Total Loss: 0.65580	Main MSE (x10^-2): 65.5796	LR: 3.97e-04	EMPP_Raw: 1.27906
2025-07-18 13:15:35,426 - logger.py:50 - Epoch 27 Training Summary: Avg Total Loss: 0.65580, Avg Main MSE: 0.65580, Time: 21.04s
2025-07-18 13:15:54,612 - logger.py:50 - Epoch 27 Summary | Train MSE (x10^-2): 65.5796 | Val MSE (x10^-2): 1.6471 | Time: 40.22s
2025-07-18 13:15:58,543 - logger.py:50 - Epoch: [28][0/6]	Total Loss: 0.63048	Main MSE (x10^-2): 63.0476	LR: 3.97e-04	EMPP_Raw: 1.22917
2025-07-18 13:16:15,859 - logger.py:50 - Epoch: [28][5/6]	Total Loss: 0.64106	Main MSE (x10^-2): 64.1063	LR: 3.97e-04	EMPP_Raw: 1.24881
2025-07-18 13:16:15,909 - logger.py:50 - Epoch 28 Training Summary: Avg Total Loss: 0.64106, Avg Main MSE: 0.64106, Time: 21.29s
2025-07-18 13:16:35,154 - logger.py:50 - Epoch 28 Summary | Train MSE (x10^-2): 64.1063 | Val MSE (x10^-2): 1.2605 | Time: 40.54s
2025-07-18 13:16:39,034 - logger.py:50 - Epoch: [29][0/6]	Total Loss: 0.66289	Main MSE (x10^-2): 66.2894	LR: 3.97e-04	EMPP_Raw: 1.30146
2025-07-18 13:16:56,357 - logger.py:50 - Epoch: [29][5/6]	Total Loss: 0.65294	Main MSE (x10^-2): 65.2937	LR: 3.97e-04	EMPP_Raw: 1.27919
2025-07-18 13:16:56,403 - logger.py:50 - Epoch 29 Training Summary: Avg Total Loss: 0.65294, Avg Main MSE: 0.65294, Time: 21.24s
2025-07-18 13:17:34,578 - logger.py:50 - *** New Best Val MSE (x10^-2): 1.2075, Corresponding Test MSE (x10^-2): 1.2336 at Epoch 29 ***
2025-07-18 13:17:34,625 - logger.py:50 - Epoch 29 Summary | Train MSE (x10^-2): 65.2937 | Val MSE (x10^-2): 1.2075 | Time: 59.47s
2025-07-18 13:17:38,485 - logger.py:50 - Epoch: [30][0/6]	Total Loss: 0.63163	Main MSE (x10^-2): 63.1631	LR: 3.97e-04	EMPP_Raw: 1.23910
2025-07-18 13:17:55,672 - logger.py:50 - Epoch: [30][5/6]	Total Loss: 0.63351	Main MSE (x10^-2): 63.3515	LR: 3.97e-04	EMPP_Raw: 1.24272
2025-07-18 13:17:55,715 - logger.py:50 - Epoch 30 Training Summary: Avg Total Loss: 0.63351, Avg Main MSE: 0.63351, Time: 21.09s
2025-07-18 13:18:14,897 - logger.py:50 - Epoch 30 Summary | Train MSE (x10^-2): 63.3515 | Val MSE (x10^-2): 1.2143 | Time: 40.27s
2025-07-18 13:18:18,601 - logger.py:50 - Epoch: [31][0/6]	Total Loss: 0.62198	Main MSE (x10^-2): 62.1980	LR: 3.96e-04	EMPP_Raw: 1.22058
2025-07-18 13:18:36,004 - logger.py:50 - Epoch: [31][5/6]	Total Loss: 0.64472	Main MSE (x10^-2): 64.4719	LR: 3.96e-04	EMPP_Raw: 1.26530
2025-07-18 13:18:36,060 - logger.py:50 - Epoch 31 Training Summary: Avg Total Loss: 0.64472, Avg Main MSE: 0.64472, Time: 21.15s
2025-07-18 13:19:14,297 - logger.py:50 - *** New Best Val MSE (x10^-2): 1.1870, Corresponding Test MSE (x10^-2): 1.2115 at Epoch 31 ***
2025-07-18 13:19:14,340 - logger.py:50 - Epoch 31 Summary | Train MSE (x10^-2): 64.4719 | Val MSE (x10^-2): 1.1870 | Time: 59.44s
2025-07-18 13:19:18,068 - logger.py:50 - Epoch: [32][0/6]	Total Loss: 0.63900	Main MSE (x10^-2): 63.8998	LR: 3.96e-04	EMPP_Raw: 1.25469
2025-07-18 13:19:35,523 - logger.py:50 - Epoch: [32][5/6]	Total Loss: 0.64645	Main MSE (x10^-2): 64.6447	LR: 3.96e-04	EMPP_Raw: 1.26891
2025-07-18 13:19:35,568 - logger.py:50 - Epoch 32 Training Summary: Avg Total Loss: 0.64645, Avg Main MSE: 0.64645, Time: 21.22s
2025-07-18 13:20:14,137 - logger.py:50 - *** New Best Val MSE (x10^-2): 1.1811, Corresponding Test MSE (x10^-2): 1.2068 at Epoch 32 ***
2025-07-18 13:20:14,184 - logger.py:50 - Epoch 32 Summary | Train MSE (x10^-2): 64.6447 | Val MSE (x10^-2): 1.1811 | Time: 59.84s
2025-07-18 13:20:17,960 - logger.py:50 - Epoch: [33][0/6]	Total Loss: 0.62475	Main MSE (x10^-2): 62.4746	LR: 3.96e-04	EMPP_Raw: 1.22506
2025-07-18 13:20:35,479 - logger.py:50 - Epoch: [33][5/6]	Total Loss: 0.64410	Main MSE (x10^-2): 64.4101	LR: 3.96e-04	EMPP_Raw: 1.26412
2025-07-18 13:20:35,523 - logger.py:50 - Epoch 33 Training Summary: Avg Total Loss: 0.64410, Avg Main MSE: 0.64410, Time: 21.34s
2025-07-18 13:20:54,647 - logger.py:50 - Epoch 33 Summary | Train MSE (x10^-2): 64.4101 | Val MSE (x10^-2): 1.1901 | Time: 40.46s
2025-07-18 13:20:58,355 - logger.py:50 - Epoch: [34][0/6]	Total Loss: 0.62986	Main MSE (x10^-2): 62.9858	LR: 3.96e-04	EMPP_Raw: 1.23524
2025-07-18 13:21:15,671 - logger.py:50 - Epoch: [34][5/6]	Total Loss: 0.64190	Main MSE (x10^-2): 64.1900	LR: 3.96e-04	EMPP_Raw: 1.25950
2025-07-18 13:21:15,719 - logger.py:50 - Epoch 34 Training Summary: Avg Total Loss: 0.64190, Avg Main MSE: 0.64190, Time: 21.06s
2025-07-18 13:21:54,201 - logger.py:50 - *** New Best Val MSE (x10^-2): 1.1724, Corresponding Test MSE (x10^-2): 1.1973 at Epoch 34 ***
2025-07-18 13:21:54,249 - logger.py:50 - Epoch 34 Summary | Train MSE (x10^-2): 64.1900 | Val MSE (x10^-2): 1.1724 | Time: 59.60s
2025-07-18 13:21:57,944 - logger.py:50 - Epoch: [35][0/6]	Total Loss: 0.64550	Main MSE (x10^-2): 64.5496	LR: 3.95e-04	EMPP_Raw: 1.26699
2025-07-18 13:22:15,172 - logger.py:50 - Epoch: [35][5/6]	Total Loss: 0.64807	Main MSE (x10^-2): 64.8067	LR: 3.95e-04	EMPP_Raw: 1.27170
2025-07-18 13:22:15,217 - logger.py:50 - Epoch 35 Training Summary: Avg Total Loss: 0.64807, Avg Main MSE: 0.64807, Time: 20.96s
2025-07-18 13:22:34,425 - logger.py:50 - Epoch 35 Summary | Train MSE (x10^-2): 64.8067 | Val MSE (x10^-2): 1.2370 | Time: 40.18s
2025-07-18 13:22:38,151 - logger.py:50 - Epoch: [36][0/6]	Total Loss: 0.63340	Main MSE (x10^-2): 63.3396	LR: 3.95e-04	EMPP_Raw: 1.24251
2025-07-18 13:22:55,459 - logger.py:50 - Epoch: [36][5/6]	Total Loss: 0.64386	Main MSE (x10^-2): 64.3861	LR: 3.95e-04	EMPP_Raw: 1.26347
2025-07-18 13:22:55,502 - logger.py:50 - Epoch 36 Training Summary: Avg Total Loss: 0.64386, Avg Main MSE: 0.64386, Time: 21.07s
2025-07-18 13:23:14,703 - logger.py:50 - Epoch 36 Summary | Train MSE (x10^-2): 64.3861 | Val MSE (x10^-2): 1.1846 | Time: 40.27s
2025-07-18 13:23:18,418 - logger.py:50 - Epoch: [37][0/6]	Total Loss: 0.62663	Main MSE (x10^-2): 62.6630	LR: 3.95e-04	EMPP_Raw: 1.23003
2025-07-18 13:23:35,708 - logger.py:50 - Epoch: [37][5/6]	Total Loss: 0.63497	Main MSE (x10^-2): 63.4967	LR: 3.95e-04	EMPP_Raw: 1.24533
2025-07-18 13:23:35,754 - logger.py:50 - Epoch 37 Training Summary: Avg Total Loss: 0.63497, Avg Main MSE: 0.63497, Time: 21.04s
2025-07-18 13:23:55,110 - logger.py:50 - Epoch 37 Summary | Train MSE (x10^-2): 63.4967 | Val MSE (x10^-2): 1.2143 | Time: 40.40s
2025-07-18 13:23:59,025 - logger.py:50 - Epoch: [38][0/6]	Total Loss: 0.63310	Main MSE (x10^-2): 63.3099	LR: 3.95e-04	EMPP_Raw: 1.23995
2025-07-18 13:24:16,382 - logger.py:50 - Epoch: [38][5/6]	Total Loss: 0.65009	Main MSE (x10^-2): 65.0092	LR: 3.95e-04	EMPP_Raw: 1.27588
2025-07-18 13:24:16,427 - logger.py:50 - Epoch 38 Training Summary: Avg Total Loss: 0.65009, Avg Main MSE: 0.65009, Time: 21.31s
2025-07-18 13:24:35,604 - logger.py:50 - Epoch 38 Summary | Train MSE (x10^-2): 65.0092 | Val MSE (x10^-2): 1.2853 | Time: 40.49s
2025-07-18 13:24:39,342 - logger.py:50 - Epoch: [39][0/6]	Total Loss: 0.67924	Main MSE (x10^-2): 67.9241	LR: 3.94e-04	EMPP_Raw: 1.33344
2025-07-18 13:24:56,749 - logger.py:50 - Epoch: [39][5/6]	Total Loss: 0.64105	Main MSE (x10^-2): 64.1045	LR: 3.94e-04	EMPP_Raw: 1.25667
2025-07-18 13:24:56,820 - logger.py:50 - Epoch 39 Training Summary: Avg Total Loss: 0.64105, Avg Main MSE: 0.64105, Time: 21.21s
2025-07-18 13:25:16,031 - logger.py:50 - Epoch 39 Summary | Train MSE (x10^-2): 64.1045 | Val MSE (x10^-2): 1.3935 | Time: 40.42s
2025-07-18 13:25:19,727 - logger.py:50 - Epoch: [40][0/6]	Total Loss: 0.64674	Main MSE (x10^-2): 64.6740	LR: 3.94e-04	EMPP_Raw: 1.26511
2025-07-18 13:25:37,094 - logger.py:50 - Epoch: [40][5/6]	Total Loss: 0.63489	Main MSE (x10^-2): 63.4891	LR: 3.94e-04	EMPP_Raw: 1.24178
2025-07-18 13:25:37,138 - logger.py:50 - Epoch 40 Training Summary: Avg Total Loss: 0.63489, Avg Main MSE: 0.63489, Time: 21.10s
2025-07-18 13:25:56,369 - logger.py:50 - Epoch 40 Summary | Train MSE (x10^-2): 63.4891 | Val MSE (x10^-2): 1.2489 | Time: 40.33s
2025-07-18 13:26:00,235 - logger.py:50 - Epoch: [41][0/6]	Total Loss: 0.65008	Main MSE (x10^-2): 65.0085	LR: 3.94e-04	EMPP_Raw: 1.27349
2025-07-18 13:26:17,470 - logger.py:50 - Epoch: [41][5/6]	Total Loss: 0.64180	Main MSE (x10^-2): 64.1796	LR: 3.94e-04	EMPP_Raw: 1.25916
2025-07-18 13:26:17,512 - logger.py:50 - Epoch 41 Training Summary: Avg Total Loss: 0.64180, Avg Main MSE: 0.64180, Time: 21.13s
2025-07-18 13:26:36,767 - logger.py:50 - Epoch 41 Summary | Train MSE (x10^-2): 64.1796 | Val MSE (x10^-2): 1.2015 | Time: 40.39s
2025-07-18 13:26:40,461 - logger.py:50 - Epoch: [42][0/6]	Total Loss: 0.63884	Main MSE (x10^-2): 63.8845	LR: 3.93e-04	EMPP_Raw: 1.25215
2025-07-18 13:26:57,909 - logger.py:50 - Epoch: [42][5/6]	Total Loss: 0.63995	Main MSE (x10^-2): 63.9947	LR: 3.93e-04	EMPP_Raw: 1.25553
2025-07-18 13:26:57,954 - logger.py:50 - Epoch 42 Training Summary: Avg Total Loss: 0.63995, Avg Main MSE: 0.63995, Time: 21.18s
2025-07-18 13:27:17,122 - logger.py:50 - Epoch 42 Summary | Train MSE (x10^-2): 63.9947 | Val MSE (x10^-2): 1.1800 | Time: 40.35s
2025-07-18 13:27:20,873 - logger.py:50 - Epoch: [43][0/6]	Total Loss: 0.65666	Main MSE (x10^-2): 65.6661	LR: 3.93e-04	EMPP_Raw: 1.28963
2025-07-18 13:27:38,143 - logger.py:50 - Epoch: [43][5/6]	Total Loss: 0.64062	Main MSE (x10^-2): 64.0619	LR: 3.93e-04	EMPP_Raw: 1.25675
2025-07-18 13:27:38,190 - logger.py:50 - Epoch 43 Training Summary: Avg Total Loss: 0.64062, Avg Main MSE: 0.64062, Time: 21.06s
2025-07-18 13:27:57,481 - logger.py:50 - Epoch 43 Summary | Train MSE (x10^-2): 64.0619 | Val MSE (x10^-2): 1.2121 | Time: 40.36s
2025-07-18 13:28:01,221 - logger.py:50 - Epoch: [44][0/6]	Total Loss: 0.64843	Main MSE (x10^-2): 64.8432	LR: 3.93e-04	EMPP_Raw: 1.27354
2025-07-18 13:28:18,602 - logger.py:50 - Epoch: [44][5/6]	Total Loss: 0.62954	Main MSE (x10^-2): 62.9535	LR: 3.93e-04	EMPP_Raw: 1.23479
2025-07-18 13:28:18,648 - logger.py:50 - Epoch 44 Training Summary: Avg Total Loss: 0.62954, Avg Main MSE: 0.62954, Time: 21.16s
2025-07-18 13:28:37,835 - logger.py:50 - Epoch 44 Summary | Train MSE (x10^-2): 62.9535 | Val MSE (x10^-2): 1.2013 | Time: 40.35s
2025-07-18 13:28:41,592 - logger.py:50 - Epoch: [45][0/6]	Total Loss: 0.63304	Main MSE (x10^-2): 63.3043	LR: 3.92e-04	EMPP_Raw: 1.24049
2025-07-18 13:28:58,959 - logger.py:50 - Epoch: [45][5/6]	Total Loss: 0.64565	Main MSE (x10^-2): 64.5650	LR: 3.92e-04	EMPP_Raw: 1.26712
2025-07-18 13:28:59,003 - logger.py:50 - Epoch 45 Training Summary: Avg Total Loss: 0.64565, Avg Main MSE: 0.64565, Time: 21.16s
2025-07-18 13:29:37,467 - logger.py:50 - *** New Best Val MSE (x10^-2): 1.1704, Corresponding Test MSE (x10^-2): 1.1943 at Epoch 45 ***
2025-07-18 13:29:37,515 - logger.py:50 - Epoch 45 Summary | Train MSE (x10^-2): 64.5650 | Val MSE (x10^-2): 1.1704 | Time: 59.67s
2025-07-18 13:29:41,228 - logger.py:50 - Epoch: [46][0/6]	Total Loss: 0.63232	Main MSE (x10^-2): 63.2323	LR: 3.92e-04	EMPP_Raw: 1.24083
2025-07-18 13:29:58,482 - logger.py:50 - Epoch: [46][5/6]	Total Loss: 0.64297	Main MSE (x10^-2): 64.2967	LR: 3.92e-04	EMPP_Raw: 1.26264
2025-07-18 13:29:58,524 - logger.py:50 - Epoch 46 Training Summary: Avg Total Loss: 0.64297, Avg Main MSE: 0.64297, Time: 21.00s
2025-07-18 13:30:36,932 - logger.py:50 - *** New Best Val MSE (x10^-2): 1.1649, Corresponding Test MSE (x10^-2): 1.1897 at Epoch 46 ***
2025-07-18 13:30:36,979 - logger.py:50 - Epoch 46 Summary | Train MSE (x10^-2): 64.2967 | Val MSE (x10^-2): 1.1649 | Time: 59.46s
2025-07-18 13:30:40,667 - logger.py:50 - Epoch: [47][0/6]	Total Loss: 0.64416	Main MSE (x10^-2): 64.4163	LR: 3.92e-04	EMPP_Raw: 1.26490
2025-07-18 13:30:57,942 - logger.py:50 - Epoch: [47][5/6]	Total Loss: 0.65514	Main MSE (x10^-2): 65.5145	LR: 3.92e-04	EMPP_Raw: 1.28663
2025-07-18 13:30:57,985 - logger.py:50 - Epoch 47 Training Summary: Avg Total Loss: 0.65514, Avg Main MSE: 0.65514, Time: 21.00s
2025-07-18 13:31:16,994 - logger.py:50 - Epoch 47 Summary | Train MSE (x10^-2): 65.5145 | Val MSE (x10^-2): 1.1837 | Time: 40.01s
2025-07-18 13:31:20,866 - logger.py:50 - Epoch: [48][0/6]	Total Loss: 0.65851	Main MSE (x10^-2): 65.8511	LR: 3.91e-04	EMPP_Raw: 1.29242
2025-07-18 13:31:38,243 - logger.py:50 - Epoch: [48][5/6]	Total Loss: 0.64153	Main MSE (x10^-2): 64.1529	LR: 3.91e-04	EMPP_Raw: 1.25970
2025-07-18 13:31:38,295 - logger.py:50 - Epoch 48 Training Summary: Avg Total Loss: 0.64153, Avg Main MSE: 0.64153, Time: 21.29s
2025-07-18 13:31:57,467 - logger.py:50 - Epoch 48 Summary | Train MSE (x10^-2): 64.1529 | Val MSE (x10^-2): 1.1851 | Time: 40.47s
2025-07-18 13:32:01,338 - logger.py:50 - Epoch: [49][0/6]	Total Loss: 0.64202	Main MSE (x10^-2): 64.2018	LR: 3.91e-04	EMPP_Raw: 1.26108
2025-07-18 13:32:18,612 - logger.py:50 - Epoch: [49][5/6]	Total Loss: 0.63386	Main MSE (x10^-2): 63.3864	LR: 3.91e-04	EMPP_Raw: 1.24398
2025-07-18 13:32:18,656 - logger.py:50 - Epoch 49 Training Summary: Avg Total Loss: 0.63386, Avg Main MSE: 0.63386, Time: 21.18s
2025-07-18 13:32:57,030 - logger.py:50 - *** New Best Val MSE (x10^-2): 1.1543, Corresponding Test MSE (x10^-2): 1.1777 at Epoch 49 ***
2025-07-18 13:32:57,078 - logger.py:50 - Epoch 49 Summary | Train MSE (x10^-2): 63.3864 | Val MSE (x10^-2): 1.1543 | Time: 59.60s
2025-07-18 13:33:00,943 - logger.py:50 - Epoch: [50][0/6]	Total Loss: 0.64826	Main MSE (x10^-2): 64.8256	LR: 3.91e-04	EMPP_Raw: 1.27278
2025-07-18 13:33:18,146 - logger.py:50 - Epoch: [50][5/6]	Total Loss: 0.64713	Main MSE (x10^-2): 64.7130	LR: 3.91e-04	EMPP_Raw: 1.27105
2025-07-18 13:33:18,189 - logger.py:50 - Epoch 50 Training Summary: Avg Total Loss: 0.64713, Avg Main MSE: 0.64713, Time: 21.11s
2025-07-18 13:33:56,488 - logger.py:50 - *** New Best Val MSE (x10^-2): 1.1437, Corresponding Test MSE (x10^-2): 1.1674 at Epoch 50 ***
2025-07-18 13:33:56,535 - logger.py:50 - Epoch 50 Summary | Train MSE (x10^-2): 64.7130 | Val MSE (x10^-2): 1.1437 | Time: 59.46s
2025-07-18 13:34:00,418 - logger.py:50 - Epoch: [51][0/6]	Total Loss: 0.61672	Main MSE (x10^-2): 61.6717	LR: 3.90e-04	EMPP_Raw: 1.20973
2025-07-18 13:34:17,616 - logger.py:50 - Epoch: [51][5/6]	Total Loss: 0.62870	Main MSE (x10^-2): 62.8697	LR: 3.90e-04	EMPP_Raw: 1.23433
2025-07-18 13:34:17,659 - logger.py:50 - Epoch 51 Training Summary: Avg Total Loss: 0.62870, Avg Main MSE: 0.62870, Time: 21.12s
2025-07-18 13:34:55,990 - logger.py:50 - *** New Best Val MSE (x10^-2): 1.1413, Corresponding Test MSE (x10^-2): 1.1663 at Epoch 51 ***
2025-07-18 13:34:56,041 - logger.py:50 - Epoch 51 Summary | Train MSE (x10^-2): 62.8697 | Val MSE (x10^-2): 1.1413 | Time: 59.51s
2025-07-18 13:34:59,898 - logger.py:50 - Epoch: [52][0/6]	Total Loss: 0.65447	Main MSE (x10^-2): 65.4466	LR: 3.90e-04	EMPP_Raw: 1.28583
2025-07-18 13:35:17,182 - logger.py:50 - Epoch: [52][5/6]	Total Loss: 0.63943	Main MSE (x10^-2): 63.9427	LR: 3.90e-04	EMPP_Raw: 1.25592
2025-07-18 13:35:17,229 - logger.py:50 - Epoch 52 Training Summary: Avg Total Loss: 0.63943, Avg Main MSE: 0.63943, Time: 21.18s
2025-07-18 13:35:36,400 - logger.py:50 - Epoch 52 Summary | Train MSE (x10^-2): 63.9427 | Val MSE (x10^-2): 1.1456 | Time: 40.36s
2025-07-18 13:35:40,102 - logger.py:50 - Epoch: [53][0/6]	Total Loss: 0.64226	Main MSE (x10^-2): 64.2264	LR: 3.89e-04	EMPP_Raw: 1.26285
2025-07-18 13:35:57,488 - logger.py:50 - Epoch: [53][5/6]	Total Loss: 0.63281	Main MSE (x10^-2): 63.2810	LR: 3.89e-04	EMPP_Raw: 1.24275
2025-07-18 13:35:57,540 - logger.py:50 - Epoch 53 Training Summary: Avg Total Loss: 0.63281, Avg Main MSE: 0.63281, Time: 21.13s
2025-07-18 13:36:16,706 - logger.py:50 - Epoch 53 Summary | Train MSE (x10^-2): 63.2810 | Val MSE (x10^-2): 1.1518 | Time: 40.30s
2025-07-18 13:36:20,436 - logger.py:50 - Epoch: [54][0/6]	Total Loss: 0.64712	Main MSE (x10^-2): 64.7118	LR: 3.89e-04	EMPP_Raw: 1.26876
2025-07-18 13:36:37,742 - logger.py:50 - Epoch: [54][5/6]	Total Loss: 0.64292	Main MSE (x10^-2): 64.2917	LR: 3.89e-04	EMPP_Raw: 1.26261
2025-07-18 13:36:37,789 - logger.py:50 - Epoch 54 Training Summary: Avg Total Loss: 0.64292, Avg Main MSE: 0.64292, Time: 21.07s
2025-07-18 13:36:56,941 - logger.py:50 - Epoch 54 Summary | Train MSE (x10^-2): 64.2917 | Val MSE (x10^-2): 1.1467 | Time: 40.23s
2025-07-18 13:37:00,650 - logger.py:50 - Epoch: [55][0/6]	Total Loss: 0.63960	Main MSE (x10^-2): 63.9605	LR: 3.89e-04	EMPP_Raw: 1.25699
2025-07-18 13:37:17,943 - logger.py:50 - Epoch: [55][5/6]	Total Loss: 0.63821	Main MSE (x10^-2): 63.8215	LR: 3.89e-04	EMPP_Raw: 1.25329
2025-07-18 13:37:17,987 - logger.py:50 - Epoch 55 Training Summary: Avg Total Loss: 0.63821, Avg Main MSE: 0.63821, Time: 21.04s
2025-07-18 13:37:37,320 - logger.py:50 - Epoch 55 Summary | Train MSE (x10^-2): 63.8215 | Val MSE (x10^-2): 1.1452 | Time: 40.37s
2025-07-18 13:37:41,050 - logger.py:50 - Epoch: [56][0/6]	Total Loss: 0.67962	Main MSE (x10^-2): 67.9622	LR: 3.88e-04	EMPP_Raw: 1.33697
2025-07-18 13:37:58,302 - logger.py:50 - Epoch: [56][5/6]	Total Loss: 0.63906	Main MSE (x10^-2): 63.9060	LR: 3.88e-04	EMPP_Raw: 1.25511
2025-07-18 13:37:58,347 - logger.py:50 - Epoch 56 Training Summary: Avg Total Loss: 0.63906, Avg Main MSE: 0.63906, Time: 21.02s
2025-07-18 13:38:17,397 - logger.py:50 - Epoch 56 Summary | Train MSE (x10^-2): 63.9060 | Val MSE (x10^-2): 1.1445 | Time: 40.07s
2025-07-18 13:38:21,281 - logger.py:50 - Epoch: [57][0/6]	Total Loss: 0.62409	Main MSE (x10^-2): 62.4095	LR: 3.88e-04	EMPP_Raw: 1.22665
2025-07-18 13:38:38,563 - logger.py:50 - Epoch: [57][5/6]	Total Loss: 0.64079	Main MSE (x10^-2): 64.0791	LR: 3.88e-04	EMPP_Raw: 1.25863
2025-07-18 13:38:38,604 - logger.py:50 - Epoch 57 Training Summary: Avg Total Loss: 0.64079, Avg Main MSE: 0.64079, Time: 21.20s
2025-07-18 13:39:16,741 - logger.py:50 - *** New Best Val MSE (x10^-2): 1.1389, Corresponding Test MSE (x10^-2): 1.1613 at Epoch 57 ***
2025-07-18 13:39:16,789 - logger.py:50 - Epoch 57 Summary | Train MSE (x10^-2): 64.0791 | Val MSE (x10^-2): 1.1389 | Time: 59.39s
2025-07-18 13:39:20,672 - logger.py:50 - Epoch: [58][0/6]	Total Loss: 0.64768	Main MSE (x10^-2): 64.7683	LR: 3.87e-04	EMPP_Raw: 1.27353
2025-07-18 13:39:37,875 - logger.py:50 - Epoch: [58][5/6]	Total Loss: 0.63145	Main MSE (x10^-2): 63.1454	LR: 3.87e-04	EMPP_Raw: 1.24018
2025-07-18 13:39:37,925 - logger.py:50 - Epoch 58 Training Summary: Avg Total Loss: 0.63145, Avg Main MSE: 0.63145, Time: 21.13s
2025-07-18 13:39:57,020 - logger.py:50 - Epoch 58 Summary | Train MSE (x10^-2): 63.1454 | Val MSE (x10^-2): 1.1415 | Time: 40.23s
2025-07-18 13:40:00,722 - logger.py:50 - Epoch: [59][0/6]	Total Loss: 0.62019	Main MSE (x10^-2): 62.0186	LR: 3.87e-04	EMPP_Raw: 1.21853
2025-07-18 13:40:18,228 - logger.py:50 - Epoch: [59][5/6]	Total Loss: 0.63475	Main MSE (x10^-2): 63.4754	LR: 3.87e-04	EMPP_Raw: 1.24660
2025-07-18 13:40:18,272 - logger.py:50 - Epoch 59 Training Summary: Avg Total Loss: 0.63475, Avg Main MSE: 0.63475, Time: 21.24s
2025-07-18 13:40:37,404 - logger.py:50 - Epoch 59 Summary | Train MSE (x10^-2): 63.4754 | Val MSE (x10^-2): 1.1420 | Time: 40.38s
2025-07-18 13:40:41,138 - logger.py:50 - Epoch: [60][0/6]	Total Loss: 0.65560	Main MSE (x10^-2): 65.5596	LR: 3.86e-04	EMPP_Raw: 1.28899
2025-07-18 13:40:58,370 - logger.py:50 - Epoch: [60][5/6]	Total Loss: 0.63437	Main MSE (x10^-2): 63.4375	LR: 3.86e-04	EMPP_Raw: 1.24580
2025-07-18 13:40:58,411 - logger.py:50 - Epoch 60 Training Summary: Avg Total Loss: 0.63437, Avg Main MSE: 0.63437, Time: 21.00s
2025-07-18 13:41:36,934 - logger.py:50 - *** New Best Val MSE (x10^-2): 1.1346, Corresponding Test MSE (x10^-2): 1.1581 at Epoch 60 ***
2025-07-18 13:41:36,982 - logger.py:50 - Epoch 60 Summary | Train MSE (x10^-2): 63.4375 | Val MSE (x10^-2): 1.1346 | Time: 59.57s
2025-07-18 13:41:40,698 - logger.py:50 - Epoch: [61][0/6]	Total Loss: 0.61456	Main MSE (x10^-2): 61.4556	LR: 3.86e-04	EMPP_Raw: 1.20498
2025-07-18 13:41:58,006 - logger.py:50 - Epoch: [61][5/6]	Total Loss: 0.62468	Main MSE (x10^-2): 62.4684	LR: 3.86e-04	EMPP_Raw: 1.22652
2025-07-18 13:41:58,052 - logger.py:50 - Epoch 61 Training Summary: Avg Total Loss: 0.62468, Avg Main MSE: 0.62468, Time: 21.07s
2025-07-18 13:42:36,297 - logger.py:50 - *** New Best Val MSE (x10^-2): 1.1303, Corresponding Test MSE (x10^-2): 1.1542 at Epoch 61 ***
2025-07-18 13:42:36,345 - logger.py:50 - Epoch 61 Summary | Train MSE (x10^-2): 62.4684 | Val MSE (x10^-2): 1.1303 | Time: 59.36s
2025-07-18 13:42:40,033 - logger.py:50 - Epoch: [62][0/6]	Total Loss: 0.65926	Main MSE (x10^-2): 65.9265	LR: 3.86e-04	EMPP_Raw: 1.29735
2025-07-18 13:42:57,308 - logger.py:50 - Epoch: [62][5/6]	Total Loss: 0.63121	Main MSE (x10^-2): 63.1208	LR: 3.86e-04	EMPP_Raw: 1.23988
2025-07-18 13:42:57,352 - logger.py:50 - Epoch 62 Training Summary: Avg Total Loss: 0.63121, Avg Main MSE: 0.63121, Time: 21.00s
2025-07-18 13:43:16,606 - logger.py:50 - Epoch 62 Summary | Train MSE (x10^-2): 63.1208 | Val MSE (x10^-2): 1.1308 | Time: 40.26s
2025-07-18 13:43:20,340 - logger.py:50 - Epoch: [63][0/6]	Total Loss: 0.61363	Main MSE (x10^-2): 61.3633	LR: 3.85e-04	EMPP_Raw: 1.20332
2025-07-18 13:43:37,615 - logger.py:50 - Epoch: [63][5/6]	Total Loss: 0.63212	Main MSE (x10^-2): 63.2116	LR: 3.85e-04	EMPP_Raw: 1.24155
2025-07-18 13:43:37,657 - logger.py:50 - Epoch 63 Training Summary: Avg Total Loss: 0.63212, Avg Main MSE: 0.63212, Time: 21.04s
2025-07-18 13:43:56,835 - logger.py:50 - Epoch 63 Summary | Train MSE (x10^-2): 63.2116 | Val MSE (x10^-2): 1.1310 | Time: 40.22s
2025-07-18 13:44:00,709 - logger.py:50 - Epoch: [64][0/6]	Total Loss: 0.65281	Main MSE (x10^-2): 65.2810	LR: 3.85e-04	EMPP_Raw: 1.28276
2025-07-18 13:44:18,045 - logger.py:50 - Epoch: [64][5/6]	Total Loss: 0.63152	Main MSE (x10^-2): 63.1520	LR: 3.85e-04	EMPP_Raw: 1.24026
2025-07-18 13:44:18,088 - logger.py:50 - Epoch 64 Training Summary: Avg Total Loss: 0.63152, Avg Main MSE: 0.63152, Time: 21.24s
2025-07-18 13:44:37,232 - logger.py:50 - Epoch 64 Summary | Train MSE (x10^-2): 63.1520 | Val MSE (x10^-2): 1.1375 | Time: 40.39s
2025-07-18 13:44:40,952 - logger.py:50 - Epoch: [65][0/6]	Total Loss: 0.62105	Main MSE (x10^-2): 62.1050	LR: 3.84e-04	EMPP_Raw: 1.21981
2025-07-18 13:44:58,446 - logger.py:50 - Epoch: [65][5/6]	Total Loss: 0.63463	Main MSE (x10^-2): 63.4626	LR: 3.84e-04	EMPP_Raw: 1.24668
2025-07-18 13:44:58,492 - logger.py:50 - Epoch 65 Training Summary: Avg Total Loss: 0.63463, Avg Main MSE: 0.63463, Time: 21.25s
2025-07-18 13:45:36,788 - logger.py:50 - *** New Best Val MSE (x10^-2): 1.1295, Corresponding Test MSE (x10^-2): 1.1508 at Epoch 65 ***
2025-07-18 13:45:36,835 - logger.py:50 - Epoch 65 Summary | Train MSE (x10^-2): 63.4626 | Val MSE (x10^-2): 1.1295 | Time: 59.60s
2025-07-18 13:45:40,556 - logger.py:50 - Epoch: [66][0/6]	Total Loss: 0.62052	Main MSE (x10^-2): 62.0520	LR: 3.84e-04	EMPP_Raw: 1.21890
2025-07-18 13:45:57,980 - logger.py:50 - Epoch: [66][5/6]	Total Loss: 0.62229	Main MSE (x10^-2): 62.2291	LR: 3.84e-04	EMPP_Raw: 1.22203
2025-07-18 13:45:58,021 - logger.py:50 - Epoch 66 Training Summary: Avg Total Loss: 0.62229, Avg Main MSE: 0.62229, Time: 21.18s
2025-07-18 13:46:17,238 - logger.py:50 - Epoch 66 Summary | Train MSE (x10^-2): 62.2291 | Val MSE (x10^-2): 1.1306 | Time: 40.40s
2025-07-18 13:46:20,958 - logger.py:50 - Epoch: [67][0/6]	Total Loss: 0.64560	Main MSE (x10^-2): 64.5595	LR: 3.83e-04	EMPP_Raw: 1.26735
2025-07-18 13:46:38,257 - logger.py:50 - Epoch: [67][5/6]	Total Loss: 0.62918	Main MSE (x10^-2): 62.9183	LR: 3.83e-04	EMPP_Raw: 1.23558
2025-07-18 13:46:38,302 - logger.py:50 - Epoch 67 Training Summary: Avg Total Loss: 0.62918, Avg Main MSE: 0.62918, Time: 21.05s
2025-07-18 13:46:57,622 - logger.py:50 - Epoch 67 Summary | Train MSE (x10^-2): 62.9183 | Val MSE (x10^-2): 1.1367 | Time: 40.38s
2025-07-18 13:47:01,373 - logger.py:50 - Epoch: [68][0/6]	Total Loss: 0.61176	Main MSE (x10^-2): 61.1761	LR: 3.83e-04	EMPP_Raw: 1.20055
2025-07-18 13:47:18,691 - logger.py:50 - Epoch: [68][5/6]	Total Loss: 0.62822	Main MSE (x10^-2): 62.8219	LR: 3.83e-04	EMPP_Raw: 1.23368
2025-07-18 13:47:18,738 - logger.py:50 - Epoch 68 Training Summary: Avg Total Loss: 0.62822, Avg Main MSE: 0.62822, Time: 21.11s
