2025-07-18 07:53:51,209 - logger.py:50 - --- Starting training for malonaldehyde ---
2025-07-18 07:53:51,210 - logger.py:50 - Namespace(amp=False, batch_size=80, clip_grad=1.0, contrastive_aug_mask_ratio=0.15, contrastive_loss_weight=0.1, contrastive_mask_token_idx=0, contrastive_prioritize_heteroatoms=False, contrastive_projection_dim=128, contrastive_temp=0.1, cooldown_epochs=10, data_path='data/md17', decay_rate=0.1, delta_frame=3000, device='cuda:0', drop_path=0.0, empp_atom_type_embed_irreps='16x0e', empp_loss_weight=0.5, empp_num_mask=1, empp_pos_pred_num_s2_channels=32, empp_pos_pred_res_s2grid=100, empp_pos_pred_temp_label=0.1, empp_pos_pred_temp_softmax=0.1, empp_prioritize_heteroatoms=True, empp_ssp_feature_dim='16x0e', enable_contrastive=False, epochs=500, exp_name='md17_final_run_20250717_152800', logger=<logger.FileLogger object at 0x7f24b7775af0>, loss='l2', lr=0.0004, max_test_samples=2000, max_train_samples=500, max_val_samples=2000, min_lr=1e-06, model_name='graph_attention_transformer_nonlinear_l2', molecule_type='malonaldehyde', momentum=0.9, num_basis=128, opt='adamw', opt_betas=None, opt_eps=1e-08, output_dir='outputs/md17_final_run_20250717_152800', patience_epochs=10, pin_mem=True, print_freq=50, radius=5.0, sched='cosine', seed=42, ssp=True, warmup_epochs=10, warmup_lr=1e-06, weight_decay=1e-06, workers=8)
2025-07-18 07:53:51,211 - logger.py:50 - Loading datasets...
2025-07-18 07:54:25,601 - logger.py:50 - Creating model...
2025-07-18 07:54:33,787 - logger.py:50 - Number of params: 3,205,881
2025-07-18 07:54:37,795 - logger.py:50 - Epoch: [0][0/6]	Total Loss: 1.89003	Main MSE (x10^-2): 189.0026	LR: 1.00e-06	EMPP_Raw: 2.21696
2025-07-18 07:54:53,060 - logger.py:50 - Epoch: [0][5/6]	Total Loss: 1.90696	Main MSE (x10^-2): 190.6965	LR: 1.00e-06	EMPP_Raw: 2.24612
2025-07-18 07:54:53,113 - logger.py:50 - Epoch 0 Training Summary: Avg Total Loss: 1.90696, Avg Main MSE: 1.90696, Time: 19.32s
2025-07-18 07:55:29,753 - logger.py:50 - *** New Best Val MSE (x10^-2): 79.4292, Corresponding Test MSE (x10^-2): 81.3973 at Epoch 0 ***
2025-07-18 07:55:29,798 - logger.py:50 - Epoch 0 Summary | Train MSE (x10^-2): 190.6965 | Val MSE (x10^-2): 79.4292 | Time: 56.01s
2025-07-18 07:55:32,961 - logger.py:50 - Epoch: [1][0/6]	Total Loss: 1.86079	Main MSE (x10^-2): 186.0786	LR: 1.00e-06	EMPP_Raw: 2.26246
2025-07-18 07:55:46,789 - logger.py:50 - Epoch: [1][5/6]	Total Loss: 1.88934	Main MSE (x10^-2): 188.9337	LR: 1.00e-06	EMPP_Raw: 2.20002
2025-07-18 07:55:46,828 - logger.py:50 - Epoch 1 Training Summary: Avg Total Loss: 1.88934, Avg Main MSE: 1.88934, Time: 17.03s
2025-07-18 07:56:22,807 - logger.py:50 - *** New Best Val MSE (x10^-2): 79.3726, Corresponding Test MSE (x10^-2): 81.3394 at Epoch 1 ***
2025-07-18 07:56:22,854 - logger.py:50 - Epoch 1 Summary | Train MSE (x10^-2): 188.9337 | Val MSE (x10^-2): 79.3726 | Time: 53.06s
2025-07-18 07:56:26,090 - logger.py:50 - Epoch: [2][0/6]	Total Loss: 1.89415	Main MSE (x10^-2): 189.4153	LR: 4.09e-05	EMPP_Raw: 2.22307
2025-07-18 07:56:39,905 - logger.py:50 - Epoch: [2][5/6]	Total Loss: 1.83918	Main MSE (x10^-2): 183.9179	LR: 4.09e-05	EMPP_Raw: 2.11451
2025-07-18 07:56:39,948 - logger.py:50 - Epoch 2 Training Summary: Avg Total Loss: 1.83918, Avg Main MSE: 1.83918, Time: 17.09s
2025-07-18 07:57:16,159 - logger.py:50 - *** New Best Val MSE (x10^-2): 77.0935, Corresponding Test MSE (x10^-2): 79.0025 at Epoch 2 ***
2025-07-18 07:57:16,206 - logger.py:50 - Epoch 2 Summary | Train MSE (x10^-2): 183.9179 | Val MSE (x10^-2): 77.0935 | Time: 53.35s
2025-07-18 07:57:19,379 - logger.py:50 - Epoch: [3][0/6]	Total Loss: 1.74909	Main MSE (x10^-2): 174.9094	LR: 8.08e-05	EMPP_Raw: 2.03599
2025-07-18 07:57:33,140 - logger.py:50 - Epoch: [3][5/6]	Total Loss: 1.72848	Main MSE (x10^-2): 172.8476	LR: 8.08e-05	EMPP_Raw: 1.96674
2025-07-18 07:57:33,177 - logger.py:50 - Epoch 3 Training Summary: Avg Total Loss: 1.72848, Avg Main MSE: 1.72848, Time: 16.97s
2025-07-18 07:58:09,237 - logger.py:50 - *** New Best Val MSE (x10^-2): 72.1917, Corresponding Test MSE (x10^-2): 73.9595 at Epoch 3 ***
2025-07-18 07:58:09,283 - logger.py:50 - Epoch 3 Summary | Train MSE (x10^-2): 172.8476 | Val MSE (x10^-2): 72.1917 | Time: 53.08s
2025-07-18 07:58:12,486 - logger.py:50 - Epoch: [4][0/6]	Total Loss: 1.63463	Main MSE (x10^-2): 163.4627	LR: 1.21e-04	EMPP_Raw: 1.85638
2025-07-18 07:58:26,339 - logger.py:50 - Epoch: [4][5/6]	Total Loss: 1.61306	Main MSE (x10^-2): 161.3057	LR: 1.21e-04	EMPP_Raw: 1.85592
2025-07-18 07:58:26,376 - logger.py:50 - Epoch 4 Training Summary: Avg Total Loss: 1.61306, Avg Main MSE: 1.61306, Time: 17.09s
2025-07-18 07:59:02,469 - logger.py:50 - *** New Best Val MSE (x10^-2): 64.4742, Corresponding Test MSE (x10^-2): 65.9170 at Epoch 4 ***
2025-07-18 07:59:02,517 - logger.py:50 - Epoch 4 Summary | Train MSE (x10^-2): 161.3057 | Val MSE (x10^-2): 64.4742 | Time: 53.23s
2025-07-18 07:59:05,681 - logger.py:50 - Epoch: [5][0/6]	Total Loss: 1.62714	Main MSE (x10^-2): 162.7141	LR: 1.61e-04	EMPP_Raw: 1.86219
2025-07-18 07:59:19,516 - logger.py:50 - Epoch: [5][5/6]	Total Loss: 1.51539	Main MSE (x10^-2): 151.5386	LR: 1.61e-04	EMPP_Raw: 1.79910
2025-07-18 07:59:19,560 - logger.py:50 - Epoch 5 Training Summary: Avg Total Loss: 1.51539, Avg Main MSE: 1.51539, Time: 17.04s
2025-07-18 07:59:55,613 - logger.py:50 - *** New Best Val MSE (x10^-2): 59.4656, Corresponding Test MSE (x10^-2): 60.3646 at Epoch 5 ***
2025-07-18 07:59:55,660 - logger.py:50 - Epoch 5 Summary | Train MSE (x10^-2): 151.5386 | Val MSE (x10^-2): 59.4656 | Time: 53.14s
2025-07-18 07:59:58,702 - logger.py:50 - Epoch: [6][0/6]	Total Loss: 1.53872	Main MSE (x10^-2): 153.8720	LR: 2.00e-04	EMPP_Raw: 1.87246
2025-07-18 08:00:12,517 - logger.py:50 - Epoch: [6][5/6]	Total Loss: 1.44520	Main MSE (x10^-2): 144.5205	LR: 2.00e-04	EMPP_Raw: 1.77524
2025-07-18 08:00:12,560 - logger.py:50 - Epoch 6 Training Summary: Avg Total Loss: 1.44520, Avg Main MSE: 1.44520, Time: 16.90s
2025-07-18 08:00:48,497 - logger.py:50 - *** New Best Val MSE (x10^-2): 52.4361, Corresponding Test MSE (x10^-2): 53.2137 at Epoch 6 ***
2025-07-18 08:00:48,546 - logger.py:50 - Epoch 6 Summary | Train MSE (x10^-2): 144.5205 | Val MSE (x10^-2): 52.4361 | Time: 52.89s
2025-07-18 08:00:51,538 - logger.py:50 - Epoch: [7][0/6]	Total Loss: 1.37329	Main MSE (x10^-2): 137.3291	LR: 2.40e-04	EMPP_Raw: 1.76150
2025-07-18 08:01:05,374 - logger.py:50 - Epoch: [7][5/6]	Total Loss: 1.37842	Main MSE (x10^-2): 137.8419	LR: 2.40e-04	EMPP_Raw: 1.73312
2025-07-18 08:01:05,414 - logger.py:50 - Epoch 7 Training Summary: Avg Total Loss: 1.37842, Avg Main MSE: 1.37842, Time: 16.86s
2025-07-18 08:01:41,675 - logger.py:50 - *** New Best Val MSE (x10^-2): 51.0117, Corresponding Test MSE (x10^-2): 51.2813 at Epoch 7 ***
2025-07-18 08:01:41,723 - logger.py:50 - Epoch 7 Summary | Train MSE (x10^-2): 137.8419 | Val MSE (x10^-2): 51.0117 | Time: 53.18s
2025-07-18 08:01:44,749 - logger.py:50 - Epoch: [8][0/6]	Total Loss: 1.33797	Main MSE (x10^-2): 133.7974	LR: 2.80e-04	EMPP_Raw: 1.67368
2025-07-18 08:01:58,519 - logger.py:50 - Epoch: [8][5/6]	Total Loss: 1.36498	Main MSE (x10^-2): 136.4976	LR: 2.80e-04	EMPP_Raw: 1.71623
2025-07-18 08:01:58,561 - logger.py:50 - Epoch 8 Training Summary: Avg Total Loss: 1.36498, Avg Main MSE: 1.36498, Time: 16.83s
2025-07-18 08:02:34,679 - logger.py:50 - *** New Best Val MSE (x10^-2): 49.3534, Corresponding Test MSE (x10^-2): 49.9685 at Epoch 8 ***
2025-07-18 08:02:34,726 - logger.py:50 - Epoch 8 Summary | Train MSE (x10^-2): 136.4976 | Val MSE (x10^-2): 49.3534 | Time: 53.00s
2025-07-18 08:02:37,742 - logger.py:50 - Epoch: [9][0/6]	Total Loss: 1.34303	Main MSE (x10^-2): 134.3034	LR: 3.20e-04	EMPP_Raw: 1.68878
2025-07-18 08:02:51,512 - logger.py:50 - Epoch: [9][5/6]	Total Loss: 1.33830	Main MSE (x10^-2): 133.8303	LR: 3.20e-04	EMPP_Raw: 1.68646
2025-07-18 08:02:51,560 - logger.py:50 - Epoch 9 Training Summary: Avg Total Loss: 1.33830, Avg Main MSE: 1.33830, Time: 16.83s
2025-07-18 08:03:27,831 - logger.py:50 - *** New Best Val MSE (x10^-2): 49.1442, Corresponding Test MSE (x10^-2): 49.8605 at Epoch 9 ***
2025-07-18 08:03:27,879 - logger.py:50 - Epoch 9 Summary | Train MSE (x10^-2): 133.8303 | Val MSE (x10^-2): 49.1442 | Time: 53.15s
2025-07-18 08:03:30,870 - logger.py:50 - Epoch: [10][0/6]	Total Loss: 1.33329	Main MSE (x10^-2): 133.3292	LR: 3.60e-04	EMPP_Raw: 1.66723
2025-07-18 08:03:44,680 - logger.py:50 - Epoch: [10][5/6]	Total Loss: 1.33183	Main MSE (x10^-2): 133.1833	LR: 3.60e-04	EMPP_Raw: 1.67355
2025-07-18 08:03:44,724 - logger.py:50 - Epoch 10 Training Summary: Avg Total Loss: 1.33183, Avg Main MSE: 1.33183, Time: 16.84s
2025-07-18 08:04:02,772 - logger.py:50 - Epoch 10 Summary | Train MSE (x10^-2): 133.1833 | Val MSE (x10^-2): 49.5729 | Time: 34.89s
2025-07-18 08:04:05,755 - logger.py:50 - Epoch: [11][0/6]	Total Loss: 1.29533	Main MSE (x10^-2): 129.5334	LR: 4.00e-04	EMPP_Raw: 1.59403
2025-07-18 08:04:19,518 - logger.py:50 - Epoch: [11][5/6]	Total Loss: 1.30934	Main MSE (x10^-2): 130.9335	LR: 4.00e-04	EMPP_Raw: 1.62837
2025-07-18 08:04:19,562 - logger.py:50 - Epoch 11 Training Summary: Avg Total Loss: 1.30934, Avg Main MSE: 1.30934, Time: 16.78s
2025-07-18 08:04:55,564 - logger.py:50 - *** New Best Val MSE (x10^-2): 48.7246, Corresponding Test MSE (x10^-2): 49.3772 at Epoch 11 ***
2025-07-18 08:04:55,611 - logger.py:50 - Epoch 11 Summary | Train MSE (x10^-2): 130.9335 | Val MSE (x10^-2): 48.7246 | Time: 52.83s
2025-07-18 08:04:58,640 - logger.py:50 - Epoch: [12][0/6]	Total Loss: 1.30085	Main MSE (x10^-2): 130.0855	LR: 4.00e-04	EMPP_Raw: 1.61624
2025-07-18 08:05:12,412 - logger.py:50 - Epoch: [12][5/6]	Total Loss: 1.30464	Main MSE (x10^-2): 130.4636	LR: 4.00e-04	EMPP_Raw: 1.63771
2025-07-18 08:05:12,459 - logger.py:50 - Epoch 12 Training Summary: Avg Total Loss: 1.30464, Avg Main MSE: 1.30464, Time: 16.84s
2025-07-18 08:05:48,467 - logger.py:50 - *** New Best Val MSE (x10^-2): 48.0548, Corresponding Test MSE (x10^-2): 48.5195 at Epoch 12 ***
2025-07-18 08:05:48,514 - logger.py:50 - Epoch 12 Summary | Train MSE (x10^-2): 130.4636 | Val MSE (x10^-2): 48.0548 | Time: 52.90s
2025-07-18 08:05:51,499 - logger.py:50 - Epoch: [13][0/6]	Total Loss: 1.29019	Main MSE (x10^-2): 129.0189	LR: 3.99e-04	EMPP_Raw: 1.62410
2025-07-18 08:06:05,277 - logger.py:50 - Epoch: [13][5/6]	Total Loss: 1.28456	Main MSE (x10^-2): 128.4560	LR: 3.99e-04	EMPP_Raw: 1.59741
2025-07-18 08:06:05,322 - logger.py:50 - Epoch 13 Training Summary: Avg Total Loss: 1.28456, Avg Main MSE: 1.28456, Time: 16.80s
2025-07-18 08:06:23,372 - logger.py:50 - Epoch 13 Summary | Train MSE (x10^-2): 128.4560 | Val MSE (x10^-2): 48.2289 | Time: 34.86s
2025-07-18 08:06:26,376 - logger.py:50 - Epoch: [14][0/6]	Total Loss: 1.30776	Main MSE (x10^-2): 130.7759	LR: 3.99e-04	EMPP_Raw: 1.64737
2025-07-18 08:06:40,176 - logger.py:50 - Epoch: [14][5/6]	Total Loss: 1.27717	Main MSE (x10^-2): 127.7170	LR: 3.99e-04	EMPP_Raw: 1.59156
2025-07-18 08:06:40,219 - logger.py:50 - Epoch 14 Training Summary: Avg Total Loss: 1.27717, Avg Main MSE: 1.27717, Time: 16.84s
2025-07-18 08:06:58,157 - logger.py:50 - Epoch 14 Summary | Train MSE (x10^-2): 127.7170 | Val MSE (x10^-2): 48.0706 | Time: 34.78s
2025-07-18 08:07:01,327 - logger.py:50 - Epoch: [15][0/6]	Total Loss: 1.24797	Main MSE (x10^-2): 124.7972	LR: 3.99e-04	EMPP_Raw: 1.50869
2025-07-18 08:07:15,090 - logger.py:50 - Epoch: [15][5/6]	Total Loss: 1.25741	Main MSE (x10^-2): 125.7407	LR: 3.99e-04	EMPP_Raw: 1.55860
2025-07-18 08:07:15,134 - logger.py:50 - Epoch 15 Training Summary: Avg Total Loss: 1.25741, Avg Main MSE: 1.25741, Time: 16.97s
2025-07-18 08:07:50,940 - logger.py:50 - *** New Best Val MSE (x10^-2): 47.8265, Corresponding Test MSE (x10^-2): 48.2850 at Epoch 15 ***
2025-07-18 08:07:50,987 - logger.py:50 - Epoch 15 Summary | Train MSE (x10^-2): 125.7407 | Val MSE (x10^-2): 47.8265 | Time: 52.83s
2025-07-18 08:07:54,158 - logger.py:50 - Epoch: [16][0/6]	Total Loss: 1.28795	Main MSE (x10^-2): 128.7952	LR: 3.99e-04	EMPP_Raw: 1.56552
2025-07-18 08:08:07,930 - logger.py:50 - Epoch: [16][5/6]	Total Loss: 1.25927	Main MSE (x10^-2): 125.9268	LR: 3.99e-04	EMPP_Raw: 1.56900
2025-07-18 08:08:07,971 - logger.py:50 - Epoch 16 Training Summary: Avg Total Loss: 1.25927, Avg Main MSE: 1.25927, Time: 16.98s
2025-07-18 08:08:25,913 - logger.py:50 - Epoch 16 Summary | Train MSE (x10^-2): 125.9268 | Val MSE (x10^-2): 48.0049 | Time: 34.93s
2025-07-18 08:08:28,951 - logger.py:50 - Epoch: [17][0/6]	Total Loss: 1.25125	Main MSE (x10^-2): 125.1247	LR: 3.99e-04	EMPP_Raw: 1.55556
2025-07-18 08:08:42,880 - logger.py:50 - Epoch: [17][5/6]	Total Loss: 1.25163	Main MSE (x10^-2): 125.1631	LR: 3.99e-04	EMPP_Raw: 1.55038
2025-07-18 08:08:42,926 - logger.py:50 - Epoch 17 Training Summary: Avg Total Loss: 1.25163, Avg Main MSE: 1.25163, Time: 17.00s
2025-07-18 08:09:18,717 - logger.py:50 - *** New Best Val MSE (x10^-2): 47.2600, Corresponding Test MSE (x10^-2): 47.6140 at Epoch 17 ***
2025-07-18 08:09:18,763 - logger.py:50 - Epoch 17 Summary | Train MSE (x10^-2): 125.1631 | Val MSE (x10^-2): 47.2600 | Time: 52.84s
2025-07-18 08:09:21,748 - logger.py:50 - Epoch: [18][0/6]	Total Loss: 1.22639	Main MSE (x10^-2): 122.6390	LR: 3.99e-04	EMPP_Raw: 1.51904
2025-07-18 08:09:35,642 - logger.py:50 - Epoch: [18][5/6]	Total Loss: 1.26303	Main MSE (x10^-2): 126.3029	LR: 3.99e-04	EMPP_Raw: 1.57150
2025-07-18 08:09:35,683 - logger.py:50 - Epoch 18 Training Summary: Avg Total Loss: 1.26303, Avg Main MSE: 1.26303, Time: 16.92s
2025-07-18 08:09:53,643 - logger.py:50 - Epoch 18 Summary | Train MSE (x10^-2): 126.3029 | Val MSE (x10^-2): 47.2891 | Time: 34.88s
2025-07-18 08:09:56,630 - logger.py:50 - Epoch: [19][0/6]	Total Loss: 1.25785	Main MSE (x10^-2): 125.7854	LR: 3.99e-04	EMPP_Raw: 1.57790
2025-07-18 08:10:10,394 - logger.py:50 - Epoch: [19][5/6]	Total Loss: 1.24345	Main MSE (x10^-2): 124.3454	LR: 3.99e-04	EMPP_Raw: 1.54416
2025-07-18 08:10:10,435 - logger.py:50 - Epoch 19 Training Summary: Avg Total Loss: 1.24345, Avg Main MSE: 1.24345, Time: 16.78s
2025-07-18 08:10:46,465 - logger.py:50 - *** New Best Val MSE (x10^-2): 47.1426, Corresponding Test MSE (x10^-2): 47.3627 at Epoch 19 ***
2025-07-18 08:10:46,512 - logger.py:50 - Epoch 19 Summary | Train MSE (x10^-2): 124.3454 | Val MSE (x10^-2): 47.1426 | Time: 52.86s
2025-07-18 08:10:49,505 - logger.py:50 - Epoch: [20][0/6]	Total Loss: 1.22906	Main MSE (x10^-2): 122.9064	LR: 3.99e-04	EMPP_Raw: 1.54049
2025-07-18 08:11:03,466 - logger.py:50 - Epoch: [20][5/6]	Total Loss: 1.23700	Main MSE (x10^-2): 123.6999	LR: 3.99e-04	EMPP_Raw: 1.53829
2025-07-18 08:11:03,506 - logger.py:50 - Epoch 20 Training Summary: Avg Total Loss: 1.23700, Avg Main MSE: 1.23700, Time: 16.99s
2025-07-18 08:11:39,341 - logger.py:50 - *** New Best Val MSE (x10^-2): 47.0453, Corresponding Test MSE (x10^-2): 47.4063 at Epoch 20 ***
2025-07-18 08:11:39,391 - logger.py:50 - Epoch 20 Summary | Train MSE (x10^-2): 123.6999 | Val MSE (x10^-2): 47.0453 | Time: 52.88s
2025-07-18 08:11:42,373 - logger.py:50 - Epoch: [21][0/6]	Total Loss: 1.26738	Main MSE (x10^-2): 126.7380	LR: 3.98e-04	EMPP_Raw: 1.60954
2025-07-18 08:11:56,128 - logger.py:50 - Epoch: [21][5/6]	Total Loss: 1.23755	Main MSE (x10^-2): 123.7552	LR: 3.98e-04	EMPP_Raw: 1.54028
2025-07-18 08:11:56,169 - logger.py:50 - Epoch 21 Training Summary: Avg Total Loss: 1.23755, Avg Main MSE: 1.23755, Time: 16.77s
2025-07-18 08:12:14,207 - logger.py:50 - Epoch 21 Summary | Train MSE (x10^-2): 123.7552 | Val MSE (x10^-2): 47.2537 | Time: 34.82s
2025-07-18 08:12:17,215 - logger.py:50 - Epoch: [22][0/6]	Total Loss: 1.25114	Main MSE (x10^-2): 125.1136	LR: 3.98e-04	EMPP_Raw: 1.54532
2025-07-18 08:12:31,040 - logger.py:50 - Epoch: [22][5/6]	Total Loss: 1.24621	Main MSE (x10^-2): 124.6208	LR: 3.98e-04	EMPP_Raw: 1.54186
2025-07-18 08:12:31,087 - logger.py:50 - Epoch 22 Training Summary: Avg Total Loss: 1.24621, Avg Main MSE: 1.24621, Time: 16.87s
2025-07-18 08:12:49,140 - logger.py:50 - Epoch 22 Summary | Train MSE (x10^-2): 124.6208 | Val MSE (x10^-2): 47.8065 | Time: 34.93s
2025-07-18 08:12:52,183 - logger.py:50 - Epoch: [23][0/6]	Total Loss: 1.21945	Main MSE (x10^-2): 121.9455	LR: 3.98e-04	EMPP_Raw: 1.49739
2025-07-18 08:13:06,032 - logger.py:50 - Epoch: [23][5/6]	Total Loss: 1.22658	Main MSE (x10^-2): 122.6577	LR: 3.98e-04	EMPP_Raw: 1.51767
2025-07-18 08:13:06,079 - logger.py:50 - Epoch 23 Training Summary: Avg Total Loss: 1.22658, Avg Main MSE: 1.22658, Time: 16.93s
2025-07-18 08:13:24,019 - logger.py:50 - Epoch 23 Summary | Train MSE (x10^-2): 122.6577 | Val MSE (x10^-2): 47.4551 | Time: 34.87s
2025-07-18 08:13:27,015 - logger.py:50 - Epoch: [24][0/6]	Total Loss: 1.27538	Main MSE (x10^-2): 127.5383	LR: 3.98e-04	EMPP_Raw: 1.57622
2025-07-18 08:13:40,961 - logger.py:50 - Epoch: [24][5/6]	Total Loss: 1.24944	Main MSE (x10^-2): 124.9438	LR: 3.98e-04	EMPP_Raw: 1.56152
2025-07-18 08:13:41,002 - logger.py:50 - Epoch 24 Training Summary: Avg Total Loss: 1.24944, Avg Main MSE: 1.24944, Time: 16.97s
2025-07-18 08:13:59,034 - logger.py:50 - Epoch 24 Summary | Train MSE (x10^-2): 124.9438 | Val MSE (x10^-2): 47.4864 | Time: 35.01s
2025-07-18 08:14:02,034 - logger.py:50 - Epoch: [25][0/6]	Total Loss: 1.28262	Main MSE (x10^-2): 128.2620	LR: 3.98e-04	EMPP_Raw: 1.57460
2025-07-18 08:14:15,852 - logger.py:50 - Epoch: [25][5/6]	Total Loss: 1.24354	Main MSE (x10^-2): 124.3539	LR: 3.98e-04	EMPP_Raw: 1.54177
2025-07-18 08:14:15,894 - logger.py:50 - Epoch 25 Training Summary: Avg Total Loss: 1.24354, Avg Main MSE: 1.24354, Time: 16.85s
2025-07-18 08:14:33,879 - logger.py:50 - Epoch 25 Summary | Train MSE (x10^-2): 124.3539 | Val MSE (x10^-2): 47.7839 | Time: 34.84s
2025-07-18 08:14:36,883 - logger.py:50 - Epoch: [26][0/6]	Total Loss: 1.22371	Main MSE (x10^-2): 122.3709	LR: 3.98e-04	EMPP_Raw: 1.52179
2025-07-18 08:14:50,698 - logger.py:50 - Epoch: [26][5/6]	Total Loss: 1.22873	Main MSE (x10^-2): 122.8734	LR: 3.98e-04	EMPP_Raw: 1.51364
2025-07-18 08:14:50,744 - logger.py:50 - Epoch 26 Training Summary: Avg Total Loss: 1.22873, Avg Main MSE: 1.22873, Time: 16.86s
2025-07-18 08:15:26,732 - logger.py:50 - *** New Best Val MSE (x10^-2): 46.9997, Corresponding Test MSE (x10^-2): 47.2275 at Epoch 26 ***
2025-07-18 08:15:26,775 - logger.py:50 - Epoch 26 Summary | Train MSE (x10^-2): 122.8734 | Val MSE (x10^-2): 46.9997 | Time: 52.89s
2025-07-18 08:15:29,766 - logger.py:50 - Epoch: [27][0/6]	Total Loss: 1.25080	Main MSE (x10^-2): 125.0795	LR: 3.97e-04	EMPP_Raw: 1.56742
2025-07-18 08:15:43,526 - logger.py:50 - Epoch: [27][5/6]	Total Loss: 1.22784	Main MSE (x10^-2): 122.7844	LR: 3.97e-04	EMPP_Raw: 1.52769
2025-07-18 08:15:43,567 - logger.py:50 - Epoch 27 Training Summary: Avg Total Loss: 1.22784, Avg Main MSE: 1.22784, Time: 16.79s
2025-07-18 08:16:01,719 - logger.py:50 - Epoch 27 Summary | Train MSE (x10^-2): 122.7844 | Val MSE (x10^-2): 47.2575 | Time: 34.94s
2025-07-18 08:16:04,733 - logger.py:50 - Epoch: [28][0/6]	Total Loss: 1.24954	Main MSE (x10^-2): 124.9540	LR: 3.97e-04	EMPP_Raw: 1.56691
2025-07-18 08:16:18,527 - logger.py:50 - Epoch: [28][5/6]	Total Loss: 1.23132	Main MSE (x10^-2): 123.1325	LR: 3.97e-04	EMPP_Raw: 1.52482
2025-07-18 08:16:18,571 - logger.py:50 - Epoch 28 Training Summary: Avg Total Loss: 1.23132, Avg Main MSE: 1.23132, Time: 16.84s
2025-07-18 08:16:36,479 - logger.py:50 - Epoch 28 Summary | Train MSE (x10^-2): 123.1325 | Val MSE (x10^-2): 47.0850 | Time: 34.75s
2025-07-18 08:16:39,641 - logger.py:50 - Epoch: [29][0/6]	Total Loss: 1.21838	Main MSE (x10^-2): 121.8379	LR: 3.97e-04	EMPP_Raw: 1.50519
2025-07-18 08:16:53,420 - logger.py:50 - Epoch: [29][5/6]	Total Loss: 1.21259	Main MSE (x10^-2): 121.2590	LR: 3.97e-04	EMPP_Raw: 1.50855
2025-07-18 08:16:53,461 - logger.py:50 - Epoch 29 Training Summary: Avg Total Loss: 1.21259, Avg Main MSE: 1.21259, Time: 16.97s
2025-07-18 08:17:11,400 - logger.py:50 - Epoch 29 Summary | Train MSE (x10^-2): 121.2590 | Val MSE (x10^-2): 47.1853 | Time: 34.91s
2025-07-18 08:17:14,582 - logger.py:50 - Epoch: [30][0/6]	Total Loss: 1.20599	Main MSE (x10^-2): 120.5990	LR: 3.97e-04	EMPP_Raw: 1.49275
2025-07-18 08:17:28,383 - logger.py:50 - Epoch: [30][5/6]	Total Loss: 1.22821	Main MSE (x10^-2): 122.8209	LR: 3.97e-04	EMPP_Raw: 1.52536
2025-07-18 08:17:28,423 - logger.py:50 - Epoch 30 Training Summary: Avg Total Loss: 1.22821, Avg Main MSE: 1.22821, Time: 17.01s
2025-07-18 08:17:46,375 - logger.py:50 - Epoch 30 Summary | Train MSE (x10^-2): 122.8209 | Val MSE (x10^-2): 48.6336 | Time: 34.96s
2025-07-18 08:17:49,385 - logger.py:50 - Epoch: [31][0/6]	Total Loss: 1.22856	Main MSE (x10^-2): 122.8557	LR: 3.96e-04	EMPP_Raw: 1.51147
2025-07-18 08:18:03,364 - logger.py:50 - Epoch: [31][5/6]	Total Loss: 1.23290	Main MSE (x10^-2): 123.2897	LR: 3.96e-04	EMPP_Raw: 1.53243
2025-07-18 08:18:03,410 - logger.py:50 - Epoch 31 Training Summary: Avg Total Loss: 1.23290, Avg Main MSE: 1.23290, Time: 17.03s
2025-07-18 08:18:21,307 - logger.py:50 - Epoch 31 Summary | Train MSE (x10^-2): 123.2897 | Val MSE (x10^-2): 47.0136 | Time: 34.93s
2025-07-18 08:18:24,323 - logger.py:50 - Epoch: [32][0/6]	Total Loss: 1.21192	Main MSE (x10^-2): 121.1924	LR: 3.96e-04	EMPP_Raw: 1.52032
2025-07-18 08:18:38,334 - logger.py:50 - Epoch: [32][5/6]	Total Loss: 1.20969	Main MSE (x10^-2): 120.9693	LR: 3.96e-04	EMPP_Raw: 1.50160
2025-07-18 08:18:38,378 - logger.py:50 - Epoch 32 Training Summary: Avg Total Loss: 1.20969, Avg Main MSE: 1.20969, Time: 17.06s
2025-07-18 08:18:56,293 - logger.py:50 - Epoch 32 Summary | Train MSE (x10^-2): 120.9693 | Val MSE (x10^-2): 47.0352 | Time: 34.98s
2025-07-18 08:18:59,299 - logger.py:50 - Epoch: [33][0/6]	Total Loss: 1.24448	Main MSE (x10^-2): 124.4477	LR: 3.96e-04	EMPP_Raw: 1.55179
2025-07-18 08:19:13,149 - logger.py:50 - Epoch: [33][5/6]	Total Loss: 1.23544	Main MSE (x10^-2): 123.5442	LR: 3.96e-04	EMPP_Raw: 1.52893
2025-07-18 08:19:13,195 - logger.py:50 - Epoch 33 Training Summary: Avg Total Loss: 1.23544, Avg Main MSE: 1.23544, Time: 16.89s
2025-07-18 08:19:31,107 - logger.py:50 - Epoch 33 Summary | Train MSE (x10^-2): 123.5442 | Val MSE (x10^-2): 47.9246 | Time: 34.81s
2025-07-18 08:19:34,267 - logger.py:50 - Epoch: [34][0/6]	Total Loss: 1.18683	Main MSE (x10^-2): 118.6829	LR: 3.96e-04	EMPP_Raw: 1.46625
2025-07-18 08:19:48,005 - logger.py:50 - Epoch: [34][5/6]	Total Loss: 1.23357	Main MSE (x10^-2): 123.3567	LR: 3.96e-04	EMPP_Raw: 1.51196
2025-07-18 08:19:48,050 - logger.py:50 - Epoch 34 Training Summary: Avg Total Loss: 1.23357, Avg Main MSE: 1.23357, Time: 16.93s
2025-07-18 08:20:06,164 - logger.py:50 - Epoch 34 Summary | Train MSE (x10^-2): 123.3567 | Val MSE (x10^-2): 48.1555 | Time: 35.05s
2025-07-18 08:20:09,350 - logger.py:50 - Epoch: [35][0/6]	Total Loss: 1.19316	Main MSE (x10^-2): 119.3159	LR: 3.95e-04	EMPP_Raw: 1.47663
2025-07-18 08:20:23,129 - logger.py:50 - Epoch: [35][5/6]	Total Loss: 1.21014	Main MSE (x10^-2): 121.0138	LR: 3.95e-04	EMPP_Raw: 1.49806
2025-07-18 08:20:23,171 - logger.py:50 - Epoch 35 Training Summary: Avg Total Loss: 1.21014, Avg Main MSE: 1.21014, Time: 17.00s
2025-07-18 08:20:41,235 - logger.py:50 - Epoch 35 Summary | Train MSE (x10^-2): 121.0138 | Val MSE (x10^-2): 48.2460 | Time: 35.06s
2025-07-18 08:20:44,274 - logger.py:50 - Epoch: [36][0/6]	Total Loss: 1.22901	Main MSE (x10^-2): 122.9008	LR: 3.95e-04	EMPP_Raw: 1.48929
2025-07-18 08:20:58,173 - logger.py:50 - Epoch: [36][5/6]	Total Loss: 1.20376	Main MSE (x10^-2): 120.3757	LR: 3.95e-04	EMPP_Raw: 1.48474
2025-07-18 08:20:58,217 - logger.py:50 - Epoch 36 Training Summary: Avg Total Loss: 1.20376, Avg Main MSE: 1.20376, Time: 16.98s
2025-07-18 08:21:16,247 - logger.py:50 - Epoch 36 Summary | Train MSE (x10^-2): 120.3757 | Val MSE (x10^-2): 47.4118 | Time: 35.01s
2025-07-18 08:21:19,255 - logger.py:50 - Epoch: [37][0/6]	Total Loss: 1.23297	Main MSE (x10^-2): 123.2974	LR: 3.95e-04	EMPP_Raw: 1.51188
2025-07-18 08:21:33,032 - logger.py:50 - Epoch: [37][5/6]	Total Loss: 1.20557	Main MSE (x10^-2): 120.5570	LR: 3.95e-04	EMPP_Raw: 1.50114
2025-07-18 08:21:33,077 - logger.py:50 - Epoch 37 Training Summary: Avg Total Loss: 1.20557, Avg Main MSE: 1.20557, Time: 16.82s
2025-07-18 08:21:51,092 - logger.py:50 - Epoch 37 Summary | Train MSE (x10^-2): 120.5570 | Val MSE (x10^-2): 47.2783 | Time: 34.84s
2025-07-18 08:21:54,084 - logger.py:50 - Epoch: [38][0/6]	Total Loss: 1.19684	Main MSE (x10^-2): 119.6843	LR: 3.95e-04	EMPP_Raw: 1.49878
2025-07-18 08:22:07,848 - logger.py:50 - Epoch: [38][5/6]	Total Loss: 1.21441	Main MSE (x10^-2): 121.4406	LR: 3.95e-04	EMPP_Raw: 1.50923
2025-07-18 08:22:07,889 - logger.py:50 - Epoch 38 Training Summary: Avg Total Loss: 1.21441, Avg Main MSE: 1.21441, Time: 16.79s
2025-07-18 08:22:26,009 - logger.py:50 - Epoch 38 Summary | Train MSE (x10^-2): 121.4406 | Val MSE (x10^-2): 47.1903 | Time: 34.91s
2025-07-18 08:22:29,026 - logger.py:50 - Epoch: [39][0/6]	Total Loss: 1.23365	Main MSE (x10^-2): 123.3646	LR: 3.94e-04	EMPP_Raw: 1.51615
2025-07-18 08:22:42,869 - logger.py:50 - Epoch: [39][5/6]	Total Loss: 1.21991	Main MSE (x10^-2): 121.9909	LR: 3.94e-04	EMPP_Raw: 1.51473
2025-07-18 08:22:42,915 - logger.py:50 - Epoch 39 Training Summary: Avg Total Loss: 1.21991, Avg Main MSE: 1.21991, Time: 16.90s
2025-07-18 08:23:00,840 - logger.py:50 - Epoch 39 Summary | Train MSE (x10^-2): 121.9909 | Val MSE (x10^-2): 47.4403 | Time: 34.82s
2025-07-18 08:23:03,900 - logger.py:50 - Epoch: [40][0/6]	Total Loss: 1.22505	Main MSE (x10^-2): 122.5054	LR: 3.94e-04	EMPP_Raw: 1.54734
2025-07-18 08:23:17,856 - logger.py:50 - Epoch: [40][5/6]	Total Loss: 1.21159	Main MSE (x10^-2): 121.1590	LR: 3.94e-04	EMPP_Raw: 1.51012
2025-07-18 08:23:17,900 - logger.py:50 - Epoch 40 Training Summary: Avg Total Loss: 1.21159, Avg Main MSE: 1.21159, Time: 17.05s
2025-07-18 08:23:35,862 - logger.py:50 - Epoch 40 Summary | Train MSE (x10^-2): 121.1590 | Val MSE (x10^-2): 49.9424 | Time: 35.02s
2025-07-18 08:23:38,901 - logger.py:50 - Epoch: [41][0/6]	Total Loss: 1.21665	Main MSE (x10^-2): 121.6647	LR: 3.94e-04	EMPP_Raw: 1.48903
2025-07-18 08:23:52,707 - logger.py:50 - Epoch: [41][5/6]	Total Loss: 1.21464	Main MSE (x10^-2): 121.4643	LR: 3.94e-04	EMPP_Raw: 1.49339
2025-07-18 08:23:52,748 - logger.py:50 - Epoch 41 Training Summary: Avg Total Loss: 1.21464, Avg Main MSE: 1.21464, Time: 16.88s
2025-07-18 08:24:10,867 - logger.py:50 - Epoch 41 Summary | Train MSE (x10^-2): 121.4643 | Val MSE (x10^-2): 48.2027 | Time: 35.00s
2025-07-18 08:24:13,897 - logger.py:50 - Epoch: [42][0/6]	Total Loss: 1.22112	Main MSE (x10^-2): 122.1122	LR: 3.93e-04	EMPP_Raw: 1.50584
2025-07-18 08:24:27,708 - logger.py:50 - Epoch: [42][5/6]	Total Loss: 1.21214	Main MSE (x10^-2): 121.2144	LR: 3.93e-04	EMPP_Raw: 1.50968
2025-07-18 08:24:27,747 - logger.py:50 - Epoch 42 Training Summary: Avg Total Loss: 1.21214, Avg Main MSE: 1.21214, Time: 16.87s
2025-07-18 08:24:45,726 - logger.py:50 - Epoch 42 Summary | Train MSE (x10^-2): 121.2144 | Val MSE (x10^-2): 47.3653 | Time: 34.85s
2025-07-18 08:24:48,744 - logger.py:50 - Epoch: [43][0/6]	Total Loss: 1.24131	Main MSE (x10^-2): 124.1310	LR: 3.93e-04	EMPP_Raw: 1.56381
2025-07-18 08:25:02,560 - logger.py:50 - Epoch: [43][5/6]	Total Loss: 1.21148	Main MSE (x10^-2): 121.1482	LR: 3.93e-04	EMPP_Raw: 1.52257
2025-07-18 08:25:02,605 - logger.py:50 - Epoch 43 Training Summary: Avg Total Loss: 1.21148, Avg Main MSE: 1.21148, Time: 16.87s
2025-07-18 08:25:20,727 - logger.py:50 - Epoch 43 Summary | Train MSE (x10^-2): 121.1482 | Val MSE (x10^-2): 47.9448 | Time: 35.00s
2025-07-18 08:25:23,749 - logger.py:50 - Epoch: [44][0/6]	Total Loss: 1.23336	Main MSE (x10^-2): 123.3363	LR: 3.93e-04	EMPP_Raw: 1.54002
2025-07-18 08:25:37,571 - logger.py:50 - Epoch: [44][5/6]	Total Loss: 1.22594	Main MSE (x10^-2): 122.5938	LR: 3.93e-04	EMPP_Raw: 1.52391
2025-07-18 08:25:37,614 - logger.py:50 - Epoch 44 Training Summary: Avg Total Loss: 1.22594, Avg Main MSE: 1.22594, Time: 16.88s
2025-07-18 08:25:55,535 - logger.py:50 - Epoch 44 Summary | Train MSE (x10^-2): 122.5938 | Val MSE (x10^-2): 48.2243 | Time: 34.80s
2025-07-18 08:25:58,697 - logger.py:50 - Epoch: [45][0/6]	Total Loss: 1.20085	Main MSE (x10^-2): 120.0850	LR: 3.92e-04	EMPP_Raw: 1.52319
2025-07-18 08:26:12,474 - logger.py:50 - Epoch: [45][5/6]	Total Loss: 1.22070	Main MSE (x10^-2): 122.0703	LR: 3.92e-04	EMPP_Raw: 1.51100
2025-07-18 08:26:12,521 - logger.py:50 - Epoch 45 Training Summary: Avg Total Loss: 1.22070, Avg Main MSE: 1.22070, Time: 16.98s
2025-07-18 08:26:30,445 - logger.py:50 - Epoch 45 Summary | Train MSE (x10^-2): 122.0703 | Val MSE (x10^-2): 47.8387 | Time: 34.90s
2025-07-18 08:26:33,459 - logger.py:50 - Epoch: [46][0/6]	Total Loss: 1.22386	Main MSE (x10^-2): 122.3865	LR: 3.92e-04	EMPP_Raw: 1.51865
2025-07-18 08:26:47,455 - logger.py:50 - Epoch: [46][5/6]	Total Loss: 1.23743	Main MSE (x10^-2): 123.7429	LR: 3.92e-04	EMPP_Raw: 1.52353
2025-07-18 08:26:47,499 - logger.py:50 - Epoch 46 Training Summary: Avg Total Loss: 1.23743, Avg Main MSE: 1.23743, Time: 17.04s
2025-07-18 08:27:05,406 - logger.py:50 - Epoch 46 Summary | Train MSE (x10^-2): 123.7429 | Val MSE (x10^-2): 48.4524 | Time: 34.95s
2025-07-18 08:27:08,414 - logger.py:50 - Epoch: [47][0/6]	Total Loss: 1.18663	Main MSE (x10^-2): 118.6632	LR: 3.92e-04	EMPP_Raw: 1.47667
2025-07-18 08:27:22,210 - logger.py:50 - Epoch: [47][5/6]	Total Loss: 1.20771	Main MSE (x10^-2): 120.7709	LR: 3.92e-04	EMPP_Raw: 1.50958
2025-07-18 08:27:22,252 - logger.py:50 - Epoch 47 Training Summary: Avg Total Loss: 1.20771, Avg Main MSE: 1.20771, Time: 16.84s
2025-07-18 08:27:40,167 - logger.py:50 - Epoch 47 Summary | Train MSE (x10^-2): 120.7709 | Val MSE (x10^-2): 47.2902 | Time: 34.76s
2025-07-18 08:27:43,354 - logger.py:50 - Epoch: [48][0/6]	Total Loss: 1.16288	Main MSE (x10^-2): 116.2884	LR: 3.91e-04	EMPP_Raw: 1.46291
2025-07-18 08:27:57,119 - logger.py:50 - Epoch: [48][5/6]	Total Loss: 1.20899	Main MSE (x10^-2): 120.8989	LR: 3.91e-04	EMPP_Raw: 1.52032
2025-07-18 08:27:57,164 - logger.py:50 - Epoch 48 Training Summary: Avg Total Loss: 1.20899, Avg Main MSE: 1.20899, Time: 16.99s
2025-07-18 08:28:15,045 - logger.py:50 - Epoch 48 Summary | Train MSE (x10^-2): 120.8989 | Val MSE (x10^-2): 48.1305 | Time: 34.87s
2025-07-18 08:28:18,205 - logger.py:50 - Epoch: [49][0/6]	Total Loss: 1.22927	Main MSE (x10^-2): 122.9266	LR: 3.91e-04	EMPP_Raw: 1.51703
2025-07-18 08:28:31,933 - logger.py:50 - Epoch: [49][5/6]	Total Loss: 1.20826	Main MSE (x10^-2): 120.8255	LR: 3.91e-04	EMPP_Raw: 1.52304
2025-07-18 08:28:31,976 - logger.py:50 - Epoch 49 Training Summary: Avg Total Loss: 1.20826, Avg Main MSE: 1.20826, Time: 16.93s
2025-07-18 08:28:49,914 - logger.py:50 - Epoch 49 Summary | Train MSE (x10^-2): 120.8255 | Val MSE (x10^-2): 47.8401 | Time: 34.87s
2025-07-18 08:28:52,926 - logger.py:50 - Epoch: [50][0/6]	Total Loss: 1.19209	Main MSE (x10^-2): 119.2090	LR: 3.91e-04	EMPP_Raw: 1.49900
2025-07-18 08:29:06,884 - logger.py:50 - Epoch: [50][5/6]	Total Loss: 1.20647	Main MSE (x10^-2): 120.6471	LR: 3.91e-04	EMPP_Raw: 1.52135
2025-07-18 08:29:06,929 - logger.py:50 - Epoch 50 Training Summary: Avg Total Loss: 1.20647, Avg Main MSE: 1.20647, Time: 17.00s
2025-07-18 08:29:24,914 - logger.py:50 - Epoch 50 Summary | Train MSE (x10^-2): 120.6471 | Val MSE (x10^-2): 48.1831 | Time: 34.99s
2025-07-18 08:29:27,913 - logger.py:50 - Epoch: [51][0/6]	Total Loss: 1.20221	Main MSE (x10^-2): 120.2208	LR: 3.90e-04	EMPP_Raw: 1.50715
2025-07-18 08:29:41,727 - logger.py:50 - Epoch: [51][5/6]	Total Loss: 1.19545	Main MSE (x10^-2): 119.5445	LR: 3.90e-04	EMPP_Raw: 1.50876
2025-07-18 08:29:41,769 - logger.py:50 - Epoch 51 Training Summary: Avg Total Loss: 1.19545, Avg Main MSE: 1.19545, Time: 16.85s
2025-07-18 08:29:59,902 - logger.py:50 - Epoch 51 Summary | Train MSE (x10^-2): 119.5445 | Val MSE (x10^-2): 48.2047 | Time: 34.98s
2025-07-18 08:30:02,907 - logger.py:50 - Epoch: [52][0/6]	Total Loss: 1.17529	Main MSE (x10^-2): 117.5287	LR: 3.90e-04	EMPP_Raw: 1.48746
2025-07-18 08:30:16,709 - logger.py:50 - Epoch: [52][5/6]	Total Loss: 1.19067	Main MSE (x10^-2): 119.0674	LR: 3.90e-04	EMPP_Raw: 1.50099
2025-07-18 08:30:16,753 - logger.py:50 - Epoch 52 Training Summary: Avg Total Loss: 1.19067, Avg Main MSE: 1.19067, Time: 16.84s
2025-07-18 08:30:34,832 - logger.py:50 - Epoch 52 Summary | Train MSE (x10^-2): 119.0674 | Val MSE (x10^-2): 48.3091 | Time: 34.93s
2025-07-18 08:30:37,998 - logger.py:50 - Epoch: [53][0/6]	Total Loss: 1.18104	Main MSE (x10^-2): 118.1042	LR: 3.89e-04	EMPP_Raw: 1.48811
2025-07-18 08:30:51,769 - logger.py:50 - Epoch: [53][5/6]	Total Loss: 1.19861	Main MSE (x10^-2): 119.8608	LR: 3.89e-04	EMPP_Raw: 1.51265
2025-07-18 08:30:51,815 - logger.py:50 - Epoch 53 Training Summary: Avg Total Loss: 1.19861, Avg Main MSE: 1.19861, Time: 16.97s
2025-07-18 08:31:09,661 - logger.py:50 - Epoch 53 Summary | Train MSE (x10^-2): 119.8608 | Val MSE (x10^-2): 48.7184 | Time: 34.82s
2025-07-18 08:31:12,674 - logger.py:50 - Epoch: [54][0/6]	Total Loss: 1.18690	Main MSE (x10^-2): 118.6896	LR: 3.89e-04	EMPP_Raw: 1.53174
2025-07-18 08:31:26,710 - logger.py:50 - Epoch: [54][5/6]	Total Loss: 1.18982	Main MSE (x10^-2): 118.9822	LR: 3.89e-04	EMPP_Raw: 1.51226
2025-07-18 08:31:26,751 - logger.py:50 - Epoch 54 Training Summary: Avg Total Loss: 1.18982, Avg Main MSE: 1.18982, Time: 17.08s
2025-07-18 08:31:44,622 - logger.py:50 - Epoch 54 Summary | Train MSE (x10^-2): 118.9822 | Val MSE (x10^-2): 48.8797 | Time: 34.96s
2025-07-18 08:31:47,628 - logger.py:50 - Epoch: [55][0/6]	Total Loss: 1.19451	Main MSE (x10^-2): 119.4513	LR: 3.89e-04	EMPP_Raw: 1.55887
2025-07-18 08:32:01,407 - logger.py:50 - Epoch: [55][5/6]	Total Loss: 1.18670	Main MSE (x10^-2): 118.6700	LR: 3.89e-04	EMPP_Raw: 1.51098
2025-07-18 08:32:01,458 - logger.py:50 - Epoch 55 Training Summary: Avg Total Loss: 1.18670, Avg Main MSE: 1.18670, Time: 16.83s
2025-07-18 08:32:19,572 - logger.py:50 - Epoch 55 Summary | Train MSE (x10^-2): 118.6700 | Val MSE (x10^-2): 49.3153 | Time: 34.94s
2025-07-18 08:32:22,633 - logger.py:50 - Epoch: [56][0/6]	Total Loss: 1.20883	Main MSE (x10^-2): 120.8834	LR: 3.88e-04	EMPP_Raw: 1.52550
2025-07-18 08:32:36,484 - logger.py:50 - Epoch: [56][5/6]	Total Loss: 1.18836	Main MSE (x10^-2): 118.8360	LR: 3.88e-04	EMPP_Raw: 1.52098
2025-07-18 08:32:36,527 - logger.py:50 - Epoch 56 Training Summary: Avg Total Loss: 1.18836, Avg Main MSE: 1.18836, Time: 16.94s
2025-07-18 08:32:54,680 - logger.py:50 - Epoch 56 Summary | Train MSE (x10^-2): 118.8360 | Val MSE (x10^-2): 49.1544 | Time: 35.10s
2025-07-18 08:32:57,686 - logger.py:50 - Epoch: [57][0/6]	Total Loss: 1.17058	Main MSE (x10^-2): 117.0576	LR: 3.88e-04	EMPP_Raw: 1.49692
2025-07-18 08:33:11,485 - logger.py:50 - Epoch: [57][5/6]	Total Loss: 1.19568	Main MSE (x10^-2): 119.5683	LR: 3.88e-04	EMPP_Raw: 1.52473
2025-07-18 08:33:11,531 - logger.py:50 - Epoch 57 Training Summary: Avg Total Loss: 1.19568, Avg Main MSE: 1.19568, Time: 16.84s
2025-07-18 08:33:29,487 - logger.py:50 - Epoch 57 Summary | Train MSE (x10^-2): 119.5683 | Val MSE (x10^-2): 50.7067 | Time: 34.80s
2025-07-18 08:33:32,842 - logger.py:50 - Epoch: [58][0/6]	Total Loss: 1.16899	Main MSE (x10^-2): 116.8986	LR: 3.87e-04	EMPP_Raw: 1.48307
2025-07-18 08:33:46,630 - logger.py:50 - Epoch: [58][5/6]	Total Loss: 1.17784	Main MSE (x10^-2): 117.7837	LR: 3.87e-04	EMPP_Raw: 1.49748
2025-07-18 08:33:46,680 - logger.py:50 - Epoch 58 Training Summary: Avg Total Loss: 1.17784, Avg Main MSE: 1.17784, Time: 17.18s
2025-07-18 08:34:04,643 - logger.py:50 - Epoch 58 Summary | Train MSE (x10^-2): 117.7837 | Val MSE (x10^-2): 52.5563 | Time: 35.15s
2025-07-18 08:34:07,819 - logger.py:50 - Epoch: [59][0/6]	Total Loss: 1.21051	Main MSE (x10^-2): 121.0513	LR: 3.87e-04	EMPP_Raw: 1.51104
2025-07-18 08:34:21,616 - logger.py:50 - Epoch: [59][5/6]	Total Loss: 1.18981	Main MSE (x10^-2): 118.9812	LR: 3.87e-04	EMPP_Raw: 1.51194
2025-07-18 08:34:21,661 - logger.py:50 - Epoch 59 Training Summary: Avg Total Loss: 1.18981, Avg Main MSE: 1.18981, Time: 17.01s
2025-07-18 08:34:39,644 - logger.py:50 - Epoch 59 Summary | Train MSE (x10^-2): 118.9812 | Val MSE (x10^-2): 49.7097 | Time: 35.00s
2025-07-18 08:34:42,647 - logger.py:50 - Epoch: [60][0/6]	Total Loss: 1.18592	Main MSE (x10^-2): 118.5924	LR: 3.86e-04	EMPP_Raw: 1.50170
2025-07-18 08:34:56,592 - logger.py:50 - Epoch: [60][5/6]	Total Loss: 1.18529	Main MSE (x10^-2): 118.5292	LR: 3.86e-04	EMPP_Raw: 1.50726
2025-07-18 08:34:56,635 - logger.py:50 - Epoch 60 Training Summary: Avg Total Loss: 1.18529, Avg Main MSE: 1.18529, Time: 16.98s
2025-07-18 08:35:14,628 - logger.py:50 - Epoch 60 Summary | Train MSE (x10^-2): 118.5292 | Val MSE (x10^-2): 50.6693 | Time: 34.98s
2025-07-18 08:35:17,629 - logger.py:50 - Epoch: [61][0/6]	Total Loss: 1.17406	Main MSE (x10^-2): 117.4058	LR: 3.86e-04	EMPP_Raw: 1.53588
2025-07-18 08:35:31,398 - logger.py:50 - Epoch: [61][5/6]	Total Loss: 1.18774	Main MSE (x10^-2): 118.7744	LR: 3.86e-04	EMPP_Raw: 1.52992
2025-07-18 08:35:31,443 - logger.py:50 - Epoch 61 Training Summary: Avg Total Loss: 1.18774, Avg Main MSE: 1.18774, Time: 16.81s
2025-07-18 08:35:49,455 - logger.py:50 - Epoch 61 Summary | Train MSE (x10^-2): 118.7744 | Val MSE (x10^-2): 50.7672 | Time: 34.82s
2025-07-18 08:35:52,451 - logger.py:50 - Epoch: [62][0/6]	Total Loss: 1.14793	Main MSE (x10^-2): 114.7929	LR: 3.86e-04	EMPP_Raw: 1.45013
2025-07-18 08:36:06,200 - logger.py:50 - Epoch: [62][5/6]	Total Loss: 1.15783	Main MSE (x10^-2): 115.7832	LR: 3.86e-04	EMPP_Raw: 1.50511
2025-07-18 08:36:06,242 - logger.py:50 - Epoch 62 Training Summary: Avg Total Loss: 1.15783, Avg Main MSE: 1.15783, Time: 16.78s
2025-07-18 08:36:24,279 - logger.py:50 - Epoch 62 Summary | Train MSE (x10^-2): 115.7832 | Val MSE (x10^-2): 51.2800 | Time: 34.82s
2025-07-18 08:36:27,354 - logger.py:50 - Epoch: [63][0/6]	Total Loss: 1.13606	Main MSE (x10^-2): 113.6057	LR: 3.85e-04	EMPP_Raw: 1.50739
2025-07-18 08:36:41,141 - logger.py:50 - Epoch: [63][5/6]	Total Loss: 1.15994	Main MSE (x10^-2): 115.9940	LR: 3.85e-04	EMPP_Raw: 1.50596
2025-07-18 08:36:41,186 - logger.py:50 - Epoch 63 Training Summary: Avg Total Loss: 1.15994, Avg Main MSE: 1.15994, Time: 16.90s
2025-07-18 08:36:59,102 - logger.py:50 - Epoch 63 Summary | Train MSE (x10^-2): 115.9940 | Val MSE (x10^-2): 52.3624 | Time: 34.82s
2025-07-18 08:37:02,247 - logger.py:50 - Epoch: [64][0/6]	Total Loss: 1.15239	Main MSE (x10^-2): 115.2387	LR: 3.85e-04	EMPP_Raw: 1.50303
2025-07-18 08:37:15,961 - logger.py:50 - Epoch: [64][5/6]	Total Loss: 1.16821	Main MSE (x10^-2): 116.8212	LR: 3.85e-04	EMPP_Raw: 1.49972
2025-07-18 08:37:16,001 - logger.py:50 - Epoch 64 Training Summary: Avg Total Loss: 1.16821, Avg Main MSE: 1.16821, Time: 16.89s
2025-07-18 08:37:34,064 - logger.py:50 - Epoch 64 Summary | Train MSE (x10^-2): 116.8212 | Val MSE (x10^-2): 50.0888 | Time: 34.95s
2025-07-18 08:37:37,056 - logger.py:50 - Epoch: [65][0/6]	Total Loss: 1.15770	Main MSE (x10^-2): 115.7703	LR: 3.84e-04	EMPP_Raw: 1.50893
2025-07-18 08:37:50,939 - logger.py:50 - Epoch: [65][5/6]	Total Loss: 1.15601	Main MSE (x10^-2): 115.6009	LR: 3.84e-04	EMPP_Raw: 1.49679
2025-07-18 08:37:50,984 - logger.py:50 - Epoch 65 Training Summary: Avg Total Loss: 1.15601, Avg Main MSE: 1.15601, Time: 16.91s
2025-07-18 08:38:08,909 - logger.py:50 - Epoch 65 Summary | Train MSE (x10^-2): 115.6009 | Val MSE (x10^-2): 54.8470 | Time: 34.84s
2025-07-18 08:38:11,953 - logger.py:50 - Epoch: [66][0/6]	Total Loss: 1.17919	Main MSE (x10^-2): 117.9192	LR: 3.84e-04	EMPP_Raw: 1.51342
2025-07-18 08:38:25,864 - logger.py:50 - Epoch: [66][5/6]	Total Loss: 1.17512	Main MSE (x10^-2): 117.5117	LR: 3.84e-04	EMPP_Raw: 1.51353
2025-07-18 08:38:25,911 - logger.py:50 - Epoch 66 Training Summary: Avg Total Loss: 1.17512, Avg Main MSE: 1.17512, Time: 16.99s
2025-07-18 08:38:43,826 - logger.py:50 - Epoch 66 Summary | Train MSE (x10^-2): 117.5117 | Val MSE (x10^-2): 52.2607 | Time: 34.91s
2025-07-18 08:38:46,827 - logger.py:50 - Epoch: [67][0/6]	Total Loss: 1.13614	Main MSE (x10^-2): 113.6140	LR: 3.83e-04	EMPP_Raw: 1.53995
2025-07-18 08:39:00,572 - logger.py:50 - Epoch: [67][5/6]	Total Loss: 1.14147	Main MSE (x10^-2): 114.1472	LR: 3.83e-04	EMPP_Raw: 1.48258
2025-07-18 08:39:00,614 - logger.py:50 - Epoch 67 Training Summary: Avg Total Loss: 1.14147, Avg Main MSE: 1.14147, Time: 16.78s
2025-07-18 08:39:18,490 - logger.py:50 - Epoch 67 Summary | Train MSE (x10^-2): 114.1472 | Val MSE (x10^-2): 53.2787 | Time: 34.66s
2025-07-18 08:39:21,638 - logger.py:50 - Epoch: [68][0/6]	Total Loss: 1.13453	Main MSE (x10^-2): 113.4526	LR: 3.83e-04	EMPP_Raw: 1.50834
2025-07-18 08:39:35,446 - logger.py:50 - Epoch: [68][5/6]	Total Loss: 1.13997	Main MSE (x10^-2): 113.9974	LR: 3.83e-04	EMPP_Raw: 1.48864
2025-07-18 08:39:35,489 - logger.py:50 - Epoch 68 Training Summary: Avg Total Loss: 1.13997, Avg Main MSE: 1.13997, Time: 16.99s
2025-07-18 08:39:53,397 - logger.py:50 - Epoch 68 Summary | Train MSE (x10^-2): 113.9974 | Val MSE (x10^-2): 55.3459 | Time: 34.90s
2025-07-18 08:39:56,566 - logger.py:50 - Epoch: [69][0/6]	Total Loss: 1.13856	Main MSE (x10^-2): 113.8561	LR: 3.82e-04	EMPP_Raw: 1.53201
2025-07-18 08:40:10,287 - logger.py:50 - Epoch: [69][5/6]	Total Loss: 1.13957	Main MSE (x10^-2): 113.9574	LR: 3.82e-04	EMPP_Raw: 1.50612
2025-07-18 08:40:10,328 - logger.py:50 - Epoch 69 Training Summary: Avg Total Loss: 1.13957, Avg Main MSE: 1.13957, Time: 16.92s
2025-07-18 08:40:28,245 - logger.py:50 - Epoch 69 Summary | Train MSE (x10^-2): 113.9574 | Val MSE (x10^-2): 54.8680 | Time: 34.84s
2025-07-18 08:40:31,246 - logger.py:50 - Epoch: [70][0/6]	Total Loss: 1.10867	Main MSE (x10^-2): 110.8668	LR: 3.82e-04	EMPP_Raw: 1.47481
2025-07-18 08:40:45,234 - logger.py:50 - Epoch: [70][5/6]	Total Loss: 1.12023	Main MSE (x10^-2): 112.0233	LR: 3.82e-04	EMPP_Raw: 1.50493
2025-07-18 08:40:45,285 - logger.py:50 - Epoch 70 Training Summary: Avg Total Loss: 1.12023, Avg Main MSE: 1.12023, Time: 17.03s
2025-07-18 08:41:03,267 - logger.py:50 - Epoch 70 Summary | Train MSE (x10^-2): 112.0233 | Val MSE (x10^-2): 55.1510 | Time: 35.02s
2025-07-18 08:41:06,272 - logger.py:50 - Epoch: [71][0/6]	Total Loss: 1.10040	Main MSE (x10^-2): 110.0403	LR: 3.81e-04	EMPP_Raw: 1.51613
2025-07-18 08:41:20,037 - logger.py:50 - Epoch: [71][5/6]	Total Loss: 1.11013	Main MSE (x10^-2): 111.0129	LR: 3.81e-04	EMPP_Raw: 1.50804
2025-07-18 08:41:20,080 - logger.py:50 - Epoch 71 Training Summary: Avg Total Loss: 1.11013, Avg Main MSE: 1.11013, Time: 16.80s
2025-07-18 08:41:38,143 - logger.py:50 - Epoch 71 Summary | Train MSE (x10^-2): 111.0129 | Val MSE (x10^-2): 56.4020 | Time: 34.87s
2025-07-18 08:41:41,161 - logger.py:50 - Epoch: [72][0/6]	Total Loss: 1.10535	Main MSE (x10^-2): 110.5347	LR: 3.80e-04	EMPP_Raw: 1.51049
2025-07-18 08:41:54,957 - logger.py:50 - Epoch: [72][5/6]	Total Loss: 1.10989	Main MSE (x10^-2): 110.9889	LR: 3.80e-04	EMPP_Raw: 1.48841
2025-07-18 08:41:54,994 - logger.py:50 - Epoch 72 Training Summary: Avg Total Loss: 1.10989, Avg Main MSE: 1.10989, Time: 16.84s
2025-07-18 08:42:13,014 - logger.py:50 - Epoch 72 Summary | Train MSE (x10^-2): 110.9889 | Val MSE (x10^-2): 55.1243 | Time: 34.86s
2025-07-18 08:42:16,193 - logger.py:50 - Epoch: [73][0/6]	Total Loss: 1.09665	Main MSE (x10^-2): 109.6652	LR: 3.80e-04	EMPP_Raw: 1.47979
2025-07-18 08:42:30,003 - logger.py:50 - Epoch: [73][5/6]	Total Loss: 1.13311	Main MSE (x10^-2): 113.3107	LR: 3.80e-04	EMPP_Raw: 1.50848
2025-07-18 08:42:30,044 - logger.py:50 - Epoch 73 Training Summary: Avg Total Loss: 1.13311, Avg Main MSE: 1.13311, Time: 17.02s
2025-07-18 08:42:47,985 - logger.py:50 - Epoch 73 Summary | Train MSE (x10^-2): 113.3107 | Val MSE (x10^-2): 58.3874 | Time: 34.96s
2025-07-18 08:42:50,997 - logger.py:50 - Epoch: [74][0/6]	Total Loss: 1.09385	Main MSE (x10^-2): 109.3854	LR: 3.79e-04	EMPP_Raw: 1.49223
2025-07-18 08:43:04,967 - logger.py:50 - Epoch: [74][5/6]	Total Loss: 1.12268	Main MSE (x10^-2): 112.2683	LR: 3.79e-04	EMPP_Raw: 1.50457
2025-07-18 08:43:05,019 - logger.py:50 - Epoch 74 Training Summary: Avg Total Loss: 1.12268, Avg Main MSE: 1.12268, Time: 17.02s
2025-07-18 08:43:22,976 - logger.py:50 - Epoch 74 Summary | Train MSE (x10^-2): 112.2683 | Val MSE (x10^-2): 57.1661 | Time: 34.99s
2025-07-18 08:43:25,994 - logger.py:50 - Epoch: [75][0/6]	Total Loss: 1.09868	Main MSE (x10^-2): 109.8682	LR: 3.79e-04	EMPP_Raw: 1.46338
2025-07-18 08:43:39,825 - logger.py:50 - Epoch: [75][5/6]	Total Loss: 1.09782	Main MSE (x10^-2): 109.7823	LR: 3.79e-04	EMPP_Raw: 1.50213
2025-07-18 08:43:39,865 - logger.py:50 - Epoch 75 Training Summary: Avg Total Loss: 1.09782, Avg Main MSE: 1.09782, Time: 16.88s
2025-07-18 08:43:57,965 - logger.py:50 - Epoch 75 Summary | Train MSE (x10^-2): 109.7823 | Val MSE (x10^-2): 56.1533 | Time: 34.98s
2025-07-18 08:44:01,022 - logger.py:50 - Epoch: [76][0/6]	Total Loss: 1.06581	Main MSE (x10^-2): 106.5812	LR: 3.78e-04	EMPP_Raw: 1.49717
2025-07-18 08:44:14,796 - logger.py:50 - Epoch: [76][5/6]	Total Loss: 1.07683	Main MSE (x10^-2): 107.6831	LR: 3.78e-04	EMPP_Raw: 1.48887
2025-07-18 08:44:14,841 - logger.py:50 - Epoch 76 Training Summary: Avg Total Loss: 1.07683, Avg Main MSE: 1.07683, Time: 16.87s
2025-07-18 08:44:33,046 - logger.py:50 - Epoch 76 Summary | Train MSE (x10^-2): 107.6831 | Val MSE (x10^-2): 59.6013 | Time: 35.07s
2025-07-18 08:44:36,073 - logger.py:50 - Epoch: [77][0/6]	Total Loss: 1.08296	Main MSE (x10^-2): 108.2956	LR: 3.78e-04	EMPP_Raw: 1.52911
2025-07-18 08:44:49,877 - logger.py:50 - Epoch: [77][5/6]	Total Loss: 1.08861	Main MSE (x10^-2): 108.8613	LR: 3.78e-04	EMPP_Raw: 1.50939
2025-07-18 08:44:49,919 - logger.py:50 - Epoch 77 Training Summary: Avg Total Loss: 1.08861, Avg Main MSE: 1.08861, Time: 16.86s
2025-07-18 08:45:07,940 - logger.py:50 - Epoch 77 Summary | Train MSE (x10^-2): 108.8613 | Val MSE (x10^-2): 57.4561 | Time: 34.89s
2025-07-18 08:45:11,283 - logger.py:50 - Epoch: [78][0/6]	Total Loss: 1.00995	Main MSE (x10^-2): 100.9948	LR: 3.77e-04	EMPP_Raw: 1.45005
2025-07-18 08:45:25,006 - logger.py:50 - Epoch: [78][5/6]	Total Loss: 1.04547	Main MSE (x10^-2): 104.5471	LR: 3.77e-04	EMPP_Raw: 1.47564
2025-07-18 08:45:25,058 - logger.py:50 - Epoch 78 Training Summary: Avg Total Loss: 1.04547, Avg Main MSE: 1.04547, Time: 17.11s
2025-07-18 08:45:43,074 - logger.py:50 - Epoch 78 Summary | Train MSE (x10^-2): 104.5471 | Val MSE (x10^-2): 59.5556 | Time: 35.13s
2025-07-18 08:45:46,232 - logger.py:50 - Epoch: [79][0/6]	Total Loss: 1.02475	Main MSE (x10^-2): 102.4748	LR: 3.77e-04	EMPP_Raw: 1.48770
2025-07-18 08:45:59,928 - logger.py:50 - Epoch: [79][5/6]	Total Loss: 1.05445	Main MSE (x10^-2): 105.4453	LR: 3.77e-04	EMPP_Raw: 1.49198
2025-07-18 08:45:59,976 - logger.py:50 - Epoch 79 Training Summary: Avg Total Loss: 1.05445, Avg Main MSE: 1.05445, Time: 16.89s
2025-07-18 08:46:17,902 - logger.py:50 - Epoch 79 Summary | Train MSE (x10^-2): 105.4453 | Val MSE (x10^-2): 61.8732 | Time: 34.82s
2025-07-18 08:46:20,911 - logger.py:50 - Epoch: [80][0/6]	Total Loss: 1.03419	Main MSE (x10^-2): 103.4186	LR: 3.76e-04	EMPP_Raw: 1.49988
2025-07-18 08:46:34,859 - logger.py:50 - Epoch: [80][5/6]	Total Loss: 1.04582	Main MSE (x10^-2): 104.5823	LR: 3.76e-04	EMPP_Raw: 1.52226
2025-07-18 08:46:34,900 - logger.py:50 - Epoch 80 Training Summary: Avg Total Loss: 1.04582, Avg Main MSE: 1.04582, Time: 16.99s
2025-07-18 08:46:52,794 - logger.py:50 - Epoch 80 Summary | Train MSE (x10^-2): 104.5823 | Val MSE (x10^-2): 61.3738 | Time: 34.89s
2025-07-18 08:46:55,797 - logger.py:50 - Epoch: [81][0/6]	Total Loss: 1.01038	Main MSE (x10^-2): 101.0377	LR: 3.75e-04	EMPP_Raw: 1.53269
2025-07-18 08:47:09,594 - logger.py:50 - Epoch: [81][5/6]	Total Loss: 1.01463	Main MSE (x10^-2): 101.4628	LR: 3.75e-04	EMPP_Raw: 1.48618
2025-07-18 08:47:09,640 - logger.py:50 - Epoch 81 Training Summary: Avg Total Loss: 1.01463, Avg Main MSE: 1.01463, Time: 16.84s
2025-07-18 08:47:27,655 - logger.py:50 - Epoch 81 Summary | Train MSE (x10^-2): 101.4628 | Val MSE (x10^-2): 62.1568 | Time: 34.85s
2025-07-18 08:47:30,672 - logger.py:50 - Epoch: [82][0/6]	Total Loss: 1.01129	Main MSE (x10^-2): 101.1292	LR: 3.75e-04	EMPP_Raw: 1.46308
2025-07-18 08:47:44,461 - logger.py:50 - Epoch: [82][5/6]	Total Loss: 1.00008	Main MSE (x10^-2): 100.0076	LR: 3.75e-04	EMPP_Raw: 1.47978
2025-07-18 08:47:44,504 - logger.py:50 - Epoch 82 Training Summary: Avg Total Loss: 1.00008, Avg Main MSE: 1.00008, Time: 16.84s
2025-07-18 08:48:02,569 - logger.py:50 - Epoch 82 Summary | Train MSE (x10^-2): 100.0076 | Val MSE (x10^-2): 62.4841 | Time: 34.91s
2025-07-18 08:48:05,571 - logger.py:50 - Epoch: [83][0/6]	Total Loss: 1.01445	Main MSE (x10^-2): 101.4453	LR: 3.74e-04	EMPP_Raw: 1.56245
2025-07-18 08:48:19,363 - logger.py:50 - Epoch: [83][5/6]	Total Loss: 1.00113	Main MSE (x10^-2): 100.1134	LR: 3.74e-04	EMPP_Raw: 1.51453
2025-07-18 08:48:19,414 - logger.py:50 - Epoch 83 Training Summary: Avg Total Loss: 1.00113, Avg Main MSE: 1.00113, Time: 16.84s
2025-07-18 08:48:37,305 - logger.py:50 - Epoch 83 Summary | Train MSE (x10^-2): 100.1134 | Val MSE (x10^-2): 63.6415 | Time: 34.73s
2025-07-18 08:48:40,477 - logger.py:50 - Epoch: [84][0/6]	Total Loss: 0.98340	Main MSE (x10^-2): 98.3396	LR: 3.73e-04	EMPP_Raw: 1.47856
2025-07-18 08:48:54,215 - logger.py:50 - Epoch: [84][5/6]	Total Loss: 0.98046	Main MSE (x10^-2): 98.0464	LR: 3.73e-04	EMPP_Raw: 1.48695
2025-07-18 08:48:54,262 - logger.py:50 - Epoch 84 Training Summary: Avg Total Loss: 0.98046, Avg Main MSE: 0.98046, Time: 16.95s
2025-07-18 08:49:12,138 - logger.py:50 - Epoch 84 Summary | Train MSE (x10^-2): 98.0464 | Val MSE (x10^-2): 66.2028 | Time: 34.83s
2025-07-18 08:49:15,148 - logger.py:50 - Epoch: [85][0/6]	Total Loss: 0.98307	Main MSE (x10^-2): 98.3072	LR: 3.73e-04	EMPP_Raw: 1.52414
2025-07-18 08:49:29,055 - logger.py:50 - Epoch: [85][5/6]	Total Loss: 0.96922	Main MSE (x10^-2): 96.9215	LR: 3.73e-04	EMPP_Raw: 1.49471
2025-07-18 08:49:29,100 - logger.py:50 - Epoch 85 Training Summary: Avg Total Loss: 0.96922, Avg Main MSE: 0.96922, Time: 16.95s
2025-07-18 08:49:47,027 - logger.py:50 - Epoch 85 Summary | Train MSE (x10^-2): 96.9215 | Val MSE (x10^-2): 64.0295 | Time: 34.88s
2025-07-18 08:49:50,072 - logger.py:50 - Epoch: [86][0/6]	Total Loss: 0.97439	Main MSE (x10^-2): 97.4391	LR: 3.72e-04	EMPP_Raw: 1.52142
2025-07-18 08:50:03,991 - logger.py:50 - Epoch: [86][5/6]	Total Loss: 0.97336	Main MSE (x10^-2): 97.3355	LR: 3.72e-04	EMPP_Raw: 1.50391
2025-07-18 08:50:04,037 - logger.py:50 - Epoch 86 Training Summary: Avg Total Loss: 0.97336, Avg Main MSE: 0.97336, Time: 17.00s
2025-07-18 08:50:21,997 - logger.py:50 - Epoch 86 Summary | Train MSE (x10^-2): 97.3355 | Val MSE (x10^-2): 67.1947 | Time: 34.96s
2025-07-18 08:50:25,043 - logger.py:50 - Epoch: [87][0/6]	Total Loss: 0.99881	Main MSE (x10^-2): 99.8807	LR: 3.72e-04	EMPP_Raw: 1.58777
2025-07-18 08:50:38,857 - logger.py:50 - Epoch: [87][5/6]	Total Loss: 0.96608	Main MSE (x10^-2): 96.6083	LR: 3.72e-04	EMPP_Raw: 1.51039
2025-07-18 08:50:38,897 - logger.py:50 - Epoch 87 Training Summary: Avg Total Loss: 0.96608, Avg Main MSE: 0.96608, Time: 16.89s
2025-07-18 08:50:56,777 - logger.py:50 - Epoch 87 Summary | Train MSE (x10^-2): 96.6083 | Val MSE (x10^-2): 66.3243 | Time: 34.77s
2025-07-18 08:50:59,929 - logger.py:50 - Epoch: [88][0/6]	Total Loss: 0.93058	Main MSE (x10^-2): 93.0577	LR: 3.71e-04	EMPP_Raw: 1.48040
2025-07-18 08:51:13,660 - logger.py:50 - Epoch: [88][5/6]	Total Loss: 0.93608	Main MSE (x10^-2): 93.6082	LR: 3.71e-04	EMPP_Raw: 1.48046
2025-07-18 08:51:13,715 - logger.py:50 - Epoch 88 Training Summary: Avg Total Loss: 0.93608, Avg Main MSE: 0.93608, Time: 16.93s
2025-07-18 08:51:31,736 - logger.py:50 - Epoch 88 Summary | Train MSE (x10^-2): 93.6082 | Val MSE (x10^-2): 66.2719 | Time: 34.95s
2025-07-18 08:51:34,912 - logger.py:50 - Epoch: [89][0/6]	Total Loss: 0.91396	Main MSE (x10^-2): 91.3964	LR: 3.70e-04	EMPP_Raw: 1.50356
2025-07-18 08:51:48,675 - logger.py:50 - Epoch: [89][5/6]	Total Loss: 0.93514	Main MSE (x10^-2): 93.5145	LR: 3.70e-04	EMPP_Raw: 1.51059
2025-07-18 08:51:48,714 - logger.py:50 - Epoch 89 Training Summary: Avg Total Loss: 0.93514, Avg Main MSE: 0.93514, Time: 16.97s
2025-07-18 08:52:06,755 - logger.py:50 - Epoch 89 Summary | Train MSE (x10^-2): 93.5145 | Val MSE (x10^-2): 68.4491 | Time: 35.01s
2025-07-18 08:52:09,761 - logger.py:50 - Epoch: [90][0/6]	Total Loss: 0.93114	Main MSE (x10^-2): 93.1144	LR: 3.70e-04	EMPP_Raw: 1.49627
2025-07-18 08:52:23,676 - logger.py:50 - Epoch: [90][5/6]	Total Loss: 0.93039	Main MSE (x10^-2): 93.0391	LR: 3.70e-04	EMPP_Raw: 1.50816
2025-07-18 08:52:23,718 - logger.py:50 - Epoch 90 Training Summary: Avg Total Loss: 0.93039, Avg Main MSE: 0.93039, Time: 16.95s
2025-07-18 08:52:41,576 - logger.py:50 - Epoch 90 Summary | Train MSE (x10^-2): 93.0391 | Val MSE (x10^-2): 69.3404 | Time: 34.82s
2025-07-18 08:52:44,574 - logger.py:50 - Epoch: [91][0/6]	Total Loss: 0.90595	Main MSE (x10^-2): 90.5954	LR: 3.69e-04	EMPP_Raw: 1.49018
2025-07-18 08:52:58,345 - logger.py:50 - Epoch: [91][5/6]	Total Loss: 0.91968	Main MSE (x10^-2): 91.9677	LR: 3.69e-04	EMPP_Raw: 1.50525
2025-07-18 08:52:58,389 - logger.py:50 - Epoch 91 Training Summary: Avg Total Loss: 0.91968, Avg Main MSE: 0.91968, Time: 16.80s
2025-07-18 08:53:16,576 - logger.py:50 - Epoch 91 Summary | Train MSE (x10^-2): 91.9677 | Val MSE (x10^-2): 66.9889 | Time: 34.99s
2025-07-18 08:53:19,593 - logger.py:50 - Epoch: [92][0/6]	Total Loss: 0.90815	Main MSE (x10^-2): 90.8150	LR: 3.68e-04	EMPP_Raw: 1.46716
2025-07-18 08:53:33,407 - logger.py:50 - Epoch: [92][5/6]	Total Loss: 0.90902	Main MSE (x10^-2): 90.9021	LR: 3.68e-04	EMPP_Raw: 1.49984
2025-07-18 08:53:33,447 - logger.py:50 - Epoch 92 Training Summary: Avg Total Loss: 0.90902, Avg Main MSE: 0.90902, Time: 16.86s
2025-07-18 08:53:51,412 - logger.py:50 - Epoch 92 Summary | Train MSE (x10^-2): 90.9021 | Val MSE (x10^-2): 72.0703 | Time: 34.83s
2025-07-18 08:53:54,596 - logger.py:50 - Epoch: [93][0/6]	Total Loss: 0.91714	Main MSE (x10^-2): 91.7142	LR: 3.68e-04	EMPP_Raw: 1.52648
2025-07-18 08:54:08,444 - logger.py:50 - Epoch: [93][5/6]	Total Loss: 0.91466	Main MSE (x10^-2): 91.4658	LR: 3.68e-04	EMPP_Raw: 1.52238
2025-07-18 08:54:08,488 - logger.py:50 - Epoch 93 Training Summary: Avg Total Loss: 0.91466, Avg Main MSE: 0.91466, Time: 17.07s
2025-07-18 08:54:26,542 - logger.py:50 - Epoch 93 Summary | Train MSE (x10^-2): 91.4658 | Val MSE (x10^-2): 72.8516 | Time: 35.12s
2025-07-18 08:54:29,642 - logger.py:50 - Epoch: [94][0/6]	Total Loss: 0.90692	Main MSE (x10^-2): 90.6919	LR: 3.67e-04	EMPP_Raw: 1.49380
2025-07-18 08:54:43,610 - logger.py:50 - Epoch: [94][5/6]	Total Loss: 0.91000	Main MSE (x10^-2): 90.9996	LR: 3.67e-04	EMPP_Raw: 1.51130
2025-07-18 08:54:43,657 - logger.py:50 - Epoch 94 Training Summary: Avg Total Loss: 0.91000, Avg Main MSE: 0.91000, Time: 17.10s
2025-07-18 08:55:01,550 - logger.py:50 - Epoch 94 Summary | Train MSE (x10^-2): 90.9996 | Val MSE (x10^-2): 71.6574 | Time: 35.00s
2025-07-18 08:55:04,600 - logger.py:50 - Epoch: [95][0/6]	Total Loss: 0.88457	Main MSE (x10^-2): 88.4566	LR: 3.66e-04	EMPP_Raw: 1.47679
2025-07-18 08:55:18,399 - logger.py:50 - Epoch: [95][5/6]	Total Loss: 0.89084	Main MSE (x10^-2): 89.0835	LR: 3.66e-04	EMPP_Raw: 1.50143
2025-07-18 08:55:18,443 - logger.py:50 - Epoch 95 Training Summary: Avg Total Loss: 0.89084, Avg Main MSE: 0.89084, Time: 16.88s
2025-07-18 08:55:36,467 - logger.py:50 - Epoch 95 Summary | Train MSE (x10^-2): 89.0835 | Val MSE (x10^-2): 75.0643 | Time: 34.91s
2025-07-18 08:55:39,552 - logger.py:50 - Epoch: [96][0/6]	Total Loss: 0.93260	Main MSE (x10^-2): 93.2596	LR: 3.66e-04	EMPP_Raw: 1.52572
2025-07-18 08:55:53,288 - logger.py:50 - Epoch: [96][5/6]	Total Loss: 0.91116	Main MSE (x10^-2): 91.1161	LR: 3.66e-04	EMPP_Raw: 1.51827
2025-07-18 08:55:53,335 - logger.py:50 - Epoch 96 Training Summary: Avg Total Loss: 0.91116, Avg Main MSE: 0.91116, Time: 16.86s
2025-07-18 08:56:11,404 - logger.py:50 - Epoch 96 Summary | Train MSE (x10^-2): 91.1161 | Val MSE (x10^-2): 74.0429 | Time: 34.93s
2025-07-18 08:56:14,412 - logger.py:50 - Epoch: [97][0/6]	Total Loss: 0.86778	Main MSE (x10^-2): 86.7775	LR: 3.65e-04	EMPP_Raw: 1.45726
2025-07-18 08:56:28,231 - logger.py:50 - Epoch: [97][5/6]	Total Loss: 0.88276	Main MSE (x10^-2): 88.2759	LR: 3.65e-04	EMPP_Raw: 1.49466
2025-07-18 08:56:28,272 - logger.py:50 - Epoch 97 Training Summary: Avg Total Loss: 0.88276, Avg Main MSE: 0.88276, Time: 16.86s
2025-07-18 08:56:46,289 - logger.py:50 - Epoch 97 Summary | Train MSE (x10^-2): 88.2759 | Val MSE (x10^-2): 69.7461 | Time: 34.88s
2025-07-18 08:56:49,716 - logger.py:50 - Epoch: [98][0/6]	Total Loss: 0.86611	Main MSE (x10^-2): 86.6112	LR: 3.64e-04	EMPP_Raw: 1.50189
2025-07-18 08:57:03,529 - logger.py:50 - Epoch: [98][5/6]	Total Loss: 0.87239	Main MSE (x10^-2): 87.2389	LR: 3.64e-04	EMPP_Raw: 1.47824
2025-07-18 08:57:03,581 - logger.py:50 - Epoch 98 Training Summary: Avg Total Loss: 0.87239, Avg Main MSE: 0.87239, Time: 17.28s
2025-07-18 08:57:21,388 - logger.py:50 - Epoch 98 Summary | Train MSE (x10^-2): 87.2389 | Val MSE (x10^-2): 71.9081 | Time: 35.09s
2025-07-18 08:57:24,559 - logger.py:50 - Epoch: [99][0/6]	Total Loss: 0.88914	Main MSE (x10^-2): 88.9140	LR: 3.63e-04	EMPP_Raw: 1.53643
2025-07-18 08:57:38,303 - logger.py:50 - Epoch: [99][5/6]	Total Loss: 0.89240	Main MSE (x10^-2): 89.2405	LR: 3.63e-04	EMPP_Raw: 1.51147
2025-07-18 08:57:38,348 - logger.py:50 - Epoch 99 Training Summary: Avg Total Loss: 0.89240, Avg Main MSE: 0.89240, Time: 16.95s
2025-07-18 08:57:56,223 - logger.py:50 - Epoch 99 Summary | Train MSE (x10^-2): 89.2405 | Val MSE (x10^-2): 71.1804 | Time: 34.83s
2025-07-18 08:57:59,250 - logger.py:50 - Epoch: [100][0/6]	Total Loss: 0.86662	Main MSE (x10^-2): 86.6622	LR: 3.63e-04	EMPP_Raw: 1.50704
2025-07-18 08:58:13,163 - logger.py:50 - Epoch: [100][5/6]	Total Loss: 0.87098	Main MSE (x10^-2): 87.0985	LR: 3.63e-04	EMPP_Raw: 1.48135
2025-07-18 08:58:13,218 - logger.py:50 - Epoch 100 Training Summary: Avg Total Loss: 0.87098, Avg Main MSE: 0.87098, Time: 16.99s
2025-07-18 08:58:31,127 - logger.py:50 - Epoch 100 Summary | Train MSE (x10^-2): 87.0985 | Val MSE (x10^-2): 69.2805 | Time: 34.90s
2025-07-18 08:58:34,130 - logger.py:50 - Epoch: [101][0/6]	Total Loss: 0.87022	Main MSE (x10^-2): 87.0217	LR: 3.62e-04	EMPP_Raw: 1.48781
2025-07-18 08:58:47,905 - logger.py:50 - Epoch: [101][5/6]	Total Loss: 0.86973	Main MSE (x10^-2): 86.9728	LR: 3.62e-04	EMPP_Raw: 1.49986
2025-07-18 08:58:47,959 - logger.py:50 - Epoch 101 Training Summary: Avg Total Loss: 0.86973, Avg Main MSE: 0.86973, Time: 16.82s
2025-07-18 08:59:05,942 - logger.py:50 - Epoch 101 Summary | Train MSE (x10^-2): 86.9728 | Val MSE (x10^-2): 73.3948 | Time: 34.81s
2025-07-18 08:59:08,992 - logger.py:50 - Epoch: [102][0/6]	Total Loss: 0.87612	Main MSE (x10^-2): 87.6125	LR: 3.61e-04	EMPP_Raw: 1.52982
2025-07-18 08:59:22,831 - logger.py:50 - Epoch: [102][5/6]	Total Loss: 0.86421	Main MSE (x10^-2): 86.4211	LR: 3.61e-04	EMPP_Raw: 1.50866
2025-07-18 08:59:22,875 - logger.py:50 - Epoch 102 Training Summary: Avg Total Loss: 0.86421, Avg Main MSE: 0.86421, Time: 16.92s
2025-07-18 08:59:40,947 - logger.py:50 - Epoch 102 Summary | Train MSE (x10^-2): 86.4211 | Val MSE (x10^-2): 71.7391 | Time: 35.00s
2025-07-18 08:59:43,962 - logger.py:50 - Epoch: [103][0/6]	Total Loss: 0.85208	Main MSE (x10^-2): 85.2082	LR: 3.60e-04	EMPP_Raw: 1.50145
2025-07-18 08:59:57,738 - logger.py:50 - Epoch: [103][5/6]	Total Loss: 0.85206	Main MSE (x10^-2): 85.2065	LR: 3.60e-04	EMPP_Raw: 1.48532
2025-07-18 08:59:57,780 - logger.py:50 - Epoch 103 Training Summary: Avg Total Loss: 0.85206, Avg Main MSE: 0.85206, Time: 16.82s
2025-07-18 09:00:15,689 - logger.py:50 - Epoch 103 Summary | Train MSE (x10^-2): 85.2065 | Val MSE (x10^-2): 73.1308 | Time: 34.74s
2025-07-18 09:00:18,844 - logger.py:50 - Epoch: [104][0/6]	Total Loss: 0.83201	Main MSE (x10^-2): 83.2012	LR: 3.60e-04	EMPP_Raw: 1.48700
2025-07-18 09:00:32,590 - logger.py:50 - Epoch: [104][5/6]	Total Loss: 0.84674	Main MSE (x10^-2): 84.6739	LR: 3.60e-04	EMPP_Raw: 1.48886
2025-07-18 09:00:32,631 - logger.py:50 - Epoch 104 Training Summary: Avg Total Loss: 0.84674, Avg Main MSE: 0.84674, Time: 16.93s
2025-07-18 09:00:50,740 - logger.py:50 - Epoch 104 Summary | Train MSE (x10^-2): 84.6739 | Val MSE (x10^-2): 69.9080 | Time: 35.04s
2025-07-18 09:00:53,789 - logger.py:50 - Epoch: [105][0/6]	Total Loss: 0.87201	Main MSE (x10^-2): 87.2008	LR: 3.59e-04	EMPP_Raw: 1.54657
2025-07-18 09:01:07,778 - logger.py:50 - Epoch: [105][5/6]	Total Loss: 0.86143	Main MSE (x10^-2): 86.1427	LR: 3.59e-04	EMPP_Raw: 1.51696
2025-07-18 09:01:07,823 - logger.py:50 - Epoch 105 Training Summary: Avg Total Loss: 0.86143, Avg Main MSE: 0.86143, Time: 17.07s
2025-07-18 09:01:25,790 - logger.py:50 - Epoch 105 Summary | Train MSE (x10^-2): 86.1427 | Val MSE (x10^-2): 73.3176 | Time: 35.04s
2025-07-18 09:01:28,828 - logger.py:50 - Epoch: [106][0/6]	Total Loss: 0.83544	Main MSE (x10^-2): 83.5439	LR: 3.58e-04	EMPP_Raw: 1.46880
2025-07-18 09:01:42,727 - logger.py:50 - Epoch: [106][5/6]	Total Loss: 0.83673	Main MSE (x10^-2): 83.6734	LR: 3.58e-04	EMPP_Raw: 1.48013
2025-07-18 09:01:42,777 - logger.py:50 - Epoch 106 Training Summary: Avg Total Loss: 0.83673, Avg Main MSE: 0.83673, Time: 16.98s
2025-07-18 09:02:00,703 - logger.py:50 - Epoch 106 Summary | Train MSE (x10^-2): 83.6734 | Val MSE (x10^-2): 76.5341 | Time: 34.91s
2025-07-18 09:02:03,755 - logger.py:50 - Epoch: [107][0/6]	Total Loss: 0.84401	Main MSE (x10^-2): 84.4008	LR: 3.57e-04	EMPP_Raw: 1.50681
2025-07-18 09:02:17,643 - logger.py:50 - Epoch: [107][5/6]	Total Loss: 0.84356	Main MSE (x10^-2): 84.3560	LR: 3.57e-04	EMPP_Raw: 1.50126
2025-07-18 09:02:17,683 - logger.py:50 - Epoch 107 Training Summary: Avg Total Loss: 0.84356, Avg Main MSE: 0.84356, Time: 16.97s
2025-07-18 09:02:35,572 - logger.py:50 - Epoch 107 Summary | Train MSE (x10^-2): 84.3560 | Val MSE (x10^-2): 77.6777 | Time: 34.86s
2025-07-18 09:02:38,727 - logger.py:50 - Epoch: [108][0/6]	Total Loss: 0.82643	Main MSE (x10^-2): 82.6429	LR: 3.57e-04	EMPP_Raw: 1.46645
2025-07-18 09:02:52,431 - logger.py:50 - Epoch: [108][5/6]	Total Loss: 0.84064	Main MSE (x10^-2): 84.0639	LR: 3.57e-04	EMPP_Raw: 1.49118
2025-07-18 09:02:52,477 - logger.py:50 - Epoch 108 Training Summary: Avg Total Loss: 0.84064, Avg Main MSE: 0.84064, Time: 16.90s
2025-07-18 09:03:10,353 - logger.py:50 - Epoch 108 Summary | Train MSE (x10^-2): 84.0639 | Val MSE (x10^-2): 76.2803 | Time: 34.78s
2025-07-18 09:03:13,533 - logger.py:50 - Epoch: [109][0/6]	Total Loss: 0.83428	Main MSE (x10^-2): 83.4283	LR: 3.56e-04	EMPP_Raw: 1.50267
2025-07-18 09:03:27,270 - logger.py:50 - Epoch: [109][5/6]	Total Loss: 0.84486	Main MSE (x10^-2): 84.4859	LR: 3.56e-04	EMPP_Raw: 1.50591
2025-07-18 09:03:27,310 - logger.py:50 - Epoch 109 Training Summary: Avg Total Loss: 0.84486, Avg Main MSE: 0.84486, Time: 16.95s
2025-07-18 09:03:45,357 - logger.py:50 - Epoch 109 Summary | Train MSE (x10^-2): 84.4859 | Val MSE (x10^-2): 73.6319 | Time: 35.00s
2025-07-18 09:03:48,421 - logger.py:50 - Epoch: [110][0/6]	Total Loss: 0.83025	Main MSE (x10^-2): 83.0246	LR: 3.55e-04	EMPP_Raw: 1.48148
2025-07-18 09:04:02,347 - logger.py:50 - Epoch: [110][5/6]	Total Loss: 0.82794	Main MSE (x10^-2): 82.7944	LR: 3.55e-04	EMPP_Raw: 1.47645
2025-07-18 09:04:02,388 - logger.py:50 - Epoch 110 Training Summary: Avg Total Loss: 0.82794, Avg Main MSE: 0.82794, Time: 17.02s
2025-07-18 09:04:20,264 - logger.py:50 - Epoch 110 Summary | Train MSE (x10^-2): 82.7944 | Val MSE (x10^-2): 74.8707 | Time: 34.90s
2025-07-18 09:04:23,269 - logger.py:50 - Epoch: [111][0/6]	Total Loss: 0.85976	Main MSE (x10^-2): 85.9756	LR: 3.54e-04	EMPP_Raw: 1.52672
2025-07-18 09:04:37,051 - logger.py:50 - Epoch: [111][5/6]	Total Loss: 0.84274	Main MSE (x10^-2): 84.2738	LR: 3.54e-04	EMPP_Raw: 1.50500
2025-07-18 09:04:37,092 - logger.py:50 - Epoch 111 Training Summary: Avg Total Loss: 0.84274, Avg Main MSE: 0.84274, Time: 16.82s
2025-07-18 09:04:55,138 - logger.py:50 - Epoch 111 Summary | Train MSE (x10^-2): 84.2738 | Val MSE (x10^-2): 76.3916 | Time: 34.87s
2025-07-18 09:04:58,148 - logger.py:50 - Epoch: [112][0/6]	Total Loss: 0.82595	Main MSE (x10^-2): 82.5952	LR: 3.53e-04	EMPP_Raw: 1.46249
2025-07-18 09:05:11,950 - logger.py:50 - Epoch: [112][5/6]	Total Loss: 0.81670	Main MSE (x10^-2): 81.6702	LR: 3.53e-04	EMPP_Raw: 1.45873
2025-07-18 09:05:11,994 - logger.py:50 - Epoch 112 Training Summary: Avg Total Loss: 0.81670, Avg Main MSE: 0.81670, Time: 16.85s
2025-07-18 09:05:29,978 - logger.py:50 - Epoch 112 Summary | Train MSE (x10^-2): 81.6702 | Val MSE (x10^-2): 74.0373 | Time: 34.83s
2025-07-18 09:05:33,179 - logger.py:50 - Epoch: [113][0/6]	Total Loss: 0.84331	Main MSE (x10^-2): 84.3315	LR: 3.53e-04	EMPP_Raw: 1.50763
2025-07-18 09:05:46,995 - logger.py:50 - Epoch: [113][5/6]	Total Loss: 0.83329	Main MSE (x10^-2): 83.3294	LR: 3.53e-04	EMPP_Raw: 1.49594
2025-07-18 09:05:47,039 - logger.py:50 - Epoch 113 Training Summary: Avg Total Loss: 0.83329, Avg Main MSE: 0.83329, Time: 17.05s
2025-07-18 09:06:04,959 - logger.py:50 - Epoch 113 Summary | Train MSE (x10^-2): 83.3294 | Val MSE (x10^-2): 76.4869 | Time: 34.98s
2025-07-18 09:06:07,960 - logger.py:50 - Epoch: [114][0/6]	Total Loss: 0.83550	Main MSE (x10^-2): 83.5504	LR: 3.52e-04	EMPP_Raw: 1.49312
2025-07-18 09:06:21,859 - logger.py:50 - Epoch: [114][5/6]	Total Loss: 0.82820	Main MSE (x10^-2): 82.8202	LR: 3.52e-04	EMPP_Raw: 1.49794
2025-07-18 09:06:21,923 - logger.py:50 - Epoch 114 Training Summary: Avg Total Loss: 0.82820, Avg Main MSE: 0.82820, Time: 16.95s
2025-07-18 09:06:39,735 - logger.py:50 - Epoch 114 Summary | Train MSE (x10^-2): 82.8202 | Val MSE (x10^-2): 73.9965 | Time: 34.77s
2025-07-18 09:06:42,755 - logger.py:50 - Epoch: [115][0/6]	Total Loss: 0.82598	Main MSE (x10^-2): 82.5975	LR: 3.51e-04	EMPP_Raw: 1.50585
2025-07-18 09:06:56,627 - logger.py:50 - Epoch: [115][5/6]	Total Loss: 0.82023	Main MSE (x10^-2): 82.0230	LR: 3.51e-04	EMPP_Raw: 1.49139
2025-07-18 09:06:56,673 - logger.py:50 - Epoch 115 Training Summary: Avg Total Loss: 0.82023, Avg Main MSE: 0.82023, Time: 16.93s
2025-07-18 09:07:14,769 - logger.py:50 - Epoch 115 Summary | Train MSE (x10^-2): 82.0230 | Val MSE (x10^-2): 74.8546 | Time: 35.02s
2025-07-18 09:07:17,824 - logger.py:50 - Epoch: [116][0/6]	Total Loss: 0.81843	Main MSE (x10^-2): 81.8429	LR: 3.50e-04	EMPP_Raw: 1.46356
2025-07-18 09:07:31,643 - logger.py:50 - Epoch: [116][5/6]	Total Loss: 0.82919	Main MSE (x10^-2): 82.9185	LR: 3.50e-04	EMPP_Raw: 1.50007
2025-07-18 09:07:31,693 - logger.py:50 - Epoch 116 Training Summary: Avg Total Loss: 0.82919, Avg Main MSE: 0.82919, Time: 16.92s
2025-07-18 09:07:49,779 - logger.py:50 - Epoch 116 Summary | Train MSE (x10^-2): 82.9185 | Val MSE (x10^-2): 72.2515 | Time: 35.00s
2025-07-18 09:07:52,788 - logger.py:50 - Epoch: [117][0/6]	Total Loss: 0.83297	Main MSE (x10^-2): 83.2970	LR: 3.49e-04	EMPP_Raw: 1.51939
2025-07-18 09:08:06,621 - logger.py:50 - Epoch: [117][5/6]	Total Loss: 0.81794	Main MSE (x10^-2): 81.7940	LR: 3.49e-04	EMPP_Raw: 1.48440
2025-07-18 09:08:06,662 - logger.py:50 - Epoch 117 Training Summary: Avg Total Loss: 0.81794, Avg Main MSE: 0.81794, Time: 16.87s
2025-07-18 09:08:24,676 - logger.py:50 - Epoch 117 Summary | Train MSE (x10^-2): 81.7940 | Val MSE (x10^-2): 75.1317 | Time: 34.89s
2025-07-18 09:08:28,045 - logger.py:50 - Epoch: [118][0/6]	Total Loss: 0.81305	Main MSE (x10^-2): 81.3049	LR: 3.48e-04	EMPP_Raw: 1.49632
2025-07-18 09:08:41,828 - logger.py:50 - Epoch: [118][5/6]	Total Loss: 0.81321	Main MSE (x10^-2): 81.3213	LR: 3.48e-04	EMPP_Raw: 1.47881
2025-07-18 09:08:41,895 - logger.py:50 - Epoch 118 Training Summary: Avg Total Loss: 0.81321, Avg Main MSE: 0.81321, Time: 17.21s
2025-07-18 09:08:59,809 - logger.py:50 - Epoch 118 Summary | Train MSE (x10^-2): 81.3213 | Val MSE (x10^-2): 71.0964 | Time: 35.13s
2025-07-18 09:09:02,982 - logger.py:50 - Epoch: [119][0/6]	Total Loss: 0.83362	Main MSE (x10^-2): 83.3622	LR: 3.48e-04	EMPP_Raw: 1.51284
2025-07-18 09:09:16,911 - logger.py:50 - Epoch: [119][5/6]	Total Loss: 0.82028	Main MSE (x10^-2): 82.0282	LR: 3.48e-04	EMPP_Raw: 1.49913
2025-07-18 09:09:16,971 - logger.py:50 - Epoch 119 Training Summary: Avg Total Loss: 0.82028, Avg Main MSE: 0.82028, Time: 17.15s
2025-07-18 09:09:34,996 - logger.py:50 - Epoch 119 Summary | Train MSE (x10^-2): 82.0282 | Val MSE (x10^-2): 74.2542 | Time: 35.18s
2025-07-18 09:09:38,011 - logger.py:50 - Epoch: [120][0/6]	Total Loss: 0.81935	Main MSE (x10^-2): 81.9349	LR: 3.47e-04	EMPP_Raw: 1.52066
2025-07-18 09:09:51,905 - logger.py:50 - Epoch: [120][5/6]	Total Loss: 0.80547	Main MSE (x10^-2): 80.5468	LR: 3.47e-04	EMPP_Raw: 1.47791
2025-07-18 09:09:51,949 - logger.py:50 - Epoch 120 Training Summary: Avg Total Loss: 0.80547, Avg Main MSE: 0.80547, Time: 16.94s
2025-07-18 09:10:09,760 - logger.py:50 - Epoch 120 Summary | Train MSE (x10^-2): 80.5468 | Val MSE (x10^-2): 75.7532 | Time: 34.76s
2025-07-18 09:10:12,806 - logger.py:50 - Epoch: [121][0/6]	Total Loss: 0.81309	Main MSE (x10^-2): 81.3092	LR: 3.46e-04	EMPP_Raw: 1.48748
2025-07-18 09:10:26,566 - logger.py:50 - Epoch: [121][5/6]	Total Loss: 0.80737	Main MSE (x10^-2): 80.7367	LR: 3.46e-04	EMPP_Raw: 1.48626
2025-07-18 09:10:26,612 - logger.py:50 - Epoch 121 Training Summary: Avg Total Loss: 0.80737, Avg Main MSE: 0.80737, Time: 16.84s
2025-07-18 09:10:44,740 - logger.py:50 - Epoch 121 Summary | Train MSE (x10^-2): 80.7367 | Val MSE (x10^-2): 74.9176 | Time: 34.98s
2025-07-18 09:10:47,757 - logger.py:50 - Epoch: [122][0/6]	Total Loss: 0.81216	Main MSE (x10^-2): 81.2156	LR: 3.45e-04	EMPP_Raw: 1.49823
2025-07-18 09:11:01,571 - logger.py:50 - Epoch: [122][5/6]	Total Loss: 0.80955	Main MSE (x10^-2): 80.9552	LR: 3.45e-04	EMPP_Raw: 1.48561
2025-07-18 09:11:01,619 - logger.py:50 - Epoch 122 Training Summary: Avg Total Loss: 0.80955, Avg Main MSE: 0.80955, Time: 16.87s
2025-07-18 09:11:19,586 - logger.py:50 - Epoch 122 Summary | Train MSE (x10^-2): 80.9552 | Val MSE (x10^-2): 75.2911 | Time: 34.84s
2025-07-18 09:11:22,669 - logger.py:50 - Epoch: [123][0/6]	Total Loss: 0.81695	Main MSE (x10^-2): 81.6954	LR: 3.44e-04	EMPP_Raw: 1.49406
2025-07-18 09:11:36,498 - logger.py:50 - Epoch: [123][5/6]	Total Loss: 0.81208	Main MSE (x10^-2): 81.2076	LR: 3.44e-04	EMPP_Raw: 1.49805
2025-07-18 09:11:36,542 - logger.py:50 - Epoch 123 Training Summary: Avg Total Loss: 0.81208, Avg Main MSE: 0.81208, Time: 16.95s
2025-07-18 09:11:54,519 - logger.py:50 - Epoch 123 Summary | Train MSE (x10^-2): 81.2076 | Val MSE (x10^-2): 78.3822 | Time: 34.93s
2025-07-18 09:11:57,699 - logger.py:50 - Epoch: [124][0/6]	Total Loss: 0.81416	Main MSE (x10^-2): 81.4156	LR: 3.43e-04	EMPP_Raw: 1.47115
2025-07-18 09:12:11,454 - logger.py:50 - Epoch: [124][5/6]	Total Loss: 0.80305	Main MSE (x10^-2): 80.3049	LR: 3.43e-04	EMPP_Raw: 1.47706
2025-07-18 09:12:11,503 - logger.py:50 - Epoch 124 Training Summary: Avg Total Loss: 0.80305, Avg Main MSE: 0.80305, Time: 16.97s
2025-07-18 09:12:29,379 - logger.py:50 - Epoch 124 Summary | Train MSE (x10^-2): 80.3049 | Val MSE (x10^-2): 75.0798 | Time: 34.85s
2025-07-18 09:12:32,417 - logger.py:50 - Epoch: [125][0/6]	Total Loss: 0.83390	Main MSE (x10^-2): 83.3898	LR: 3.42e-04	EMPP_Raw: 1.52989
2025-07-18 09:12:46,390 - logger.py:50 - Epoch: [125][5/6]	Total Loss: 0.81120	Main MSE (x10^-2): 81.1203	LR: 3.42e-04	EMPP_Raw: 1.49428
2025-07-18 09:12:46,441 - logger.py:50 - Epoch 125 Training Summary: Avg Total Loss: 0.81120, Avg Main MSE: 0.81120, Time: 17.05s
2025-07-18 09:13:04,496 - logger.py:50 - Epoch 125 Summary | Train MSE (x10^-2): 81.1203 | Val MSE (x10^-2): 74.4420 | Time: 35.11s
2025-07-18 09:13:07,512 - logger.py:50 - Epoch: [126][0/6]	Total Loss: 0.79538	Main MSE (x10^-2): 79.5376	LR: 3.42e-04	EMPP_Raw: 1.46285
2025-07-18 09:13:21,448 - logger.py:50 - Epoch: [126][5/6]	Total Loss: 0.79592	Main MSE (x10^-2): 79.5925	LR: 3.42e-04	EMPP_Raw: 1.46236
2025-07-18 09:13:21,495 - logger.py:50 - Epoch 126 Training Summary: Avg Total Loss: 0.79592, Avg Main MSE: 0.79592, Time: 16.99s
2025-07-18 09:13:39,335 - logger.py:50 - Epoch 126 Summary | Train MSE (x10^-2): 79.5925 | Val MSE (x10^-2): 80.3136 | Time: 34.83s
2025-07-18 09:13:42,385 - logger.py:50 - Epoch: [127][0/6]	Total Loss: 0.81435	Main MSE (x10^-2): 81.4345	LR: 3.41e-04	EMPP_Raw: 1.49232
2025-07-18 09:13:56,233 - logger.py:50 - Epoch: [127][5/6]	Total Loss: 0.79460	Main MSE (x10^-2): 79.4598	LR: 3.41e-04	EMPP_Raw: 1.47045
2025-07-18 09:13:56,279 - logger.py:50 - Epoch 127 Training Summary: Avg Total Loss: 0.79460, Avg Main MSE: 0.79460, Time: 16.93s
2025-07-18 09:14:14,206 - logger.py:50 - Epoch 127 Summary | Train MSE (x10^-2): 79.4598 | Val MSE (x10^-2): 79.6167 | Time: 34.86s
2025-07-18 09:14:17,378 - logger.py:50 - Epoch: [128][0/6]	Total Loss: 0.79398	Main MSE (x10^-2): 79.3977	LR: 3.40e-04	EMPP_Raw: 1.48366
2025-07-18 09:14:31,196 - logger.py:50 - Epoch: [128][5/6]	Total Loss: 0.79945	Main MSE (x10^-2): 79.9446	LR: 3.40e-04	EMPP_Raw: 1.47815
2025-07-18 09:14:31,245 - logger.py:50 - Epoch 128 Training Summary: Avg Total Loss: 0.79945, Avg Main MSE: 0.79945, Time: 17.03s
2025-07-18 09:14:49,257 - logger.py:50 - Epoch 128 Summary | Train MSE (x10^-2): 79.9446 | Val MSE (x10^-2): 79.0765 | Time: 35.05s
2025-07-18 09:14:52,422 - logger.py:50 - Epoch: [129][0/6]	Total Loss: 0.81128	Main MSE (x10^-2): 81.1282	LR: 3.39e-04	EMPP_Raw: 1.51161
2025-07-18 09:15:06,189 - logger.py:50 - Epoch: [129][5/6]	Total Loss: 0.79154	Main MSE (x10^-2): 79.1542	LR: 3.39e-04	EMPP_Raw: 1.47453
2025-07-18 09:15:06,232 - logger.py:50 - Epoch 129 Training Summary: Avg Total Loss: 0.79154, Avg Main MSE: 0.79154, Time: 16.97s
2025-07-18 09:15:24,319 - logger.py:50 - Epoch 129 Summary | Train MSE (x10^-2): 79.1542 | Val MSE (x10^-2): 78.0367 | Time: 35.06s
2025-07-18 09:15:27,320 - logger.py:50 - Epoch: [130][0/6]	Total Loss: 0.78462	Main MSE (x10^-2): 78.4625	LR: 3.38e-04	EMPP_Raw: 1.46404
2025-07-18 09:15:41,350 - logger.py:50 - Epoch: [130][5/6]	Total Loss: 0.79671	Main MSE (x10^-2): 79.6711	LR: 3.38e-04	EMPP_Raw: 1.47809
2025-07-18 09:15:41,395 - logger.py:50 - Epoch 130 Training Summary: Avg Total Loss: 0.79671, Avg Main MSE: 0.79671, Time: 17.07s
2025-07-18 09:15:59,305 - logger.py:50 - Epoch 130 Summary | Train MSE (x10^-2): 79.6711 | Val MSE (x10^-2): 76.8275 | Time: 34.98s
2025-07-18 09:16:02,307 - logger.py:50 - Epoch: [131][0/6]	Total Loss: 0.77003	Main MSE (x10^-2): 77.0026	LR: 3.37e-04	EMPP_Raw: 1.43077
2025-07-18 09:16:16,100 - logger.py:50 - Epoch: [131][5/6]	Total Loss: 0.79420	Main MSE (x10^-2): 79.4197	LR: 3.37e-04	EMPP_Raw: 1.48136
2025-07-18 09:16:16,143 - logger.py:50 - Epoch 131 Training Summary: Avg Total Loss: 0.79420, Avg Main MSE: 0.79420, Time: 16.83s
2025-07-18 09:16:34,166 - logger.py:50 - Epoch 131 Summary | Train MSE (x10^-2): 79.4197 | Val MSE (x10^-2): 75.5154 | Time: 34.86s
2025-07-18 09:16:37,217 - logger.py:50 - Epoch: [132][0/6]	Total Loss: 0.78036	Main MSE (x10^-2): 78.0362	LR: 3.36e-04	EMPP_Raw: 1.44888
2025-07-18 09:16:51,030 - logger.py:50 - Epoch: [132][5/6]	Total Loss: 0.79402	Main MSE (x10^-2): 79.4015	LR: 3.36e-04	EMPP_Raw: 1.47410
2025-07-18 09:16:51,070 - logger.py:50 - Epoch 132 Training Summary: Avg Total Loss: 0.79402, Avg Main MSE: 0.79402, Time: 16.89s
2025-07-18 09:17:09,009 - logger.py:50 - Epoch 132 Summary | Train MSE (x10^-2): 79.4015 | Val MSE (x10^-2): 76.3497 | Time: 34.84s
2025-07-18 09:17:12,213 - logger.py:50 - Epoch: [133][0/6]	Total Loss: 0.79377	Main MSE (x10^-2): 79.3767	LR: 3.35e-04	EMPP_Raw: 1.48398
2025-07-18 09:17:25,972 - logger.py:50 - Epoch: [133][5/6]	Total Loss: 0.80560	Main MSE (x10^-2): 80.5598	LR: 3.35e-04	EMPP_Raw: 1.50130
2025-07-18 09:17:26,016 - logger.py:50 - Epoch 133 Training Summary: Avg Total Loss: 0.80560, Avg Main MSE: 0.80560, Time: 17.00s
2025-07-18 09:17:43,947 - logger.py:50 - Epoch 133 Summary | Train MSE (x10^-2): 80.5598 | Val MSE (x10^-2): 81.5819 | Time: 34.93s
2025-07-18 09:17:46,984 - logger.py:50 - Epoch: [134][0/6]	Total Loss: 0.78425	Main MSE (x10^-2): 78.4249	LR: 3.34e-04	EMPP_Raw: 1.47234
2025-07-18 09:18:00,924 - logger.py:50 - Epoch: [134][5/6]	Total Loss: 0.79810	Main MSE (x10^-2): 79.8095	LR: 3.34e-04	EMPP_Raw: 1.49903
2025-07-18 09:18:00,973 - logger.py:50 - Epoch 134 Training Summary: Avg Total Loss: 0.79810, Avg Main MSE: 0.79810, Time: 17.02s
2025-07-18 09:18:18,909 - logger.py:50 - Epoch 134 Summary | Train MSE (x10^-2): 79.8095 | Val MSE (x10^-2): 81.7919 | Time: 34.96s
2025-07-18 09:18:21,909 - logger.py:50 - Epoch: [135][0/6]	Total Loss: 0.78631	Main MSE (x10^-2): 78.6307	LR: 3.33e-04	EMPP_Raw: 1.47368
2025-07-18 09:18:35,700 - logger.py:50 - Epoch: [135][5/6]	Total Loss: 0.79104	Main MSE (x10^-2): 79.1037	LR: 3.33e-04	EMPP_Raw: 1.47699
2025-07-18 09:18:35,742 - logger.py:50 - Epoch 135 Training Summary: Avg Total Loss: 0.79104, Avg Main MSE: 0.79104, Time: 16.82s
2025-07-18 09:18:53,797 - logger.py:50 - Epoch 135 Summary | Train MSE (x10^-2): 79.1037 | Val MSE (x10^-2): 79.6839 | Time: 34.88s
2025-07-18 09:18:56,801 - logger.py:50 - Epoch: [136][0/6]	Total Loss: 0.79277	Main MSE (x10^-2): 79.2773	LR: 3.32e-04	EMPP_Raw: 1.47813
2025-07-18 09:19:10,593 - logger.py:50 - Epoch: [136][5/6]	Total Loss: 0.80333	Main MSE (x10^-2): 80.3332	LR: 3.32e-04	EMPP_Raw: 1.50822
2025-07-18 09:19:10,634 - logger.py:50 - Epoch 136 Training Summary: Avg Total Loss: 0.80333, Avg Main MSE: 0.80333, Time: 16.83s
2025-07-18 09:19:28,705 - logger.py:50 - Epoch 136 Summary | Train MSE (x10^-2): 80.3332 | Val MSE (x10^-2): 77.0857 | Time: 34.90s
2025-07-18 09:19:31,760 - logger.py:50 - Epoch: [137][0/6]	Total Loss: 0.77546	Main MSE (x10^-2): 77.5458	LR: 3.31e-04	EMPP_Raw: 1.45598
2025-07-18 09:19:45,579 - logger.py:50 - Epoch: [137][5/6]	Total Loss: 0.78506	Main MSE (x10^-2): 78.5060	LR: 3.31e-04	EMPP_Raw: 1.47375
2025-07-18 09:19:45,628 - logger.py:50 - Epoch 137 Training Summary: Avg Total Loss: 0.78506, Avg Main MSE: 0.78506, Time: 16.91s
2025-07-18 09:20:03,601 - logger.py:50 - Epoch 137 Summary | Train MSE (x10^-2): 78.5060 | Val MSE (x10^-2): 77.9146 | Time: 34.89s
2025-07-18 09:20:06,993 - logger.py:50 - Epoch: [138][0/6]	Total Loss: 0.79174	Main MSE (x10^-2): 79.1741	LR: 3.31e-04	EMPP_Raw: 1.48675
2025-07-18 09:20:20,818 - logger.py:50 - Epoch: [138][5/6]	Total Loss: 0.78933	Main MSE (x10^-2): 78.9327	LR: 3.31e-04	EMPP_Raw: 1.47333
2025-07-18 09:20:20,870 - logger.py:50 - Epoch 138 Training Summary: Avg Total Loss: 0.78933, Avg Main MSE: 0.78933, Time: 17.26s
2025-07-18 09:20:38,802 - logger.py:50 - Epoch 138 Summary | Train MSE (x10^-2): 78.9327 | Val MSE (x10^-2): 77.4351 | Time: 35.19s
2025-07-18 09:20:41,988 - logger.py:50 - Epoch: [139][0/6]	Total Loss: 0.80283	Main MSE (x10^-2): 80.2832	LR: 3.30e-04	EMPP_Raw: 1.50338
2025-07-18 09:20:55,739 - logger.py:50 - Epoch: [139][5/6]	Total Loss: 0.80017	Main MSE (x10^-2): 80.0167	LR: 3.30e-04	EMPP_Raw: 1.49427
2025-07-18 09:20:55,787 - logger.py:50 - Epoch 139 Training Summary: Avg Total Loss: 0.80017, Avg Main MSE: 0.80017, Time: 16.98s
2025-07-18 09:21:13,657 - logger.py:50 - Epoch 139 Summary | Train MSE (x10^-2): 80.0167 | Val MSE (x10^-2): 77.3507 | Time: 34.85s
2025-07-18 09:21:16,660 - logger.py:50 - Epoch: [140][0/6]	Total Loss: 0.78202	Main MSE (x10^-2): 78.2023	LR: 3.29e-04	EMPP_Raw: 1.47085
2025-07-18 09:21:30,594 - logger.py:50 - Epoch: [140][5/6]	Total Loss: 0.78384	Main MSE (x10^-2): 78.3836	LR: 3.29e-04	EMPP_Raw: 1.47511
2025-07-18 09:21:30,638 - logger.py:50 - Epoch 140 Training Summary: Avg Total Loss: 0.78384, Avg Main MSE: 0.78384, Time: 16.97s
2025-07-18 09:21:48,552 - logger.py:50 - Epoch 140 Summary | Train MSE (x10^-2): 78.3836 | Val MSE (x10^-2): 76.8198 | Time: 34.89s
2025-07-18 09:21:51,575 - logger.py:50 - Epoch: [141][0/6]	Total Loss: 0.78207	Main MSE (x10^-2): 78.2066	LR: 3.28e-04	EMPP_Raw: 1.48215
2025-07-18 09:22:05,388 - logger.py:50 - Epoch: [141][5/6]	Total Loss: 0.79138	Main MSE (x10^-2): 79.1375	LR: 3.28e-04	EMPP_Raw: 1.49164
2025-07-18 09:22:05,430 - logger.py:50 - Epoch 141 Training Summary: Avg Total Loss: 0.79138, Avg Main MSE: 0.79138, Time: 16.87s
2025-07-18 09:22:23,398 - logger.py:50 - Epoch 141 Summary | Train MSE (x10^-2): 79.1375 | Val MSE (x10^-2): 76.2368 | Time: 34.84s
2025-07-18 09:22:26,394 - logger.py:50 - Epoch: [142][0/6]	Total Loss: 0.78265	Main MSE (x10^-2): 78.2649	LR: 3.27e-04	EMPP_Raw: 1.46657
2025-07-18 09:22:40,161 - logger.py:50 - Epoch: [142][5/6]	Total Loss: 0.78144	Main MSE (x10^-2): 78.1444	LR: 3.27e-04	EMPP_Raw: 1.46878
2025-07-18 09:22:40,202 - logger.py:50 - Epoch 142 Training Summary: Avg Total Loss: 0.78144, Avg Main MSE: 0.78144, Time: 16.79s
2025-07-18 09:22:58,193 - logger.py:50 - Epoch 142 Summary | Train MSE (x10^-2): 78.1444 | Val MSE (x10^-2): 75.9258 | Time: 34.79s
2025-07-18 09:23:01,205 - logger.py:50 - Epoch: [143][0/6]	Total Loss: 0.78352	Main MSE (x10^-2): 78.3516	LR: 3.26e-04	EMPP_Raw: 1.46421
2025-07-18 09:23:15,030 - logger.py:50 - Epoch: [143][5/6]	Total Loss: 0.78507	Main MSE (x10^-2): 78.5070	LR: 3.26e-04	EMPP_Raw: 1.46933
2025-07-18 09:23:15,075 - logger.py:50 - Epoch 143 Training Summary: Avg Total Loss: 0.78507, Avg Main MSE: 0.78507, Time: 16.87s
2025-07-18 09:23:33,052 - logger.py:50 - Epoch 143 Summary | Train MSE (x10^-2): 78.5070 | Val MSE (x10^-2): 76.4036 | Time: 34.85s
2025-07-18 09:23:36,250 - logger.py:50 - Epoch: [144][0/6]	Total Loss: 0.79452	Main MSE (x10^-2): 79.4521	LR: 3.25e-04	EMPP_Raw: 1.49144
2025-07-18 09:23:50,027 - logger.py:50 - Epoch: [144][5/6]	Total Loss: 0.78450	Main MSE (x10^-2): 78.4504	LR: 3.25e-04	EMPP_Raw: 1.47457
2025-07-18 09:23:50,072 - logger.py:50 - Epoch 144 Training Summary: Avg Total Loss: 0.78450, Avg Main MSE: 0.78450, Time: 17.01s
2025-07-18 09:24:08,085 - logger.py:50 - Epoch 144 Summary | Train MSE (x10^-2): 78.4504 | Val MSE (x10^-2): 77.3235 | Time: 35.03s
2025-07-18 09:24:11,082 - logger.py:50 - Epoch: [145][0/6]	Total Loss: 0.80639	Main MSE (x10^-2): 80.6392	LR: 3.24e-04	EMPP_Raw: 1.51270
2025-07-18 09:24:25,009 - logger.py:50 - Epoch: [145][5/6]	Total Loss: 0.78177	Main MSE (x10^-2): 78.1766	LR: 3.24e-04	EMPP_Raw: 1.46438
2025-07-18 09:24:25,056 - logger.py:50 - Epoch 145 Training Summary: Avg Total Loss: 0.78177, Avg Main MSE: 0.78177, Time: 16.96s
2025-07-18 09:24:43,114 - logger.py:50 - Epoch 145 Summary | Train MSE (x10^-2): 78.1766 | Val MSE (x10^-2): 80.2253 | Time: 35.02s
2025-07-18 09:24:46,114 - logger.py:50 - Epoch: [146][0/6]	Total Loss: 0.78188	Main MSE (x10^-2): 78.1882	LR: 3.23e-04	EMPP_Raw: 1.47083
2025-07-18 09:25:00,051 - logger.py:50 - Epoch: [146][5/6]	Total Loss: 0.77559	Main MSE (x10^-2): 77.5586	LR: 3.23e-04	EMPP_Raw: 1.46432
2025-07-18 09:25:00,098 - logger.py:50 - Epoch 146 Training Summary: Avg Total Loss: 0.77559, Avg Main MSE: 0.77559, Time: 16.97s
2025-07-18 09:25:18,102 - logger.py:50 - Epoch 146 Summary | Train MSE (x10^-2): 77.5586 | Val MSE (x10^-2): 79.2555 | Time: 34.98s
2025-07-18 09:25:21,156 - logger.py:50 - Epoch: [147][0/6]	Total Loss: 0.76669	Main MSE (x10^-2): 76.6686	LR: 3.22e-04	EMPP_Raw: 1.45435
2025-07-18 09:25:34,937 - logger.py:50 - Epoch: [147][5/6]	Total Loss: 0.77212	Main MSE (x10^-2): 77.2118	LR: 3.22e-04	EMPP_Raw: 1.46417
2025-07-18 09:25:34,982 - logger.py:50 - Epoch 147 Training Summary: Avg Total Loss: 0.77212, Avg Main MSE: 0.77212, Time: 16.87s
2025-07-18 09:25:52,945 - logger.py:50 - Epoch 147 Summary | Train MSE (x10^-2): 77.2118 | Val MSE (x10^-2): 79.1070 | Time: 34.84s
2025-07-18 09:25:56,154 - logger.py:50 - Epoch: [148][0/6]	Total Loss: 0.78366	Main MSE (x10^-2): 78.3664	LR: 3.21e-04	EMPP_Raw: 1.49718
2025-07-18 09:26:09,910 - logger.py:50 - Epoch: [148][5/6]	Total Loss: 0.77362	Main MSE (x10^-2): 77.3619	LR: 3.21e-04	EMPP_Raw: 1.46657
2025-07-18 09:26:09,950 - logger.py:50 - Epoch 148 Training Summary: Avg Total Loss: 0.77362, Avg Main MSE: 0.77362, Time: 17.00s
2025-07-18 09:26:27,800 - logger.py:50 - Epoch 148 Summary | Train MSE (x10^-2): 77.3619 | Val MSE (x10^-2): 79.7618 | Time: 34.85s
2025-07-18 09:26:30,966 - logger.py:50 - Epoch: [149][0/6]	Total Loss: 0.75516	Main MSE (x10^-2): 75.5157	LR: 3.20e-04	EMPP_Raw: 1.43387
2025-07-18 09:26:44,776 - logger.py:50 - Epoch: [149][5/6]	Total Loss: 0.77824	Main MSE (x10^-2): 77.8244	LR: 3.20e-04	EMPP_Raw: 1.47874
2025-07-18 09:26:44,822 - logger.py:50 - Epoch 149 Training Summary: Avg Total Loss: 0.77824, Avg Main MSE: 0.77824, Time: 17.01s
2025-07-18 09:27:02,737 - logger.py:50 - Epoch 149 Summary | Train MSE (x10^-2): 77.8244 | Val MSE (x10^-2): 78.6867 | Time: 34.93s
2025-07-18 09:27:05,750 - logger.py:50 - Epoch: [150][0/6]	Total Loss: 0.80017	Main MSE (x10^-2): 80.0168	LR: 3.19e-04	EMPP_Raw: 1.51660
2025-07-18 09:27:19,716 - logger.py:50 - Epoch: [150][5/6]	Total Loss: 0.77931	Main MSE (x10^-2): 77.9306	LR: 3.19e-04	EMPP_Raw: 1.47508
2025-07-18 09:27:19,762 - logger.py:50 - Epoch 150 Training Summary: Avg Total Loss: 0.77931, Avg Main MSE: 0.77931, Time: 17.02s
2025-07-18 09:27:37,620 - logger.py:50 - Epoch 150 Summary | Train MSE (x10^-2): 77.9306 | Val MSE (x10^-2): 76.6247 | Time: 34.88s
2025-07-18 09:27:40,622 - logger.py:50 - Epoch: [151][0/6]	Total Loss: 0.76217	Main MSE (x10^-2): 76.2171	LR: 3.18e-04	EMPP_Raw: 1.43854
2025-07-18 09:27:54,391 - logger.py:50 - Epoch: [151][5/6]	Total Loss: 0.77665	Main MSE (x10^-2): 77.6654	LR: 3.18e-04	EMPP_Raw: 1.46920
2025-07-18 09:27:54,439 - logger.py:50 - Epoch 151 Training Summary: Avg Total Loss: 0.77665, Avg Main MSE: 0.77665, Time: 16.81s
2025-07-18 09:28:12,500 - logger.py:50 - Epoch 151 Summary | Train MSE (x10^-2): 77.6654 | Val MSE (x10^-2): 75.2884 | Time: 34.87s
2025-07-18 09:28:15,514 - logger.py:50 - Epoch: [152][0/6]	Total Loss: 0.77585	Main MSE (x10^-2): 77.5848	LR: 3.17e-04	EMPP_Raw: 1.47064
2025-07-18 09:28:29,335 - logger.py:50 - Epoch: [152][5/6]	Total Loss: 0.77086	Main MSE (x10^-2): 77.0859	LR: 3.17e-04	EMPP_Raw: 1.45991
2025-07-18 09:28:29,381 - logger.py:50 - Epoch 152 Training Summary: Avg Total Loss: 0.77086, Avg Main MSE: 0.77086, Time: 16.87s
2025-07-18 09:28:47,349 - logger.py:50 - Epoch 152 Summary | Train MSE (x10^-2): 77.0859 | Val MSE (x10^-2): 75.6213 | Time: 34.84s
2025-07-18 09:28:50,513 - logger.py:50 - Epoch: [153][0/6]	Total Loss: 0.77383	Main MSE (x10^-2): 77.3829	LR: 3.16e-04	EMPP_Raw: 1.46006
2025-07-18 09:29:04,298 - logger.py:50 - Epoch: [153][5/6]	Total Loss: 0.77684	Main MSE (x10^-2): 77.6837	LR: 3.16e-04	EMPP_Raw: 1.46929
2025-07-18 09:29:04,342 - logger.py:50 - Epoch 153 Training Summary: Avg Total Loss: 0.77684, Avg Main MSE: 0.77684, Time: 16.98s
2025-07-18 09:29:22,354 - logger.py:50 - Epoch 153 Summary | Train MSE (x10^-2): 77.6837 | Val MSE (x10^-2): 76.9296 | Time: 35.00s
2025-07-18 09:29:25,361 - logger.py:50 - Epoch: [154][0/6]	Total Loss: 0.77414	Main MSE (x10^-2): 77.4135	LR: 3.15e-04	EMPP_Raw: 1.46343
2025-07-18 09:29:39,313 - logger.py:50 - Epoch: [154][5/6]	Total Loss: 0.78927	Main MSE (x10^-2): 78.9272	LR: 3.15e-04	EMPP_Raw: 1.49072
2025-07-18 09:29:39,360 - logger.py:50 - Epoch 154 Training Summary: Avg Total Loss: 0.78927, Avg Main MSE: 0.78927, Time: 17.00s
2025-07-18 09:29:57,236 - logger.py:50 - Epoch 154 Summary | Train MSE (x10^-2): 78.9272 | Val MSE (x10^-2): 76.3507 | Time: 34.88s
2025-07-18 09:30:00,239 - logger.py:50 - Epoch: [155][0/6]	Total Loss: 0.79631	Main MSE (x10^-2): 79.6313	LR: 3.14e-04	EMPP_Raw: 1.51508
2025-07-18 09:30:14,050 - logger.py:50 - Epoch: [155][5/6]	Total Loss: 0.78073	Main MSE (x10^-2): 78.0733	LR: 3.14e-04	EMPP_Raw: 1.48439
2025-07-18 09:30:14,097 - logger.py:50 - Epoch 155 Training Summary: Avg Total Loss: 0.78073, Avg Main MSE: 0.78073, Time: 16.85s
2025-07-18 09:30:32,112 - logger.py:50 - Epoch 155 Summary | Train MSE (x10^-2): 78.0733 | Val MSE (x10^-2): 78.7624 | Time: 34.87s
2025-07-18 09:30:35,138 - logger.py:50 - Epoch: [156][0/6]	Total Loss: 0.77377	Main MSE (x10^-2): 77.3771	LR: 3.13e-04	EMPP_Raw: 1.47617
2025-07-18 09:30:48,987 - logger.py:50 - Epoch: [156][5/6]	Total Loss: 0.77911	Main MSE (x10^-2): 77.9106	LR: 3.13e-04	EMPP_Raw: 1.47807
2025-07-18 09:30:49,034 - logger.py:50 - Epoch 156 Training Summary: Avg Total Loss: 0.77911, Avg Main MSE: 0.77911, Time: 16.91s
2025-07-18 09:31:07,050 - logger.py:50 - Epoch 156 Summary | Train MSE (x10^-2): 77.9106 | Val MSE (x10^-2): 75.4181 | Time: 34.93s
2025-07-18 09:31:10,070 - logger.py:50 - Epoch: [157][0/6]	Total Loss: 0.76296	Main MSE (x10^-2): 76.2964	LR: 3.12e-04	EMPP_Raw: 1.45791
2025-07-18 09:31:23,907 - logger.py:50 - Epoch: [157][5/6]	Total Loss: 0.78584	Main MSE (x10^-2): 78.5842	LR: 3.12e-04	EMPP_Raw: 1.49696
2025-07-18 09:31:23,952 - logger.py:50 - Epoch 157 Training Summary: Avg Total Loss: 0.78584, Avg Main MSE: 0.78584, Time: 16.89s
2025-07-18 09:31:41,938 - logger.py:50 - Epoch 157 Summary | Train MSE (x10^-2): 78.5842 | Val MSE (x10^-2): 76.5151 | Time: 34.88s
2025-07-18 09:31:45,341 - logger.py:50 - Epoch: [158][0/6]	Total Loss: 0.76858	Main MSE (x10^-2): 76.8580	LR: 3.11e-04	EMPP_Raw: 1.46947
2025-07-18 09:31:59,169 - logger.py:50 - Epoch: [158][5/6]	Total Loss: 0.76771	Main MSE (x10^-2): 76.7710	LR: 3.11e-04	EMPP_Raw: 1.45676
2025-07-18 09:31:59,234 - logger.py:50 - Epoch 158 Training Summary: Avg Total Loss: 0.76771, Avg Main MSE: 0.76771, Time: 17.29s
2025-07-18 09:32:17,204 - logger.py:50 - Epoch 158 Summary | Train MSE (x10^-2): 76.7710 | Val MSE (x10^-2): 77.7811 | Time: 35.26s
2025-07-18 09:32:20,361 - logger.py:50 - Epoch: [159][0/6]	Total Loss: 0.75439	Main MSE (x10^-2): 75.4393	LR: 3.10e-04	EMPP_Raw: 1.43564
2025-07-18 09:32:34,101 - logger.py:50 - Epoch: [159][5/6]	Total Loss: 0.77139	Main MSE (x10^-2): 77.1394	LR: 3.10e-04	EMPP_Raw: 1.46700
2025-07-18 09:32:34,142 - logger.py:50 - Epoch 159 Training Summary: Avg Total Loss: 0.77139, Avg Main MSE: 0.77139, Time: 16.93s
2025-07-18 09:32:52,199 - logger.py:50 - Epoch 159 Summary | Train MSE (x10^-2): 77.1394 | Val MSE (x10^-2): 73.6458 | Time: 34.99s
2025-07-18 09:32:55,214 - logger.py:50 - Epoch: [160][0/6]	Total Loss: 0.75767	Main MSE (x10^-2): 75.7672	LR: 3.08e-04	EMPP_Raw: 1.43923
2025-07-18 09:33:09,190 - logger.py:50 - Epoch: [160][5/6]	Total Loss: 0.78018	Main MSE (x10^-2): 78.0181	LR: 3.08e-04	EMPP_Raw: 1.49080
2025-07-18 09:33:09,236 - logger.py:50 - Epoch 160 Training Summary: Avg Total Loss: 0.78018, Avg Main MSE: 0.78018, Time: 17.03s
2025-07-18 09:33:27,140 - logger.py:50 - Epoch 160 Summary | Train MSE (x10^-2): 78.0181 | Val MSE (x10^-2): 77.1322 | Time: 34.93s
2025-07-18 09:33:30,142 - logger.py:50 - Epoch: [161][0/6]	Total Loss: 0.79723	Main MSE (x10^-2): 79.7227	LR: 3.07e-04	EMPP_Raw: 1.52432
2025-07-18 09:33:43,913 - logger.py:50 - Epoch: [161][5/6]	Total Loss: 0.77712	Main MSE (x10^-2): 77.7124	LR: 3.07e-04	EMPP_Raw: 1.47979
2025-07-18 09:33:43,953 - logger.py:50 - Epoch 161 Training Summary: Avg Total Loss: 0.77712, Avg Main MSE: 0.77712, Time: 16.80s
2025-07-18 09:34:02,062 - logger.py:50 - Epoch 161 Summary | Train MSE (x10^-2): 77.7124 | Val MSE (x10^-2): 78.4113 | Time: 34.92s
2025-07-18 09:34:05,062 - logger.py:50 - Epoch: [162][0/6]	Total Loss: 0.76009	Main MSE (x10^-2): 76.0090	LR: 3.06e-04	EMPP_Raw: 1.44229
2025-07-18 09:34:18,855 - logger.py:50 - Epoch: [162][5/6]	Total Loss: 0.76391	Main MSE (x10^-2): 76.3906	LR: 3.06e-04	EMPP_Raw: 1.45442
2025-07-18 09:34:18,896 - logger.py:50 - Epoch 162 Training Summary: Avg Total Loss: 0.76391, Avg Main MSE: 0.76391, Time: 16.82s
2025-07-18 09:34:36,985 - logger.py:50 - Epoch 162 Summary | Train MSE (x10^-2): 76.3906 | Val MSE (x10^-2): 79.0437 | Time: 34.92s
2025-07-18 09:34:39,988 - logger.py:50 - Epoch: [163][0/6]	Total Loss: 0.77977	Main MSE (x10^-2): 77.9772	LR: 3.05e-04	EMPP_Raw: 1.49153
2025-07-18 09:34:53,776 - logger.py:50 - Epoch: [163][5/6]	Total Loss: 0.77180	Main MSE (x10^-2): 77.1796	LR: 3.05e-04	EMPP_Raw: 1.47219
2025-07-18 09:34:53,814 - logger.py:50 - Epoch 163 Training Summary: Avg Total Loss: 0.77180, Avg Main MSE: 0.77180, Time: 16.82s
2025-07-18 09:35:11,697 - logger.py:50 - Epoch 163 Summary | Train MSE (x10^-2): 77.1796 | Val MSE (x10^-2): 77.7561 | Time: 34.70s
2025-07-18 09:35:14,865 - logger.py:50 - Epoch: [164][0/6]	Total Loss: 0.79128	Main MSE (x10^-2): 79.1283	LR: 3.04e-04	EMPP_Raw: 1.50352
2025-07-18 09:35:28,686 - logger.py:50 - Epoch: [164][5/6]	Total Loss: 0.77535	Main MSE (x10^-2): 77.5348	LR: 3.04e-04	EMPP_Raw: 1.48095
2025-07-18 09:35:28,734 - logger.py:50 - Epoch 164 Training Summary: Avg Total Loss: 0.77535, Avg Main MSE: 0.77535, Time: 17.03s
2025-07-18 09:35:46,640 - logger.py:50 - Epoch 164 Summary | Train MSE (x10^-2): 77.5348 | Val MSE (x10^-2): 77.7124 | Time: 34.94s
2025-07-18 09:35:49,664 - logger.py:50 - Epoch: [165][0/6]	Total Loss: 0.78315	Main MSE (x10^-2): 78.3147	LR: 3.03e-04	EMPP_Raw: 1.50742
2025-07-18 09:36:03,602 - logger.py:50 - Epoch: [165][5/6]	Total Loss: 0.77675	Main MSE (x10^-2): 77.6753	LR: 3.03e-04	EMPP_Raw: 1.48599
2025-07-18 09:36:03,649 - logger.py:50 - Epoch 165 Training Summary: Avg Total Loss: 0.77675, Avg Main MSE: 0.77675, Time: 17.00s
2025-07-18 09:36:21,565 - logger.py:50 - Epoch 165 Summary | Train MSE (x10^-2): 77.6753 | Val MSE (x10^-2): 78.4897 | Time: 34.92s
2025-07-18 09:36:24,574 - logger.py:50 - Epoch: [166][0/6]	Total Loss: 0.78420	Main MSE (x10^-2): 78.4203	LR: 3.02e-04	EMPP_Raw: 1.49885
2025-07-18 09:36:38,527 - logger.py:50 - Epoch: [166][5/6]	Total Loss: 0.77231	Main MSE (x10^-2): 77.2311	LR: 3.02e-04	EMPP_Raw: 1.48119
2025-07-18 09:36:38,567 - logger.py:50 - Epoch 166 Training Summary: Avg Total Loss: 0.77231, Avg Main MSE: 0.77231, Time: 16.99s
2025-07-18 09:36:56,470 - logger.py:50 - Epoch 166 Summary | Train MSE (x10^-2): 77.2311 | Val MSE (x10^-2): 77.7752 | Time: 34.90s
2025-07-18 09:36:59,487 - logger.py:50 - Epoch: [167][0/6]	Total Loss: 0.75713	Main MSE (x10^-2): 75.7132	LR: 3.01e-04	EMPP_Raw: 1.44804
2025-07-18 09:37:13,405 - logger.py:50 - Epoch: [167][5/6]	Total Loss: 0.76249	Main MSE (x10^-2): 76.2488	LR: 3.01e-04	EMPP_Raw: 1.44928
2025-07-18 09:37:13,446 - logger.py:50 - Epoch 167 Training Summary: Avg Total Loss: 0.76249, Avg Main MSE: 0.76249, Time: 16.97s
2025-07-18 09:37:31,416 - logger.py:50 - Epoch 167 Summary | Train MSE (x10^-2): 76.2488 | Val MSE (x10^-2): 77.6917 | Time: 34.94s
2025-07-18 09:37:34,596 - logger.py:50 - Epoch: [168][0/6]	Total Loss: 0.79030	Main MSE (x10^-2): 79.0303	LR: 3.00e-04	EMPP_Raw: 1.51858
2025-07-18 09:37:48,381 - logger.py:50 - Epoch: [168][5/6]	Total Loss: 0.78173	Main MSE (x10^-2): 78.1735	LR: 3.00e-04	EMPP_Raw: 1.48934
2025-07-18 09:37:48,421 - logger.py:50 - Epoch 168 Training Summary: Avg Total Loss: 0.78173, Avg Main MSE: 0.78173, Time: 16.99s
2025-07-18 09:38:06,448 - logger.py:50 - Epoch 168 Summary | Train MSE (x10^-2): 78.1735 | Val MSE (x10^-2): 82.0512 | Time: 35.03s
2025-07-18 09:38:09,666 - logger.py:50 - Epoch: [169][0/6]	Total Loss: 0.79331	Main MSE (x10^-2): 79.3313	LR: 2.99e-04	EMPP_Raw: 1.51024
2025-07-18 09:38:23,436 - logger.py:50 - Epoch: [169][5/6]	Total Loss: 0.76548	Main MSE (x10^-2): 76.5482	LR: 2.99e-04	EMPP_Raw: 1.45871
2025-07-18 09:38:23,480 - logger.py:50 - Epoch 169 Training Summary: Avg Total Loss: 0.76548, Avg Main MSE: 0.76548, Time: 17.02s
2025-07-18 09:38:41,442 - logger.py:50 - Epoch 169 Summary | Train MSE (x10^-2): 76.5482 | Val MSE (x10^-2): 79.6020 | Time: 34.99s
2025-07-18 09:38:44,500 - logger.py:50 - Epoch: [170][0/6]	Total Loss: 0.76720	Main MSE (x10^-2): 76.7195	LR: 2.98e-04	EMPP_Raw: 1.46859
2025-07-18 09:38:58,400 - logger.py:50 - Epoch: [170][5/6]	Total Loss: 0.77037	Main MSE (x10^-2): 77.0375	LR: 2.98e-04	EMPP_Raw: 1.47407
2025-07-18 09:38:58,442 - logger.py:50 - Epoch 170 Training Summary: Avg Total Loss: 0.77037, Avg Main MSE: 0.77037, Time: 16.99s
2025-07-18 09:39:16,488 - logger.py:50 - Epoch 170 Summary | Train MSE (x10^-2): 77.0375 | Val MSE (x10^-2): 80.0114 | Time: 35.04s
2025-07-18 09:39:19,483 - logger.py:50 - Epoch: [171][0/6]	Total Loss: 0.76659	Main MSE (x10^-2): 76.6592	LR: 2.97e-04	EMPP_Raw: 1.47393
2025-07-18 09:39:33,261 - logger.py:50 - Epoch: [171][5/6]	Total Loss: 0.78101	Main MSE (x10^-2): 78.1011	LR: 2.97e-04	EMPP_Raw: 1.49228
2025-07-18 09:39:33,306 - logger.py:50 - Epoch 171 Training Summary: Avg Total Loss: 0.78101, Avg Main MSE: 0.78101, Time: 16.81s
2025-07-18 09:39:51,399 - logger.py:50 - Epoch 171 Summary | Train MSE (x10^-2): 78.1011 | Val MSE (x10^-2): 82.1582 | Time: 34.90s
2025-07-18 09:39:54,472 - logger.py:50 - Epoch: [172][0/6]	Total Loss: 0.76082	Main MSE (x10^-2): 76.0817	LR: 2.96e-04	EMPP_Raw: 1.45281
2025-07-18 09:40:08,317 - logger.py:50 - Epoch: [172][5/6]	Total Loss: 0.77072	Main MSE (x10^-2): 77.0719	LR: 2.96e-04	EMPP_Raw: 1.47156
2025-07-18 09:40:08,362 - logger.py:50 - Epoch 172 Training Summary: Avg Total Loss: 0.77072, Avg Main MSE: 0.77072, Time: 16.95s
2025-07-18 09:40:26,299 - logger.py:50 - Epoch 172 Summary | Train MSE (x10^-2): 77.0719 | Val MSE (x10^-2): 77.2493 | Time: 34.89s
2025-07-18 09:40:29,450 - logger.py:50 - Epoch: [173][0/6]	Total Loss: 0.78520	Main MSE (x10^-2): 78.5202	LR: 2.94e-04	EMPP_Raw: 1.50523
2025-07-18 09:40:43,216 - logger.py:50 - Epoch: [173][5/6]	Total Loss: 0.76500	Main MSE (x10^-2): 76.5004	LR: 2.94e-04	EMPP_Raw: 1.46204
2025-07-18 09:40:43,256 - logger.py:50 - Epoch 173 Training Summary: Avg Total Loss: 0.76500, Avg Main MSE: 0.76500, Time: 16.95s
2025-07-18 09:41:01,150 - logger.py:50 - Epoch 173 Summary | Train MSE (x10^-2): 76.5004 | Val MSE (x10^-2): 75.6250 | Time: 34.85s
2025-07-18 09:41:04,149 - logger.py:50 - Epoch: [174][0/6]	Total Loss: 0.75998	Main MSE (x10^-2): 75.9984	LR: 2.93e-04	EMPP_Raw: 1.46356
2025-07-18 09:41:18,045 - logger.py:50 - Epoch: [174][5/6]	Total Loss: 0.75915	Main MSE (x10^-2): 75.9149	LR: 2.93e-04	EMPP_Raw: 1.45929
2025-07-18 09:41:18,088 - logger.py:50 - Epoch 174 Training Summary: Avg Total Loss: 0.75915, Avg Main MSE: 0.75915, Time: 16.93s
2025-07-18 09:41:36,015 - logger.py:50 - Epoch 174 Summary | Train MSE (x10^-2): 75.9149 | Val MSE (x10^-2): 78.0480 | Time: 34.86s
2025-07-18 09:41:39,029 - logger.py:50 - Epoch: [175][0/6]	Total Loss: 0.76452	Main MSE (x10^-2): 76.4522	LR: 2.92e-04	EMPP_Raw: 1.47075
2025-07-18 09:41:52,815 - logger.py:50 - Epoch: [175][5/6]	Total Loss: 0.77078	Main MSE (x10^-2): 77.0782	LR: 2.92e-04	EMPP_Raw: 1.47802
2025-07-18 09:41:52,865 - logger.py:50 - Epoch 175 Training Summary: Avg Total Loss: 0.77078, Avg Main MSE: 0.77078, Time: 16.84s
2025-07-18 09:42:10,909 - logger.py:50 - Epoch 175 Summary | Train MSE (x10^-2): 77.0782 | Val MSE (x10^-2): 77.7581 | Time: 34.89s
2025-07-18 09:42:13,908 - logger.py:50 - Epoch: [176][0/6]	Total Loss: 0.77675	Main MSE (x10^-2): 77.6753	LR: 2.91e-04	EMPP_Raw: 1.49797
2025-07-18 09:42:27,702 - logger.py:50 - Epoch: [176][5/6]	Total Loss: 0.77513	Main MSE (x10^-2): 77.5128	LR: 2.91e-04	EMPP_Raw: 1.48716
2025-07-18 09:42:27,742 - logger.py:50 - Epoch 176 Training Summary: Avg Total Loss: 0.77513, Avg Main MSE: 0.77513, Time: 16.82s
2025-07-18 09:42:45,705 - logger.py:50 - Epoch 176 Summary | Train MSE (x10^-2): 77.5128 | Val MSE (x10^-2): 76.8803 | Time: 34.79s
2025-07-18 09:42:48,715 - logger.py:50 - Epoch: [177][0/6]	Total Loss: 0.75323	Main MSE (x10^-2): 75.3230	LR: 2.90e-04	EMPP_Raw: 1.44113
2025-07-18 09:43:02,565 - logger.py:50 - Epoch: [177][5/6]	Total Loss: 0.76542	Main MSE (x10^-2): 76.5421	LR: 2.90e-04	EMPP_Raw: 1.46434
2025-07-18 09:43:02,615 - logger.py:50 - Epoch 177 Training Summary: Avg Total Loss: 0.76542, Avg Main MSE: 0.76542, Time: 16.90s
2025-07-18 09:43:20,506 - logger.py:50 - Epoch 177 Summary | Train MSE (x10^-2): 76.5421 | Val MSE (x10^-2): 77.2762 | Time: 34.80s
2025-07-18 09:43:23,846 - logger.py:50 - Epoch: [178][0/6]	Total Loss: 0.77366	Main MSE (x10^-2): 77.3657	LR: 2.89e-04	EMPP_Raw: 1.46903
2025-07-18 09:43:37,569 - logger.py:50 - Epoch: [178][5/6]	Total Loss: 0.78064	Main MSE (x10^-2): 78.0644	LR: 2.89e-04	EMPP_Raw: 1.49439
2025-07-18 09:43:37,643 - logger.py:50 - Epoch 178 Training Summary: Avg Total Loss: 0.78064, Avg Main MSE: 0.78064, Time: 17.13s
2025-07-18 09:43:55,518 - logger.py:50 - Epoch 178 Summary | Train MSE (x10^-2): 78.0644 | Val MSE (x10^-2): 76.7144 | Time: 35.01s
2025-07-18 09:43:58,682 - logger.py:50 - Epoch: [179][0/6]	Total Loss: 0.75978	Main MSE (x10^-2): 75.9779	LR: 2.88e-04	EMPP_Raw: 1.44776
2025-07-18 09:44:12,507 - logger.py:50 - Epoch: [179][5/6]	Total Loss: 0.76954	Main MSE (x10^-2): 76.9544	LR: 2.88e-04	EMPP_Raw: 1.46918
2025-07-18 09:44:12,554 - logger.py:50 - Epoch 179 Training Summary: Avg Total Loss: 0.76954, Avg Main MSE: 0.76954, Time: 17.03s
2025-07-18 09:44:30,506 - logger.py:50 - Epoch 179 Summary | Train MSE (x10^-2): 76.9544 | Val MSE (x10^-2): 74.2294 | Time: 34.98s
2025-07-18 09:44:33,522 - logger.py:50 - Epoch: [180][0/6]	Total Loss: 0.76161	Main MSE (x10^-2): 76.1609	LR: 2.87e-04	EMPP_Raw: 1.45702
2025-07-18 09:44:47,523 - logger.py:50 - Epoch: [180][5/6]	Total Loss: 0.76814	Main MSE (x10^-2): 76.8143	LR: 2.87e-04	EMPP_Raw: 1.47009
2025-07-18 09:44:47,569 - logger.py:50 - Epoch 180 Training Summary: Avg Total Loss: 0.76814, Avg Main MSE: 0.76814, Time: 17.05s
2025-07-18 09:45:05,512 - logger.py:50 - Epoch 180 Summary | Train MSE (x10^-2): 76.8143 | Val MSE (x10^-2): 74.6700 | Time: 35.00s
2025-07-18 09:45:08,513 - logger.py:50 - Epoch: [181][0/6]	Total Loss: 0.75511	Main MSE (x10^-2): 75.5110	LR: 2.85e-04	EMPP_Raw: 1.44525
2025-07-18 09:45:22,293 - logger.py:50 - Epoch: [181][5/6]	Total Loss: 0.77409	Main MSE (x10^-2): 77.4090	LR: 2.85e-04	EMPP_Raw: 1.48156
2025-07-18 09:45:22,335 - logger.py:50 - Epoch 181 Training Summary: Avg Total Loss: 0.77409, Avg Main MSE: 0.77409, Time: 16.82s
2025-07-18 09:45:40,359 - logger.py:50 - Epoch 181 Summary | Train MSE (x10^-2): 77.4090 | Val MSE (x10^-2): 76.8012 | Time: 34.84s
2025-07-18 09:45:43,363 - logger.py:50 - Epoch: [182][0/6]	Total Loss: 0.75209	Main MSE (x10^-2): 75.2088	LR: 2.84e-04	EMPP_Raw: 1.44267
2025-07-18 09:45:57,258 - logger.py:50 - Epoch: [182][5/6]	Total Loss: 0.76248	Main MSE (x10^-2): 76.2479	LR: 2.84e-04	EMPP_Raw: 1.46054
2025-07-18 09:45:57,303 - logger.py:50 - Epoch 182 Training Summary: Avg Total Loss: 0.76248, Avg Main MSE: 0.76248, Time: 16.94s
2025-07-18 09:46:15,335 - logger.py:50 - Epoch 182 Summary | Train MSE (x10^-2): 76.2479 | Val MSE (x10^-2): 77.8646 | Time: 34.97s
2025-07-18 09:46:18,335 - logger.py:50 - Epoch: [183][0/6]	Total Loss: 0.73992	Main MSE (x10^-2): 73.9916	LR: 2.83e-04	EMPP_Raw: 1.41662
2025-07-18 09:46:32,107 - logger.py:50 - Epoch: [183][5/6]	Total Loss: 0.76490	Main MSE (x10^-2): 76.4900	LR: 2.83e-04	EMPP_Raw: 1.46492
2025-07-18 09:46:32,150 - logger.py:50 - Epoch 183 Training Summary: Avg Total Loss: 0.76490, Avg Main MSE: 0.76490, Time: 16.80s
2025-07-18 09:46:50,160 - logger.py:50 - Epoch 183 Summary | Train MSE (x10^-2): 76.4900 | Val MSE (x10^-2): 77.0798 | Time: 34.82s
2025-07-18 09:46:53,329 - logger.py:50 - Epoch: [184][0/6]	Total Loss: 0.77239	Main MSE (x10^-2): 77.2394	LR: 2.82e-04	EMPP_Raw: 1.47544
2025-07-18 09:47:07,128 - logger.py:50 - Epoch: [184][5/6]	Total Loss: 0.76677	Main MSE (x10^-2): 76.6769	LR: 2.82e-04	EMPP_Raw: 1.46656
2025-07-18 09:47:07,175 - logger.py:50 - Epoch 184 Training Summary: Avg Total Loss: 0.76677, Avg Main MSE: 0.76677, Time: 17.01s
2025-07-18 09:47:25,060 - logger.py:50 - Epoch 184 Summary | Train MSE (x10^-2): 76.6769 | Val MSE (x10^-2): 80.1606 | Time: 34.90s
2025-07-18 09:47:28,112 - logger.py:50 - Epoch: [185][0/6]	Total Loss: 0.76944	Main MSE (x10^-2): 76.9439	LR: 2.81e-04	EMPP_Raw: 1.47287
2025-07-18 09:47:42,057 - logger.py:50 - Epoch: [185][5/6]	Total Loss: 0.77697	Main MSE (x10^-2): 77.6971	LR: 2.81e-04	EMPP_Raw: 1.48104
2025-07-18 09:47:42,097 - logger.py:50 - Epoch 185 Training Summary: Avg Total Loss: 0.77697, Avg Main MSE: 0.77697, Time: 17.03s
2025-07-18 09:48:00,022 - logger.py:50 - Epoch 185 Summary | Train MSE (x10^-2): 77.6971 | Val MSE (x10^-2): 75.0017 | Time: 34.96s
2025-07-18 09:48:03,092 - logger.py:50 - Epoch: [186][0/6]	Total Loss: 0.75689	Main MSE (x10^-2): 75.6887	LR: 2.80e-04	EMPP_Raw: 1.44398
2025-07-18 09:48:17,065 - logger.py:50 - Epoch: [186][5/6]	Total Loss: 0.76648	Main MSE (x10^-2): 76.6482	LR: 2.80e-04	EMPP_Raw: 1.46576
2025-07-18 09:48:17,116 - logger.py:50 - Epoch 186 Training Summary: Avg Total Loss: 0.76648, Avg Main MSE: 0.76648, Time: 17.09s
2025-07-18 09:48:34,955 - logger.py:50 - Epoch 186 Summary | Train MSE (x10^-2): 76.6482 | Val MSE (x10^-2): 77.6374 | Time: 34.93s
2025-07-18 09:48:37,992 - logger.py:50 - Epoch: [187][0/6]	Total Loss: 0.75635	Main MSE (x10^-2): 75.6345	LR: 2.79e-04	EMPP_Raw: 1.44759
2025-07-18 09:48:51,803 - logger.py:50 - Epoch: [187][5/6]	Total Loss: 0.77409	Main MSE (x10^-2): 77.4086	LR: 2.79e-04	EMPP_Raw: 1.48653
2025-07-18 09:48:51,847 - logger.py:50 - Epoch 187 Training Summary: Avg Total Loss: 0.77409, Avg Main MSE: 0.77409, Time: 16.88s
2025-07-18 09:49:09,743 - logger.py:50 - Epoch 187 Summary | Train MSE (x10^-2): 77.4086 | Val MSE (x10^-2): 80.4622 | Time: 34.78s
2025-07-18 09:49:12,921 - logger.py:50 - Epoch: [188][0/6]	Total Loss: 0.75511	Main MSE (x10^-2): 75.5111	LR: 2.77e-04	EMPP_Raw: 1.45519
2025-07-18 09:49:26,692 - logger.py:50 - Epoch: [188][5/6]	Total Loss: 0.75123	Main MSE (x10^-2): 75.1226	LR: 2.77e-04	EMPP_Raw: 1.44439
2025-07-18 09:49:26,732 - logger.py:50 - Epoch 188 Training Summary: Avg Total Loss: 0.75123, Avg Main MSE: 0.75123, Time: 16.98s
2025-07-18 09:49:44,660 - logger.py:50 - Epoch 188 Summary | Train MSE (x10^-2): 75.1226 | Val MSE (x10^-2): 79.8642 | Time: 34.91s
2025-07-18 09:49:47,844 - logger.py:50 - Epoch: [189][0/6]	Total Loss: 0.79051	Main MSE (x10^-2): 79.0509	LR: 2.76e-04	EMPP_Raw: 1.52484
2025-07-18 09:50:01,579 - logger.py:50 - Epoch: [189][5/6]	Total Loss: 0.75718	Main MSE (x10^-2): 75.7177	LR: 2.76e-04	EMPP_Raw: 1.45912
2025-07-18 09:50:01,627 - logger.py:50 - Epoch 189 Training Summary: Avg Total Loss: 0.75718, Avg Main MSE: 0.75718, Time: 16.96s
2025-07-18 09:50:19,635 - logger.py:50 - Epoch 189 Summary | Train MSE (x10^-2): 75.7177 | Val MSE (x10^-2): 81.5661 | Time: 34.97s
2025-07-18 09:50:22,685 - logger.py:50 - Epoch: [190][0/6]	Total Loss: 0.75932	Main MSE (x10^-2): 75.9322	LR: 2.75e-04	EMPP_Raw: 1.45739
2025-07-18 09:50:36,583 - logger.py:50 - Epoch: [190][5/6]	Total Loss: 0.76026	Main MSE (x10^-2): 76.0255	LR: 2.75e-04	EMPP_Raw: 1.46480
2025-07-18 09:50:36,628 - logger.py:50 - Epoch 190 Training Summary: Avg Total Loss: 0.76026, Avg Main MSE: 0.76026, Time: 16.98s
2025-07-18 09:50:54,428 - logger.py:50 - Epoch 190 Summary | Train MSE (x10^-2): 76.0255 | Val MSE (x10^-2): 79.1069 | Time: 34.79s
2025-07-18 09:50:57,488 - logger.py:50 - Epoch: [191][0/6]	Total Loss: 0.75891	Main MSE (x10^-2): 75.8914	LR: 2.74e-04	EMPP_Raw: 1.47137
2025-07-18 09:51:11,293 - logger.py:50 - Epoch: [191][5/6]	Total Loss: 0.75706	Main MSE (x10^-2): 75.7056	LR: 2.74e-04	EMPP_Raw: 1.45990
2025-07-18 09:51:11,335 - logger.py:50 - Epoch 191 Training Summary: Avg Total Loss: 0.75706, Avg Main MSE: 0.75706, Time: 16.90s
2025-07-18 09:51:29,511 - logger.py:50 - Epoch 191 Summary | Train MSE (x10^-2): 75.7056 | Val MSE (x10^-2): 79.8482 | Time: 35.08s
2025-07-18 09:51:32,503 - logger.py:50 - Epoch: [192][0/6]	Total Loss: 0.77938	Main MSE (x10^-2): 77.9377	LR: 2.73e-04	EMPP_Raw: 1.50330
2025-07-18 09:51:46,282 - logger.py:50 - Epoch: [192][5/6]	Total Loss: 0.76002	Main MSE (x10^-2): 76.0016	LR: 2.73e-04	EMPP_Raw: 1.46485
2025-07-18 09:51:46,323 - logger.py:50 - Epoch 192 Training Summary: Avg Total Loss: 0.76002, Avg Main MSE: 0.76002, Time: 16.80s
2025-07-18 09:52:04,193 - logger.py:50 - Epoch 192 Summary | Train MSE (x10^-2): 76.0016 | Val MSE (x10^-2): 79.9090 | Time: 34.68s
2025-07-18 09:52:07,344 - logger.py:50 - Epoch: [193][0/6]	Total Loss: 0.78167	Main MSE (x10^-2): 78.1674	LR: 2.72e-04	EMPP_Raw: 1.50541
2025-07-18 09:52:21,091 - logger.py:50 - Epoch: [193][5/6]	Total Loss: 0.76004	Main MSE (x10^-2): 76.0039	LR: 2.72e-04	EMPP_Raw: 1.46610
2025-07-18 09:52:21,129 - logger.py:50 - Epoch 193 Training Summary: Avg Total Loss: 0.76004, Avg Main MSE: 0.76004, Time: 16.93s
2025-07-18 09:52:39,106 - logger.py:50 - Epoch 193 Summary | Train MSE (x10^-2): 76.0039 | Val MSE (x10^-2): 78.5642 | Time: 34.91s
2025-07-18 09:52:42,112 - logger.py:50 - Epoch: [194][0/6]	Total Loss: 0.75101	Main MSE (x10^-2): 75.1012	LR: 2.70e-04	EMPP_Raw: 1.45306
2025-07-18 09:52:56,030 - logger.py:50 - Epoch: [194][5/6]	Total Loss: 0.75588	Main MSE (x10^-2): 75.5885	LR: 2.70e-04	EMPP_Raw: 1.45725
2025-07-18 09:52:56,074 - logger.py:50 - Epoch 194 Training Summary: Avg Total Loss: 0.75588, Avg Main MSE: 0.75588, Time: 16.96s
2025-07-18 09:53:13,989 - logger.py:50 - Epoch 194 Summary | Train MSE (x10^-2): 75.5885 | Val MSE (x10^-2): 77.8634 | Time: 34.88s
2025-07-18 09:53:17,050 - logger.py:50 - Epoch: [195][0/6]	Total Loss: 0.76809	Main MSE (x10^-2): 76.8087	LR: 2.69e-04	EMPP_Raw: 1.48366
2025-07-18 09:53:30,851 - logger.py:50 - Epoch: [195][5/6]	Total Loss: 0.76704	Main MSE (x10^-2): 76.7043	LR: 2.69e-04	EMPP_Raw: 1.47890
2025-07-18 09:53:30,900 - logger.py:50 - Epoch 195 Training Summary: Avg Total Loss: 0.76704, Avg Main MSE: 0.76704, Time: 16.90s
2025-07-18 09:53:48,918 - logger.py:50 - Epoch 195 Summary | Train MSE (x10^-2): 76.7043 | Val MSE (x10^-2): 80.0828 | Time: 34.92s
2025-07-18 09:53:51,923 - logger.py:50 - Epoch: [196][0/6]	Total Loss: 0.77215	Main MSE (x10^-2): 77.2151	LR: 2.68e-04	EMPP_Raw: 1.48767
2025-07-18 09:54:05,740 - logger.py:50 - Epoch: [196][5/6]	Total Loss: 0.77504	Main MSE (x10^-2): 77.5044	LR: 2.68e-04	EMPP_Raw: 1.48987
2025-07-18 09:54:05,780 - logger.py:50 - Epoch 196 Training Summary: Avg Total Loss: 0.77504, Avg Main MSE: 0.77504, Time: 16.85s
2025-07-18 09:54:23,811 - logger.py:50 - Epoch 196 Summary | Train MSE (x10^-2): 77.5044 | Val MSE (x10^-2): 80.7919 | Time: 34.89s
2025-07-18 09:54:26,809 - logger.py:50 - Epoch: [197][0/6]	Total Loss: 0.77749	Main MSE (x10^-2): 77.7489	LR: 2.67e-04	EMPP_Raw: 1.49921
2025-07-18 09:54:40,567 - logger.py:50 - Epoch: [197][5/6]	Total Loss: 0.76154	Main MSE (x10^-2): 76.1537	LR: 2.67e-04	EMPP_Raw: 1.46688
2025-07-18 09:54:40,618 - logger.py:50 - Epoch 197 Training Summary: Avg Total Loss: 0.76154, Avg Main MSE: 0.76154, Time: 16.80s
2025-07-18 09:54:58,565 - logger.py:50 - Epoch 197 Summary | Train MSE (x10^-2): 76.1537 | Val MSE (x10^-2): 83.0556 | Time: 34.75s
2025-07-18 09:55:01,914 - logger.py:50 - Epoch: [198][0/6]	Total Loss: 0.75223	Main MSE (x10^-2): 75.2229	LR: 2.66e-04	EMPP_Raw: 1.44450
2025-07-18 09:55:15,678 - logger.py:50 - Epoch: [198][5/6]	Total Loss: 0.75997	Main MSE (x10^-2): 75.9970	LR: 2.66e-04	EMPP_Raw: 1.46381
2025-07-18 09:55:15,732 - logger.py:50 - Epoch 198 Training Summary: Avg Total Loss: 0.75997, Avg Main MSE: 0.75997, Time: 17.16s
2025-07-18 09:55:33,731 - logger.py:50 - Epoch 198 Summary | Train MSE (x10^-2): 75.9970 | Val MSE (x10^-2): 78.8092 | Time: 35.16s
2025-07-18 09:55:36,929 - logger.py:50 - Epoch: [199][0/6]	Total Loss: 0.73378	Main MSE (x10^-2): 73.3785	LR: 2.65e-04	EMPP_Raw: 1.40839
2025-07-18 09:55:50,768 - logger.py:50 - Epoch: [199][5/6]	Total Loss: 0.74956	Main MSE (x10^-2): 74.9560	LR: 2.65e-04	EMPP_Raw: 1.44502
2025-07-18 09:55:50,816 - logger.py:50 - Epoch 199 Training Summary: Avg Total Loss: 0.74956, Avg Main MSE: 0.74956, Time: 17.08s
2025-07-18 09:56:08,825 - logger.py:50 - Epoch 199 Summary | Train MSE (x10^-2): 74.9560 | Val MSE (x10^-2): 79.8144 | Time: 35.09s
2025-07-18 09:56:11,845 - logger.py:50 - Epoch: [200][0/6]	Total Loss: 0.73955	Main MSE (x10^-2): 73.9546	LR: 2.63e-04	EMPP_Raw: 1.43183
2025-07-18 09:56:25,772 - logger.py:50 - Epoch: [200][5/6]	Total Loss: 0.75291	Main MSE (x10^-2): 75.2906	LR: 2.63e-04	EMPP_Raw: 1.45401
2025-07-18 09:56:25,813 - logger.py:50 - Epoch 200 Training Summary: Avg Total Loss: 0.75291, Avg Main MSE: 0.75291, Time: 16.98s
2025-07-18 09:56:43,780 - logger.py:50 - Epoch 200 Summary | Train MSE (x10^-2): 75.2906 | Val MSE (x10^-2): 78.1594 | Time: 34.95s
2025-07-18 09:56:46,785 - logger.py:50 - Epoch: [201][0/6]	Total Loss: 0.78619	Main MSE (x10^-2): 78.6189	LR: 2.62e-04	EMPP_Raw: 1.51997
2025-07-18 09:57:00,579 - logger.py:50 - Epoch: [201][5/6]	Total Loss: 0.76898	Main MSE (x10^-2): 76.8979	LR: 2.62e-04	EMPP_Raw: 1.48895
2025-07-18 09:57:00,624 - logger.py:50 - Epoch 201 Training Summary: Avg Total Loss: 0.76898, Avg Main MSE: 0.76898, Time: 16.83s
2025-07-18 09:57:18,648 - logger.py:50 - Epoch 201 Summary | Train MSE (x10^-2): 76.8979 | Val MSE (x10^-2): 76.9169 | Time: 34.86s
2025-07-18 09:57:21,651 - logger.py:50 - Epoch: [202][0/6]	Total Loss: 0.74736	Main MSE (x10^-2): 74.7357	LR: 2.61e-04	EMPP_Raw: 1.44196
2025-07-18 09:57:35,455 - logger.py:50 - Epoch: [202][5/6]	Total Loss: 0.74843	Main MSE (x10^-2): 74.8433	LR: 2.61e-04	EMPP_Raw: 1.44310
2025-07-18 09:57:35,507 - logger.py:50 - Epoch 202 Training Summary: Avg Total Loss: 0.74843, Avg Main MSE: 0.74843, Time: 16.85s
2025-07-18 09:57:53,564 - logger.py:50 - Epoch 202 Summary | Train MSE (x10^-2): 74.8433 | Val MSE (x10^-2): 75.2602 | Time: 34.91s
2025-07-18 09:57:56,619 - logger.py:50 - Epoch: [203][0/6]	Total Loss: 0.73464	Main MSE (x10^-2): 73.4637	LR: 2.60e-04	EMPP_Raw: 1.41364
2025-07-18 09:58:10,440 - logger.py:50 - Epoch: [203][5/6]	Total Loss: 0.75526	Main MSE (x10^-2): 75.5256	LR: 2.60e-04	EMPP_Raw: 1.45787
2025-07-18 09:58:10,480 - logger.py:50 - Epoch 203 Training Summary: Avg Total Loss: 0.75526, Avg Main MSE: 0.75526, Time: 16.91s
2025-07-18 09:58:28,420 - logger.py:50 - Epoch 203 Summary | Train MSE (x10^-2): 75.5256 | Val MSE (x10^-2): 75.6885 | Time: 34.85s
2025-07-18 09:58:31,586 - logger.py:50 - Epoch: [204][0/6]	Total Loss: 0.76268	Main MSE (x10^-2): 76.2685	LR: 2.59e-04	EMPP_Raw: 1.47457
2025-07-18 09:58:45,304 - logger.py:50 - Epoch: [204][5/6]	Total Loss: 0.75898	Main MSE (x10^-2): 75.8980	LR: 2.59e-04	EMPP_Raw: 1.47101
2025-07-18 09:58:45,346 - logger.py:50 - Epoch 204 Training Summary: Avg Total Loss: 0.75898, Avg Main MSE: 0.75898, Time: 16.92s
2025-07-18 09:59:03,230 - logger.py:50 - Epoch 204 Summary | Train MSE (x10^-2): 75.8980 | Val MSE (x10^-2): 76.5943 | Time: 34.80s
2025-07-18 09:59:06,233 - logger.py:50 - Epoch: [205][0/6]	Total Loss: 0.75076	Main MSE (x10^-2): 75.0756	LR: 2.57e-04	EMPP_Raw: 1.45365
2025-07-18 09:59:20,204 - logger.py:50 - Epoch: [205][5/6]	Total Loss: 0.75248	Main MSE (x10^-2): 75.2482	LR: 2.57e-04	EMPP_Raw: 1.45503
2025-07-18 09:59:20,246 - logger.py:50 - Epoch 205 Training Summary: Avg Total Loss: 0.75248, Avg Main MSE: 0.75248, Time: 17.01s
2025-07-18 09:59:38,086 - logger.py:50 - Epoch 205 Summary | Train MSE (x10^-2): 75.2482 | Val MSE (x10^-2): 78.2351 | Time: 34.85s
2025-07-18 09:59:41,085 - logger.py:50 - Epoch: [206][0/6]	Total Loss: 0.75666	Main MSE (x10^-2): 75.6664	LR: 2.56e-04	EMPP_Raw: 1.46443
2025-07-18 09:59:55,035 - logger.py:50 - Epoch: [206][5/6]	Total Loss: 0.75441	Main MSE (x10^-2): 75.4410	LR: 2.56e-04	EMPP_Raw: 1.45899
2025-07-18 09:59:55,080 - logger.py:50 - Epoch 206 Training Summary: Avg Total Loss: 0.75441, Avg Main MSE: 0.75441, Time: 16.98s
2025-07-18 10:00:13,083 - logger.py:50 - Epoch 206 Summary | Train MSE (x10^-2): 75.4410 | Val MSE (x10^-2): 76.1656 | Time: 34.99s
2025-07-18 10:00:16,078 - logger.py:50 - Epoch: [207][0/6]	Total Loss: 0.77689	Main MSE (x10^-2): 77.6886	LR: 2.55e-04	EMPP_Raw: 1.50408
2025-07-18 10:00:29,874 - logger.py:50 - Epoch: [207][5/6]	Total Loss: 0.76090	Main MSE (x10^-2): 76.0905	LR: 2.55e-04	EMPP_Raw: 1.47155
2025-07-18 10:00:29,915 - logger.py:50 - Epoch 207 Training Summary: Avg Total Loss: 0.76090, Avg Main MSE: 0.76090, Time: 16.82s
2025-07-18 10:00:47,792 - logger.py:50 - Epoch 207 Summary | Train MSE (x10^-2): 76.0905 | Val MSE (x10^-2): 76.4756 | Time: 34.70s
2025-07-18 10:00:50,988 - logger.py:50 - Epoch: [208][0/6]	Total Loss: 0.76572	Main MSE (x10^-2): 76.5719	LR: 2.54e-04	EMPP_Raw: 1.46037
2025-07-18 10:01:04,716 - logger.py:50 - Epoch: [208][5/6]	Total Loss: 0.75797	Main MSE (x10^-2): 75.7975	LR: 2.54e-04	EMPP_Raw: 1.46123
2025-07-18 10:01:04,764 - logger.py:50 - Epoch 208 Training Summary: Avg Total Loss: 0.75797, Avg Main MSE: 0.75797, Time: 16.97s
2025-07-18 10:01:22,659 - logger.py:50 - Epoch 208 Summary | Train MSE (x10^-2): 75.7975 | Val MSE (x10^-2): 79.8380 | Time: 34.86s
2025-07-18 10:01:25,836 - logger.py:50 - Epoch: [209][0/6]	Total Loss: 0.75539	Main MSE (x10^-2): 75.5386	LR: 2.53e-04	EMPP_Raw: 1.46426
2025-07-18 10:01:39,610 - logger.py:50 - Epoch: [209][5/6]	Total Loss: 0.75278	Main MSE (x10^-2): 75.2779	LR: 2.53e-04	EMPP_Raw: 1.45550
2025-07-18 10:01:39,654 - logger.py:50 - Epoch 209 Training Summary: Avg Total Loss: 0.75278, Avg Main MSE: 0.75278, Time: 16.99s
2025-07-18 10:01:57,508 - logger.py:50 - Epoch 209 Summary | Train MSE (x10^-2): 75.2779 | Val MSE (x10^-2): 80.1361 | Time: 34.84s
2025-07-18 10:02:00,537 - logger.py:50 - Epoch: [210][0/6]	Total Loss: 0.74497	Main MSE (x10^-2): 74.4972	LR: 2.51e-04	EMPP_Raw: 1.44138
2025-07-18 10:02:14,444 - logger.py:50 - Epoch: [210][5/6]	Total Loss: 0.75410	Main MSE (x10^-2): 75.4104	LR: 2.51e-04	EMPP_Raw: 1.46207
2025-07-18 10:02:14,485 - logger.py:50 - Epoch 210 Training Summary: Avg Total Loss: 0.75410, Avg Main MSE: 0.75410, Time: 16.97s
2025-07-18 10:02:32,303 - logger.py:50 - Epoch 210 Summary | Train MSE (x10^-2): 75.4104 | Val MSE (x10^-2): 79.7372 | Time: 34.79s
2025-07-18 10:02:35,294 - logger.py:50 - Epoch: [211][0/6]	Total Loss: 0.76215	Main MSE (x10^-2): 76.2150	LR: 2.50e-04	EMPP_Raw: 1.48039
2025-07-18 10:02:49,045 - logger.py:50 - Epoch: [211][5/6]	Total Loss: 0.74727	Main MSE (x10^-2): 74.7272	LR: 2.50e-04	EMPP_Raw: 1.45044
2025-07-18 10:02:49,086 - logger.py:50 - Epoch 211 Training Summary: Avg Total Loss: 0.74727, Avg Main MSE: 0.74727, Time: 16.77s
2025-07-18 10:03:07,185 - logger.py:50 - Epoch 211 Summary | Train MSE (x10^-2): 74.7272 | Val MSE (x10^-2): 79.4314 | Time: 34.88s
2025-07-18 10:03:10,210 - logger.py:50 - Epoch: [212][0/6]	Total Loss: 0.75113	Main MSE (x10^-2): 75.1131	LR: 2.49e-04	EMPP_Raw: 1.46054
2025-07-18 10:03:23,971 - logger.py:50 - Epoch: [212][5/6]	Total Loss: 0.75797	Main MSE (x10^-2): 75.7969	LR: 2.49e-04	EMPP_Raw: 1.46904
2025-07-18 10:03:24,018 - logger.py:50 - Epoch 212 Training Summary: Avg Total Loss: 0.75797, Avg Main MSE: 0.75797, Time: 16.82s
2025-07-18 10:03:42,011 - logger.py:50 - Epoch 212 Summary | Train MSE (x10^-2): 75.7969 | Val MSE (x10^-2): 78.4332 | Time: 34.82s
2025-07-18 10:03:45,201 - logger.py:50 - Epoch: [213][0/6]	Total Loss: 0.75998	Main MSE (x10^-2): 75.9975	LR: 2.48e-04	EMPP_Raw: 1.47253
2025-07-18 10:03:58,969 - logger.py:50 - Epoch: [213][5/6]	Total Loss: 0.76725	Main MSE (x10^-2): 76.7252	LR: 2.48e-04	EMPP_Raw: 1.48604
2025-07-18 10:03:59,017 - logger.py:50 - Epoch 213 Training Summary: Avg Total Loss: 0.76725, Avg Main MSE: 0.76725, Time: 17.00s
2025-07-18 10:04:17,018 - logger.py:50 - Epoch 213 Summary | Train MSE (x10^-2): 76.7252 | Val MSE (x10^-2): 76.5882 | Time: 35.00s
2025-07-18 10:04:20,054 - logger.py:50 - Epoch: [214][0/6]	Total Loss: 0.77303	Main MSE (x10^-2): 77.3027	LR: 2.46e-04	EMPP_Raw: 1.49609
2025-07-18 10:04:33,999 - logger.py:50 - Epoch: [214][5/6]	Total Loss: 0.75821	Main MSE (x10^-2): 75.8213	LR: 2.46e-04	EMPP_Raw: 1.46605
2025-07-18 10:04:34,041 - logger.py:50 - Epoch 214 Training Summary: Avg Total Loss: 0.75821, Avg Main MSE: 0.75821, Time: 17.01s
2025-07-18 10:04:51,935 - logger.py:50 - Epoch 214 Summary | Train MSE (x10^-2): 75.8213 | Val MSE (x10^-2): 78.0690 | Time: 34.91s
2025-07-18 10:04:54,978 - logger.py:50 - Epoch: [215][0/6]	Total Loss: 0.75700	Main MSE (x10^-2): 75.6997	LR: 2.45e-04	EMPP_Raw: 1.46715
2025-07-18 10:05:08,739 - logger.py:50 - Epoch: [215][5/6]	Total Loss: 0.75495	Main MSE (x10^-2): 75.4951	LR: 2.45e-04	EMPP_Raw: 1.46147
2025-07-18 10:05:08,780 - logger.py:50 - Epoch 215 Training Summary: Avg Total Loss: 0.75495, Avg Main MSE: 0.75495, Time: 16.84s
2025-07-18 10:05:26,804 - logger.py:50 - Epoch 215 Summary | Train MSE (x10^-2): 75.4951 | Val MSE (x10^-2): 78.7561 | Time: 34.86s
2025-07-18 10:05:29,799 - logger.py:50 - Epoch: [216][0/6]	Total Loss: 0.76762	Main MSE (x10^-2): 76.7618	LR: 2.44e-04	EMPP_Raw: 1.48133
2025-07-18 10:05:43,634 - logger.py:50 - Epoch: [216][5/6]	Total Loss: 0.76441	Main MSE (x10^-2): 76.4407	LR: 2.44e-04	EMPP_Raw: 1.47856
2025-07-18 10:05:43,676 - logger.py:50 - Epoch 216 Training Summary: Avg Total Loss: 0.76441, Avg Main MSE: 0.76441, Time: 16.86s
2025-07-18 10:06:01,688 - logger.py:50 - Epoch 216 Summary | Train MSE (x10^-2): 76.4407 | Val MSE (x10^-2): 79.1216 | Time: 34.88s
2025-07-18 10:06:04,683 - logger.py:50 - Epoch: [217][0/6]	Total Loss: 0.75782	Main MSE (x10^-2): 75.7817	LR: 2.43e-04	EMPP_Raw: 1.46768
2025-07-18 10:06:18,429 - logger.py:50 - Epoch: [217][5/6]	Total Loss: 0.76021	Main MSE (x10^-2): 76.0214	LR: 2.43e-04	EMPP_Raw: 1.47237
2025-07-18 10:06:18,469 - logger.py:50 - Epoch 217 Training Summary: Avg Total Loss: 0.76021, Avg Main MSE: 0.76021, Time: 16.77s
2025-07-18 10:06:36,354 - logger.py:50 - Epoch 217 Summary | Train MSE (x10^-2): 76.0214 | Val MSE (x10^-2): 76.6808 | Time: 34.66s
2025-07-18 10:06:39,736 - logger.py:50 - Epoch: [218][0/6]	Total Loss: 0.76418	Main MSE (x10^-2): 76.4181	LR: 2.42e-04	EMPP_Raw: 1.48462
2025-07-18 10:06:53,513 - logger.py:50 - Epoch: [218][5/6]	Total Loss: 0.75899	Main MSE (x10^-2): 75.8991	LR: 2.42e-04	EMPP_Raw: 1.47328
2025-07-18 10:06:53,563 - logger.py:50 - Epoch 218 Training Summary: Avg Total Loss: 0.75899, Avg Main MSE: 0.75899, Time: 17.20s
2025-07-18 10:07:11,502 - logger.py:50 - Epoch 218 Summary | Train MSE (x10^-2): 75.8991 | Val MSE (x10^-2): 77.9069 | Time: 35.14s
2025-07-18 10:07:14,710 - logger.py:50 - Epoch: [219][0/6]	Total Loss: 0.77336	Main MSE (x10^-2): 77.3362	LR: 2.40e-04	EMPP_Raw: 1.49652
2025-07-18 10:07:28,503 - logger.py:50 - Epoch: [219][5/6]	Total Loss: 0.74647	Main MSE (x10^-2): 74.6475	LR: 2.40e-04	EMPP_Raw: 1.44734
2025-07-18 10:07:28,549 - logger.py:50 - Epoch 219 Training Summary: Avg Total Loss: 0.74647, Avg Main MSE: 0.74647, Time: 17.04s
2025-07-18 10:07:46,477 - logger.py:50 - Epoch 219 Summary | Train MSE (x10^-2): 74.6475 | Val MSE (x10^-2): 77.5155 | Time: 34.97s
2025-07-18 10:07:49,469 - logger.py:50 - Epoch: [220][0/6]	Total Loss: 0.73919	Main MSE (x10^-2): 73.9193	LR: 2.39e-04	EMPP_Raw: 1.43531
2025-07-18 10:08:03,416 - logger.py:50 - Epoch: [220][5/6]	Total Loss: 0.74567	Main MSE (x10^-2): 74.5671	LR: 2.39e-04	EMPP_Raw: 1.44789
2025-07-18 10:08:03,456 - logger.py:50 - Epoch 220 Training Summary: Avg Total Loss: 0.74567, Avg Main MSE: 0.74567, Time: 16.97s
2025-07-18 10:08:21,704 - logger.py:50 - Epoch 220 Summary | Train MSE (x10^-2): 74.5671 | Val MSE (x10^-2): 77.4723 | Time: 35.22s
2025-07-18 10:08:24,709 - logger.py:50 - Epoch: [221][0/6]	Total Loss: 0.74428	Main MSE (x10^-2): 74.4275	LR: 2.38e-04	EMPP_Raw: 1.44710
2025-07-18 10:08:38,613 - logger.py:50 - Epoch: [221][5/6]	Total Loss: 0.75226	Main MSE (x10^-2): 75.2261	LR: 2.38e-04	EMPP_Raw: 1.46016
2025-07-18 10:08:38,657 - logger.py:50 - Epoch 221 Training Summary: Avg Total Loss: 0.75226, Avg Main MSE: 0.75226, Time: 16.94s
2025-07-18 10:08:56,807 - logger.py:50 - Epoch 221 Summary | Train MSE (x10^-2): 75.2261 | Val MSE (x10^-2): 78.2757 | Time: 35.10s
2025-07-18 10:08:59,856 - logger.py:50 - Epoch: [222][0/6]	Total Loss: 0.75810	Main MSE (x10^-2): 75.8099	LR: 2.37e-04	EMPP_Raw: 1.47368
2025-07-18 10:09:13,612 - logger.py:50 - Epoch: [222][5/6]	Total Loss: 0.75807	Main MSE (x10^-2): 75.8067	LR: 2.37e-04	EMPP_Raw: 1.47199
2025-07-18 10:09:13,658 - logger.py:50 - Epoch 222 Training Summary: Avg Total Loss: 0.75807, Avg Main MSE: 0.75807, Time: 16.84s
2025-07-18 10:09:31,809 - logger.py:50 - Epoch 222 Summary | Train MSE (x10^-2): 75.8067 | Val MSE (x10^-2): 76.9092 | Time: 35.00s
2025-07-18 10:09:34,815 - logger.py:50 - Epoch: [223][0/6]	Total Loss: 0.72594	Main MSE (x10^-2): 72.5941	LR: 2.35e-04	EMPP_Raw: 1.41329
2025-07-18 10:09:48,654 - logger.py:50 - Epoch: [223][5/6]	Total Loss: 0.73887	Main MSE (x10^-2): 73.8869	LR: 2.35e-04	EMPP_Raw: 1.43703
2025-07-18 10:09:48,698 - logger.py:50 - Epoch 223 Training Summary: Avg Total Loss: 0.73887, Avg Main MSE: 0.73887, Time: 16.88s
2025-07-18 10:10:06,620 - logger.py:50 - Epoch 223 Summary | Train MSE (x10^-2): 73.8869 | Val MSE (x10^-2): 75.9419 | Time: 34.80s
2025-07-18 10:10:09,792 - logger.py:50 - Epoch: [224][0/6]	Total Loss: 0.74581	Main MSE (x10^-2): 74.5807	LR: 2.34e-04	EMPP_Raw: 1.45136
2025-07-18 10:10:23,540 - logger.py:50 - Epoch: [224][5/6]	Total Loss: 0.74417	Main MSE (x10^-2): 74.4170	LR: 2.34e-04	EMPP_Raw: 1.44814
2025-07-18 10:10:23,586 - logger.py:50 - Epoch 224 Training Summary: Avg Total Loss: 0.74417, Avg Main MSE: 0.74417, Time: 16.96s
2025-07-18 10:10:41,719 - logger.py:50 - Epoch 224 Summary | Train MSE (x10^-2): 74.4170 | Val MSE (x10^-2): 78.0168 | Time: 35.09s
2025-07-18 10:10:44,737 - logger.py:50 - Epoch: [225][0/6]	Total Loss: 0.73416	Main MSE (x10^-2): 73.4165	LR: 2.33e-04	EMPP_Raw: 1.43068
2025-07-18 10:10:58,667 - logger.py:50 - Epoch: [225][5/6]	Total Loss: 0.75903	Main MSE (x10^-2): 75.9033	LR: 2.33e-04	EMPP_Raw: 1.47734
2025-07-18 10:10:58,710 - logger.py:50 - Epoch 225 Training Summary: Avg Total Loss: 0.75903, Avg Main MSE: 0.75903, Time: 16.98s
2025-07-18 10:11:16,708 - logger.py:50 - Epoch 225 Summary | Train MSE (x10^-2): 75.9033 | Val MSE (x10^-2): 78.3690 | Time: 34.98s
2025-07-18 10:11:19,711 - logger.py:50 - Epoch: [226][0/6]	Total Loss: 0.77276	Main MSE (x10^-2): 77.2763	LR: 2.32e-04	EMPP_Raw: 1.50890
2025-07-18 10:11:33,661 - logger.py:50 - Epoch: [226][5/6]	Total Loss: 0.75122	Main MSE (x10^-2): 75.1219	LR: 2.32e-04	EMPP_Raw: 1.46320
2025-07-18 10:11:33,708 - logger.py:50 - Epoch 226 Training Summary: Avg Total Loss: 0.75122, Avg Main MSE: 0.75122, Time: 16.99s
2025-07-18 10:11:51,635 - logger.py:50 - Epoch 226 Summary | Train MSE (x10^-2): 75.1219 | Val MSE (x10^-2): 77.3474 | Time: 34.92s
2025-07-18 10:11:54,667 - logger.py:50 - Epoch: [227][0/6]	Total Loss: 0.76860	Main MSE (x10^-2): 76.8596	LR: 2.30e-04	EMPP_Raw: 1.49173
2025-07-18 10:12:08,497 - logger.py:50 - Epoch: [227][5/6]	Total Loss: 0.75306	Main MSE (x10^-2): 75.3061	LR: 2.30e-04	EMPP_Raw: 1.45946
2025-07-18 10:12:08,542 - logger.py:50 - Epoch 227 Training Summary: Avg Total Loss: 0.75306, Avg Main MSE: 0.75306, Time: 16.90s
2025-07-18 10:12:26,504 - logger.py:50 - Epoch 227 Summary | Train MSE (x10^-2): 75.3061 | Val MSE (x10^-2): 77.5849 | Time: 34.86s
2025-07-18 10:12:29,678 - logger.py:50 - Epoch: [228][0/6]	Total Loss: 0.77392	Main MSE (x10^-2): 77.3922	LR: 2.29e-04	EMPP_Raw: 1.50134
2025-07-18 10:12:43,457 - logger.py:50 - Epoch: [228][5/6]	Total Loss: 0.75422	Main MSE (x10^-2): 75.4221	LR: 2.29e-04	EMPP_Raw: 1.46637
2025-07-18 10:12:43,504 - logger.py:50 - Epoch 228 Training Summary: Avg Total Loss: 0.75422, Avg Main MSE: 0.75422, Time: 16.99s
2025-07-18 10:13:01,436 - logger.py:50 - Epoch 228 Summary | Train MSE (x10^-2): 75.4221 | Val MSE (x10^-2): 78.1778 | Time: 34.93s
2025-07-18 10:13:04,610 - logger.py:50 - Epoch: [229][0/6]	Total Loss: 0.76594	Main MSE (x10^-2): 76.5944	LR: 2.28e-04	EMPP_Raw: 1.49279
2025-07-18 10:13:18,406 - logger.py:50 - Epoch: [229][5/6]	Total Loss: 0.75189	Main MSE (x10^-2): 75.1887	LR: 2.28e-04	EMPP_Raw: 1.46146
2025-07-18 10:13:18,443 - logger.py:50 - Epoch 229 Training Summary: Avg Total Loss: 0.75189, Avg Main MSE: 0.75189, Time: 17.00s
2025-07-18 10:13:36,368 - logger.py:50 - Epoch 229 Summary | Train MSE (x10^-2): 75.1887 | Val MSE (x10^-2): 77.0689 | Time: 34.93s
2025-07-18 10:13:39,381 - logger.py:50 - Epoch: [230][0/6]	Total Loss: 0.74893	Main MSE (x10^-2): 74.8925	LR: 2.27e-04	EMPP_Raw: 1.45164
2025-07-18 10:13:53,414 - logger.py:50 - Epoch: [230][5/6]	Total Loss: 0.75368	Main MSE (x10^-2): 75.3683	LR: 2.27e-04	EMPP_Raw: 1.46434
2025-07-18 10:13:53,456 - logger.py:50 - Epoch 230 Training Summary: Avg Total Loss: 0.75368, Avg Main MSE: 0.75368, Time: 17.08s
2025-07-18 10:14:11,333 - logger.py:50 - Epoch 230 Summary | Train MSE (x10^-2): 75.3683 | Val MSE (x10^-2): 80.3722 | Time: 34.96s
2025-07-18 10:14:14,340 - logger.py:50 - Epoch: [231][0/6]	Total Loss: 0.76476	Main MSE (x10^-2): 76.4758	LR: 2.26e-04	EMPP_Raw: 1.48771
2025-07-18 10:14:28,122 - logger.py:50 - Epoch: [231][5/6]	Total Loss: 0.75063	Main MSE (x10^-2): 75.0633	LR: 2.26e-04	EMPP_Raw: 1.46067
2025-07-18 10:14:28,167 - logger.py:50 - Epoch 231 Training Summary: Avg Total Loss: 0.75063, Avg Main MSE: 0.75063, Time: 16.82s
2025-07-18 10:14:46,351 - logger.py:50 - Epoch 231 Summary | Train MSE (x10^-2): 75.0633 | Val MSE (x10^-2): 79.0793 | Time: 35.01s
2025-07-18 10:14:49,352 - logger.py:50 - Epoch: [232][0/6]	Total Loss: 0.75151	Main MSE (x10^-2): 75.1515	LR: 2.24e-04	EMPP_Raw: 1.46638
2025-07-18 10:15:03,222 - logger.py:50 - Epoch: [232][5/6]	Total Loss: 0.75041	Main MSE (x10^-2): 75.0414	LR: 2.24e-04	EMPP_Raw: 1.46007
2025-07-18 10:15:03,265 - logger.py:50 - Epoch 232 Training Summary: Avg Total Loss: 0.75041, Avg Main MSE: 0.75041, Time: 16.90s
2025-07-18 10:15:21,302 - logger.py:50 - Epoch 232 Summary | Train MSE (x10^-2): 75.0414 | Val MSE (x10^-2): 78.7210 | Time: 34.94s
2025-07-18 10:15:24,474 - logger.py:50 - Epoch: [233][0/6]	Total Loss: 0.75983	Main MSE (x10^-2): 75.9830	LR: 2.23e-04	EMPP_Raw: 1.47934
2025-07-18 10:15:38,325 - logger.py:50 - Epoch: [233][5/6]	Total Loss: 0.75046	Main MSE (x10^-2): 75.0458	LR: 2.23e-04	EMPP_Raw: 1.45907
2025-07-18 10:15:38,376 - logger.py:50 - Epoch 233 Training Summary: Avg Total Loss: 0.75046, Avg Main MSE: 0.75046, Time: 17.06s
2025-07-18 10:15:56,289 - logger.py:50 - Epoch 233 Summary | Train MSE (x10^-2): 75.0458 | Val MSE (x10^-2): 77.2242 | Time: 34.98s
2025-07-18 10:15:59,296 - logger.py:50 - Epoch: [234][0/6]	Total Loss: 0.74374	Main MSE (x10^-2): 74.3743	LR: 2.22e-04	EMPP_Raw: 1.44279
2025-07-18 10:16:13,262 - logger.py:50 - Epoch: [234][5/6]	Total Loss: 0.74820	Main MSE (x10^-2): 74.8198	LR: 2.22e-04	EMPP_Raw: 1.45147
2025-07-18 10:16:13,306 - logger.py:50 - Epoch 234 Training Summary: Avg Total Loss: 0.74820, Avg Main MSE: 0.74820, Time: 17.01s
2025-07-18 10:16:31,287 - logger.py:50 - Epoch 234 Summary | Train MSE (x10^-2): 74.8198 | Val MSE (x10^-2): 78.2915 | Time: 34.99s
2025-07-18 10:16:34,367 - logger.py:50 - Epoch: [235][0/6]	Total Loss: 0.72850	Main MSE (x10^-2): 72.8501	LR: 2.21e-04	EMPP_Raw: 1.41597
2025-07-18 10:16:48,197 - logger.py:50 - Epoch: [235][5/6]	Total Loss: 0.75078	Main MSE (x10^-2): 75.0778	LR: 2.21e-04	EMPP_Raw: 1.46011
2025-07-18 10:16:48,240 - logger.py:50 - Epoch 235 Training Summary: Avg Total Loss: 0.75078, Avg Main MSE: 0.75078, Time: 16.94s
2025-07-18 10:17:06,379 - logger.py:50 - Epoch 235 Summary | Train MSE (x10^-2): 75.0778 | Val MSE (x10^-2): 80.6926 | Time: 35.09s
2025-07-18 10:17:09,380 - logger.py:50 - Epoch: [236][0/6]	Total Loss: 0.77965	Main MSE (x10^-2): 77.9651	LR: 2.19e-04	EMPP_Raw: 1.51969
2025-07-18 10:17:23,200 - logger.py:50 - Epoch: [236][5/6]	Total Loss: 0.76240	Main MSE (x10^-2): 76.2398	LR: 2.19e-04	EMPP_Raw: 1.48423
2025-07-18 10:17:23,240 - logger.py:50 - Epoch 236 Training Summary: Avg Total Loss: 0.76240, Avg Main MSE: 0.76240, Time: 16.85s
2025-07-18 10:17:41,345 - logger.py:50 - Epoch 236 Summary | Train MSE (x10^-2): 76.2398 | Val MSE (x10^-2): 79.7855 | Time: 34.96s
2025-07-18 10:17:44,352 - logger.py:50 - Epoch: [237][0/6]	Total Loss: 0.75708	Main MSE (x10^-2): 75.7078	LR: 2.18e-04	EMPP_Raw: 1.47774
2025-07-18 10:17:58,136 - logger.py:50 - Epoch: [237][5/6]	Total Loss: 0.75355	Main MSE (x10^-2): 75.3547	LR: 2.18e-04	EMPP_Raw: 1.46931
2025-07-18 10:17:58,183 - logger.py:50 - Epoch 237 Training Summary: Avg Total Loss: 0.75355, Avg Main MSE: 0.75355, Time: 16.83s
2025-07-18 10:18:16,085 - logger.py:50 - Epoch 237 Summary | Train MSE (x10^-2): 75.3547 | Val MSE (x10^-2): 80.7790 | Time: 34.73s
2025-07-18 10:18:19,545 - logger.py:50 - Epoch: [238][0/6]	Total Loss: 0.75360	Main MSE (x10^-2): 75.3600	LR: 2.17e-04	EMPP_Raw: 1.46911
2025-07-18 10:18:33,319 - logger.py:50 - Epoch: [238][5/6]	Total Loss: 0.75914	Main MSE (x10^-2): 75.9144	LR: 2.17e-04	EMPP_Raw: 1.47970
2025-07-18 10:18:33,369 - logger.py:50 - Epoch 238 Training Summary: Avg Total Loss: 0.75914, Avg Main MSE: 0.75914, Time: 17.27s
2025-07-18 10:18:51,722 - logger.py:50 - Epoch 238 Summary | Train MSE (x10^-2): 75.9144 | Val MSE (x10^-2): 80.2579 | Time: 35.63s
2025-07-18 10:18:54,968 - logger.py:50 - Epoch: [239][0/6]	Total Loss: 0.77603	Main MSE (x10^-2): 77.6033	LR: 2.16e-04	EMPP_Raw: 1.51063
2025-07-18 10:19:08,810 - logger.py:50 - Epoch: [239][5/6]	Total Loss: 0.75749	Main MSE (x10^-2): 75.7491	LR: 2.16e-04	EMPP_Raw: 1.47418
2025-07-18 10:19:08,859 - logger.py:50 - Epoch 239 Training Summary: Avg Total Loss: 0.75749, Avg Main MSE: 0.75749, Time: 17.13s
2025-07-18 10:19:26,838 - logger.py:50 - Epoch 239 Summary | Train MSE (x10^-2): 75.7491 | Val MSE (x10^-2): 78.8849 | Time: 35.11s
2025-07-18 10:19:29,892 - logger.py:50 - Epoch: [240][0/6]	Total Loss: 0.74246	Main MSE (x10^-2): 74.2457	LR: 2.14e-04	EMPP_Raw: 1.43773
2025-07-18 10:19:43,938 - logger.py:50 - Epoch: [240][5/6]	Total Loss: 0.75417	Main MSE (x10^-2): 75.4172	LR: 2.14e-04	EMPP_Raw: 1.46921
2025-07-18 10:19:43,977 - logger.py:50 - Epoch 240 Training Summary: Avg Total Loss: 0.75417, Avg Main MSE: 0.75417, Time: 17.13s
2025-07-18 10:20:01,893 - logger.py:50 - Epoch 240 Summary | Train MSE (x10^-2): 75.4172 | Val MSE (x10^-2): 79.2861 | Time: 35.05s
2025-07-18 10:20:04,898 - logger.py:50 - Epoch: [241][0/6]	Total Loss: 0.76245	Main MSE (x10^-2): 76.2451	LR: 2.13e-04	EMPP_Raw: 1.48356
2025-07-18 10:20:18,725 - logger.py:50 - Epoch: [241][5/6]	Total Loss: 0.75438	Main MSE (x10^-2): 75.4381	LR: 2.13e-04	EMPP_Raw: 1.47048
2025-07-18 10:20:18,766 - logger.py:50 - Epoch 241 Training Summary: Avg Total Loss: 0.75438, Avg Main MSE: 0.75438, Time: 16.86s
2025-07-18 10:20:36,870 - logger.py:50 - Epoch 241 Summary | Train MSE (x10^-2): 75.4381 | Val MSE (x10^-2): 79.8710 | Time: 34.97s
2025-07-18 10:20:39,902 - logger.py:50 - Epoch: [242][0/6]	Total Loss: 0.74896	Main MSE (x10^-2): 74.8962	LR: 2.12e-04	EMPP_Raw: 1.46111
2025-07-18 10:20:53,704 - logger.py:50 - Epoch: [242][5/6]	Total Loss: 0.74835	Main MSE (x10^-2): 74.8354	LR: 2.12e-04	EMPP_Raw: 1.45896
2025-07-18 10:20:53,741 - logger.py:50 - Epoch 242 Training Summary: Avg Total Loss: 0.74835, Avg Main MSE: 0.74835, Time: 16.86s
2025-07-18 10:21:11,848 - logger.py:50 - Epoch 242 Summary | Train MSE (x10^-2): 74.8354 | Val MSE (x10^-2): 80.4417 | Time: 34.97s
2025-07-18 10:21:14,866 - logger.py:50 - Epoch: [243][0/6]	Total Loss: 0.74252	Main MSE (x10^-2): 74.2516	LR: 2.11e-04	EMPP_Raw: 1.44162
2025-07-18 10:21:28,658 - logger.py:50 - Epoch: [243][5/6]	Total Loss: 0.75925	Main MSE (x10^-2): 75.9251	LR: 2.11e-04	EMPP_Raw: 1.47856
2025-07-18 10:21:28,700 - logger.py:50 - Epoch 243 Training Summary: Avg Total Loss: 0.75925, Avg Main MSE: 0.75925, Time: 16.84s
2025-07-18 10:21:46,606 - logger.py:50 - Epoch 243 Summary | Train MSE (x10^-2): 75.9251 | Val MSE (x10^-2): 79.2398 | Time: 34.75s
2025-07-18 10:21:49,798 - logger.py:50 - Epoch: [244][0/6]	Total Loss: 0.75992	Main MSE (x10^-2): 75.9916	LR: 2.09e-04	EMPP_Raw: 1.48233
2025-07-18 10:22:03,604 - logger.py:50 - Epoch: [244][5/6]	Total Loss: 0.74756	Main MSE (x10^-2): 74.7557	LR: 2.09e-04	EMPP_Raw: 1.45529
2025-07-18 10:22:03,649 - logger.py:50 - Epoch 244 Training Summary: Avg Total Loss: 0.74756, Avg Main MSE: 0.74756, Time: 17.03s
2025-07-18 10:22:21,545 - logger.py:50 - Epoch 244 Summary | Train MSE (x10^-2): 74.7557 | Val MSE (x10^-2): 77.5715 | Time: 34.93s
2025-07-18 10:22:24,600 - logger.py:50 - Epoch: [245][0/6]	Total Loss: 0.74966	Main MSE (x10^-2): 74.9661	LR: 2.08e-04	EMPP_Raw: 1.46602
2025-07-18 10:22:38,523 - logger.py:50 - Epoch: [245][5/6]	Total Loss: 0.74942	Main MSE (x10^-2): 74.9422	LR: 2.08e-04	EMPP_Raw: 1.46104
2025-07-18 10:22:38,570 - logger.py:50 - Epoch 245 Training Summary: Avg Total Loss: 0.74942, Avg Main MSE: 0.74942, Time: 17.01s
2025-07-18 10:22:56,533 - logger.py:50 - Epoch 245 Summary | Train MSE (x10^-2): 74.9422 | Val MSE (x10^-2): 77.7924 | Time: 34.98s
2025-07-18 10:22:59,580 - logger.py:50 - Epoch: [246][0/6]	Total Loss: 0.74947	Main MSE (x10^-2): 74.9469	LR: 2.07e-04	EMPP_Raw: 1.46397
2025-07-18 10:23:13,533 - logger.py:50 - Epoch: [246][5/6]	Total Loss: 0.74990	Main MSE (x10^-2): 74.9904	LR: 2.07e-04	EMPP_Raw: 1.46372
2025-07-18 10:23:13,579 - logger.py:50 - Epoch 246 Training Summary: Avg Total Loss: 0.74990, Avg Main MSE: 0.74990, Time: 17.04s
2025-07-18 10:23:31,479 - logger.py:50 - Epoch 246 Summary | Train MSE (x10^-2): 74.9904 | Val MSE (x10^-2): 77.6086 | Time: 34.94s
2025-07-18 10:23:34,485 - logger.py:50 - Epoch: [247][0/6]	Total Loss: 0.76892	Main MSE (x10^-2): 76.8916	LR: 2.06e-04	EMPP_Raw: 1.50563
2025-07-18 10:23:48,312 - logger.py:50 - Epoch: [247][5/6]	Total Loss: 0.75561	Main MSE (x10^-2): 75.5615	LR: 2.06e-04	EMPP_Raw: 1.47533
2025-07-18 10:23:48,356 - logger.py:50 - Epoch 247 Training Summary: Avg Total Loss: 0.75561, Avg Main MSE: 0.75561, Time: 16.87s
2025-07-18 10:24:06,245 - logger.py:50 - Epoch 247 Summary | Train MSE (x10^-2): 75.5615 | Val MSE (x10^-2): 78.2254 | Time: 34.76s
2025-07-18 10:24:09,457 - logger.py:50 - Epoch: [248][0/6]	Total Loss: 0.73224	Main MSE (x10^-2): 73.2240	LR: 2.04e-04	EMPP_Raw: 1.43051
2025-07-18 10:24:23,222 - logger.py:50 - Epoch: [248][5/6]	Total Loss: 0.74490	Main MSE (x10^-2): 74.4895	LR: 2.04e-04	EMPP_Raw: 1.45105
2025-07-18 10:24:23,262 - logger.py:50 - Epoch 248 Training Summary: Avg Total Loss: 0.74490, Avg Main MSE: 0.74490, Time: 17.01s
2025-07-18 10:24:41,124 - logger.py:50 - Epoch 248 Summary | Train MSE (x10^-2): 74.4895 | Val MSE (x10^-2): 76.9927 | Time: 34.87s
2025-07-18 10:24:44,312 - logger.py:50 - Epoch: [249][0/6]	Total Loss: 0.75010	Main MSE (x10^-2): 75.0100	LR: 2.03e-04	EMPP_Raw: 1.46307
2025-07-18 10:24:58,043 - logger.py:50 - Epoch: [249][5/6]	Total Loss: 0.75082	Main MSE (x10^-2): 75.0823	LR: 2.03e-04	EMPP_Raw: 1.46465
2025-07-18 10:24:58,088 - logger.py:50 - Epoch 249 Training Summary: Avg Total Loss: 0.75082, Avg Main MSE: 0.75082, Time: 16.96s
2025-07-18 10:25:15,947 - logger.py:50 - Epoch 249 Summary | Train MSE (x10^-2): 75.0823 | Val MSE (x10^-2): 77.4226 | Time: 34.82s
2025-07-18 10:25:18,956 - logger.py:50 - Epoch: [250][0/6]	Total Loss: 0.75331	Main MSE (x10^-2): 75.3309	LR: 2.02e-04	EMPP_Raw: 1.47312
2025-07-18 10:25:32,873 - logger.py:50 - Epoch: [250][5/6]	Total Loss: 0.75136	Main MSE (x10^-2): 75.1361	LR: 2.02e-04	EMPP_Raw: 1.46492
2025-07-18 10:25:32,917 - logger.py:50 - Epoch 250 Training Summary: Avg Total Loss: 0.75136, Avg Main MSE: 0.75136, Time: 16.96s
2025-07-18 10:25:50,913 - logger.py:50 - Epoch 250 Summary | Train MSE (x10^-2): 75.1361 | Val MSE (x10^-2): 80.0787 | Time: 34.96s
2025-07-18 10:25:53,921 - logger.py:50 - Epoch: [251][0/6]	Total Loss: 0.77233	Main MSE (x10^-2): 77.2328	LR: 2.00e-04	EMPP_Raw: 1.50978
2025-07-18 10:26:07,724 - logger.py:50 - Epoch: [251][5/6]	Total Loss: 0.75476	Main MSE (x10^-2): 75.4761	LR: 2.00e-04	EMPP_Raw: 1.47443
2025-07-18 10:26:07,766 - logger.py:50 - Epoch 251 Training Summary: Avg Total Loss: 0.75476, Avg Main MSE: 0.75476, Time: 16.84s
2025-07-18 10:26:25,858 - logger.py:50 - Epoch 251 Summary | Train MSE (x10^-2): 75.4761 | Val MSE (x10^-2): 79.5609 | Time: 34.94s
2025-07-18 10:26:28,859 - logger.py:50 - Epoch: [252][0/6]	Total Loss: 0.74627	Main MSE (x10^-2): 74.6265	LR: 1.99e-04	EMPP_Raw: 1.46046
2025-07-18 10:26:42,658 - logger.py:50 - Epoch: [252][5/6]	Total Loss: 0.74287	Main MSE (x10^-2): 74.2867	LR: 1.99e-04	EMPP_Raw: 1.45267
2025-07-18 10:26:42,699 - logger.py:50 - Epoch 252 Training Summary: Avg Total Loss: 0.74287, Avg Main MSE: 0.74287, Time: 16.83s
2025-07-18 10:27:00,642 - logger.py:50 - Epoch 252 Summary | Train MSE (x10^-2): 74.2867 | Val MSE (x10^-2): 80.4183 | Time: 34.78s
2025-07-18 10:27:03,843 - logger.py:50 - Epoch: [253][0/6]	Total Loss: 0.74109	Main MSE (x10^-2): 74.1094	LR: 1.98e-04	EMPP_Raw: 1.44492
2025-07-18 10:27:17,622 - logger.py:50 - Epoch: [253][5/6]	Total Loss: 0.75223	Main MSE (x10^-2): 75.2228	LR: 1.98e-04	EMPP_Raw: 1.47049
2025-07-18 10:27:17,666 - logger.py:50 - Epoch 253 Training Summary: Avg Total Loss: 0.75223, Avg Main MSE: 0.75223, Time: 17.02s
2025-07-18 10:27:35,598 - logger.py:50 - Epoch 253 Summary | Train MSE (x10^-2): 75.2228 | Val MSE (x10^-2): 78.6925 | Time: 34.95s
2025-07-18 10:27:38,591 - logger.py:50 - Epoch: [254][0/6]	Total Loss: 0.73535	Main MSE (x10^-2): 73.5346	LR: 1.97e-04	EMPP_Raw: 1.43584
2025-07-18 10:27:52,532 - logger.py:50 - Epoch: [254][5/6]	Total Loss: 0.75061	Main MSE (x10^-2): 75.0607	LR: 1.97e-04	EMPP_Raw: 1.46687
2025-07-18 10:27:52,577 - logger.py:50 - Epoch 254 Training Summary: Avg Total Loss: 0.75061, Avg Main MSE: 0.75061, Time: 16.97s
2025-07-18 10:28:10,451 - logger.py:50 - Epoch 254 Summary | Train MSE (x10^-2): 75.0607 | Val MSE (x10^-2): 79.0459 | Time: 34.85s
2025-07-18 10:28:13,483 - logger.py:50 - Epoch: [255][0/6]	Total Loss: 0.74083	Main MSE (x10^-2): 74.0830	LR: 1.95e-04	EMPP_Raw: 1.45172
2025-07-18 10:28:27,255 - logger.py:50 - Epoch: [255][5/6]	Total Loss: 0.73959	Main MSE (x10^-2): 73.9587	LR: 1.95e-04	EMPP_Raw: 1.44660
2025-07-18 10:28:27,300 - logger.py:50 - Epoch 255 Training Summary: Avg Total Loss: 0.73959, Avg Main MSE: 0.73959, Time: 16.84s
2025-07-18 10:28:45,368 - logger.py:50 - Epoch 255 Summary | Train MSE (x10^-2): 73.9587 | Val MSE (x10^-2): 78.8342 | Time: 34.91s
2025-07-18 10:28:48,434 - logger.py:50 - Epoch: [256][0/6]	Total Loss: 0.75390	Main MSE (x10^-2): 75.3900	LR: 1.94e-04	EMPP_Raw: 1.47760
2025-07-18 10:29:02,287 - logger.py:50 - Epoch: [256][5/6]	Total Loss: 0.73897	Main MSE (x10^-2): 73.8967	LR: 1.94e-04	EMPP_Raw: 1.44542
2025-07-18 10:29:02,334 - logger.py:50 - Epoch 256 Training Summary: Avg Total Loss: 0.73897, Avg Main MSE: 0.73897, Time: 16.96s
2025-07-18 10:29:20,407 - logger.py:50 - Epoch 256 Summary | Train MSE (x10^-2): 73.8967 | Val MSE (x10^-2): 77.7007 | Time: 35.03s
2025-07-18 10:29:23,413 - logger.py:50 - Epoch: [257][0/6]	Total Loss: 0.76381	Main MSE (x10^-2): 76.3806	LR: 1.93e-04	EMPP_Raw: 1.49246
2025-07-18 10:29:37,176 - logger.py:50 - Epoch: [257][5/6]	Total Loss: 0.75467	Main MSE (x10^-2): 75.4671	LR: 1.93e-04	EMPP_Raw: 1.47412
2025-07-18 10:29:37,220 - logger.py:50 - Epoch 257 Training Summary: Avg Total Loss: 0.75467, Avg Main MSE: 0.75467, Time: 16.80s
2025-07-18 10:29:55,065 - logger.py:50 - Epoch 257 Summary | Train MSE (x10^-2): 75.4671 | Val MSE (x10^-2): 79.4513 | Time: 34.65s
2025-07-18 10:29:58,389 - logger.py:50 - Epoch: [258][0/6]	Total Loss: 0.74667	Main MSE (x10^-2): 74.6667	LR: 1.92e-04	EMPP_Raw: 1.46349
2025-07-18 10:30:12,120 - logger.py:50 - Epoch: [258][5/6]	Total Loss: 0.74720	Main MSE (x10^-2): 74.7200	LR: 1.92e-04	EMPP_Raw: 1.45976
2025-07-18 10:30:12,172 - logger.py:50 - Epoch 258 Training Summary: Avg Total Loss: 0.74720, Avg Main MSE: 0.74720, Time: 17.10s
2025-07-18 10:30:30,114 - logger.py:50 - Epoch 258 Summary | Train MSE (x10^-2): 74.7200 | Val MSE (x10^-2): 77.4514 | Time: 35.05s
2025-07-18 10:30:33,324 - logger.py:50 - Epoch: [259][0/6]	Total Loss: 0.75982	Main MSE (x10^-2): 75.9817	LR: 1.90e-04	EMPP_Raw: 1.48636
2025-07-18 10:30:47,083 - logger.py:50 - Epoch: [259][5/6]	Total Loss: 0.75016	Main MSE (x10^-2): 75.0164	LR: 1.90e-04	EMPP_Raw: 1.46637
2025-07-18 10:30:47,127 - logger.py:50 - Epoch 259 Training Summary: Avg Total Loss: 0.75016, Avg Main MSE: 0.75016, Time: 17.00s
2025-07-18 10:31:05,014 - logger.py:50 - Epoch 259 Summary | Train MSE (x10^-2): 75.0164 | Val MSE (x10^-2): 78.1367 | Time: 34.89s
2025-07-18 10:31:08,049 - logger.py:50 - Epoch: [260][0/6]	Total Loss: 0.73546	Main MSE (x10^-2): 73.5462	LR: 1.89e-04	EMPP_Raw: 1.43709
2025-07-18 10:31:21,996 - logger.py:50 - Epoch: [260][5/6]	Total Loss: 0.74973	Main MSE (x10^-2): 74.9734	LR: 1.89e-04	EMPP_Raw: 1.46498
2025-07-18 10:31:22,038 - logger.py:50 - Epoch 260 Training Summary: Avg Total Loss: 0.74973, Avg Main MSE: 0.74973, Time: 17.01s
2025-07-18 10:31:39,845 - logger.py:50 - Epoch 260 Summary | Train MSE (x10^-2): 74.9734 | Val MSE (x10^-2): 78.9318 | Time: 34.82s
2025-07-18 10:31:42,831 - logger.py:50 - Epoch: [261][0/6]	Total Loss: 0.74127	Main MSE (x10^-2): 74.1269	LR: 1.88e-04	EMPP_Raw: 1.44682
2025-07-18 10:31:56,608 - logger.py:50 - Epoch: [261][5/6]	Total Loss: 0.73863	Main MSE (x10^-2): 73.8633	LR: 1.88e-04	EMPP_Raw: 1.44285
2025-07-18 10:31:56,656 - logger.py:50 - Epoch 261 Training Summary: Avg Total Loss: 0.73863, Avg Main MSE: 0.73863, Time: 16.80s
2025-07-18 10:32:14,739 - logger.py:50 - Epoch 261 Summary | Train MSE (x10^-2): 73.8633 | Val MSE (x10^-2): 79.0449 | Time: 34.89s
2025-07-18 10:32:17,742 - logger.py:50 - Epoch: [262][0/6]	Total Loss: 0.74799	Main MSE (x10^-2): 74.7987	LR: 1.87e-04	EMPP_Raw: 1.46488
2025-07-18 10:32:31,567 - logger.py:50 - Epoch: [262][5/6]	Total Loss: 0.75714	Main MSE (x10^-2): 75.7142	LR: 1.87e-04	EMPP_Raw: 1.48174
2025-07-18 10:32:31,613 - logger.py:50 - Epoch 262 Training Summary: Avg Total Loss: 0.75714, Avg Main MSE: 0.75714, Time: 16.87s
2025-07-18 10:32:49,664 - logger.py:50 - Epoch 262 Summary | Train MSE (x10^-2): 75.7142 | Val MSE (x10^-2): 79.7043 | Time: 34.92s
2025-07-18 10:32:52,678 - logger.py:50 - Epoch: [263][0/6]	Total Loss: 0.75399	Main MSE (x10^-2): 75.3989	LR: 1.85e-04	EMPP_Raw: 1.47543
2025-07-18 10:33:06,417 - logger.py:50 - Epoch: [263][5/6]	Total Loss: 0.74467	Main MSE (x10^-2): 74.4665	LR: 1.85e-04	EMPP_Raw: 1.45581
2025-07-18 10:33:06,467 - logger.py:50 - Epoch 263 Training Summary: Avg Total Loss: 0.74467, Avg Main MSE: 0.74467, Time: 16.79s
2025-07-18 10:33:24,315 - logger.py:50 - Epoch 263 Summary | Train MSE (x10^-2): 74.4665 | Val MSE (x10^-2): 79.6800 | Time: 34.64s
2025-07-18 10:33:27,529 - logger.py:50 - Epoch: [264][0/6]	Total Loss: 0.73755	Main MSE (x10^-2): 73.7554	LR: 1.84e-04	EMPP_Raw: 1.44016
2025-07-18 10:33:41,233 - logger.py:50 - Epoch: [264][5/6]	Total Loss: 0.74559	Main MSE (x10^-2): 74.5587	LR: 1.84e-04	EMPP_Raw: 1.45762
2025-07-18 10:33:41,278 - logger.py:50 - Epoch 264 Training Summary: Avg Total Loss: 0.74559, Avg Main MSE: 0.74559, Time: 16.96s
2025-07-18 10:33:59,185 - logger.py:50 - Epoch 264 Summary | Train MSE (x10^-2): 74.5587 | Val MSE (x10^-2): 79.3293 | Time: 34.87s
2025-07-18 10:34:02,224 - logger.py:50 - Epoch: [265][0/6]	Total Loss: 0.74102	Main MSE (x10^-2): 74.1023	LR: 1.83e-04	EMPP_Raw: 1.44591
2025-07-18 10:34:16,118 - logger.py:50 - Epoch: [265][5/6]	Total Loss: 0.74556	Main MSE (x10^-2): 74.5563	LR: 1.83e-04	EMPP_Raw: 1.45728
2025-07-18 10:34:16,160 - logger.py:50 - Epoch 265 Training Summary: Avg Total Loss: 0.74556, Avg Main MSE: 0.74556, Time: 16.96s
2025-07-18 10:34:34,068 - logger.py:50 - Epoch 265 Summary | Train MSE (x10^-2): 74.5563 | Val MSE (x10^-2): 79.3941 | Time: 34.88s
2025-07-18 10:34:37,066 - logger.py:50 - Epoch: [266][0/6]	Total Loss: 0.74771	Main MSE (x10^-2): 74.7707	LR: 1.82e-04	EMPP_Raw: 1.45551
2025-07-18 10:34:50,997 - logger.py:50 - Epoch: [266][5/6]	Total Loss: 0.74107	Main MSE (x10^-2): 74.1068	LR: 1.82e-04	EMPP_Raw: 1.44696
2025-07-18 10:34:51,039 - logger.py:50 - Epoch 266 Training Summary: Avg Total Loss: 0.74107, Avg Main MSE: 0.74107, Time: 16.96s
2025-07-18 10:35:09,067 - logger.py:50 - Epoch 266 Summary | Train MSE (x10^-2): 74.1068 | Val MSE (x10^-2): 78.9648 | Time: 34.99s
2025-07-18 10:35:12,086 - logger.py:50 - Epoch: [267][0/6]	Total Loss: 0.73856	Main MSE (x10^-2): 73.8556	LR: 1.80e-04	EMPP_Raw: 1.43894
2025-07-18 10:35:26,052 - logger.py:50 - Epoch: [267][5/6]	Total Loss: 0.74749	Main MSE (x10^-2): 74.7488	LR: 1.80e-04	EMPP_Raw: 1.46087
2025-07-18 10:35:26,092 - logger.py:50 - Epoch 267 Training Summary: Avg Total Loss: 0.74749, Avg Main MSE: 0.74749, Time: 17.02s
2025-07-18 10:35:44,060 - logger.py:50 - Epoch 267 Summary | Train MSE (x10^-2): 74.7488 | Val MSE (x10^-2): 79.2963 | Time: 34.99s
2025-07-18 10:35:47,209 - logger.py:50 - Epoch: [268][0/6]	Total Loss: 0.74448	Main MSE (x10^-2): 74.4483	LR: 1.79e-04	EMPP_Raw: 1.45428
2025-07-18 10:36:00,959 - logger.py:50 - Epoch: [268][5/6]	Total Loss: 0.74213	Main MSE (x10^-2): 74.2134	LR: 1.79e-04	EMPP_Raw: 1.45237
2025-07-18 10:36:00,998 - logger.py:50 - Epoch 268 Training Summary: Avg Total Loss: 0.74213, Avg Main MSE: 0.74213, Time: 16.93s
2025-07-18 10:36:19,055 - logger.py:50 - Epoch 268 Summary | Train MSE (x10^-2): 74.2134 | Val MSE (x10^-2): 79.6849 | Time: 34.99s
2025-07-18 10:36:22,277 - logger.py:50 - Epoch: [269][0/6]	Total Loss: 0.74535	Main MSE (x10^-2): 74.5351	LR: 1.78e-04	EMPP_Raw: 1.45623
2025-07-18 10:36:36,038 - logger.py:50 - Epoch: [269][5/6]	Total Loss: 0.73759	Main MSE (x10^-2): 73.7592	LR: 1.78e-04	EMPP_Raw: 1.44169
2025-07-18 10:36:36,078 - logger.py:50 - Epoch 269 Training Summary: Avg Total Loss: 0.73759, Avg Main MSE: 0.73759, Time: 17.01s
2025-07-18 10:36:54,015 - logger.py:50 - Epoch 269 Summary | Train MSE (x10^-2): 73.7592 | Val MSE (x10^-2): 77.9010 | Time: 34.95s
2025-07-18 10:36:57,068 - logger.py:50 - Epoch: [270][0/6]	Total Loss: 0.74364	Main MSE (x10^-2): 74.3635	LR: 1.77e-04	EMPP_Raw: 1.45378
2025-07-18 10:37:11,015 - logger.py:50 - Epoch: [270][5/6]	Total Loss: 0.73945	Main MSE (x10^-2): 73.9453	LR: 1.77e-04	EMPP_Raw: 1.44577
2025-07-18 10:37:11,058 - logger.py:50 - Epoch 270 Training Summary: Avg Total Loss: 0.73945, Avg Main MSE: 0.73945, Time: 17.03s
2025-07-18 10:37:29,137 - logger.py:50 - Epoch 270 Summary | Train MSE (x10^-2): 73.9453 | Val MSE (x10^-2): 79.0878 | Time: 35.12s
2025-07-18 10:37:32,143 - logger.py:50 - Epoch: [271][0/6]	Total Loss: 0.72010	Main MSE (x10^-2): 72.0097	LR: 1.75e-04	EMPP_Raw: 1.40924
2025-07-18 10:37:45,957 - logger.py:50 - Epoch: [271][5/6]	Total Loss: 0.74418	Main MSE (x10^-2): 74.4177	LR: 1.75e-04	EMPP_Raw: 1.45425
2025-07-18 10:37:46,000 - logger.py:50 - Epoch 271 Training Summary: Avg Total Loss: 0.74418, Avg Main MSE: 0.74418, Time: 16.85s
2025-07-18 10:38:04,027 - logger.py:50 - Epoch 271 Summary | Train MSE (x10^-2): 74.4177 | Val MSE (x10^-2): 79.8852 | Time: 34.88s
2025-07-18 10:38:07,024 - logger.py:50 - Epoch: [272][0/6]	Total Loss: 0.74066	Main MSE (x10^-2): 74.0655	LR: 1.74e-04	EMPP_Raw: 1.44606
2025-07-18 10:38:20,778 - logger.py:50 - Epoch: [272][5/6]	Total Loss: 0.75575	Main MSE (x10^-2): 75.5750	LR: 1.74e-04	EMPP_Raw: 1.47558
2025-07-18 10:38:20,823 - logger.py:50 - Epoch 272 Training Summary: Avg Total Loss: 0.75575, Avg Main MSE: 0.75575, Time: 16.79s
2025-07-18 10:38:38,723 - logger.py:50 - Epoch 272 Summary | Train MSE (x10^-2): 75.5750 | Val MSE (x10^-2): 76.9283 | Time: 34.69s
2025-07-18 10:38:41,869 - logger.py:50 - Epoch: [273][0/6]	Total Loss: 0.75319	Main MSE (x10^-2): 75.3188	LR: 1.73e-04	EMPP_Raw: 1.46913
2025-07-18 10:38:55,650 - logger.py:50 - Epoch: [273][5/6]	Total Loss: 0.74745	Main MSE (x10^-2): 74.7448	LR: 1.73e-04	EMPP_Raw: 1.46072
2025-07-18 10:38:55,692 - logger.py:50 - Epoch 273 Training Summary: Avg Total Loss: 0.74745, Avg Main MSE: 0.74745, Time: 16.96s
2025-07-18 10:39:13,577 - logger.py:50 - Epoch 273 Summary | Train MSE (x10^-2): 74.7448 | Val MSE (x10^-2): 80.2179 | Time: 34.85s
2025-07-18 10:39:16,590 - logger.py:50 - Epoch: [274][0/6]	Total Loss: 0.72920	Main MSE (x10^-2): 72.9197	LR: 1.72e-04	EMPP_Raw: 1.42284
2025-07-18 10:39:30,522 - logger.py:50 - Epoch: [274][5/6]	Total Loss: 0.74281	Main MSE (x10^-2): 74.2806	LR: 1.72e-04	EMPP_Raw: 1.45233
2025-07-18 10:39:30,563 - logger.py:50 - Epoch 274 Training Summary: Avg Total Loss: 0.74281, Avg Main MSE: 0.74281, Time: 16.98s
2025-07-18 10:39:48,458 - logger.py:50 - Epoch 274 Summary | Train MSE (x10^-2): 74.2806 | Val MSE (x10^-2): 80.3646 | Time: 34.88s
2025-07-18 10:39:51,462 - logger.py:50 - Epoch: [275][0/6]	Total Loss: 0.74666	Main MSE (x10^-2): 74.6661	LR: 1.71e-04	EMPP_Raw: 1.46549
2025-07-18 10:40:05,249 - logger.py:50 - Epoch: [275][5/6]	Total Loss: 0.74354	Main MSE (x10^-2): 74.3540	LR: 1.71e-04	EMPP_Raw: 1.45671
2025-07-18 10:40:05,289 - logger.py:50 - Epoch 275 Training Summary: Avg Total Loss: 0.74354, Avg Main MSE: 0.74354, Time: 16.82s
2025-07-18 10:40:23,309 - logger.py:50 - Epoch 275 Summary | Train MSE (x10^-2): 74.3540 | Val MSE (x10^-2): 79.9440 | Time: 34.84s
2025-07-18 10:40:26,294 - logger.py:50 - Epoch: [276][0/6]	Total Loss: 0.73928	Main MSE (x10^-2): 73.9281	LR: 1.69e-04	EMPP_Raw: 1.45015
2025-07-18 10:40:40,077 - logger.py:50 - Epoch: [276][5/6]	Total Loss: 0.74717	Main MSE (x10^-2): 74.7169	LR: 1.69e-04	EMPP_Raw: 1.46421
2025-07-18 10:40:40,117 - logger.py:50 - Epoch 276 Training Summary: Avg Total Loss: 0.74717, Avg Main MSE: 0.74717, Time: 16.80s
2025-07-18 10:40:58,134 - logger.py:50 - Epoch 276 Summary | Train MSE (x10^-2): 74.7169 | Val MSE (x10^-2): 79.4622 | Time: 34.82s
2025-07-18 10:41:01,175 - logger.py:50 - Epoch: [277][0/6]	Total Loss: 0.75535	Main MSE (x10^-2): 75.5352	LR: 1.68e-04	EMPP_Raw: 1.48164
2025-07-18 10:41:14,920 - logger.py:50 - Epoch: [277][5/6]	Total Loss: 0.74447	Main MSE (x10^-2): 74.4473	LR: 1.68e-04	EMPP_Raw: 1.45837
2025-07-18 10:41:14,961 - logger.py:50 - Epoch 277 Training Summary: Avg Total Loss: 0.74447, Avg Main MSE: 0.74447, Time: 16.82s
2025-07-18 10:41:32,914 - logger.py:50 - Epoch 277 Summary | Train MSE (x10^-2): 74.4473 | Val MSE (x10^-2): 79.9456 | Time: 34.77s
2025-07-18 10:41:36,285 - logger.py:50 - Epoch: [278][0/6]	Total Loss: 0.77218	Main MSE (x10^-2): 77.2180	LR: 1.67e-04	EMPP_Raw: 1.51154
2025-07-18 10:41:50,003 - logger.py:50 - Epoch: [278][5/6]	Total Loss: 0.73947	Main MSE (x10^-2): 73.9467	LR: 1.67e-04	EMPP_Raw: 1.44784
2025-07-18 10:41:50,055 - logger.py:50 - Epoch 278 Training Summary: Avg Total Loss: 0.73947, Avg Main MSE: 0.73947, Time: 17.13s
2025-07-18 10:42:08,015 - logger.py:50 - Epoch 278 Summary | Train MSE (x10^-2): 73.9467 | Val MSE (x10^-2): 79.5348 | Time: 35.09s
2025-07-18 10:42:11,254 - logger.py:50 - Epoch: [279][0/6]	Total Loss: 0.76243	Main MSE (x10^-2): 76.2432	LR: 1.66e-04	EMPP_Raw: 1.49232
2025-07-18 10:42:25,088 - logger.py:50 - Epoch: [279][5/6]	Total Loss: 0.74460	Main MSE (x10^-2): 74.4599	LR: 1.66e-04	EMPP_Raw: 1.45665
2025-07-18 10:42:25,129 - logger.py:50 - Epoch 279 Training Summary: Avg Total Loss: 0.74460, Avg Main MSE: 0.74460, Time: 17.10s
2025-07-18 10:42:43,024 - logger.py:50 - Epoch 279 Summary | Train MSE (x10^-2): 74.4599 | Val MSE (x10^-2): 77.9814 | Time: 35.00s
2025-07-18 10:42:46,017 - logger.py:50 - Epoch: [280][0/6]	Total Loss: 0.74843	Main MSE (x10^-2): 74.8433	LR: 1.64e-04	EMPP_Raw: 1.46682
2025-07-18 10:42:59,969 - logger.py:50 - Epoch: [280][5/6]	Total Loss: 0.74959	Main MSE (x10^-2): 74.9588	LR: 1.64e-04	EMPP_Raw: 1.46694
2025-07-18 10:43:00,013 - logger.py:50 - Epoch 280 Training Summary: Avg Total Loss: 0.74959, Avg Main MSE: 0.74959, Time: 16.98s
2025-07-18 10:43:17,938 - logger.py:50 - Epoch 280 Summary | Train MSE (x10^-2): 74.9588 | Val MSE (x10^-2): 79.0793 | Time: 34.91s
2025-07-18 10:43:20,939 - logger.py:50 - Epoch: [281][0/6]	Total Loss: 0.74384	Main MSE (x10^-2): 74.3838	LR: 1.63e-04	EMPP_Raw: 1.45527
2025-07-18 10:43:34,721 - logger.py:50 - Epoch: [281][5/6]	Total Loss: 0.73738	Main MSE (x10^-2): 73.7380	LR: 1.63e-04	EMPP_Raw: 1.44309
2025-07-18 10:43:34,767 - logger.py:50 - Epoch 281 Training Summary: Avg Total Loss: 0.73738, Avg Main MSE: 0.73738, Time: 16.82s
2025-07-18 10:43:52,769 - logger.py:50 - Epoch 281 Summary | Train MSE (x10^-2): 73.7380 | Val MSE (x10^-2): 79.7701 | Time: 34.83s
2025-07-18 10:43:55,764 - logger.py:50 - Epoch: [282][0/6]	Total Loss: 0.72692	Main MSE (x10^-2): 72.6922	LR: 1.62e-04	EMPP_Raw: 1.42385
2025-07-18 10:44:09,522 - logger.py:50 - Epoch: [282][5/6]	Total Loss: 0.74317	Main MSE (x10^-2): 74.3165	LR: 1.62e-04	EMPP_Raw: 1.45562
2025-07-18 10:44:09,565 - logger.py:50 - Epoch 282 Training Summary: Avg Total Loss: 0.74317, Avg Main MSE: 0.74317, Time: 16.79s
2025-07-18 10:44:27,683 - logger.py:50 - Epoch 282 Summary | Train MSE (x10^-2): 74.3165 | Val MSE (x10^-2): 77.8911 | Time: 34.91s
2025-07-18 10:44:30,733 - logger.py:50 - Epoch: [283][0/6]	Total Loss: 0.75811	Main MSE (x10^-2): 75.8111	LR: 1.61e-04	EMPP_Raw: 1.48491
2025-07-18 10:44:44,485 - logger.py:50 - Epoch: [283][5/6]	Total Loss: 0.74743	Main MSE (x10^-2): 74.7433	LR: 1.61e-04	EMPP_Raw: 1.46160
2025-07-18 10:44:44,529 - logger.py:50 - Epoch 283 Training Summary: Avg Total Loss: 0.74743, Avg Main MSE: 0.74743, Time: 16.84s
2025-07-18 10:45:02,636 - logger.py:50 - Epoch 283 Summary | Train MSE (x10^-2): 74.7433 | Val MSE (x10^-2): 81.2184 | Time: 34.95s
2025-07-18 10:45:05,809 - logger.py:50 - Epoch: [284][0/6]	Total Loss: 0.75701	Main MSE (x10^-2): 75.7015	LR: 1.59e-04	EMPP_Raw: 1.48221
2025-07-18 10:45:19,533 - logger.py:50 - Epoch: [284][5/6]	Total Loss: 0.75269	Main MSE (x10^-2): 75.2693	LR: 1.59e-04	EMPP_Raw: 1.47453
2025-07-18 10:45:19,591 - logger.py:50 - Epoch 284 Training Summary: Avg Total Loss: 0.75269, Avg Main MSE: 0.75269, Time: 16.94s
2025-07-18 10:45:37,550 - logger.py:50 - Epoch 284 Summary | Train MSE (x10^-2): 75.2693 | Val MSE (x10^-2): 79.7386 | Time: 34.91s
2025-07-18 10:45:40,584 - logger.py:50 - Epoch: [285][0/6]	Total Loss: 0.75725	Main MSE (x10^-2): 75.7246	LR: 1.58e-04	EMPP_Raw: 1.48694
2025-07-18 10:45:54,479 - logger.py:50 - Epoch: [285][5/6]	Total Loss: 0.74162	Main MSE (x10^-2): 74.1625	LR: 1.58e-04	EMPP_Raw: 1.45373
2025-07-18 10:45:54,525 - logger.py:50 - Epoch 285 Training Summary: Avg Total Loss: 0.74162, Avg Main MSE: 0.74162, Time: 16.97s
2025-07-18 10:46:12,500 - logger.py:50 - Epoch 285 Summary | Train MSE (x10^-2): 74.1625 | Val MSE (x10^-2): 79.0757 | Time: 34.94s
2025-07-18 10:46:15,534 - logger.py:50 - Epoch: [286][0/6]	Total Loss: 0.75196	Main MSE (x10^-2): 75.1964	LR: 1.57e-04	EMPP_Raw: 1.47357
2025-07-18 10:46:29,472 - logger.py:50 - Epoch: [286][5/6]	Total Loss: 0.75425	Main MSE (x10^-2): 75.4252	LR: 1.57e-04	EMPP_Raw: 1.47931
2025-07-18 10:46:29,512 - logger.py:50 - Epoch 286 Training Summary: Avg Total Loss: 0.75425, Avg Main MSE: 0.75425, Time: 17.00s
2025-07-18 10:46:47,380 - logger.py:50 - Epoch 286 Summary | Train MSE (x10^-2): 75.4252 | Val MSE (x10^-2): 79.2218 | Time: 34.87s
2025-07-18 10:46:50,373 - logger.py:50 - Epoch: [287][0/6]	Total Loss: 0.78118	Main MSE (x10^-2): 78.1176	LR: 1.56e-04	EMPP_Raw: 1.53151
2025-07-18 10:47:04,171 - logger.py:50 - Epoch: [287][5/6]	Total Loss: 0.73724	Main MSE (x10^-2): 73.7244	LR: 1.56e-04	EMPP_Raw: 1.44357
2025-07-18 10:47:04,212 - logger.py:50 - Epoch 287 Training Summary: Avg Total Loss: 0.73724, Avg Main MSE: 0.73724, Time: 16.83s
2025-07-18 10:47:22,121 - logger.py:50 - Epoch 287 Summary | Train MSE (x10^-2): 73.7244 | Val MSE (x10^-2): 79.1557 | Time: 34.74s
2025-07-18 10:47:25,277 - logger.py:50 - Epoch: [288][0/6]	Total Loss: 0.72724	Main MSE (x10^-2): 72.7241	LR: 1.55e-04	EMPP_Raw: 1.42455
2025-07-18 10:47:39,096 - logger.py:50 - Epoch: [288][5/6]	Total Loss: 0.74681	Main MSE (x10^-2): 74.6810	LR: 1.55e-04	EMPP_Raw: 1.46466
2025-07-18 10:47:39,139 - logger.py:50 - Epoch 288 Training Summary: Avg Total Loss: 0.74681, Avg Main MSE: 0.74681, Time: 17.01s
2025-07-18 10:47:57,082 - logger.py:50 - Epoch 288 Summary | Train MSE (x10^-2): 74.6810 | Val MSE (x10^-2): 78.8293 | Time: 34.96s
2025-07-18 10:48:00,239 - logger.py:50 - Epoch: [289][0/6]	Total Loss: 0.72881	Main MSE (x10^-2): 72.8813	LR: 1.53e-04	EMPP_Raw: 1.43041
2025-07-18 10:48:14,007 - logger.py:50 - Epoch: [289][5/6]	Total Loss: 0.74334	Main MSE (x10^-2): 74.3340	LR: 1.53e-04	EMPP_Raw: 1.45522
2025-07-18 10:48:14,051 - logger.py:50 - Epoch 289 Training Summary: Avg Total Loss: 0.74334, Avg Main MSE: 0.74334, Time: 16.96s
2025-07-18 10:48:31,925 - logger.py:50 - Epoch 289 Summary | Train MSE (x10^-2): 74.3340 | Val MSE (x10^-2): 82.2844 | Time: 34.84s
2025-07-18 10:48:34,917 - logger.py:50 - Epoch: [290][0/6]	Total Loss: 0.75582	Main MSE (x10^-2): 75.5823	LR: 1.52e-04	EMPP_Raw: 1.47145
2025-07-18 10:48:48,863 - logger.py:50 - Epoch: [290][5/6]	Total Loss: 0.74050	Main MSE (x10^-2): 74.0495	LR: 1.52e-04	EMPP_Raw: 1.44618
2025-07-18 10:48:48,907 - logger.py:50 - Epoch 290 Training Summary: Avg Total Loss: 0.74050, Avg Main MSE: 0.74050, Time: 16.97s
2025-07-18 10:49:06,823 - logger.py:50 - Epoch 290 Summary | Train MSE (x10^-2): 74.0495 | Val MSE (x10^-2): 76.2399 | Time: 34.89s
2025-07-18 10:49:09,826 - logger.py:50 - Epoch: [291][0/6]	Total Loss: 0.76589	Main MSE (x10^-2): 76.5893	LR: 1.51e-04	EMPP_Raw: 1.50131
2025-07-18 10:49:23,628 - logger.py:50 - Epoch: [291][5/6]	Total Loss: 0.74916	Main MSE (x10^-2): 74.9160	LR: 1.51e-04	EMPP_Raw: 1.46770
2025-07-18 10:49:23,670 - logger.py:50 - Epoch 291 Training Summary: Avg Total Loss: 0.74916, Avg Main MSE: 0.74916, Time: 16.84s
2025-07-18 10:49:41,772 - logger.py:50 - Epoch 291 Summary | Train MSE (x10^-2): 74.9160 | Val MSE (x10^-2): 82.5924 | Time: 34.94s
2025-07-18 10:49:44,765 - logger.py:50 - Epoch: [292][0/6]	Total Loss: 0.75466	Main MSE (x10^-2): 75.4655	LR: 1.50e-04	EMPP_Raw: 1.47829
2025-07-18 10:49:58,511 - logger.py:50 - Epoch: [292][5/6]	Total Loss: 0.74719	Main MSE (x10^-2): 74.7188	LR: 1.50e-04	EMPP_Raw: 1.46476
2025-07-18 10:49:58,556 - logger.py:50 - Epoch 292 Training Summary: Avg Total Loss: 0.74719, Avg Main MSE: 0.74719, Time: 16.77s
2025-07-18 10:50:16,455 - logger.py:50 - Epoch 292 Summary | Train MSE (x10^-2): 74.7188 | Val MSE (x10^-2): 78.1300 | Time: 34.68s
2025-07-18 10:50:19,660 - logger.py:50 - Epoch: [293][0/6]	Total Loss: 0.75821	Main MSE (x10^-2): 75.8214	LR: 1.48e-04	EMPP_Raw: 1.48938
2025-07-18 10:50:33,412 - logger.py:50 - Epoch: [293][5/6]	Total Loss: 0.74956	Main MSE (x10^-2): 74.9564	LR: 1.48e-04	EMPP_Raw: 1.47205
2025-07-18 10:50:33,456 - logger.py:50 - Epoch 293 Training Summary: Avg Total Loss: 0.74956, Avg Main MSE: 0.74956, Time: 16.99s
2025-07-18 10:50:51,311 - logger.py:50 - Epoch 293 Summary | Train MSE (x10^-2): 74.9564 | Val MSE (x10^-2): 78.6851 | Time: 34.85s
2025-07-18 10:50:54,306 - logger.py:50 - Epoch: [294][0/6]	Total Loss: 0.74735	Main MSE (x10^-2): 74.7353	LR: 1.47e-04	EMPP_Raw: 1.46679
2025-07-18 10:51:08,216 - logger.py:50 - Epoch: [294][5/6]	Total Loss: 0.73097	Main MSE (x10^-2): 73.0972	LR: 1.47e-04	EMPP_Raw: 1.43343
2025-07-18 10:51:08,257 - logger.py:50 - Epoch 294 Training Summary: Avg Total Loss: 0.73097, Avg Main MSE: 0.73097, Time: 16.94s
2025-07-18 10:51:26,196 - logger.py:50 - Epoch 294 Summary | Train MSE (x10^-2): 73.0972 | Val MSE (x10^-2): 78.8765 | Time: 34.88s
2025-07-18 10:51:29,187 - logger.py:50 - Epoch: [295][0/6]	Total Loss: 0.75127	Main MSE (x10^-2): 75.1271	LR: 1.46e-04	EMPP_Raw: 1.47733
2025-07-18 10:51:42,933 - logger.py:50 - Epoch: [295][5/6]	Total Loss: 0.74372	Main MSE (x10^-2): 74.3721	LR: 1.46e-04	EMPP_Raw: 1.46075
2025-07-18 10:51:42,978 - logger.py:50 - Epoch 295 Training Summary: Avg Total Loss: 0.74372, Avg Main MSE: 0.74372, Time: 16.77s
2025-07-18 10:52:01,013 - logger.py:50 - Epoch 295 Summary | Train MSE (x10^-2): 74.3721 | Val MSE (x10^-2): 79.0606 | Time: 34.81s
2025-07-18 10:52:04,018 - logger.py:50 - Epoch: [296][0/6]	Total Loss: 0.75047	Main MSE (x10^-2): 75.0475	LR: 1.45e-04	EMPP_Raw: 1.47529
2025-07-18 10:52:17,771 - logger.py:50 - Epoch: [296][5/6]	Total Loss: 0.74426	Main MSE (x10^-2): 74.4258	LR: 1.45e-04	EMPP_Raw: 1.45927
2025-07-18 10:52:17,816 - logger.py:50 - Epoch 296 Training Summary: Avg Total Loss: 0.74426, Avg Main MSE: 0.74426, Time: 16.79s
2025-07-18 10:52:35,797 - logger.py:50 - Epoch 296 Summary | Train MSE (x10^-2): 74.4258 | Val MSE (x10^-2): 78.9022 | Time: 34.78s
2025-07-18 10:52:38,799 - logger.py:50 - Epoch: [297][0/6]	Total Loss: 0.74841	Main MSE (x10^-2): 74.8410	LR: 1.44e-04	EMPP_Raw: 1.47153
2025-07-18 10:52:52,585 - logger.py:50 - Epoch: [297][5/6]	Total Loss: 0.73436	Main MSE (x10^-2): 73.4360	LR: 1.44e-04	EMPP_Raw: 1.44121
2025-07-18 10:52:52,634 - logger.py:50 - Epoch 297 Training Summary: Avg Total Loss: 0.73436, Avg Main MSE: 0.73436, Time: 16.83s
2025-07-18 10:53:10,643 - logger.py:50 - Epoch 297 Summary | Train MSE (x10^-2): 73.4360 | Val MSE (x10^-2): 79.2160 | Time: 34.84s
2025-07-18 10:53:14,041 - logger.py:50 - Epoch: [298][0/6]	Total Loss: 0.74913	Main MSE (x10^-2): 74.9129	LR: 1.42e-04	EMPP_Raw: 1.46736
2025-07-18 10:53:27,851 - logger.py:50 - Epoch: [298][5/6]	Total Loss: 0.74789	Main MSE (x10^-2): 74.7890	LR: 1.42e-04	EMPP_Raw: 1.46644
2025-07-18 10:53:27,912 - logger.py:50 - Epoch 298 Training Summary: Avg Total Loss: 0.74789, Avg Main MSE: 0.74789, Time: 17.26s
2025-07-18 10:53:45,953 - logger.py:50 - Epoch 298 Summary | Train MSE (x10^-2): 74.7890 | Val MSE (x10^-2): 79.5707 | Time: 35.30s
2025-07-18 10:53:49,165 - logger.py:50 - Epoch: [299][0/6]	Total Loss: 0.73136	Main MSE (x10^-2): 73.1358	LR: 1.41e-04	EMPP_Raw: 1.43541
2025-07-18 10:54:02,986 - logger.py:50 - Epoch: [299][5/6]	Total Loss: 0.75154	Main MSE (x10^-2): 75.1542	LR: 1.41e-04	EMPP_Raw: 1.47518
2025-07-18 10:54:03,032 - logger.py:50 - Epoch 299 Training Summary: Avg Total Loss: 0.75154, Avg Main MSE: 0.75154, Time: 17.07s
2025-07-18 10:54:21,025 - logger.py:50 - Epoch 299 Summary | Train MSE (x10^-2): 75.1542 | Val MSE (x10^-2): 79.4406 | Time: 35.07s
2025-07-18 10:54:24,062 - logger.py:50 - Epoch: [300][0/6]	Total Loss: 0.73873	Main MSE (x10^-2): 73.8733	LR: 1.40e-04	EMPP_Raw: 1.45032
2025-07-18 10:54:37,987 - logger.py:50 - Epoch: [300][5/6]	Total Loss: 0.73653	Main MSE (x10^-2): 73.6529	LR: 1.40e-04	EMPP_Raw: 1.44493
2025-07-18 10:54:38,028 - logger.py:50 - Epoch 300 Training Summary: Avg Total Loss: 0.73653, Avg Main MSE: 0.73653, Time: 16.99s
2025-07-18 10:54:55,878 - logger.py:50 - Epoch 300 Summary | Train MSE (x10^-2): 73.6529 | Val MSE (x10^-2): 79.0547 | Time: 34.85s
2025-07-18 10:54:58,932 - logger.py:50 - Epoch: [301][0/6]	Total Loss: 0.75031	Main MSE (x10^-2): 75.0311	LR: 1.39e-04	EMPP_Raw: 1.47374
2025-07-18 10:55:12,758 - logger.py:50 - Epoch: [301][5/6]	Total Loss: 0.74254	Main MSE (x10^-2): 74.2543	LR: 1.39e-04	EMPP_Raw: 1.45605
2025-07-18 10:55:12,812 - logger.py:50 - Epoch 301 Training Summary: Avg Total Loss: 0.74254, Avg Main MSE: 0.74254, Time: 16.93s
2025-07-18 10:55:30,804 - logger.py:50 - Epoch 301 Summary | Train MSE (x10^-2): 74.2543 | Val MSE (x10^-2): 78.7687 | Time: 34.92s
2025-07-18 10:55:33,812 - logger.py:50 - Epoch: [302][0/6]	Total Loss: 0.72865	Main MSE (x10^-2): 72.8652	LR: 1.38e-04	EMPP_Raw: 1.42781
2025-07-18 10:55:47,587 - logger.py:50 - Epoch: [302][5/6]	Total Loss: 0.74141	Main MSE (x10^-2): 74.1412	LR: 1.38e-04	EMPP_Raw: 1.45337
2025-07-18 10:55:47,633 - logger.py:50 - Epoch 302 Training Summary: Avg Total Loss: 0.74141, Avg Main MSE: 0.74141, Time: 16.82s
2025-07-18 10:56:05,645 - logger.py:50 - Epoch 302 Summary | Train MSE (x10^-2): 74.1412 | Val MSE (x10^-2): 78.2020 | Time: 34.83s
2025-07-18 10:56:08,687 - logger.py:50 - Epoch: [303][0/6]	Total Loss: 0.76612	Main MSE (x10^-2): 76.6121	LR: 1.36e-04	EMPP_Raw: 1.50364
2025-07-18 10:56:22,530 - logger.py:50 - Epoch: [303][5/6]	Total Loss: 0.74507	Main MSE (x10^-2): 74.5075	LR: 1.36e-04	EMPP_Raw: 1.46200
2025-07-18 10:56:22,569 - logger.py:50 - Epoch 303 Training Summary: Avg Total Loss: 0.74507, Avg Main MSE: 0.74507, Time: 16.92s
2025-07-18 10:56:40,527 - logger.py:50 - Epoch 303 Summary | Train MSE (x10^-2): 74.5075 | Val MSE (x10^-2): 78.8878 | Time: 34.88s
2025-07-18 10:56:43,708 - logger.py:50 - Epoch: [304][0/6]	Total Loss: 0.73797	Main MSE (x10^-2): 73.7973	LR: 1.35e-04	EMPP_Raw: 1.45040
2025-07-18 10:56:57,455 - logger.py:50 - Epoch: [304][5/6]	Total Loss: 0.74862	Main MSE (x10^-2): 74.8619	LR: 1.35e-04	EMPP_Raw: 1.46881
2025-07-18 10:56:57,505 - logger.py:50 - Epoch 304 Training Summary: Avg Total Loss: 0.74862, Avg Main MSE: 0.74862, Time: 16.97s
2025-07-18 10:57:15,299 - logger.py:50 - Epoch 304 Summary | Train MSE (x10^-2): 74.8619 | Val MSE (x10^-2): 77.5263 | Time: 34.77s
2025-07-18 10:57:18,295 - logger.py:50 - Epoch: [305][0/6]	Total Loss: 0.72085	Main MSE (x10^-2): 72.0846	LR: 1.34e-04	EMPP_Raw: 1.41436
2025-07-18 10:57:32,202 - logger.py:50 - Epoch: [305][5/6]	Total Loss: 0.73525	Main MSE (x10^-2): 73.5249	LR: 1.34e-04	EMPP_Raw: 1.44020
2025-07-18 10:57:32,249 - logger.py:50 - Epoch 305 Training Summary: Avg Total Loss: 0.73525, Avg Main MSE: 0.73525, Time: 16.94s
2025-07-18 10:57:50,143 - logger.py:50 - Epoch 305 Summary | Train MSE (x10^-2): 73.5249 | Val MSE (x10^-2): 77.6879 | Time: 34.84s
2025-07-18 10:57:53,140 - logger.py:50 - Epoch: [306][0/6]	Total Loss: 0.75145	Main MSE (x10^-2): 75.1455	LR: 1.33e-04	EMPP_Raw: 1.47517
2025-07-18 10:58:07,065 - logger.py:50 - Epoch: [306][5/6]	Total Loss: 0.74107	Main MSE (x10^-2): 74.1065	LR: 1.33e-04	EMPP_Raw: 1.45516
2025-07-18 10:58:07,111 - logger.py:50 - Epoch 306 Training Summary: Avg Total Loss: 0.74107, Avg Main MSE: 0.74107, Time: 16.96s
2025-07-18 10:58:25,011 - logger.py:50 - Epoch 306 Summary | Train MSE (x10^-2): 74.1065 | Val MSE (x10^-2): 79.3471 | Time: 34.86s
2025-07-18 10:58:28,008 - logger.py:50 - Epoch: [307][0/6]	Total Loss: 0.74857	Main MSE (x10^-2): 74.8569	LR: 1.32e-04	EMPP_Raw: 1.47178
2025-07-18 10:58:41,785 - logger.py:50 - Epoch: [307][5/6]	Total Loss: 0.74303	Main MSE (x10^-2): 74.3033	LR: 1.32e-04	EMPP_Raw: 1.46029
2025-07-18 10:58:41,826 - logger.py:50 - Epoch 307 Training Summary: Avg Total Loss: 0.74303, Avg Main MSE: 0.74303, Time: 16.81s
2025-07-18 10:58:59,795 - logger.py:50 - Epoch 307 Summary | Train MSE (x10^-2): 74.3033 | Val MSE (x10^-2): 79.8363 | Time: 34.78s
2025-07-18 10:59:03,023 - logger.py:50 - Epoch: [308][0/6]	Total Loss: 0.74054	Main MSE (x10^-2): 74.0541	LR: 1.31e-04	EMPP_Raw: 1.45356
2025-07-18 10:59:16,816 - logger.py:50 - Epoch: [308][5/6]	Total Loss: 0.75312	Main MSE (x10^-2): 75.3117	LR: 1.31e-04	EMPP_Raw: 1.47998
2025-07-18 10:59:16,862 - logger.py:50 - Epoch 308 Training Summary: Avg Total Loss: 0.75312, Avg Main MSE: 0.75312, Time: 17.06s
2025-07-18 10:59:34,705 - logger.py:50 - Epoch 308 Summary | Train MSE (x10^-2): 75.3117 | Val MSE (x10^-2): 79.3549 | Time: 34.90s
2025-07-18 10:59:37,866 - logger.py:50 - Epoch: [309][0/6]	Total Loss: 0.72779	Main MSE (x10^-2): 72.7791	LR: 1.29e-04	EMPP_Raw: 1.43297
2025-07-18 10:59:51,634 - logger.py:50 - Epoch: [309][5/6]	Total Loss: 0.73923	Main MSE (x10^-2): 73.9232	LR: 1.29e-04	EMPP_Raw: 1.45174
2025-07-18 10:59:51,682 - logger.py:50 - Epoch 309 Training Summary: Avg Total Loss: 0.73923, Avg Main MSE: 0.73923, Time: 16.97s
2025-07-18 11:00:09,703 - logger.py:50 - Epoch 309 Summary | Train MSE (x10^-2): 73.9232 | Val MSE (x10^-2): 79.1363 | Time: 34.99s
2025-07-18 11:00:12,720 - logger.py:50 - Epoch: [310][0/6]	Total Loss: 0.72371	Main MSE (x10^-2): 72.3713	LR: 1.28e-04	EMPP_Raw: 1.41661
2025-07-18 11:00:26,709 - logger.py:50 - Epoch: [310][5/6]	Total Loss: 0.73507	Main MSE (x10^-2): 73.5070	LR: 1.28e-04	EMPP_Raw: 1.44130
2025-07-18 11:00:26,750 - logger.py:50 - Epoch 310 Training Summary: Avg Total Loss: 0.73507, Avg Main MSE: 0.73507, Time: 17.04s
2025-07-18 11:00:44,652 - logger.py:50 - Epoch 310 Summary | Train MSE (x10^-2): 73.5070 | Val MSE (x10^-2): 79.6483 | Time: 34.94s
2025-07-18 11:00:47,656 - logger.py:50 - Epoch: [311][0/6]	Total Loss: 0.72296	Main MSE (x10^-2): 72.2964	LR: 1.27e-04	EMPP_Raw: 1.41823
2025-07-18 11:01:01,529 - logger.py:50 - Epoch: [311][5/6]	Total Loss: 0.73715	Main MSE (x10^-2): 73.7149	LR: 1.27e-04	EMPP_Raw: 1.44724
2025-07-18 11:01:01,585 - logger.py:50 - Epoch 311 Training Summary: Avg Total Loss: 0.73715, Avg Main MSE: 0.73715, Time: 16.92s
2025-07-18 11:01:19,674 - logger.py:50 - Epoch 311 Summary | Train MSE (x10^-2): 73.7149 | Val MSE (x10^-2): 79.9549 | Time: 35.02s
2025-07-18 11:01:22,712 - logger.py:50 - Epoch: [312][0/6]	Total Loss: 0.75606	Main MSE (x10^-2): 75.6057	LR: 1.26e-04	EMPP_Raw: 1.48504
2025-07-18 11:01:36,491 - logger.py:50 - Epoch: [312][5/6]	Total Loss: 0.74618	Main MSE (x10^-2): 74.6175	LR: 1.26e-04	EMPP_Raw: 1.46557
2025-07-18 11:01:36,537 - logger.py:50 - Epoch 312 Training Summary: Avg Total Loss: 0.74618, Avg Main MSE: 0.74618, Time: 16.85s
2025-07-18 11:01:54,472 - logger.py:50 - Epoch 312 Summary | Train MSE (x10^-2): 74.6175 | Val MSE (x10^-2): 78.6781 | Time: 34.79s
2025-07-18 11:01:57,630 - logger.py:50 - Epoch: [313][0/6]	Total Loss: 0.74248	Main MSE (x10^-2): 74.2480	LR: 1.25e-04	EMPP_Raw: 1.45834
2025-07-18 11:02:11,396 - logger.py:50 - Epoch: [313][5/6]	Total Loss: 0.73773	Main MSE (x10^-2): 73.7726	LR: 1.25e-04	EMPP_Raw: 1.44934
2025-07-18 11:02:11,437 - logger.py:50 - Epoch 313 Training Summary: Avg Total Loss: 0.73773, Avg Main MSE: 0.73773, Time: 16.95s
2025-07-18 11:02:29,418 - logger.py:50 - Epoch 313 Summary | Train MSE (x10^-2): 73.7726 | Val MSE (x10^-2): 78.5839 | Time: 34.94s
2025-07-18 11:02:32,419 - logger.py:50 - Epoch: [314][0/6]	Total Loss: 0.72003	Main MSE (x10^-2): 72.0031	LR: 1.24e-04	EMPP_Raw: 1.41481
2025-07-18 11:02:46,354 - logger.py:50 - Epoch: [314][5/6]	Total Loss: 0.73578	Main MSE (x10^-2): 73.5779	LR: 1.24e-04	EMPP_Raw: 1.44622
2025-07-18 11:02:46,404 - logger.py:50 - Epoch 314 Training Summary: Avg Total Loss: 0.73578, Avg Main MSE: 0.73578, Time: 16.98s
2025-07-18 11:03:04,421 - logger.py:50 - Epoch 314 Summary | Train MSE (x10^-2): 73.5779 | Val MSE (x10^-2): 78.9721 | Time: 35.00s
2025-07-18 11:03:07,420 - logger.py:50 - Epoch: [315][0/6]	Total Loss: 0.73743	Main MSE (x10^-2): 73.7433	LR: 1.22e-04	EMPP_Raw: 1.45062
2025-07-18 11:03:21,199 - logger.py:50 - Epoch: [315][5/6]	Total Loss: 0.74339	Main MSE (x10^-2): 74.3393	LR: 1.22e-04	EMPP_Raw: 1.46134
2025-07-18 11:03:21,244 - logger.py:50 - Epoch 315 Training Summary: Avg Total Loss: 0.74339, Avg Main MSE: 0.74339, Time: 16.81s
2025-07-18 11:03:39,382 - logger.py:50 - Epoch 315 Summary | Train MSE (x10^-2): 74.3393 | Val MSE (x10^-2): 79.1063 | Time: 34.96s
2025-07-18 11:03:42,438 - logger.py:50 - Epoch: [316][0/6]	Total Loss: 0.73675	Main MSE (x10^-2): 73.6749	LR: 1.21e-04	EMPP_Raw: 1.44240
2025-07-18 11:03:56,211 - logger.py:50 - Epoch: [316][5/6]	Total Loss: 0.74689	Main MSE (x10^-2): 74.6890	LR: 1.21e-04	EMPP_Raw: 1.46741
2025-07-18 11:03:56,251 - logger.py:50 - Epoch 316 Training Summary: Avg Total Loss: 0.74689, Avg Main MSE: 0.74689, Time: 16.86s
2025-07-18 11:04:14,272 - logger.py:50 - Epoch 316 Summary | Train MSE (x10^-2): 74.6890 | Val MSE (x10^-2): 78.8723 | Time: 34.88s
2025-07-18 11:04:17,285 - logger.py:50 - Epoch: [317][0/6]	Total Loss: 0.74125	Main MSE (x10^-2): 74.1253	LR: 1.20e-04	EMPP_Raw: 1.45476
2025-07-18 11:04:31,342 - logger.py:50 - Epoch: [317][5/6]	Total Loss: 0.72963	Main MSE (x10^-2): 72.9630	LR: 1.20e-04	EMPP_Raw: 1.43347
2025-07-18 11:04:31,387 - logger.py:50 - Epoch 317 Training Summary: Avg Total Loss: 0.72963, Avg Main MSE: 0.72963, Time: 17.11s
2025-07-18 11:04:49,408 - logger.py:50 - Epoch 317 Summary | Train MSE (x10^-2): 72.9630 | Val MSE (x10^-2): 78.8804 | Time: 35.13s
2025-07-18 11:04:52,848 - logger.py:50 - Epoch: [318][0/6]	Total Loss: 0.72627	Main MSE (x10^-2): 72.6269	LR: 1.19e-04	EMPP_Raw: 1.42846
2025-07-18 11:05:06,703 - logger.py:50 - Epoch: [318][5/6]	Total Loss: 0.74706	Main MSE (x10^-2): 74.7064	LR: 1.19e-04	EMPP_Raw: 1.46858
2025-07-18 11:05:06,760 - logger.py:50 - Epoch 318 Training Summary: Avg Total Loss: 0.74706, Avg Main MSE: 0.74706, Time: 17.34s
2025-07-18 11:05:24,852 - logger.py:50 - Epoch 318 Summary | Train MSE (x10^-2): 74.7064 | Val MSE (x10^-2): 78.1196 | Time: 35.44s
2025-07-18 11:05:28,019 - logger.py:50 - Epoch: [319][0/6]	Total Loss: 0.72770	Main MSE (x10^-2): 72.7696	LR: 1.18e-04	EMPP_Raw: 1.43034
2025-07-18 11:05:41,739 - logger.py:50 - Epoch: [319][5/6]	Total Loss: 0.73520	Main MSE (x10^-2): 73.5203	LR: 1.18e-04	EMPP_Raw: 1.44502
2025-07-18 11:05:41,786 - logger.py:50 - Epoch 319 Training Summary: Avg Total Loss: 0.73520, Avg Main MSE: 0.73520, Time: 16.92s
2025-07-18 11:05:59,743 - logger.py:50 - Epoch 319 Summary | Train MSE (x10^-2): 73.5203 | Val MSE (x10^-2): 78.9831 | Time: 34.89s
2025-07-18 11:06:02,750 - logger.py:50 - Epoch: [320][0/6]	Total Loss: 0.74737	Main MSE (x10^-2): 74.7373	LR: 1.17e-04	EMPP_Raw: 1.47040
2025-07-18 11:06:16,772 - logger.py:50 - Epoch: [320][5/6]	Total Loss: 0.73464	Main MSE (x10^-2): 73.4644	LR: 1.17e-04	EMPP_Raw: 1.44446
2025-07-18 11:06:16,822 - logger.py:50 - Epoch 320 Training Summary: Avg Total Loss: 0.73464, Avg Main MSE: 0.73464, Time: 17.07s
2025-07-18 11:06:34,873 - logger.py:50 - Epoch 320 Summary | Train MSE (x10^-2): 73.4644 | Val MSE (x10^-2): 79.3289 | Time: 35.12s
2025-07-18 11:06:37,876 - logger.py:50 - Epoch: [321][0/6]	Total Loss: 0.74727	Main MSE (x10^-2): 74.7271	LR: 1.16e-04	EMPP_Raw: 1.46671
2025-07-18 11:06:51,700 - logger.py:50 - Epoch: [321][5/6]	Total Loss: 0.74027	Main MSE (x10^-2): 74.0268	LR: 1.16e-04	EMPP_Raw: 1.45395
2025-07-18 11:06:51,741 - logger.py:50 - Epoch 321 Training Summary: Avg Total Loss: 0.74027, Avg Main MSE: 0.74027, Time: 16.86s
2025-07-18 11:07:09,769 - logger.py:50 - Epoch 321 Summary | Train MSE (x10^-2): 74.0268 | Val MSE (x10^-2): 80.2456 | Time: 34.89s
2025-07-18 11:07:12,774 - logger.py:50 - Epoch: [322][0/6]	Total Loss: 0.76391	Main MSE (x10^-2): 76.3913	LR: 1.14e-04	EMPP_Raw: 1.50364
2025-07-18 11:07:26,559 - logger.py:50 - Epoch: [322][5/6]	Total Loss: 0.74138	Main MSE (x10^-2): 74.1382	LR: 1.14e-04	EMPP_Raw: 1.45632
2025-07-18 11:07:26,600 - logger.py:50 - Epoch 322 Training Summary: Avg Total Loss: 0.74138, Avg Main MSE: 0.74138, Time: 16.82s
2025-07-18 11:07:44,660 - logger.py:50 - Epoch 322 Summary | Train MSE (x10^-2): 74.1382 | Val MSE (x10^-2): 78.8808 | Time: 34.88s
2025-07-18 11:07:47,687 - logger.py:50 - Epoch: [323][0/6]	Total Loss: 0.74707	Main MSE (x10^-2): 74.7074	LR: 1.13e-04	EMPP_Raw: 1.46746
2025-07-18 11:08:01,436 - logger.py:50 - Epoch: [323][5/6]	Total Loss: 0.75396	Main MSE (x10^-2): 75.3958	LR: 1.13e-04	EMPP_Raw: 1.48200
2025-07-18 11:08:01,484 - logger.py:50 - Epoch 323 Training Summary: Avg Total Loss: 0.75396, Avg Main MSE: 0.75396, Time: 16.81s
2025-07-18 11:08:19,320 - logger.py:50 - Epoch 323 Summary | Train MSE (x10^-2): 75.3958 | Val MSE (x10^-2): 79.6379 | Time: 34.65s
2025-07-18 11:08:22,513 - logger.py:50 - Epoch: [324][0/6]	Total Loss: 0.74411	Main MSE (x10^-2): 74.4114	LR: 1.12e-04	EMPP_Raw: 1.45896
2025-07-18 11:08:36,299 - logger.py:50 - Epoch: [324][5/6]	Total Loss: 0.75524	Main MSE (x10^-2): 75.5241	LR: 1.12e-04	EMPP_Raw: 1.48452
2025-07-18 11:08:36,365 - logger.py:50 - Epoch 324 Training Summary: Avg Total Loss: 0.75524, Avg Main MSE: 0.75524, Time: 17.04s
2025-07-18 11:08:54,202 - logger.py:50 - Epoch 324 Summary | Train MSE (x10^-2): 75.5241 | Val MSE (x10^-2): 79.8904 | Time: 34.88s
2025-07-18 11:08:57,197 - logger.py:50 - Epoch: [325][0/6]	Total Loss: 0.74509	Main MSE (x10^-2): 74.5086	LR: 1.11e-04	EMPP_Raw: 1.46736
2025-07-18 11:09:11,086 - logger.py:50 - Epoch: [325][5/6]	Total Loss: 0.74983	Main MSE (x10^-2): 74.9828	LR: 1.11e-04	EMPP_Raw: 1.47589
2025-07-18 11:09:11,128 - logger.py:50 - Epoch 325 Training Summary: Avg Total Loss: 0.74983, Avg Main MSE: 0.74983, Time: 16.91s
2025-07-18 11:09:29,084 - logger.py:50 - Epoch 325 Summary | Train MSE (x10^-2): 74.9828 | Val MSE (x10^-2): 79.8000 | Time: 34.87s
2025-07-18 11:09:32,136 - logger.py:50 - Epoch: [326][0/6]	Total Loss: 0.72583	Main MSE (x10^-2): 72.5830	LR: 1.10e-04	EMPP_Raw: 1.42866
2025-07-18 11:09:46,082 - logger.py:50 - Epoch: [326][5/6]	Total Loss: 0.74142	Main MSE (x10^-2): 74.1416	LR: 1.10e-04	EMPP_Raw: 1.45911
2025-07-18 11:09:46,128 - logger.py:50 - Epoch 326 Training Summary: Avg Total Loss: 0.74142, Avg Main MSE: 0.74142, Time: 17.03s
2025-07-18 11:10:04,124 - logger.py:50 - Epoch 326 Summary | Train MSE (x10^-2): 74.1416 | Val MSE (x10^-2): 79.7717 | Time: 35.03s
2025-07-18 11:10:07,185 - logger.py:50 - Epoch: [327][0/6]	Total Loss: 0.76635	Main MSE (x10^-2): 76.6349	LR: 1.09e-04	EMPP_Raw: 1.50921
2025-07-18 11:10:20,990 - logger.py:50 - Epoch: [327][5/6]	Total Loss: 0.74151	Main MSE (x10^-2): 74.1505	LR: 1.09e-04	EMPP_Raw: 1.45847
2025-07-18 11:10:21,032 - logger.py:50 - Epoch 327 Training Summary: Avg Total Loss: 0.74151, Avg Main MSE: 0.74151, Time: 16.90s
2025-07-18 11:10:38,875 - logger.py:50 - Epoch 327 Summary | Train MSE (x10^-2): 74.1505 | Val MSE (x10^-2): 78.3053 | Time: 34.75s
2025-07-18 11:10:42,039 - logger.py:50 - Epoch: [328][0/6]	Total Loss: 0.71734	Main MSE (x10^-2): 71.7337	LR: 1.08e-04	EMPP_Raw: 1.41195
2025-07-18 11:10:55,820 - logger.py:50 - Epoch: [328][5/6]	Total Loss: 0.74121	Main MSE (x10^-2): 74.1206	LR: 1.08e-04	EMPP_Raw: 1.45747
2025-07-18 11:10:55,860 - logger.py:50 - Epoch 328 Training Summary: Avg Total Loss: 0.74121, Avg Main MSE: 0.74121, Time: 16.97s
2025-07-18 11:11:13,813 - logger.py:50 - Epoch 328 Summary | Train MSE (x10^-2): 74.1206 | Val MSE (x10^-2): 78.3543 | Time: 34.93s
2025-07-18 11:11:16,986 - logger.py:50 - Epoch: [329][0/6]	Total Loss: 0.72056	Main MSE (x10^-2): 72.0560	LR: 1.07e-04	EMPP_Raw: 1.41615
2025-07-18 11:11:30,763 - logger.py:50 - Epoch: [329][5/6]	Total Loss: 0.73747	Main MSE (x10^-2): 73.7467	LR: 1.07e-04	EMPP_Raw: 1.45055
2025-07-18 11:11:30,807 - logger.py:50 - Epoch 329 Training Summary: Avg Total Loss: 0.73747, Avg Main MSE: 0.73747, Time: 16.99s
2025-07-18 11:11:48,740 - logger.py:50 - Epoch 329 Summary | Train MSE (x10^-2): 73.7467 | Val MSE (x10^-2): 78.0858 | Time: 34.92s
2025-07-18 11:11:51,747 - logger.py:50 - Epoch: [330][0/6]	Total Loss: 0.75389	Main MSE (x10^-2): 75.3892	LR: 1.05e-04	EMPP_Raw: 1.47934
2025-07-18 11:12:05,737 - logger.py:50 - Epoch: [330][5/6]	Total Loss: 0.73964	Main MSE (x10^-2): 73.9644	LR: 1.05e-04	EMPP_Raw: 1.45311
2025-07-18 11:12:05,781 - logger.py:50 - Epoch 330 Training Summary: Avg Total Loss: 0.73964, Avg Main MSE: 0.73964, Time: 17.03s
2025-07-18 11:12:23,686 - logger.py:50 - Epoch 330 Summary | Train MSE (x10^-2): 73.9644 | Val MSE (x10^-2): 79.9870 | Time: 34.94s
2025-07-18 11:12:26,720 - logger.py:50 - Epoch: [331][0/6]	Total Loss: 0.73375	Main MSE (x10^-2): 73.3747	LR: 1.04e-04	EMPP_Raw: 1.44233
2025-07-18 11:12:40,473 - logger.py:50 - Epoch: [331][5/6]	Total Loss: 0.74229	Main MSE (x10^-2): 74.2295	LR: 1.04e-04	EMPP_Raw: 1.46015
2025-07-18 11:12:40,515 - logger.py:50 - Epoch 331 Training Summary: Avg Total Loss: 0.74229, Avg Main MSE: 0.74229, Time: 16.82s
2025-07-18 11:12:58,599 - logger.py:50 - Epoch 331 Summary | Train MSE (x10^-2): 74.2295 | Val MSE (x10^-2): 79.9344 | Time: 34.91s
2025-07-18 11:13:01,591 - logger.py:50 - Epoch: [332][0/6]	Total Loss: 0.74481	Main MSE (x10^-2): 74.4812	LR: 1.03e-04	EMPP_Raw: 1.46698
2025-07-18 11:13:15,365 - logger.py:50 - Epoch: [332][5/6]	Total Loss: 0.74861	Main MSE (x10^-2): 74.8612	LR: 1.03e-04	EMPP_Raw: 1.47315
2025-07-18 11:13:15,405 - logger.py:50 - Epoch 332 Training Summary: Avg Total Loss: 0.74861, Avg Main MSE: 0.74861, Time: 16.80s
2025-07-18 11:13:33,376 - logger.py:50 - Epoch 332 Summary | Train MSE (x10^-2): 74.8612 | Val MSE (x10^-2): 78.0311 | Time: 34.77s
2025-07-18 11:13:36,549 - logger.py:50 - Epoch: [333][0/6]	Total Loss: 0.76371	Main MSE (x10^-2): 76.3706	LR: 1.02e-04	EMPP_Raw: 1.50392
2025-07-18 11:13:50,328 - logger.py:50 - Epoch: [333][5/6]	Total Loss: 0.74776	Main MSE (x10^-2): 74.7760	LR: 1.02e-04	EMPP_Raw: 1.47189
2025-07-18 11:13:50,369 - logger.py:50 - Epoch 333 Training Summary: Avg Total Loss: 0.74776, Avg Main MSE: 0.74776, Time: 16.98s
2025-07-18 11:14:08,414 - logger.py:50 - Epoch 333 Summary | Train MSE (x10^-2): 74.7760 | Val MSE (x10^-2): 78.3638 | Time: 35.03s
2025-07-18 11:14:11,427 - logger.py:50 - Epoch: [334][0/6]	Total Loss: 0.74712	Main MSE (x10^-2): 74.7124	LR: 1.01e-04	EMPP_Raw: 1.47107
2025-07-18 11:14:25,396 - logger.py:50 - Epoch: [334][5/6]	Total Loss: 0.73688	Main MSE (x10^-2): 73.6881	LR: 1.01e-04	EMPP_Raw: 1.45090
2025-07-18 11:14:25,438 - logger.py:50 - Epoch 334 Training Summary: Avg Total Loss: 0.73688, Avg Main MSE: 0.73688, Time: 17.01s
2025-07-18 11:14:43,350 - logger.py:50 - Epoch 334 Summary | Train MSE (x10^-2): 73.6881 | Val MSE (x10^-2): 78.8051 | Time: 34.93s
2025-07-18 11:14:46,351 - logger.py:50 - Epoch: [335][0/6]	Total Loss: 0.75386	Main MSE (x10^-2): 75.3862	LR: 1.00e-04	EMPP_Raw: 1.48420
2025-07-18 11:15:00,185 - logger.py:50 - Epoch: [335][5/6]	Total Loss: 0.74044	Main MSE (x10^-2): 74.0442	LR: 1.00e-04	EMPP_Raw: 1.45682
2025-07-18 11:15:00,228 - logger.py:50 - Epoch 335 Training Summary: Avg Total Loss: 0.74044, Avg Main MSE: 0.74044, Time: 16.87s
2025-07-18 11:15:18,286 - logger.py:50 - Epoch 335 Summary | Train MSE (x10^-2): 74.0442 | Val MSE (x10^-2): 79.0259 | Time: 34.93s
2025-07-18 11:15:21,285 - logger.py:50 - Epoch: [336][0/6]	Total Loss: 0.75221	Main MSE (x10^-2): 75.2206	LR: 9.89e-05	EMPP_Raw: 1.47769
2025-07-18 11:15:35,121 - logger.py:50 - Epoch: [336][5/6]	Total Loss: 0.74682	Main MSE (x10^-2): 74.6822	LR: 9.89e-05	EMPP_Raw: 1.46881
2025-07-18 11:15:35,162 - logger.py:50 - Epoch 336 Training Summary: Avg Total Loss: 0.74682, Avg Main MSE: 0.74682, Time: 16.87s
2025-07-18 11:15:53,232 - logger.py:50 - Epoch 336 Summary | Train MSE (x10^-2): 74.6822 | Val MSE (x10^-2): 79.5520 | Time: 34.94s
2025-07-18 11:15:56,257 - logger.py:50 - Epoch: [337][0/6]	Total Loss: 0.75000	Main MSE (x10^-2): 74.9996	LR: 9.79e-05	EMPP_Raw: 1.47622
2025-07-18 11:16:10,096 - logger.py:50 - Epoch: [337][5/6]	Total Loss: 0.73246	Main MSE (x10^-2): 73.2464	LR: 9.79e-05	EMPP_Raw: 1.44067
2025-07-18 11:16:10,137 - logger.py:50 - Epoch 337 Training Summary: Avg Total Loss: 0.73246, Avg Main MSE: 0.73246, Time: 16.89s
2025-07-18 11:16:28,093 - logger.py:50 - Epoch 337 Summary | Train MSE (x10^-2): 73.2464 | Val MSE (x10^-2): 78.5957 | Time: 34.85s
2025-07-18 11:16:31,475 - logger.py:50 - Epoch: [338][0/6]	Total Loss: 0.73829	Main MSE (x10^-2): 73.8288	LR: 9.68e-05	EMPP_Raw: 1.45340
2025-07-18 11:16:45,234 - logger.py:50 - Epoch: [338][5/6]	Total Loss: 0.73530	Main MSE (x10^-2): 73.5300	LR: 9.68e-05	EMPP_Raw: 1.44644
2025-07-18 11:16:45,286 - logger.py:50 - Epoch 338 Training Summary: Avg Total Loss: 0.73530, Avg Main MSE: 0.73530, Time: 17.18s
2025-07-18 11:17:03,225 - logger.py:50 - Epoch 338 Summary | Train MSE (x10^-2): 73.5300 | Val MSE (x10^-2): 78.9518 | Time: 35.13s
2025-07-18 11:17:06,406 - logger.py:50 - Epoch: [339][0/6]	Total Loss: 0.73744	Main MSE (x10^-2): 73.7443	LR: 9.57e-05	EMPP_Raw: 1.45382
2025-07-18 11:17:20,222 - logger.py:50 - Epoch: [339][5/6]	Total Loss: 0.74232	Main MSE (x10^-2): 74.2322	LR: 9.57e-05	EMPP_Raw: 1.46117
2025-07-18 11:17:20,263 - logger.py:50 - Epoch 339 Training Summary: Avg Total Loss: 0.74232, Avg Main MSE: 0.74232, Time: 17.03s
2025-07-18 11:17:38,251 - logger.py:50 - Epoch 339 Summary | Train MSE (x10^-2): 74.2322 | Val MSE (x10^-2): 79.3941 | Time: 35.02s
2025-07-18 11:17:41,258 - logger.py:50 - Epoch: [340][0/6]	Total Loss: 0.72656	Main MSE (x10^-2): 72.6559	LR: 9.47e-05	EMPP_Raw: 1.42938
2025-07-18 11:17:55,163 - logger.py:50 - Epoch: [340][5/6]	Total Loss: 0.72354	Main MSE (x10^-2): 72.3539	LR: 9.47e-05	EMPP_Raw: 1.42333
2025-07-18 11:17:55,210 - logger.py:50 - Epoch 340 Training Summary: Avg Total Loss: 0.72354, Avg Main MSE: 0.72354, Time: 16.95s
2025-07-18 11:18:13,213 - logger.py:50 - Epoch 340 Summary | Train MSE (x10^-2): 72.3539 | Val MSE (x10^-2): 79.5822 | Time: 34.96s
2025-07-18 11:18:16,223 - logger.py:50 - Epoch: [341][0/6]	Total Loss: 0.74647	Main MSE (x10^-2): 74.6468	LR: 9.36e-05	EMPP_Raw: 1.47000
2025-07-18 11:18:30,000 - logger.py:50 - Epoch: [341][5/6]	Total Loss: 0.73693	Main MSE (x10^-2): 73.6928	LR: 9.36e-05	EMPP_Raw: 1.45036
2025-07-18 11:18:30,048 - logger.py:50 - Epoch 341 Training Summary: Avg Total Loss: 0.73693, Avg Main MSE: 0.73693, Time: 16.83s
2025-07-18 11:18:48,032 - logger.py:50 - Epoch 341 Summary | Train MSE (x10^-2): 73.6928 | Val MSE (x10^-2): 79.9054 | Time: 34.81s
2025-07-18 11:18:51,079 - logger.py:50 - Epoch: [342][0/6]	Total Loss: 0.74375	Main MSE (x10^-2): 74.3748	LR: 9.25e-05	EMPP_Raw: 1.46462
2025-07-18 11:19:04,849 - logger.py:50 - Epoch: [342][5/6]	Total Loss: 0.73888	Main MSE (x10^-2): 73.8882	LR: 9.25e-05	EMPP_Raw: 1.45391
2025-07-18 11:19:04,894 - logger.py:50 - Epoch 342 Training Summary: Avg Total Loss: 0.73888, Avg Main MSE: 0.73888, Time: 16.85s
2025-07-18 11:19:22,973 - logger.py:50 - Epoch 342 Summary | Train MSE (x10^-2): 73.8882 | Val MSE (x10^-2): 78.6901 | Time: 34.94s
2025-07-18 11:19:26,020 - logger.py:50 - Epoch: [343][0/6]	Total Loss: 0.71954	Main MSE (x10^-2): 71.9539	LR: 9.15e-05	EMPP_Raw: 1.41751
2025-07-18 11:19:39,814 - logger.py:50 - Epoch: [343][5/6]	Total Loss: 0.73135	Main MSE (x10^-2): 73.1352	LR: 9.15e-05	EMPP_Raw: 1.43932
2025-07-18 11:19:39,854 - logger.py:50 - Epoch 343 Training Summary: Avg Total Loss: 0.73135, Avg Main MSE: 0.73135, Time: 16.87s
2025-07-18 11:19:57,727 - logger.py:50 - Epoch 343 Summary | Train MSE (x10^-2): 73.1352 | Val MSE (x10^-2): 78.8502 | Time: 34.75s
2025-07-18 11:20:00,891 - logger.py:50 - Epoch: [344][0/6]	Total Loss: 0.75589	Main MSE (x10^-2): 75.5888	LR: 9.04e-05	EMPP_Raw: 1.48878
2025-07-18 11:20:14,643 - logger.py:50 - Epoch: [344][5/6]	Total Loss: 0.74368	Main MSE (x10^-2): 74.3683	LR: 9.04e-05	EMPP_Raw: 1.46383
2025-07-18 11:20:14,687 - logger.py:50 - Epoch 344 Training Summary: Avg Total Loss: 0.74368, Avg Main MSE: 0.74368, Time: 16.95s
2025-07-18 11:20:32,513 - logger.py:50 - Epoch 344 Summary | Train MSE (x10^-2): 74.3683 | Val MSE (x10^-2): 79.5807 | Time: 34.78s
2025-07-18 11:20:35,557 - logger.py:50 - Epoch: [345][0/6]	Total Loss: 0.75003	Main MSE (x10^-2): 75.0031	LR: 8.94e-05	EMPP_Raw: 1.47792
2025-07-18 11:20:49,460 - logger.py:50 - Epoch: [345][5/6]	Total Loss: 0.73511	Main MSE (x10^-2): 73.5107	LR: 8.94e-05	EMPP_Raw: 1.44708
2025-07-18 11:20:49,509 - logger.py:50 - Epoch 345 Training Summary: Avg Total Loss: 0.73511, Avg Main MSE: 0.73511, Time: 16.99s
2025-07-18 11:21:07,465 - logger.py:50 - Epoch 345 Summary | Train MSE (x10^-2): 73.5107 | Val MSE (x10^-2): 79.2413 | Time: 34.95s
2025-07-18 11:21:10,469 - logger.py:50 - Epoch: [346][0/6]	Total Loss: 0.74978	Main MSE (x10^-2): 74.9783	LR: 8.84e-05	EMPP_Raw: 1.47704
2025-07-18 11:21:24,384 - logger.py:50 - Epoch: [346][5/6]	Total Loss: 0.75148	Main MSE (x10^-2): 75.1476	LR: 8.84e-05	EMPP_Raw: 1.47945
2025-07-18 11:21:24,426 - logger.py:50 - Epoch 346 Training Summary: Avg Total Loss: 0.75148, Avg Main MSE: 0.75148, Time: 16.95s
2025-07-18 11:21:42,333 - logger.py:50 - Epoch 346 Summary | Train MSE (x10^-2): 75.1476 | Val MSE (x10^-2): 79.5903 | Time: 34.86s
2025-07-18 11:21:45,377 - logger.py:50 - Epoch: [347][0/6]	Total Loss: 0.75625	Main MSE (x10^-2): 75.6247	LR: 8.73e-05	EMPP_Raw: 1.49153
2025-07-18 11:21:59,128 - logger.py:50 - Epoch: [347][5/6]	Total Loss: 0.74581	Main MSE (x10^-2): 74.5811	LR: 8.73e-05	EMPP_Raw: 1.46779
2025-07-18 11:21:59,168 - logger.py:50 - Epoch 347 Training Summary: Avg Total Loss: 0.74581, Avg Main MSE: 0.74581, Time: 16.82s
2025-07-18 11:22:17,146 - logger.py:50 - Epoch 347 Summary | Train MSE (x10^-2): 74.5811 | Val MSE (x10^-2): 79.5019 | Time: 34.81s
2025-07-18 11:22:20,338 - logger.py:50 - Epoch: [348][0/6]	Total Loss: 0.75233	Main MSE (x10^-2): 75.2333	LR: 8.63e-05	EMPP_Raw: 1.47756
2025-07-18 11:22:34,085 - logger.py:50 - Epoch: [348][5/6]	Total Loss: 0.74548	Main MSE (x10^-2): 74.5476	LR: 8.63e-05	EMPP_Raw: 1.46725
2025-07-18 11:22:34,132 - logger.py:50 - Epoch 348 Training Summary: Avg Total Loss: 0.74548, Avg Main MSE: 0.74548, Time: 16.98s
2025-07-18 11:22:52,098 - logger.py:50 - Epoch 348 Summary | Train MSE (x10^-2): 74.5476 | Val MSE (x10^-2): 78.9244 | Time: 34.95s
2025-07-18 11:22:55,269 - logger.py:50 - Epoch: [349][0/6]	Total Loss: 0.74666	Main MSE (x10^-2): 74.6658	LR: 8.53e-05	EMPP_Raw: 1.47172
2025-07-18 11:23:09,017 - logger.py:50 - Epoch: [349][5/6]	Total Loss: 0.73791	Main MSE (x10^-2): 73.7906	LR: 8.53e-05	EMPP_Raw: 1.45198
2025-07-18 11:23:09,060 - logger.py:50 - Epoch 349 Training Summary: Avg Total Loss: 0.73791, Avg Main MSE: 0.73791, Time: 16.95s
2025-07-18 11:23:26,978 - logger.py:50 - Epoch 349 Summary | Train MSE (x10^-2): 73.7906 | Val MSE (x10^-2): 80.0014 | Time: 34.87s
2025-07-18 11:23:30,015 - logger.py:50 - Epoch: [350][0/6]	Total Loss: 0.75370	Main MSE (x10^-2): 75.3704	LR: 8.43e-05	EMPP_Raw: 1.48685
2025-07-18 11:23:43,919 - logger.py:50 - Epoch: [350][5/6]	Total Loss: 0.74538	Main MSE (x10^-2): 74.5384	LR: 8.43e-05	EMPP_Raw: 1.46775
2025-07-18 11:23:43,964 - logger.py:50 - Epoch 350 Training Summary: Avg Total Loss: 0.74538, Avg Main MSE: 0.74538, Time: 16.97s
2025-07-18 11:24:01,843 - logger.py:50 - Epoch 350 Summary | Train MSE (x10^-2): 74.5384 | Val MSE (x10^-2): 80.6157 | Time: 34.86s
2025-07-18 11:24:04,857 - logger.py:50 - Epoch: [351][0/6]	Total Loss: 0.72611	Main MSE (x10^-2): 72.6112	LR: 8.32e-05	EMPP_Raw: 1.42833
2025-07-18 11:24:18,749 - logger.py:50 - Epoch: [351][5/6]	Total Loss: 0.72678	Main MSE (x10^-2): 72.6780	LR: 8.32e-05	EMPP_Raw: 1.42921
2025-07-18 11:24:18,797 - logger.py:50 - Epoch 351 Training Summary: Avg Total Loss: 0.72678, Avg Main MSE: 0.72678, Time: 16.95s
2025-07-18 11:24:37,079 - logger.py:50 - Epoch 351 Summary | Train MSE (x10^-2): 72.6780 | Val MSE (x10^-2): 80.5779 | Time: 35.23s
2025-07-18 11:24:40,107 - logger.py:50 - Epoch: [352][0/6]	Total Loss: 0.74400	Main MSE (x10^-2): 74.3997	LR: 8.22e-05	EMPP_Raw: 1.46455
2025-07-18 11:24:54,002 - logger.py:50 - Epoch: [352][5/6]	Total Loss: 0.73369	Main MSE (x10^-2): 73.3694	LR: 8.22e-05	EMPP_Raw: 1.44411
2025-07-18 11:24:54,057 - logger.py:50 - Epoch 352 Training Summary: Avg Total Loss: 0.73369, Avg Main MSE: 0.73369, Time: 16.97s
2025-07-18 11:25:12,104 - logger.py:50 - Epoch 352 Summary | Train MSE (x10^-2): 73.3694 | Val MSE (x10^-2): 80.0894 | Time: 35.02s
2025-07-18 11:25:15,326 - logger.py:50 - Epoch: [353][0/6]	Total Loss: 0.75182	Main MSE (x10^-2): 75.1822	LR: 8.12e-05	EMPP_Raw: 1.47832
2025-07-18 11:25:29,329 - logger.py:50 - Epoch: [353][5/6]	Total Loss: 0.74152	Main MSE (x10^-2): 74.1515	LR: 8.12e-05	EMPP_Raw: 1.45997
2025-07-18 11:25:29,378 - logger.py:50 - Epoch 353 Training Summary: Avg Total Loss: 0.74152, Avg Main MSE: 0.74152, Time: 17.26s
2025-07-18 11:25:47,659 - logger.py:50 - Epoch 353 Summary | Train MSE (x10^-2): 74.1515 | Val MSE (x10^-2): 79.2707 | Time: 35.55s
2025-07-18 11:25:50,681 - logger.py:50 - Epoch: [354][0/6]	Total Loss: 0.74672	Main MSE (x10^-2): 74.6715	LR: 8.02e-05	EMPP_Raw: 1.47076
2025-07-18 11:26:04,716 - logger.py:50 - Epoch: [354][5/6]	Total Loss: 0.73333	Main MSE (x10^-2): 73.3335	LR: 8.02e-05	EMPP_Raw: 1.44318
2025-07-18 11:26:04,780 - logger.py:50 - Epoch 354 Training Summary: Avg Total Loss: 0.73333, Avg Main MSE: 0.73333, Time: 17.11s
2025-07-18 11:26:22,898 - logger.py:50 - Epoch 354 Summary | Train MSE (x10^-2): 73.3335 | Val MSE (x10^-2): 79.0721 | Time: 35.23s
2025-07-18 11:26:25,935 - logger.py:50 - Epoch: [355][0/6]	Total Loss: 0.75103	Main MSE (x10^-2): 75.1031	LR: 7.92e-05	EMPP_Raw: 1.48006
2025-07-18 11:26:39,816 - logger.py:50 - Epoch: [355][5/6]	Total Loss: 0.73755	Main MSE (x10^-2): 73.7549	LR: 7.92e-05	EMPP_Raw: 1.45255
2025-07-18 11:26:39,860 - logger.py:50 - Epoch 355 Training Summary: Avg Total Loss: 0.73755, Avg Main MSE: 0.73755, Time: 16.95s
2025-07-18 11:26:57,959 - logger.py:50 - Epoch 355 Summary | Train MSE (x10^-2): 73.7549 | Val MSE (x10^-2): 80.2255 | Time: 35.05s
2025-07-18 11:27:00,972 - logger.py:50 - Epoch: [356][0/6]	Total Loss: 0.74049	Main MSE (x10^-2): 74.0494	LR: 7.82e-05	EMPP_Raw: 1.45815
2025-07-18 11:27:14,817 - logger.py:50 - Epoch: [356][5/6]	Total Loss: 0.73432	Main MSE (x10^-2): 73.4319	LR: 7.82e-05	EMPP_Raw: 1.44545
2025-07-18 11:27:14,860 - logger.py:50 - Epoch 356 Training Summary: Avg Total Loss: 0.73432, Avg Main MSE: 0.73432, Time: 16.90s
2025-07-18 11:27:33,013 - logger.py:50 - Epoch 356 Summary | Train MSE (x10^-2): 73.4319 | Val MSE (x10^-2): 79.9363 | Time: 35.05s
2025-07-18 11:27:36,016 - logger.py:50 - Epoch: [357][0/6]	Total Loss: 0.75452	Main MSE (x10^-2): 75.4519	LR: 7.72e-05	EMPP_Raw: 1.48613
2025-07-18 11:27:49,809 - logger.py:50 - Epoch: [357][5/6]	Total Loss: 0.73219	Main MSE (x10^-2): 73.2194	LR: 7.72e-05	EMPP_Raw: 1.44145
2025-07-18 11:27:49,856 - logger.py:50 - Epoch 357 Training Summary: Avg Total Loss: 0.73219, Avg Main MSE: 0.73219, Time: 16.83s
2025-07-18 11:28:07,835 - logger.py:50 - Epoch 357 Summary | Train MSE (x10^-2): 73.2194 | Val MSE (x10^-2): 77.7408 | Time: 34.82s
2025-07-18 11:28:11,211 - logger.py:50 - Epoch: [358][0/6]	Total Loss: 0.73982	Main MSE (x10^-2): 73.9817	LR: 7.63e-05	EMPP_Raw: 1.45520
2025-07-18 11:28:25,009 - logger.py:50 - Epoch: [358][5/6]	Total Loss: 0.73886	Main MSE (x10^-2): 73.8859	LR: 7.63e-05	EMPP_Raw: 1.45521
2025-07-18 11:28:25,065 - logger.py:50 - Epoch 358 Training Summary: Avg Total Loss: 0.73886, Avg Main MSE: 0.73886, Time: 17.22s
2025-07-18 11:28:42,925 - logger.py:50 - Epoch 358 Summary | Train MSE (x10^-2): 73.8859 | Val MSE (x10^-2): 79.4896 | Time: 35.08s
2025-07-18 11:28:46,090 - logger.py:50 - Epoch: [359][0/6]	Total Loss: 0.71260	Main MSE (x10^-2): 71.2602	LR: 7.53e-05	EMPP_Raw: 1.40383
2025-07-18 11:28:59,859 - logger.py:50 - Epoch: [359][5/6]	Total Loss: 0.74142	Main MSE (x10^-2): 74.1416	LR: 7.53e-05	EMPP_Raw: 1.46118
2025-07-18 11:28:59,904 - logger.py:50 - Epoch 359 Training Summary: Avg Total Loss: 0.74142, Avg Main MSE: 0.74142, Time: 16.97s
2025-07-18 11:29:17,850 - logger.py:50 - Epoch 359 Summary | Train MSE (x10^-2): 74.1416 | Val MSE (x10^-2): 79.5124 | Time: 34.92s
2025-07-18 11:29:20,858 - logger.py:50 - Epoch: [360][0/6]	Total Loss: 0.74418	Main MSE (x10^-2): 74.4177	LR: 7.43e-05	EMPP_Raw: 1.46391
2025-07-18 11:29:34,825 - logger.py:50 - Epoch: [360][5/6]	Total Loss: 0.74017	Main MSE (x10^-2): 74.0171	LR: 7.43e-05	EMPP_Raw: 1.45719
2025-07-18 11:29:34,866 - logger.py:50 - Epoch 360 Training Summary: Avg Total Loss: 0.74017, Avg Main MSE: 0.74017, Time: 17.01s
2025-07-18 11:29:52,711 - logger.py:50 - Epoch 360 Summary | Train MSE (x10^-2): 74.0171 | Val MSE (x10^-2): 78.8095 | Time: 34.85s
2025-07-18 11:29:55,784 - logger.py:50 - Epoch: [361][0/6]	Total Loss: 0.73449	Main MSE (x10^-2): 73.4489	LR: 7.33e-05	EMPP_Raw: 1.44672
2025-07-18 11:30:09,565 - logger.py:50 - Epoch: [361][5/6]	Total Loss: 0.72706	Main MSE (x10^-2): 72.7063	LR: 7.33e-05	EMPP_Raw: 1.43226
2025-07-18 11:30:09,606 - logger.py:50 - Epoch 361 Training Summary: Avg Total Loss: 0.72706, Avg Main MSE: 0.72706, Time: 16.89s
2025-07-18 11:30:27,713 - logger.py:50 - Epoch 361 Summary | Train MSE (x10^-2): 72.7063 | Val MSE (x10^-2): 79.3652 | Time: 35.00s
2025-07-18 11:30:30,773 - logger.py:50 - Epoch: [362][0/6]	Total Loss: 0.73091	Main MSE (x10^-2): 73.0914	LR: 7.24e-05	EMPP_Raw: 1.43957
2025-07-18 11:30:44,701 - logger.py:50 - Epoch: [362][5/6]	Total Loss: 0.73208	Main MSE (x10^-2): 73.2085	LR: 7.24e-05	EMPP_Raw: 1.44251
2025-07-18 11:30:44,753 - logger.py:50 - Epoch 362 Training Summary: Avg Total Loss: 0.73208, Avg Main MSE: 0.73208, Time: 17.03s
2025-07-18 11:31:02,844 - logger.py:50 - Epoch 362 Summary | Train MSE (x10^-2): 73.2085 | Val MSE (x10^-2): 79.1548 | Time: 35.13s
2025-07-18 11:31:05,853 - logger.py:50 - Epoch: [363][0/6]	Total Loss: 0.73432	Main MSE (x10^-2): 73.4318	LR: 7.14e-05	EMPP_Raw: 1.44554
2025-07-18 11:31:19,671 - logger.py:50 - Epoch: [363][5/6]	Total Loss: 0.73652	Main MSE (x10^-2): 73.6525	LR: 7.14e-05	EMPP_Raw: 1.45085
2025-07-18 11:31:19,712 - logger.py:50 - Epoch 363 Training Summary: Avg Total Loss: 0.73652, Avg Main MSE: 0.73652, Time: 16.86s
2025-07-18 11:31:37,613 - logger.py:50 - Epoch 363 Summary | Train MSE (x10^-2): 73.6525 | Val MSE (x10^-2): 78.6324 | Time: 34.76s
2025-07-18 11:31:40,794 - logger.py:50 - Epoch: [364][0/6]	Total Loss: 0.75236	Main MSE (x10^-2): 75.2358	LR: 7.05e-05	EMPP_Raw: 1.48059
2025-07-18 11:31:54,636 - logger.py:50 - Epoch: [364][5/6]	Total Loss: 0.74179	Main MSE (x10^-2): 74.1792	LR: 7.05e-05	EMPP_Raw: 1.46199
2025-07-18 11:31:54,684 - logger.py:50 - Epoch 364 Training Summary: Avg Total Loss: 0.74179, Avg Main MSE: 0.74179, Time: 17.06s
2025-07-18 11:32:12,614 - logger.py:50 - Epoch 364 Summary | Train MSE (x10^-2): 74.1792 | Val MSE (x10^-2): 79.6096 | Time: 34.99s
2025-07-18 11:32:15,653 - logger.py:50 - Epoch: [365][0/6]	Total Loss: 0.72786	Main MSE (x10^-2): 72.7863	LR: 6.95e-05	EMPP_Raw: 1.43406
2025-07-18 11:32:29,647 - logger.py:50 - Epoch: [365][5/6]	Total Loss: 0.73917	Main MSE (x10^-2): 73.9168	LR: 6.95e-05	EMPP_Raw: 1.45654
2025-07-18 11:32:29,691 - logger.py:50 - Epoch 365 Training Summary: Avg Total Loss: 0.73917, Avg Main MSE: 0.73917, Time: 17.07s
2025-07-18 11:32:47,613 - logger.py:50 - Epoch 365 Summary | Train MSE (x10^-2): 73.9168 | Val MSE (x10^-2): 79.0819 | Time: 34.99s
2025-07-18 11:32:50,623 - logger.py:50 - Epoch: [366][0/6]	Total Loss: 0.72954	Main MSE (x10^-2): 72.9537	LR: 6.86e-05	EMPP_Raw: 1.43753
2025-07-18 11:33:04,598 - logger.py:50 - Epoch: [366][5/6]	Total Loss: 0.73901	Main MSE (x10^-2): 73.9007	LR: 6.86e-05	EMPP_Raw: 1.45614
2025-07-18 11:33:04,642 - logger.py:50 - Epoch 366 Training Summary: Avg Total Loss: 0.73901, Avg Main MSE: 0.73901, Time: 17.02s
2025-07-18 11:33:22,552 - logger.py:50 - Epoch 366 Summary | Train MSE (x10^-2): 73.9007 | Val MSE (x10^-2): 79.0996 | Time: 34.93s
2025-07-18 11:33:25,563 - logger.py:50 - Epoch: [367][0/6]	Total Loss: 0.73353	Main MSE (x10^-2): 73.3525	LR: 6.76e-05	EMPP_Raw: 1.44590
2025-07-18 11:33:39,378 - logger.py:50 - Epoch: [367][5/6]	Total Loss: 0.74925	Main MSE (x10^-2): 74.9254	LR: 6.76e-05	EMPP_Raw: 1.47673
2025-07-18 11:33:39,424 - logger.py:50 - Epoch 367 Training Summary: Avg Total Loss: 0.74925, Avg Main MSE: 0.74925, Time: 16.86s
2025-07-18 11:33:57,418 - logger.py:50 - Epoch 367 Summary | Train MSE (x10^-2): 74.9254 | Val MSE (x10^-2): 79.1763 | Time: 34.86s
2025-07-18 11:34:00,615 - logger.py:50 - Epoch: [368][0/6]	Total Loss: 0.74068	Main MSE (x10^-2): 74.0675	LR: 6.67e-05	EMPP_Raw: 1.45796
2025-07-18 11:34:14,421 - logger.py:50 - Epoch: [368][5/6]	Total Loss: 0.72503	Main MSE (x10^-2): 72.5027	LR: 6.67e-05	EMPP_Raw: 1.42819
2025-07-18 11:34:14,464 - logger.py:50 - Epoch 368 Training Summary: Avg Total Loss: 0.72503, Avg Main MSE: 0.72503, Time: 17.04s
2025-07-18 11:34:32,502 - logger.py:50 - Epoch 368 Summary | Train MSE (x10^-2): 72.5027 | Val MSE (x10^-2): 78.9564 | Time: 35.08s
2025-07-18 11:34:35,729 - logger.py:50 - Epoch: [369][0/6]	Total Loss: 0.72127	Main MSE (x10^-2): 72.1270	LR: 6.58e-05	EMPP_Raw: 1.42209
2025-07-18 11:34:49,498 - logger.py:50 - Epoch: [369][5/6]	Total Loss: 0.73621	Main MSE (x10^-2): 73.6208	LR: 6.58e-05	EMPP_Raw: 1.45142
2025-07-18 11:34:49,543 - logger.py:50 - Epoch 369 Training Summary: Avg Total Loss: 0.73621, Avg Main MSE: 0.73621, Time: 17.03s
2025-07-18 11:35:07,470 - logger.py:50 - Epoch 369 Summary | Train MSE (x10^-2): 73.6208 | Val MSE (x10^-2): 78.8825 | Time: 34.96s
2025-07-18 11:35:10,474 - logger.py:50 - Epoch: [370][0/6]	Total Loss: 0.73570	Main MSE (x10^-2): 73.5703	LR: 6.48e-05	EMPP_Raw: 1.44917
2025-07-18 11:35:24,436 - logger.py:50 - Epoch: [370][5/6]	Total Loss: 0.72906	Main MSE (x10^-2): 72.9063	LR: 6.48e-05	EMPP_Raw: 1.43626
2025-07-18 11:35:24,483 - logger.py:50 - Epoch 370 Training Summary: Avg Total Loss: 0.72906, Avg Main MSE: 0.72906, Time: 17.00s
2025-07-18 11:35:42,451 - logger.py:50 - Epoch 370 Summary | Train MSE (x10^-2): 72.9063 | Val MSE (x10^-2): 79.9313 | Time: 34.97s
2025-07-18 11:35:45,452 - logger.py:50 - Epoch: [371][0/6]	Total Loss: 0.73792	Main MSE (x10^-2): 73.7919	LR: 6.39e-05	EMPP_Raw: 1.45712
2025-07-18 11:35:59,261 - logger.py:50 - Epoch: [371][5/6]	Total Loss: 0.74876	Main MSE (x10^-2): 74.8762	LR: 6.39e-05	EMPP_Raw: 1.47621
2025-07-18 11:35:59,302 - logger.py:50 - Epoch 371 Training Summary: Avg Total Loss: 0.74876, Avg Main MSE: 0.74876, Time: 16.84s
2025-07-18 11:36:17,357 - logger.py:50 - Epoch 371 Summary | Train MSE (x10^-2): 74.8762 | Val MSE (x10^-2): 79.6283 | Time: 34.90s
2025-07-18 11:36:20,400 - logger.py:50 - Epoch: [372][0/6]	Total Loss: 0.71575	Main MSE (x10^-2): 71.5748	LR: 6.30e-05	EMPP_Raw: 1.40913
2025-07-18 11:36:34,220 - logger.py:50 - Epoch: [372][5/6]	Total Loss: 0.73191	Main MSE (x10^-2): 73.1909	LR: 6.30e-05	EMPP_Raw: 1.44213
2025-07-18 11:36:34,262 - logger.py:50 - Epoch 372 Training Summary: Avg Total Loss: 0.73191, Avg Main MSE: 0.73191, Time: 16.90s
2025-07-18 11:36:52,072 - logger.py:50 - Epoch 372 Summary | Train MSE (x10^-2): 73.1909 | Val MSE (x10^-2): 79.4320 | Time: 34.71s
2025-07-18 11:36:55,231 - logger.py:50 - Epoch: [373][0/6]	Total Loss: 0.73542	Main MSE (x10^-2): 73.5416	LR: 6.21e-05	EMPP_Raw: 1.44901
2025-07-18 11:37:09,020 - logger.py:50 - Epoch: [373][5/6]	Total Loss: 0.73165	Main MSE (x10^-2): 73.1655	LR: 6.21e-05	EMPP_Raw: 1.44148
2025-07-18 11:37:09,067 - logger.py:50 - Epoch 373 Training Summary: Avg Total Loss: 0.73165, Avg Main MSE: 0.73165, Time: 16.99s
2025-07-18 11:37:26,956 - logger.py:50 - Epoch 373 Summary | Train MSE (x10^-2): 73.1655 | Val MSE (x10^-2): 79.6401 | Time: 34.88s
2025-07-18 11:37:29,967 - logger.py:50 - Epoch: [374][0/6]	Total Loss: 0.73432	Main MSE (x10^-2): 73.4322	LR: 6.12e-05	EMPP_Raw: 1.44858
2025-07-18 11:37:43,917 - logger.py:50 - Epoch: [374][5/6]	Total Loss: 0.74289	Main MSE (x10^-2): 74.2890	LR: 6.12e-05	EMPP_Raw: 1.46483
2025-07-18 11:37:43,958 - logger.py:50 - Epoch 374 Training Summary: Avg Total Loss: 0.74289, Avg Main MSE: 0.74289, Time: 17.00s
2025-07-18 11:38:01,906 - logger.py:50 - Epoch 374 Summary | Train MSE (x10^-2): 74.2890 | Val MSE (x10^-2): 79.7970 | Time: 34.95s
2025-07-18 11:38:04,959 - logger.py:50 - Epoch: [375][0/6]	Total Loss: 0.71937	Main MSE (x10^-2): 71.9369	LR: 6.03e-05	EMPP_Raw: 1.42094
2025-07-18 11:38:18,842 - logger.py:50 - Epoch: [375][5/6]	Total Loss: 0.73350	Main MSE (x10^-2): 73.3501	LR: 6.03e-05	EMPP_Raw: 1.44622
2025-07-18 11:38:18,883 - logger.py:50 - Epoch 375 Training Summary: Avg Total Loss: 0.73350, Avg Main MSE: 0.73350, Time: 16.97s
2025-07-18 11:38:36,948 - logger.py:50 - Epoch 375 Summary | Train MSE (x10^-2): 73.3501 | Val MSE (x10^-2): 79.8350 | Time: 35.04s
2025-07-18 11:38:39,999 - logger.py:50 - Epoch: [376][0/6]	Total Loss: 0.73952	Main MSE (x10^-2): 73.9515	LR: 5.94e-05	EMPP_Raw: 1.46032
2025-07-18 11:38:53,776 - logger.py:50 - Epoch: [376][5/6]	Total Loss: 0.74486	Main MSE (x10^-2): 74.4856	LR: 5.94e-05	EMPP_Raw: 1.46846
2025-07-18 11:38:53,820 - logger.py:50 - Epoch 376 Training Summary: Avg Total Loss: 0.74486, Avg Main MSE: 0.74486, Time: 16.86s
2025-07-18 11:39:11,813 - logger.py:50 - Epoch 376 Summary | Train MSE (x10^-2): 74.4856 | Val MSE (x10^-2): 79.8298 | Time: 34.86s
2025-07-18 11:39:14,847 - logger.py:50 - Epoch: [377][0/6]	Total Loss: 0.74430	Main MSE (x10^-2): 74.4297	LR: 5.85e-05	EMPP_Raw: 1.46820
2025-07-18 11:39:28,647 - logger.py:50 - Epoch: [377][5/6]	Total Loss: 0.74139	Main MSE (x10^-2): 74.1388	LR: 5.85e-05	EMPP_Raw: 1.46199
2025-07-18 11:39:28,688 - logger.py:50 - Epoch 377 Training Summary: Avg Total Loss: 0.74139, Avg Main MSE: 0.74139, Time: 16.87s
2025-07-18 11:39:46,513 - logger.py:50 - Epoch 377 Summary | Train MSE (x10^-2): 74.1388 | Val MSE (x10^-2): 78.9860 | Time: 34.69s
2025-07-18 11:39:49,885 - logger.py:50 - Epoch: [378][0/6]	Total Loss: 0.73552	Main MSE (x10^-2): 73.5524	LR: 5.77e-05	EMPP_Raw: 1.45059
2025-07-18 11:40:03,714 - logger.py:50 - Epoch: [378][5/6]	Total Loss: 0.72300	Main MSE (x10^-2): 72.2998	LR: 5.77e-05	EMPP_Raw: 1.42540
2025-07-18 11:40:03,768 - logger.py:50 - Epoch 378 Training Summary: Avg Total Loss: 0.72300, Avg Main MSE: 0.72300, Time: 17.25s
2025-07-18 11:40:21,691 - logger.py:50 - Epoch 378 Summary | Train MSE (x10^-2): 72.2998 | Val MSE (x10^-2): 79.7336 | Time: 35.17s
2025-07-18 11:40:24,853 - logger.py:50 - Epoch: [379][0/6]	Total Loss: 0.74465	Main MSE (x10^-2): 74.4652	LR: 5.68e-05	EMPP_Raw: 1.47050
2025-07-18 11:40:38,566 - logger.py:50 - Epoch: [379][5/6]	Total Loss: 0.74025	Main MSE (x10^-2): 74.0252	LR: 5.68e-05	EMPP_Raw: 1.45993
2025-07-18 11:40:38,615 - logger.py:50 - Epoch 379 Training Summary: Avg Total Loss: 0.74025, Avg Main MSE: 0.74025, Time: 16.91s
2025-07-18 11:40:56,576 - logger.py:50 - Epoch 379 Summary | Train MSE (x10^-2): 74.0252 | Val MSE (x10^-2): 79.8004 | Time: 34.88s
2025-07-18 11:40:59,599 - logger.py:50 - Epoch: [380][0/6]	Total Loss: 0.72630	Main MSE (x10^-2): 72.6303	LR: 5.59e-05	EMPP_Raw: 1.43117
2025-07-18 11:41:13,511 - logger.py:50 - Epoch: [380][5/6]	Total Loss: 0.73333	Main MSE (x10^-2): 73.3330	LR: 5.59e-05	EMPP_Raw: 1.44567
2025-07-18 11:41:13,557 - logger.py:50 - Epoch 380 Training Summary: Avg Total Loss: 0.73333, Avg Main MSE: 0.73333, Time: 16.97s
2025-07-18 11:41:31,482 - logger.py:50 - Epoch 380 Summary | Train MSE (x10^-2): 73.3330 | Val MSE (x10^-2): 79.1547 | Time: 34.90s
2025-07-18 11:41:34,480 - logger.py:50 - Epoch: [381][0/6]	Total Loss: 0.73011	Main MSE (x10^-2): 73.0105	LR: 5.51e-05	EMPP_Raw: 1.44017
2025-07-18 11:41:48,253 - logger.py:50 - Epoch: [381][5/6]	Total Loss: 0.74200	Main MSE (x10^-2): 74.2002	LR: 5.51e-05	EMPP_Raw: 1.46267
2025-07-18 11:41:48,296 - logger.py:50 - Epoch 381 Training Summary: Avg Total Loss: 0.74200, Avg Main MSE: 0.74200, Time: 16.81s
2025-07-18 11:42:06,347 - logger.py:50 - Epoch 381 Summary | Train MSE (x10^-2): 74.2002 | Val MSE (x10^-2): 79.1294 | Time: 34.86s
2025-07-18 11:42:09,343 - logger.py:50 - Epoch: [382][0/6]	Total Loss: 0.72571	Main MSE (x10^-2): 72.5713	LR: 5.42e-05	EMPP_Raw: 1.43177
2025-07-18 11:42:23,136 - logger.py:50 - Epoch: [382][5/6]	Total Loss: 0.73345	Main MSE (x10^-2): 73.3453	LR: 5.42e-05	EMPP_Raw: 1.44542
2025-07-18 11:42:23,178 - logger.py:50 - Epoch 382 Training Summary: Avg Total Loss: 0.73345, Avg Main MSE: 0.73345, Time: 16.82s
2025-07-18 11:42:41,289 - logger.py:50 - Epoch 382 Summary | Train MSE (x10^-2): 73.3453 | Val MSE (x10^-2): 79.0855 | Time: 34.94s
2025-07-18 11:42:44,335 - logger.py:50 - Epoch: [383][0/6]	Total Loss: 0.73465	Main MSE (x10^-2): 73.4648	LR: 5.34e-05	EMPP_Raw: 1.44995
2025-07-18 11:42:58,158 - logger.py:50 - Epoch: [383][5/6]	Total Loss: 0.73943	Main MSE (x10^-2): 73.9433	LR: 5.34e-05	EMPP_Raw: 1.45865
2025-07-18 11:42:58,201 - logger.py:50 - Epoch 383 Training Summary: Avg Total Loss: 0.73943, Avg Main MSE: 0.73943, Time: 16.91s
2025-07-18 11:43:16,110 - logger.py:50 - Epoch 383 Summary | Train MSE (x10^-2): 73.9433 | Val MSE (x10^-2): 79.8454 | Time: 34.82s
2025-07-18 11:43:19,272 - logger.py:50 - Epoch: [384][0/6]	Total Loss: 0.74097	Main MSE (x10^-2): 74.0971	LR: 5.25e-05	EMPP_Raw: 1.46168
2025-07-18 11:43:32,965 - logger.py:50 - Epoch: [384][5/6]	Total Loss: 0.74605	Main MSE (x10^-2): 74.6051	LR: 5.25e-05	EMPP_Raw: 1.47140
2025-07-18 11:43:33,009 - logger.py:50 - Epoch 384 Training Summary: Avg Total Loss: 0.74605, Avg Main MSE: 0.74605, Time: 16.89s
2025-07-18 11:43:50,951 - logger.py:50 - Epoch 384 Summary | Train MSE (x10^-2): 74.6051 | Val MSE (x10^-2): 79.0576 | Time: 34.84s
2025-07-18 11:43:53,982 - logger.py:50 - Epoch: [385][0/6]	Total Loss: 0.71952	Main MSE (x10^-2): 71.9523	LR: 5.17e-05	EMPP_Raw: 1.41963
2025-07-18 11:44:07,888 - logger.py:50 - Epoch: [385][5/6]	Total Loss: 0.73679	Main MSE (x10^-2): 73.6789	LR: 5.17e-05	EMPP_Raw: 1.45344
2025-07-18 11:44:07,928 - logger.py:50 - Epoch 385 Training Summary: Avg Total Loss: 0.73679, Avg Main MSE: 0.73679, Time: 16.97s
2025-07-18 11:44:25,973 - logger.py:50 - Epoch 385 Summary | Train MSE (x10^-2): 73.6789 | Val MSE (x10^-2): 79.4674 | Time: 35.02s
2025-07-18 11:44:28,996 - logger.py:50 - Epoch: [386][0/6]	Total Loss: 0.74528	Main MSE (x10^-2): 74.5279	LR: 5.09e-05	EMPP_Raw: 1.46550
2025-07-18 11:44:42,954 - logger.py:50 - Epoch: [386][5/6]	Total Loss: 0.73765	Main MSE (x10^-2): 73.7653	LR: 5.09e-05	EMPP_Raw: 1.45416
2025-07-18 11:44:43,000 - logger.py:50 - Epoch 386 Training Summary: Avg Total Loss: 0.73765, Avg Main MSE: 0.73765, Time: 17.02s
2025-07-18 11:45:00,976 - logger.py:50 - Epoch 386 Summary | Train MSE (x10^-2): 73.7653 | Val MSE (x10^-2): 79.2911 | Time: 35.00s
2025-07-18 11:45:03,976 - logger.py:50 - Epoch: [387][0/6]	Total Loss: 0.71090	Main MSE (x10^-2): 71.0901	LR: 5.00e-05	EMPP_Raw: 1.40199
2025-07-18 11:45:17,799 - logger.py:50 - Epoch: [387][5/6]	Total Loss: 0.72814	Main MSE (x10^-2): 72.8138	LR: 5.00e-05	EMPP_Raw: 1.43613
2025-07-18 11:45:17,844 - logger.py:50 - Epoch 387 Training Summary: Avg Total Loss: 0.72814, Avg Main MSE: 0.72814, Time: 16.86s
2025-07-18 11:45:35,873 - logger.py:50 - Epoch 387 Summary | Train MSE (x10^-2): 72.8138 | Val MSE (x10^-2): 79.2779 | Time: 34.89s
2025-07-18 11:45:39,043 - logger.py:50 - Epoch: [388][0/6]	Total Loss: 0.73814	Main MSE (x10^-2): 73.8141	LR: 4.92e-05	EMPP_Raw: 1.45542
2025-07-18 11:45:52,817 - logger.py:50 - Epoch: [388][5/6]	Total Loss: 0.74154	Main MSE (x10^-2): 74.1543	LR: 4.92e-05	EMPP_Raw: 1.46219
2025-07-18 11:45:52,858 - logger.py:50 - Epoch 388 Training Summary: Avg Total Loss: 0.74154, Avg Main MSE: 0.74154, Time: 16.98s
2025-07-18 11:46:10,788 - logger.py:50 - Epoch 388 Summary | Train MSE (x10^-2): 74.1543 | Val MSE (x10^-2): 78.7847 | Time: 34.91s
2025-07-18 11:46:13,956 - logger.py:50 - Epoch: [389][0/6]	Total Loss: 0.74073	Main MSE (x10^-2): 74.0733	LR: 4.84e-05	EMPP_Raw: 1.45897
2025-07-18 11:46:27,739 - logger.py:50 - Epoch: [389][5/6]	Total Loss: 0.73186	Main MSE (x10^-2): 73.1861	LR: 4.84e-05	EMPP_Raw: 1.44383
2025-07-18 11:46:27,785 - logger.py:50 - Epoch 389 Training Summary: Avg Total Loss: 0.73186, Avg Main MSE: 0.73186, Time: 16.99s
2025-07-18 11:46:45,647 - logger.py:50 - Epoch 389 Summary | Train MSE (x10^-2): 73.1861 | Val MSE (x10^-2): 79.5464 | Time: 34.85s
2025-07-18 11:46:48,657 - logger.py:50 - Epoch: [390][0/6]	Total Loss: 0.73992	Main MSE (x10^-2): 73.9915	LR: 4.76e-05	EMPP_Raw: 1.46062
2025-07-18 11:47:02,633 - logger.py:50 - Epoch: [390][5/6]	Total Loss: 0.73300	Main MSE (x10^-2): 73.3002	LR: 4.76e-05	EMPP_Raw: 1.44614
2025-07-18 11:47:02,678 - logger.py:50 - Epoch 390 Training Summary: Avg Total Loss: 0.73300, Avg Main MSE: 0.73300, Time: 17.02s
2025-07-18 11:47:20,630 - logger.py:50 - Epoch 390 Summary | Train MSE (x10^-2): 73.3002 | Val MSE (x10^-2): 79.3031 | Time: 34.98s
2025-07-18 11:47:23,650 - logger.py:50 - Epoch: [391][0/6]	Total Loss: 0.75427	Main MSE (x10^-2): 75.4268	LR: 4.68e-05	EMPP_Raw: 1.48938
2025-07-18 11:47:37,492 - logger.py:50 - Epoch: [391][5/6]	Total Loss: 0.74009	Main MSE (x10^-2): 74.0090	LR: 4.68e-05	EMPP_Raw: 1.46027
2025-07-18 11:47:37,531 - logger.py:50 - Epoch 391 Training Summary: Avg Total Loss: 0.74009, Avg Main MSE: 0.74009, Time: 16.89s
2025-07-18 11:47:55,697 - logger.py:50 - Epoch 391 Summary | Train MSE (x10^-2): 74.0090 | Val MSE (x10^-2): 78.9402 | Time: 35.06s
2025-07-18 11:47:58,760 - logger.py:50 - Epoch: [392][0/6]	Total Loss: 0.72972	Main MSE (x10^-2): 72.9717	LR: 4.60e-05	EMPP_Raw: 1.44002
2025-07-18 11:48:12,623 - logger.py:50 - Epoch: [392][5/6]	Total Loss: 0.73493	Main MSE (x10^-2): 73.4927	LR: 4.60e-05	EMPP_Raw: 1.44991
2025-07-18 11:48:12,669 - logger.py:50 - Epoch 392 Training Summary: Avg Total Loss: 0.73493, Avg Main MSE: 0.73493, Time: 16.96s
2025-07-18 11:48:30,558 - logger.py:50 - Epoch 392 Summary | Train MSE (x10^-2): 73.4927 | Val MSE (x10^-2): 79.3144 | Time: 34.85s
2025-07-18 11:48:33,722 - logger.py:50 - Epoch: [393][0/6]	Total Loss: 0.72994	Main MSE (x10^-2): 72.9941	LR: 4.52e-05	EMPP_Raw: 1.44033
2025-07-18 11:48:47,525 - logger.py:50 - Epoch: [393][5/6]	Total Loss: 0.74729	Main MSE (x10^-2): 74.7289	LR: 4.52e-05	EMPP_Raw: 1.47479
2025-07-18 11:48:47,570 - logger.py:50 - Epoch 393 Training Summary: Avg Total Loss: 0.74729, Avg Main MSE: 0.74729, Time: 17.00s
2025-07-18 11:49:05,453 - logger.py:50 - Epoch 393 Summary | Train MSE (x10^-2): 74.7289 | Val MSE (x10^-2): 79.4582 | Time: 34.89s
2025-07-18 11:49:08,461 - logger.py:50 - Epoch: [394][0/6]	Total Loss: 0.72817	Main MSE (x10^-2): 72.8165	LR: 4.44e-05	EMPP_Raw: 1.43524
2025-07-18 11:49:22,430 - logger.py:50 - Epoch: [394][5/6]	Total Loss: 0.73288	Main MSE (x10^-2): 73.2879	LR: 4.44e-05	EMPP_Raw: 1.44536
2025-07-18 11:49:22,472 - logger.py:50 - Epoch 394 Training Summary: Avg Total Loss: 0.73288, Avg Main MSE: 0.73288, Time: 17.01s
2025-07-18 11:49:40,364 - logger.py:50 - Epoch 394 Summary | Train MSE (x10^-2): 73.2879 | Val MSE (x10^-2): 79.0780 | Time: 34.91s
2025-07-18 11:49:43,404 - logger.py:50 - Epoch: [395][0/6]	Total Loss: 0.72797	Main MSE (x10^-2): 72.7971	LR: 4.36e-05	EMPP_Raw: 1.43520
2025-07-18 11:49:57,170 - logger.py:50 - Epoch: [395][5/6]	Total Loss: 0.73196	Main MSE (x10^-2): 73.1957	LR: 4.36e-05	EMPP_Raw: 1.44435
2025-07-18 11:49:57,212 - logger.py:50 - Epoch 395 Training Summary: Avg Total Loss: 0.73196, Avg Main MSE: 0.73196, Time: 16.84s
2025-07-18 11:50:15,297 - logger.py:50 - Epoch 395 Summary | Train MSE (x10^-2): 73.1957 | Val MSE (x10^-2): 80.1120 | Time: 34.93s
2025-07-18 11:50:18,301 - logger.py:50 - Epoch: [396][0/6]	Total Loss: 0.72471	Main MSE (x10^-2): 72.4708	LR: 4.29e-05	EMPP_Raw: 1.42749
2025-07-18 11:50:32,102 - logger.py:50 - Epoch: [396][5/6]	Total Loss: 0.73891	Main MSE (x10^-2): 73.8913	LR: 4.29e-05	EMPP_Raw: 1.45732
2025-07-18 11:50:32,143 - logger.py:50 - Epoch 396 Training Summary: Avg Total Loss: 0.73891, Avg Main MSE: 0.73891, Time: 16.84s
2025-07-18 11:50:50,111 - logger.py:50 - Epoch 396 Summary | Train MSE (x10^-2): 73.8913 | Val MSE (x10^-2): 78.8086 | Time: 34.81s
2025-07-18 11:50:53,109 - logger.py:50 - Epoch: [397][0/6]	Total Loss: 0.73582	Main MSE (x10^-2): 73.5824	LR: 4.21e-05	EMPP_Raw: 1.45202
2025-07-18 11:51:06,862 - logger.py:50 - Epoch: [397][5/6]	Total Loss: 0.72941	Main MSE (x10^-2): 72.9407	LR: 4.21e-05	EMPP_Raw: 1.43978
2025-07-18 11:51:06,908 - logger.py:50 - Epoch 397 Training Summary: Avg Total Loss: 0.72941, Avg Main MSE: 0.72941, Time: 16.79s
2025-07-18 11:51:24,829 - logger.py:50 - Epoch 397 Summary | Train MSE (x10^-2): 72.9407 | Val MSE (x10^-2): 79.5824 | Time: 34.71s
2025-07-18 11:51:28,195 - logger.py:50 - Epoch: [398][0/6]	Total Loss: 0.74677	Main MSE (x10^-2): 74.6768	LR: 4.13e-05	EMPP_Raw: 1.47495
2025-07-18 11:51:41,995 - logger.py:50 - Epoch: [398][5/6]	Total Loss: 0.74617	Main MSE (x10^-2): 74.6172	LR: 4.13e-05	EMPP_Raw: 1.47260
2025-07-18 11:51:42,047 - logger.py:50 - Epoch 398 Training Summary: Avg Total Loss: 0.74617, Avg Main MSE: 0.74617, Time: 17.21s
2025-07-18 11:51:59,916 - logger.py:50 - Epoch 398 Summary | Train MSE (x10^-2): 74.6172 | Val MSE (x10^-2): 79.2304 | Time: 35.08s
2025-07-18 11:52:03,089 - logger.py:50 - Epoch: [399][0/6]	Total Loss: 0.72495	Main MSE (x10^-2): 72.4953	LR: 4.06e-05	EMPP_Raw: 1.43120
2025-07-18 11:52:16,900 - logger.py:50 - Epoch: [399][5/6]	Total Loss: 0.72895	Main MSE (x10^-2): 72.8952	LR: 4.06e-05	EMPP_Raw: 1.43806
2025-07-18 11:52:16,945 - logger.py:50 - Epoch 399 Training Summary: Avg Total Loss: 0.72895, Avg Main MSE: 0.72895, Time: 17.02s
2025-07-18 11:52:34,840 - logger.py:50 - Epoch 399 Summary | Train MSE (x10^-2): 72.8952 | Val MSE (x10^-2): 79.8393 | Time: 34.92s
2025-07-18 11:52:37,858 - logger.py:50 - Epoch: [400][0/6]	Total Loss: 0.72453	Main MSE (x10^-2): 72.4528	LR: 3.98e-05	EMPP_Raw: 1.42840
2025-07-18 11:52:51,768 - logger.py:50 - Epoch: [400][5/6]	Total Loss: 0.72885	Main MSE (x10^-2): 72.8851	LR: 3.98e-05	EMPP_Raw: 1.43807
2025-07-18 11:52:51,813 - logger.py:50 - Epoch 400 Training Summary: Avg Total Loss: 0.72885, Avg Main MSE: 0.72885, Time: 16.96s
2025-07-18 11:53:09,732 - logger.py:50 - Epoch 400 Summary | Train MSE (x10^-2): 72.8851 | Val MSE (x10^-2): 78.9205 | Time: 34.89s
2025-07-18 11:53:12,791 - logger.py:50 - Epoch: [401][0/6]	Total Loss: 0.72935	Main MSE (x10^-2): 72.9347	LR: 3.91e-05	EMPP_Raw: 1.44163
2025-07-18 11:53:26,589 - logger.py:50 - Epoch: [401][5/6]	Total Loss: 0.73061	Main MSE (x10^-2): 73.0610	LR: 3.91e-05	EMPP_Raw: 1.44198
2025-07-18 11:53:26,627 - logger.py:50 - Epoch 401 Training Summary: Avg Total Loss: 0.73061, Avg Main MSE: 0.73061, Time: 16.88s
2025-07-18 11:53:44,650 - logger.py:50 - Epoch 401 Summary | Train MSE (x10^-2): 73.0610 | Val MSE (x10^-2): 78.9011 | Time: 34.91s
2025-07-18 11:53:47,664 - logger.py:50 - Epoch: [402][0/6]	Total Loss: 0.72112	Main MSE (x10^-2): 72.1122	LR: 3.84e-05	EMPP_Raw: 1.42115
2025-07-18 11:54:01,486 - logger.py:50 - Epoch: [402][5/6]	Total Loss: 0.73212	Main MSE (x10^-2): 73.2120	LR: 3.84e-05	EMPP_Raw: 1.44422
2025-07-18 11:54:01,531 - logger.py:50 - Epoch 402 Training Summary: Avg Total Loss: 0.73212, Avg Main MSE: 0.73212, Time: 16.87s
2025-07-18 11:54:19,573 - logger.py:50 - Epoch 402 Summary | Train MSE (x10^-2): 73.2120 | Val MSE (x10^-2): 79.3346 | Time: 34.92s
2025-07-18 11:54:22,579 - logger.py:50 - Epoch: [403][0/6]	Total Loss: 0.74014	Main MSE (x10^-2): 74.0143	LR: 3.76e-05	EMPP_Raw: 1.45960
2025-07-18 11:54:36,405 - logger.py:50 - Epoch: [403][5/6]	Total Loss: 0.74001	Main MSE (x10^-2): 74.0006	LR: 3.76e-05	EMPP_Raw: 1.46062
2025-07-18 11:54:36,452 - logger.py:50 - Epoch 403 Training Summary: Avg Total Loss: 0.74001, Avg Main MSE: 0.74001, Time: 16.87s
2025-07-18 11:54:54,330 - logger.py:50 - Epoch 403 Summary | Train MSE (x10^-2): 74.0006 | Val MSE (x10^-2): 79.3029 | Time: 34.75s
2025-07-18 11:54:57,512 - logger.py:50 - Epoch: [404][0/6]	Total Loss: 0.71890	Main MSE (x10^-2): 71.8899	LR: 3.69e-05	EMPP_Raw: 1.41606
2025-07-18 11:55:11,289 - logger.py:50 - Epoch: [404][5/6]	Total Loss: 0.73696	Main MSE (x10^-2): 73.6955	LR: 3.69e-05	EMPP_Raw: 1.45257
2025-07-18 11:55:11,336 - logger.py:50 - Epoch 404 Training Summary: Avg Total Loss: 0.73696, Avg Main MSE: 0.73696, Time: 17.00s
2025-07-18 11:55:29,313 - logger.py:50 - Epoch 404 Summary | Train MSE (x10^-2): 73.6955 | Val MSE (x10^-2): 79.2748 | Time: 34.98s
2025-07-18 11:55:32,343 - logger.py:50 - Epoch: [405][0/6]	Total Loss: 0.74488	Main MSE (x10^-2): 74.4879	LR: 3.62e-05	EMPP_Raw: 1.46758
2025-07-18 11:55:46,241 - logger.py:50 - Epoch: [405][5/6]	Total Loss: 0.73555	Main MSE (x10^-2): 73.5547	LR: 3.62e-05	EMPP_Raw: 1.45041
2025-07-18 11:55:46,286 - logger.py:50 - Epoch 405 Training Summary: Avg Total Loss: 0.73555, Avg Main MSE: 0.73555, Time: 16.96s
2025-07-18 11:56:04,282 - logger.py:50 - Epoch 405 Summary | Train MSE (x10^-2): 73.5547 | Val MSE (x10^-2): 79.3015 | Time: 34.96s
2025-07-18 11:56:07,291 - logger.py:50 - Epoch: [406][0/6]	Total Loss: 0.71518	Main MSE (x10^-2): 71.5177	LR: 3.55e-05	EMPP_Raw: 1.41107
2025-07-18 11:56:21,270 - logger.py:50 - Epoch: [406][5/6]	Total Loss: 0.73004	Main MSE (x10^-2): 73.0043	LR: 3.55e-05	EMPP_Raw: 1.44052
2025-07-18 11:56:21,309 - logger.py:50 - Epoch 406 Training Summary: Avg Total Loss: 0.73004, Avg Main MSE: 0.73004, Time: 17.02s
2025-07-18 11:56:39,257 - logger.py:50 - Epoch 406 Summary | Train MSE (x10^-2): 73.0043 | Val MSE (x10^-2): 79.2749 | Time: 34.97s
2025-07-18 11:56:42,261 - logger.py:50 - Epoch: [407][0/6]	Total Loss: 0.71652	Main MSE (x10^-2): 71.6517	LR: 3.48e-05	EMPP_Raw: 1.41002
2025-07-18 11:56:56,068 - logger.py:50 - Epoch: [407][5/6]	Total Loss: 0.73801	Main MSE (x10^-2): 73.8014	LR: 3.48e-05	EMPP_Raw: 1.45575
2025-07-18 11:56:56,113 - logger.py:50 - Epoch 407 Training Summary: Avg Total Loss: 0.73801, Avg Main MSE: 0.73801, Time: 16.85s
2025-07-18 11:57:13,975 - logger.py:50 - Epoch 407 Summary | Train MSE (x10^-2): 73.8014 | Val MSE (x10^-2): 79.2183 | Time: 34.71s
2025-07-18 11:57:17,148 - logger.py:50 - Epoch: [408][0/6]	Total Loss: 0.73323	Main MSE (x10^-2): 73.3234	LR: 3.41e-05	EMPP_Raw: 1.44530
2025-07-18 11:57:30,920 - logger.py:50 - Epoch: [408][5/6]	Total Loss: 0.73118	Main MSE (x10^-2): 73.1178	LR: 3.41e-05	EMPP_Raw: 1.44284
2025-07-18 11:57:30,965 - logger.py:50 - Epoch 408 Training Summary: Avg Total Loss: 0.73118, Avg Main MSE: 0.73118, Time: 16.98s
2025-07-18 11:57:48,960 - logger.py:50 - Epoch 408 Summary | Train MSE (x10^-2): 73.1178 | Val MSE (x10^-2): 79.0750 | Time: 34.98s
2025-07-18 11:57:52,137 - logger.py:50 - Epoch: [409][0/6]	Total Loss: 0.73537	Main MSE (x10^-2): 73.5367	LR: 3.34e-05	EMPP_Raw: 1.45345
2025-07-18 11:58:05,898 - logger.py:50 - Epoch: [409][5/6]	Total Loss: 0.73795	Main MSE (x10^-2): 73.7953	LR: 3.34e-05	EMPP_Raw: 1.45677
2025-07-18 11:58:05,943 - logger.py:50 - Epoch 409 Training Summary: Avg Total Loss: 0.73795, Avg Main MSE: 0.73795, Time: 16.97s
2025-07-18 11:58:23,845 - logger.py:50 - Epoch 409 Summary | Train MSE (x10^-2): 73.7953 | Val MSE (x10^-2): 79.0912 | Time: 34.88s
2025-07-18 11:58:26,854 - logger.py:50 - Epoch: [410][0/6]	Total Loss: 0.77501	Main MSE (x10^-2): 77.5009	LR: 3.27e-05	EMPP_Raw: 1.53224
2025-07-18 11:58:40,797 - logger.py:50 - Epoch: [410][5/6]	Total Loss: 0.74787	Main MSE (x10^-2): 74.7868	LR: 3.27e-05	EMPP_Raw: 1.47668
2025-07-18 11:58:40,844 - logger.py:50 - Epoch 410 Training Summary: Avg Total Loss: 0.74787, Avg Main MSE: 0.74787, Time: 16.99s
2025-07-18 11:58:58,821 - logger.py:50 - Epoch 410 Summary | Train MSE (x10^-2): 74.7868 | Val MSE (x10^-2): 79.6748 | Time: 34.97s
2025-07-18 11:59:01,845 - logger.py:50 - Epoch: [411][0/6]	Total Loss: 0.75157	Main MSE (x10^-2): 75.1573	LR: 3.21e-05	EMPP_Raw: 1.48471
2025-07-18 11:59:15,678 - logger.py:50 - Epoch: [411][5/6]	Total Loss: 0.73258	Main MSE (x10^-2): 73.2583	LR: 3.21e-05	EMPP_Raw: 1.44629
2025-07-18 11:59:15,724 - logger.py:50 - Epoch 411 Training Summary: Avg Total Loss: 0.73258, Avg Main MSE: 0.73258, Time: 16.89s
2025-07-18 11:59:33,820 - logger.py:50 - Epoch 411 Summary | Train MSE (x10^-2): 73.2583 | Val MSE (x10^-2): 78.8386 | Time: 34.99s
2025-07-18 11:59:36,823 - logger.py:50 - Epoch: [412][0/6]	Total Loss: 0.73486	Main MSE (x10^-2): 73.4857	LR: 3.14e-05	EMPP_Raw: 1.45097
2025-07-18 11:59:50,597 - logger.py:50 - Epoch: [412][5/6]	Total Loss: 0.72968	Main MSE (x10^-2): 72.9681	LR: 3.14e-05	EMPP_Raw: 1.44045
2025-07-18 11:59:50,640 - logger.py:50 - Epoch 412 Training Summary: Avg Total Loss: 0.72968, Avg Main MSE: 0.72968, Time: 16.81s
2025-07-18 12:00:08,516 - logger.py:50 - Epoch 412 Summary | Train MSE (x10^-2): 72.9681 | Val MSE (x10^-2): 80.0206 | Time: 34.69s
2025-07-18 12:00:11,674 - logger.py:50 - Epoch: [413][0/6]	Total Loss: 0.74403	Main MSE (x10^-2): 74.4028	LR: 3.07e-05	EMPP_Raw: 1.46798
2025-07-18 12:00:25,419 - logger.py:50 - Epoch: [413][5/6]	Total Loss: 0.74275	Main MSE (x10^-2): 74.2748	LR: 3.07e-05	EMPP_Raw: 1.46657
2025-07-18 12:00:25,462 - logger.py:50 - Epoch 413 Training Summary: Avg Total Loss: 0.74275, Avg Main MSE: 0.74275, Time: 16.94s
2025-07-18 12:00:43,336 - logger.py:50 - Epoch 413 Summary | Train MSE (x10^-2): 74.2748 | Val MSE (x10^-2): 78.8020 | Time: 34.81s
2025-07-18 12:00:46,367 - logger.py:50 - Epoch: [414][0/6]	Total Loss: 0.75853	Main MSE (x10^-2): 75.8534	LR: 3.01e-05	EMPP_Raw: 1.49913
2025-07-18 12:01:00,269 - logger.py:50 - Epoch: [414][5/6]	Total Loss: 0.73638	Main MSE (x10^-2): 73.6381	LR: 3.01e-05	EMPP_Raw: 1.45445
2025-07-18 12:01:00,308 - logger.py:50 - Epoch 414 Training Summary: Avg Total Loss: 0.73638, Avg Main MSE: 0.73638, Time: 16.96s
2025-07-18 12:01:18,193 - logger.py:50 - Epoch 414 Summary | Train MSE (x10^-2): 73.6381 | Val MSE (x10^-2): 79.3323 | Time: 34.85s
2025-07-18 12:01:21,187 - logger.py:50 - Epoch: [415][0/6]	Total Loss: 0.72006	Main MSE (x10^-2): 72.0063	LR: 2.94e-05	EMPP_Raw: 1.41887
2025-07-18 12:01:34,963 - logger.py:50 - Epoch: [415][5/6]	Total Loss: 0.73491	Main MSE (x10^-2): 73.4911	LR: 2.94e-05	EMPP_Raw: 1.45014
2025-07-18 12:01:35,010 - logger.py:50 - Epoch 415 Training Summary: Avg Total Loss: 0.73491, Avg Main MSE: 0.73491, Time: 16.81s
2025-07-18 12:01:53,025 - logger.py:50 - Epoch 415 Summary | Train MSE (x10^-2): 73.4911 | Val MSE (x10^-2): 79.2914 | Time: 34.83s
2025-07-18 12:01:56,038 - logger.py:50 - Epoch: [416][0/6]	Total Loss: 0.75112	Main MSE (x10^-2): 75.1123	LR: 2.88e-05	EMPP_Raw: 1.48244
2025-07-18 12:02:09,890 - logger.py:50 - Epoch: [416][5/6]	Total Loss: 0.74398	Main MSE (x10^-2): 74.3979	LR: 2.88e-05	EMPP_Raw: 1.46884
2025-07-18 12:02:09,930 - logger.py:50 - Epoch 416 Training Summary: Avg Total Loss: 0.74398, Avg Main MSE: 0.74398, Time: 16.89s
2025-07-18 12:02:27,936 - logger.py:50 - Epoch 416 Summary | Train MSE (x10^-2): 74.3979 | Val MSE (x10^-2): 79.0110 | Time: 34.90s
2025-07-18 12:02:30,943 - logger.py:50 - Epoch: [417][0/6]	Total Loss: 0.75526	Main MSE (x10^-2): 75.5262	LR: 2.81e-05	EMPP_Raw: 1.48960
2025-07-18 12:02:44,699 - logger.py:50 - Epoch: [417][5/6]	Total Loss: 0.74082	Main MSE (x10^-2): 74.0824	LR: 2.81e-05	EMPP_Raw: 1.46189
2025-07-18 12:02:44,748 - logger.py:50 - Epoch 417 Training Summary: Avg Total Loss: 0.74082, Avg Main MSE: 0.74082, Time: 16.80s
2025-07-18 12:03:02,698 - logger.py:50 - Epoch 417 Summary | Train MSE (x10^-2): 74.0824 | Val MSE (x10^-2): 79.4686 | Time: 34.76s
2025-07-18 12:03:06,062 - logger.py:50 - Epoch: [418][0/6]	Total Loss: 0.73146	Main MSE (x10^-2): 73.1460	LR: 2.75e-05	EMPP_Raw: 1.44169
2025-07-18 12:03:19,892 - logger.py:50 - Epoch: [418][5/6]	Total Loss: 0.73491	Main MSE (x10^-2): 73.4908	LR: 2.75e-05	EMPP_Raw: 1.45054
2025-07-18 12:03:19,944 - logger.py:50 - Epoch 418 Training Summary: Avg Total Loss: 0.73491, Avg Main MSE: 0.73491, Time: 17.24s
2025-07-18 12:03:37,889 - logger.py:50 - Epoch 418 Summary | Train MSE (x10^-2): 73.4908 | Val MSE (x10^-2): 79.1452 | Time: 35.18s
2025-07-18 12:03:41,052 - logger.py:50 - Epoch: [419][0/6]	Total Loss: 0.74118	Main MSE (x10^-2): 74.1182	LR: 2.69e-05	EMPP_Raw: 1.46525
2025-07-18 12:03:54,840 - logger.py:50 - Epoch: [419][5/6]	Total Loss: 0.73218	Main MSE (x10^-2): 73.2183	LR: 2.69e-05	EMPP_Raw: 1.44621
2025-07-18 12:03:54,884 - logger.py:50 - Epoch 419 Training Summary: Avg Total Loss: 0.73218, Avg Main MSE: 0.73218, Time: 16.99s
2025-07-18 12:04:12,895 - logger.py:50 - Epoch 419 Summary | Train MSE (x10^-2): 73.2183 | Val MSE (x10^-2): 79.4795 | Time: 35.00s
2025-07-18 12:04:15,960 - logger.py:50 - Epoch: [420][0/6]	Total Loss: 0.72798	Main MSE (x10^-2): 72.7979	LR: 2.63e-05	EMPP_Raw: 1.43701
2025-07-18 12:04:29,969 - logger.py:50 - Epoch: [420][5/6]	Total Loss: 0.74562	Main MSE (x10^-2): 74.5619	LR: 2.63e-05	EMPP_Raw: 1.47293
2025-07-18 12:04:30,014 - logger.py:50 - Epoch 420 Training Summary: Avg Total Loss: 0.74562, Avg Main MSE: 0.74562, Time: 17.11s
2025-07-18 12:04:47,858 - logger.py:50 - Epoch 420 Summary | Train MSE (x10^-2): 74.5619 | Val MSE (x10^-2): 78.7990 | Time: 34.96s
2025-07-18 12:04:50,868 - logger.py:50 - Epoch: [421][0/6]	Total Loss: 0.72627	Main MSE (x10^-2): 72.6265	LR: 2.57e-05	EMPP_Raw: 1.43159
2025-07-18 12:05:04,659 - logger.py:50 - Epoch: [421][5/6]	Total Loss: 0.72663	Main MSE (x10^-2): 72.6633	LR: 2.57e-05	EMPP_Raw: 1.43398
2025-07-18 12:05:04,698 - logger.py:50 - Epoch 421 Training Summary: Avg Total Loss: 0.72663, Avg Main MSE: 0.72663, Time: 16.83s
2025-07-18 12:05:22,787 - logger.py:50 - Epoch 421 Summary | Train MSE (x10^-2): 72.6633 | Val MSE (x10^-2): 79.5577 | Time: 34.92s
2025-07-18 12:05:25,794 - logger.py:50 - Epoch: [422][0/6]	Total Loss: 0.72204	Main MSE (x10^-2): 72.2041	LR: 2.51e-05	EMPP_Raw: 1.42673
2025-07-18 12:05:39,671 - logger.py:50 - Epoch: [422][5/6]	Total Loss: 0.72668	Main MSE (x10^-2): 72.6685	LR: 2.51e-05	EMPP_Raw: 1.43535
2025-07-18 12:05:39,716 - logger.py:50 - Epoch 422 Training Summary: Avg Total Loss: 0.72668, Avg Main MSE: 0.72668, Time: 16.92s
2025-07-18 12:05:57,832 - logger.py:50 - Epoch 422 Summary | Train MSE (x10^-2): 72.6685 | Val MSE (x10^-2): 78.5704 | Time: 35.04s
2025-07-18 12:06:00,879 - logger.py:50 - Epoch: [423][0/6]	Total Loss: 0.72405	Main MSE (x10^-2): 72.4046	LR: 2.45e-05	EMPP_Raw: 1.42981
2025-07-18 12:06:14,652 - logger.py:50 - Epoch: [423][5/6]	Total Loss: 0.73135	Main MSE (x10^-2): 73.1348	LR: 2.45e-05	EMPP_Raw: 1.44424
2025-07-18 12:06:14,697 - logger.py:50 - Epoch 423 Training Summary: Avg Total Loss: 0.73135, Avg Main MSE: 0.73135, Time: 16.86s
2025-07-18 12:06:32,612 - logger.py:50 - Epoch 423 Summary | Train MSE (x10^-2): 73.1348 | Val MSE (x10^-2): 79.4931 | Time: 34.77s
2025-07-18 12:06:35,832 - logger.py:50 - Epoch: [424][0/6]	Total Loss: 0.72156	Main MSE (x10^-2): 72.1557	LR: 2.39e-05	EMPP_Raw: 1.42419
2025-07-18 12:06:49,581 - logger.py:50 - Epoch: [424][5/6]	Total Loss: 0.74425	Main MSE (x10^-2): 74.4255	LR: 2.39e-05	EMPP_Raw: 1.46971
2025-07-18 12:06:49,624 - logger.py:50 - Epoch 424 Training Summary: Avg Total Loss: 0.74425, Avg Main MSE: 0.74425, Time: 17.00s
2025-07-18 12:07:07,593 - logger.py:50 - Epoch 424 Summary | Train MSE (x10^-2): 74.4255 | Val MSE (x10^-2): 78.9182 | Time: 34.98s
2025-07-18 12:07:10,607 - logger.py:50 - Epoch: [425][0/6]	Total Loss: 0.74516	Main MSE (x10^-2): 74.5158	LR: 2.33e-05	EMPP_Raw: 1.47128
2025-07-18 12:07:24,504 - logger.py:50 - Epoch: [425][5/6]	Total Loss: 0.72805	Main MSE (x10^-2): 72.8050	LR: 2.33e-05	EMPP_Raw: 1.43807
2025-07-18 12:07:24,546 - logger.py:50 - Epoch 425 Training Summary: Avg Total Loss: 0.72805, Avg Main MSE: 0.72805, Time: 16.94s
2025-07-18 12:07:42,396 - logger.py:50 - Epoch 425 Summary | Train MSE (x10^-2): 72.8050 | Val MSE (x10^-2): 79.2323 | Time: 34.80s
2025-07-18 12:07:45,397 - logger.py:50 - Epoch: [426][0/6]	Total Loss: 0.70729	Main MSE (x10^-2): 70.7289	LR: 2.27e-05	EMPP_Raw: 1.39762
2025-07-18 12:07:59,373 - logger.py:50 - Epoch: [426][5/6]	Total Loss: 0.72259	Main MSE (x10^-2): 72.2585	LR: 2.27e-05	EMPP_Raw: 1.42696
2025-07-18 12:07:59,421 - logger.py:50 - Epoch 426 Training Summary: Avg Total Loss: 0.72259, Avg Main MSE: 0.72259, Time: 17.02s
2025-07-18 12:08:17,396 - logger.py:50 - Epoch 426 Summary | Train MSE (x10^-2): 72.2585 | Val MSE (x10^-2): 79.2983 | Time: 34.99s
2025-07-18 12:08:20,391 - logger.py:50 - Epoch: [427][0/6]	Total Loss: 0.73399	Main MSE (x10^-2): 73.3989	LR: 2.22e-05	EMPP_Raw: 1.44787
2025-07-18 12:08:34,195 - logger.py:50 - Epoch: [427][5/6]	Total Loss: 0.73321	Main MSE (x10^-2): 73.3211	LR: 2.22e-05	EMPP_Raw: 1.44726
2025-07-18 12:08:34,240 - logger.py:50 - Epoch 427 Training Summary: Avg Total Loss: 0.73321, Avg Main MSE: 0.73321, Time: 16.83s
2025-07-18 12:08:52,102 - logger.py:50 - Epoch 427 Summary | Train MSE (x10^-2): 73.3211 | Val MSE (x10^-2): 79.0299 | Time: 34.70s
2025-07-18 12:08:55,291 - logger.py:50 - Epoch: [428][0/6]	Total Loss: 0.75624	Main MSE (x10^-2): 75.6243	LR: 2.16e-05	EMPP_Raw: 1.49476
2025-07-18 12:09:09,054 - logger.py:50 - Epoch: [428][5/6]	Total Loss: 0.73602	Main MSE (x10^-2): 73.6015	LR: 2.16e-05	EMPP_Raw: 1.45337
2025-07-18 12:09:09,102 - logger.py:50 - Epoch 428 Training Summary: Avg Total Loss: 0.73602, Avg Main MSE: 0.73602, Time: 16.99s
2025-07-18 12:09:27,039 - logger.py:50 - Epoch 428 Summary | Train MSE (x10^-2): 73.6015 | Val MSE (x10^-2): 79.3889 | Time: 34.93s
2025-07-18 12:09:30,233 - logger.py:50 - Epoch: [429][0/6]	Total Loss: 0.72837	Main MSE (x10^-2): 72.8367	LR: 2.11e-05	EMPP_Raw: 1.43819
2025-07-18 12:09:44,073 - logger.py:50 - Epoch: [429][5/6]	Total Loss: 0.72172	Main MSE (x10^-2): 72.1721	LR: 2.11e-05	EMPP_Raw: 1.42444
2025-07-18 12:09:44,113 - logger.py:50 - Epoch 429 Training Summary: Avg Total Loss: 0.72172, Avg Main MSE: 0.72172, Time: 17.06s
2025-07-18 12:10:01,962 - logger.py:50 - Epoch 429 Summary | Train MSE (x10^-2): 72.1721 | Val MSE (x10^-2): 79.0013 | Time: 34.92s
2025-07-18 12:10:04,961 - logger.py:50 - Epoch: [430][0/6]	Total Loss: 0.74347	Main MSE (x10^-2): 74.3467	LR: 2.05e-05	EMPP_Raw: 1.46959
2025-07-18 12:10:18,844 - logger.py:50 - Epoch: [430][5/6]	Total Loss: 0.72416	Main MSE (x10^-2): 72.4163	LR: 2.05e-05	EMPP_Raw: 1.42951
2025-07-18 12:10:18,891 - logger.py:50 - Epoch 430 Training Summary: Avg Total Loss: 0.72416, Avg Main MSE: 0.72416, Time: 16.92s
2025-07-18 12:10:36,822 - logger.py:50 - Epoch 430 Summary | Train MSE (x10^-2): 72.4163 | Val MSE (x10^-2): 79.0829 | Time: 34.86s
2025-07-18 12:10:39,825 - logger.py:50 - Epoch: [431][0/6]	Total Loss: 0.73266	Main MSE (x10^-2): 73.2661	LR: 2.00e-05	EMPP_Raw: 1.44349
2025-07-18 12:10:53,640 - logger.py:50 - Epoch: [431][5/6]	Total Loss: 0.73696	Main MSE (x10^-2): 73.6958	LR: 2.00e-05	EMPP_Raw: 1.45528
2025-07-18 12:10:53,685 - logger.py:50 - Epoch 431 Training Summary: Avg Total Loss: 0.73696, Avg Main MSE: 0.73696, Time: 16.86s
2025-07-18 12:11:11,699 - logger.py:50 - Epoch 431 Summary | Train MSE (x10^-2): 73.6958 | Val MSE (x10^-2): 79.0807 | Time: 34.87s
2025-07-18 12:11:14,701 - logger.py:50 - Epoch: [432][0/6]	Total Loss: 0.75138	Main MSE (x10^-2): 75.1380	LR: 1.95e-05	EMPP_Raw: 1.48593
2025-07-18 12:11:28,543 - logger.py:50 - Epoch: [432][5/6]	Total Loss: 0.73034	Main MSE (x10^-2): 73.0344	LR: 1.95e-05	EMPP_Raw: 1.44193
2025-07-18 12:11:28,583 - logger.py:50 - Epoch 432 Training Summary: Avg Total Loss: 0.73034, Avg Main MSE: 0.73034, Time: 16.87s
2025-07-18 12:11:46,559 - logger.py:50 - Epoch 432 Summary | Train MSE (x10^-2): 73.0344 | Val MSE (x10^-2): 79.8122 | Time: 34.85s
2025-07-18 12:11:49,725 - logger.py:50 - Epoch: [433][0/6]	Total Loss: 0.74844	Main MSE (x10^-2): 74.8441	LR: 1.89e-05	EMPP_Raw: 1.47674
2025-07-18 12:12:03,472 - logger.py:50 - Epoch: [433][5/6]	Total Loss: 0.73923	Main MSE (x10^-2): 73.9225	LR: 1.89e-05	EMPP_Raw: 1.45901
2025-07-18 12:12:03,513 - logger.py:50 - Epoch 433 Training Summary: Avg Total Loss: 0.73923, Avg Main MSE: 0.73923, Time: 16.94s
2025-07-18 12:12:21,449 - logger.py:50 - Epoch 433 Summary | Train MSE (x10^-2): 73.9225 | Val MSE (x10^-2): 78.9779 | Time: 34.88s
2025-07-18 12:12:24,526 - logger.py:50 - Epoch: [434][0/6]	Total Loss: 0.72764	Main MSE (x10^-2): 72.7640	LR: 1.84e-05	EMPP_Raw: 1.43573
2025-07-18 12:12:38,535 - logger.py:50 - Epoch: [434][5/6]	Total Loss: 0.73655	Main MSE (x10^-2): 73.6552	LR: 1.84e-05	EMPP_Raw: 1.45395
2025-07-18 12:12:38,580 - logger.py:50 - Epoch 434 Training Summary: Avg Total Loss: 0.73655, Avg Main MSE: 0.73655, Time: 17.12s
2025-07-18 12:12:56,532 - logger.py:50 - Epoch 434 Summary | Train MSE (x10^-2): 73.6552 | Val MSE (x10^-2): 79.2454 | Time: 35.08s
2025-07-18 12:12:59,581 - logger.py:50 - Epoch: [435][0/6]	Total Loss: 0.73145	Main MSE (x10^-2): 73.1453	LR: 1.79e-05	EMPP_Raw: 1.44659
2025-07-18 12:13:13,369 - logger.py:50 - Epoch: [435][5/6]	Total Loss: 0.74133	Main MSE (x10^-2): 74.1329	LR: 1.79e-05	EMPP_Raw: 1.46544
2025-07-18 12:13:13,413 - logger.py:50 - Epoch 435 Training Summary: Avg Total Loss: 0.74133, Avg Main MSE: 0.74133, Time: 16.87s
2025-07-18 12:13:31,391 - logger.py:50 - Epoch 435 Summary | Train MSE (x10^-2): 74.1329 | Val MSE (x10^-2): 79.2944 | Time: 34.85s
2025-07-18 12:13:34,411 - logger.py:50 - Epoch: [436][0/6]	Total Loss: 0.71979	Main MSE (x10^-2): 71.9792	LR: 1.74e-05	EMPP_Raw: 1.42215
2025-07-18 12:13:48,248 - logger.py:50 - Epoch: [436][5/6]	Total Loss: 0.74053	Main MSE (x10^-2): 74.0528	LR: 1.74e-05	EMPP_Raw: 1.46278
2025-07-18 12:13:48,301 - logger.py:50 - Epoch 436 Training Summary: Avg Total Loss: 0.74053, Avg Main MSE: 0.74053, Time: 16.90s
2025-07-18 12:14:06,473 - logger.py:50 - Epoch 436 Summary | Train MSE (x10^-2): 74.0528 | Val MSE (x10^-2): 79.1879 | Time: 35.08s
2025-07-18 12:14:09,481 - logger.py:50 - Epoch: [437][0/6]	Total Loss: 0.72542	Main MSE (x10^-2): 72.5419	LR: 1.69e-05	EMPP_Raw: 1.43174
2025-07-18 12:14:23,284 - logger.py:50 - Epoch: [437][5/6]	Total Loss: 0.72981	Main MSE (x10^-2): 72.9810	LR: 1.69e-05	EMPP_Raw: 1.44129
2025-07-18 12:14:23,330 - logger.py:50 - Epoch 437 Training Summary: Avg Total Loss: 0.72981, Avg Main MSE: 0.72981, Time: 16.85s
2025-07-18 12:14:41,271 - logger.py:50 - Epoch 437 Summary | Train MSE (x10^-2): 72.9810 | Val MSE (x10^-2): 79.2394 | Time: 34.79s
2025-07-18 12:14:44,635 - logger.py:50 - Epoch: [438][0/6]	Total Loss: 0.73959	Main MSE (x10^-2): 73.9587	LR: 1.64e-05	EMPP_Raw: 1.46263
2025-07-18 12:14:58,385 - logger.py:50 - Epoch: [438][5/6]	Total Loss: 0.73632	Main MSE (x10^-2): 73.6323	LR: 1.64e-05	EMPP_Raw: 1.45371
2025-07-18 12:14:58,444 - logger.py:50 - Epoch 438 Training Summary: Avg Total Loss: 0.73632, Avg Main MSE: 0.73632, Time: 17.16s
2025-07-18 12:15:16,500 - logger.py:50 - Epoch 438 Summary | Train MSE (x10^-2): 73.6323 | Val MSE (x10^-2): 79.4408 | Time: 35.22s
2025-07-18 12:15:19,669 - logger.py:50 - Epoch: [439][0/6]	Total Loss: 0.72166	Main MSE (x10^-2): 72.1661	LR: 1.59e-05	EMPP_Raw: 1.42517
2025-07-18 12:15:33,395 - logger.py:50 - Epoch: [439][5/6]	Total Loss: 0.73893	Main MSE (x10^-2): 73.8929	LR: 1.59e-05	EMPP_Raw: 1.45950
2025-07-18 12:15:33,435 - logger.py:50 - Epoch 439 Training Summary: Avg Total Loss: 0.73893, Avg Main MSE: 0.73893, Time: 16.93s
2025-07-18 12:15:51,418 - logger.py:50 - Epoch 439 Summary | Train MSE (x10^-2): 73.8929 | Val MSE (x10^-2): 78.9405 | Time: 34.91s
2025-07-18 12:15:54,469 - logger.py:50 - Epoch: [440][0/6]	Total Loss: 0.74536	Main MSE (x10^-2): 74.5356	LR: 1.55e-05	EMPP_Raw: 1.47019
2025-07-18 12:16:08,403 - logger.py:50 - Epoch: [440][5/6]	Total Loss: 0.74174	Main MSE (x10^-2): 74.1739	LR: 1.55e-05	EMPP_Raw: 1.46472
2025-07-18 12:16:08,444 - logger.py:50 - Epoch 440 Training Summary: Avg Total Loss: 0.74174, Avg Main MSE: 0.74174, Time: 17.02s
2025-07-18 12:16:26,389 - logger.py:50 - Epoch 440 Summary | Train MSE (x10^-2): 74.1739 | Val MSE (x10^-2): 79.2937 | Time: 34.96s
2025-07-18 12:16:29,390 - logger.py:50 - Epoch: [441][0/6]	Total Loss: 0.71851	Main MSE (x10^-2): 71.8511	LR: 1.50e-05	EMPP_Raw: 1.41614
2025-07-18 12:16:43,242 - logger.py:50 - Epoch: [441][5/6]	Total Loss: 0.72857	Main MSE (x10^-2): 72.8566	LR: 1.50e-05	EMPP_Raw: 1.43807
2025-07-18 12:16:43,284 - logger.py:50 - Epoch 441 Training Summary: Avg Total Loss: 0.72857, Avg Main MSE: 0.72857, Time: 16.89s
2025-07-18 12:17:01,300 - logger.py:50 - Epoch 441 Summary | Train MSE (x10^-2): 72.8566 | Val MSE (x10^-2): 79.5080 | Time: 34.91s
2025-07-18 12:17:04,307 - logger.py:50 - Epoch: [442][0/6]	Total Loss: 0.74896	Main MSE (x10^-2): 74.8963	LR: 1.46e-05	EMPP_Raw: 1.48024
2025-07-18 12:17:18,112 - logger.py:50 - Epoch: [442][5/6]	Total Loss: 0.74039	Main MSE (x10^-2): 74.0385	LR: 1.46e-05	EMPP_Raw: 1.46257
2025-07-18 12:17:18,155 - logger.py:50 - Epoch 442 Training Summary: Avg Total Loss: 0.74039, Avg Main MSE: 0.74039, Time: 16.85s
2025-07-18 12:17:36,268 - logger.py:50 - Epoch 442 Summary | Train MSE (x10^-2): 74.0385 | Val MSE (x10^-2): 79.3093 | Time: 34.96s
2025-07-18 12:17:39,278 - logger.py:50 - Epoch: [443][0/6]	Total Loss: 0.73616	Main MSE (x10^-2): 73.6159	LR: 1.41e-05	EMPP_Raw: 1.45351
2025-07-18 12:17:53,124 - logger.py:50 - Epoch: [443][5/6]	Total Loss: 0.73836	Main MSE (x10^-2): 73.8361	LR: 1.41e-05	EMPP_Raw: 1.45859
2025-07-18 12:17:53,165 - logger.py:50 - Epoch 443 Training Summary: Avg Total Loss: 0.73836, Avg Main MSE: 0.73836, Time: 16.89s
2025-07-18 12:18:11,152 - logger.py:50 - Epoch 443 Summary | Train MSE (x10^-2): 73.8361 | Val MSE (x10^-2): 79.1797 | Time: 34.88s
2025-07-18 12:18:14,308 - logger.py:50 - Epoch: [444][0/6]	Total Loss: 0.73955	Main MSE (x10^-2): 73.9554	LR: 1.37e-05	EMPP_Raw: 1.46035
2025-07-18 12:18:28,029 - logger.py:50 - Epoch: [444][5/6]	Total Loss: 0.73354	Main MSE (x10^-2): 73.3535	LR: 1.37e-05	EMPP_Raw: 1.44832
2025-07-18 12:18:28,068 - logger.py:50 - Epoch 444 Training Summary: Avg Total Loss: 0.73354, Avg Main MSE: 0.73354, Time: 16.91s
2025-07-18 12:18:46,069 - logger.py:50 - Epoch 444 Summary | Train MSE (x10^-2): 73.3535 | Val MSE (x10^-2): 79.5185 | Time: 34.91s
2025-07-18 12:18:49,081 - logger.py:50 - Epoch: [445][0/6]	Total Loss: 0.73655	Main MSE (x10^-2): 73.6548	LR: 1.32e-05	EMPP_Raw: 1.45470
2025-07-18 12:19:03,037 - logger.py:50 - Epoch: [445][5/6]	Total Loss: 0.72583	Main MSE (x10^-2): 72.5828	LR: 1.32e-05	EMPP_Raw: 1.43351
2025-07-18 12:19:03,079 - logger.py:50 - Epoch 445 Training Summary: Avg Total Loss: 0.72583, Avg Main MSE: 0.72583, Time: 17.00s
2025-07-18 12:19:21,045 - logger.py:50 - Epoch 445 Summary | Train MSE (x10^-2): 72.5828 | Val MSE (x10^-2): 79.3230 | Time: 34.97s
2025-07-18 12:19:24,069 - logger.py:50 - Epoch: [446][0/6]	Total Loss: 0.71983	Main MSE (x10^-2): 71.9830	LR: 1.28e-05	EMPP_Raw: 1.42278
2025-07-18 12:19:38,053 - logger.py:50 - Epoch: [446][5/6]	Total Loss: 0.73749	Main MSE (x10^-2): 73.7491	LR: 1.28e-05	EMPP_Raw: 1.45661
2025-07-18 12:19:38,100 - logger.py:50 - Epoch 446 Training Summary: Avg Total Loss: 0.73749, Avg Main MSE: 0.73749, Time: 17.04s
2025-07-18 12:19:56,023 - logger.py:50 - Epoch 446 Summary | Train MSE (x10^-2): 73.7491 | Val MSE (x10^-2): 79.3766 | Time: 34.97s
2025-07-18 12:19:59,027 - logger.py:50 - Epoch: [447][0/6]	Total Loss: 0.72072	Main MSE (x10^-2): 72.0724	LR: 1.24e-05	EMPP_Raw: 1.42296
2025-07-18 12:20:12,814 - logger.py:50 - Epoch: [447][5/6]	Total Loss: 0.73538	Main MSE (x10^-2): 73.5379	LR: 1.24e-05	EMPP_Raw: 1.45289
2025-07-18 12:20:12,857 - logger.py:50 - Epoch 447 Training Summary: Avg Total Loss: 0.73538, Avg Main MSE: 0.73538, Time: 16.82s
2025-07-18 12:20:30,729 - logger.py:50 - Epoch 447 Summary | Train MSE (x10^-2): 73.5379 | Val MSE (x10^-2): 79.4391 | Time: 34.70s
2025-07-18 12:20:33,893 - logger.py:50 - Epoch: [448][0/6]	Total Loss: 0.73241	Main MSE (x10^-2): 73.2414	LR: 1.20e-05	EMPP_Raw: 1.44545
2025-07-18 12:20:47,639 - logger.py:50 - Epoch: [448][5/6]	Total Loss: 0.71786	Main MSE (x10^-2): 71.7855	LR: 1.20e-05	EMPP_Raw: 1.41693
2025-07-18 12:20:47,680 - logger.py:50 - Epoch 448 Training Summary: Avg Total Loss: 0.71786, Avg Main MSE: 0.71786, Time: 16.94s
2025-07-18 12:21:05,516 - logger.py:50 - Epoch 448 Summary | Train MSE (x10^-2): 71.7855 | Val MSE (x10^-2): 79.3695 | Time: 34.78s
2025-07-18 12:21:08,672 - logger.py:50 - Epoch: [449][0/6]	Total Loss: 0.72854	Main MSE (x10^-2): 72.8536	LR: 1.16e-05	EMPP_Raw: 1.43840
2025-07-18 12:21:22,443 - logger.py:50 - Epoch: [449][5/6]	Total Loss: 0.73254	Main MSE (x10^-2): 73.2544	LR: 1.16e-05	EMPP_Raw: 1.44653
2025-07-18 12:21:22,487 - logger.py:50 - Epoch 449 Training Summary: Avg Total Loss: 0.73254, Avg Main MSE: 0.73254, Time: 16.96s
2025-07-18 12:21:40,315 - logger.py:50 - Epoch 449 Summary | Train MSE (x10^-2): 73.2544 | Val MSE (x10^-2): 79.2355 | Time: 34.79s
2025-07-18 12:21:43,388 - logger.py:50 - Epoch: [450][0/6]	Total Loss: 0.75115	Main MSE (x10^-2): 75.1146	LR: 1.12e-05	EMPP_Raw: 1.48239
2025-07-18 12:21:57,337 - logger.py:50 - Epoch: [450][5/6]	Total Loss: 0.73537	Main MSE (x10^-2): 73.5372	LR: 1.12e-05	EMPP_Raw: 1.45256
2025-07-18 12:21:57,384 - logger.py:50 - Epoch 450 Training Summary: Avg Total Loss: 0.73537, Avg Main MSE: 0.73537, Time: 17.06s
2025-07-18 12:22:15,514 - logger.py:50 - Epoch 450 Summary | Train MSE (x10^-2): 73.5372 | Val MSE (x10^-2): 79.2560 | Time: 35.19s
2025-07-18 12:22:18,530 - logger.py:50 - Epoch: [451][0/6]	Total Loss: 0.74175	Main MSE (x10^-2): 74.1746	LR: 1.08e-05	EMPP_Raw: 1.46740
2025-07-18 12:22:32,431 - logger.py:50 - Epoch: [451][5/6]	Total Loss: 0.73565	Main MSE (x10^-2): 73.5649	LR: 1.08e-05	EMPP_Raw: 1.45326
2025-07-18 12:22:32,485 - logger.py:50 - Epoch 451 Training Summary: Avg Total Loss: 0.73565, Avg Main MSE: 0.73565, Time: 16.96s
2025-07-18 12:22:50,704 - logger.py:50 - Epoch 451 Summary | Train MSE (x10^-2): 73.5649 | Val MSE (x10^-2): 79.1807 | Time: 35.18s
2025-07-18 12:22:53,710 - logger.py:50 - Epoch: [452][0/6]	Total Loss: 0.74597	Main MSE (x10^-2): 74.5966	LR: 1.04e-05	EMPP_Raw: 1.47332
2025-07-18 12:23:07,569 - logger.py:50 - Epoch: [452][5/6]	Total Loss: 0.74219	Main MSE (x10^-2): 74.2192	LR: 1.04e-05	EMPP_Raw: 1.46669
2025-07-18 12:23:07,616 - logger.py:50 - Epoch 452 Training Summary: Avg Total Loss: 0.74219, Avg Main MSE: 0.74219, Time: 16.90s
2025-07-18 12:23:25,484 - logger.py:50 - Epoch 452 Summary | Train MSE (x10^-2): 74.2192 | Val MSE (x10^-2): 79.1998 | Time: 34.77s
2025-07-18 12:23:28,686 - logger.py:50 - Epoch: [453][0/6]	Total Loss: 0.74571	Main MSE (x10^-2): 74.5710	LR: 1.00e-05	EMPP_Raw: 1.47287
2025-07-18 12:23:42,450 - logger.py:50 - Epoch: [453][5/6]	Total Loss: 0.73587	Main MSE (x10^-2): 73.5869	LR: 1.00e-05	EMPP_Raw: 1.45339
2025-07-18 12:23:42,492 - logger.py:50 - Epoch 453 Training Summary: Avg Total Loss: 0.73587, Avg Main MSE: 0.73587, Time: 17.00s
2025-07-18 12:24:00,380 - logger.py:50 - Epoch 453 Summary | Train MSE (x10^-2): 73.5869 | Val MSE (x10^-2): 79.4695 | Time: 34.89s
2025-07-18 12:24:03,384 - logger.py:50 - Epoch: [454][0/6]	Total Loss: 0.72918	Main MSE (x10^-2): 72.9181	LR: 9.64e-06	EMPP_Raw: 1.44096
2025-07-18 12:24:17,344 - logger.py:50 - Epoch: [454][5/6]	Total Loss: 0.72496	Main MSE (x10^-2): 72.4959	LR: 9.64e-06	EMPP_Raw: 1.43182
2025-07-18 12:24:17,389 - logger.py:50 - Epoch 454 Training Summary: Avg Total Loss: 0.72496, Avg Main MSE: 0.72496, Time: 17.00s
2025-07-18 12:24:35,232 - logger.py:50 - Epoch 454 Summary | Train MSE (x10^-2): 72.4959 | Val MSE (x10^-2): 79.3028 | Time: 34.85s
2025-07-18 12:24:38,279 - logger.py:50 - Epoch: [455][0/6]	Total Loss: 0.72805	Main MSE (x10^-2): 72.8048	LR: 9.27e-06	EMPP_Raw: 1.43912
2025-07-18 12:24:52,044 - logger.py:50 - Epoch: [455][5/6]	Total Loss: 0.73331	Main MSE (x10^-2): 73.3310	LR: 9.27e-06	EMPP_Raw: 1.44848
2025-07-18 12:24:52,088 - logger.py:50 - Epoch 455 Training Summary: Avg Total Loss: 0.73331, Avg Main MSE: 0.73331, Time: 16.85s
2025-07-18 12:25:10,161 - logger.py:50 - Epoch 455 Summary | Train MSE (x10^-2): 73.3310 | Val MSE (x10^-2): 79.3401 | Time: 34.93s
2025-07-18 12:25:13,162 - logger.py:50 - Epoch: [456][0/6]	Total Loss: 0.73574	Main MSE (x10^-2): 73.5735	LR: 8.92e-06	EMPP_Raw: 1.45169
2025-07-18 12:25:27,027 - logger.py:50 - Epoch: [456][5/6]	Total Loss: 0.73451	Main MSE (x10^-2): 73.4513	LR: 8.92e-06	EMPP_Raw: 1.45057
2025-07-18 12:25:27,070 - logger.py:50 - Epoch 456 Training Summary: Avg Total Loss: 0.73451, Avg Main MSE: 0.73451, Time: 16.90s
2025-07-18 12:25:45,146 - logger.py:50 - Epoch 456 Summary | Train MSE (x10^-2): 73.4513 | Val MSE (x10^-2): 79.3169 | Time: 34.98s
2025-07-18 12:25:48,203 - logger.py:50 - Epoch: [457][0/6]	Total Loss: 0.75282	Main MSE (x10^-2): 75.2824	LR: 8.58e-06	EMPP_Raw: 1.48753
2025-07-18 12:26:02,008 - logger.py:50 - Epoch: [457][5/6]	Total Loss: 0.73560	Main MSE (x10^-2): 73.5599	LR: 8.58e-06	EMPP_Raw: 1.45314
2025-07-18 12:26:02,047 - logger.py:50 - Epoch 457 Training Summary: Avg Total Loss: 0.73560, Avg Main MSE: 0.73560, Time: 16.89s
2025-07-18 12:26:19,939 - logger.py:50 - Epoch 457 Summary | Train MSE (x10^-2): 73.5599 | Val MSE (x10^-2): 79.2757 | Time: 34.79s
2025-07-18 12:26:23,333 - logger.py:50 - Epoch: [458][0/6]	Total Loss: 0.72515	Main MSE (x10^-2): 72.5151	LR: 8.24e-06	EMPP_Raw: 1.43339
2025-07-18 12:26:37,133 - logger.py:50 - Epoch: [458][5/6]	Total Loss: 0.73183	Main MSE (x10^-2): 73.1828	LR: 8.24e-06	EMPP_Raw: 1.44622
2025-07-18 12:26:37,185 - logger.py:50 - Epoch 458 Training Summary: Avg Total Loss: 0.73183, Avg Main MSE: 0.73183, Time: 17.24s
2025-07-18 12:26:55,064 - logger.py:50 - Epoch 458 Summary | Train MSE (x10^-2): 73.1828 | Val MSE (x10^-2): 79.2507 | Time: 35.12s
2025-07-18 12:26:58,225 - logger.py:50 - Epoch: [459][0/6]	Total Loss: 0.72804	Main MSE (x10^-2): 72.8042	LR: 7.91e-06	EMPP_Raw: 1.43853
2025-07-18 12:27:11,983 - logger.py:50 - Epoch: [459][5/6]	Total Loss: 0.74181	Main MSE (x10^-2): 74.1810	LR: 7.91e-06	EMPP_Raw: 1.46608
2025-07-18 12:27:12,028 - logger.py:50 - Epoch 459 Training Summary: Avg Total Loss: 0.74181, Avg Main MSE: 0.74181, Time: 16.95s
2025-07-18 12:27:29,975 - logger.py:50 - Epoch 459 Summary | Train MSE (x10^-2): 74.1810 | Val MSE (x10^-2): 79.2033 | Time: 34.90s
2025-07-18 12:27:33,036 - logger.py:50 - Epoch: [460][0/6]	Total Loss: 0.74371	Main MSE (x10^-2): 74.3705	LR: 7.58e-06	EMPP_Raw: 1.46965
2025-07-18 12:27:46,989 - logger.py:50 - Epoch: [460][5/6]	Total Loss: 0.73892	Main MSE (x10^-2): 73.8919	LR: 7.58e-06	EMPP_Raw: 1.45973
2025-07-18 12:27:47,036 - logger.py:50 - Epoch 460 Training Summary: Avg Total Loss: 0.73892, Avg Main MSE: 0.73892, Time: 17.05s
2025-07-18 12:28:04,878 - logger.py:50 - Epoch 460 Summary | Train MSE (x10^-2): 73.8919 | Val MSE (x10^-2): 79.2242 | Time: 34.90s
2025-07-18 12:28:07,871 - logger.py:50 - Epoch: [461][0/6]	Total Loss: 0.74039	Main MSE (x10^-2): 74.0388	LR: 7.27e-06	EMPP_Raw: 1.46293
2025-07-18 12:28:21,623 - logger.py:50 - Epoch: [461][5/6]	Total Loss: 0.73124	Main MSE (x10^-2): 73.1236	LR: 7.27e-06	EMPP_Raw: 1.44444
2025-07-18 12:28:21,669 - logger.py:50 - Epoch 461 Training Summary: Avg Total Loss: 0.73124, Avg Main MSE: 0.73124, Time: 16.78s
2025-07-18 12:28:39,715 - logger.py:50 - Epoch 461 Summary | Train MSE (x10^-2): 73.1236 | Val MSE (x10^-2): 79.3898 | Time: 34.83s
2025-07-18 12:28:42,776 - logger.py:50 - Epoch: [462][0/6]	Total Loss: 0.71138	Main MSE (x10^-2): 71.1383	LR: 6.96e-06	EMPP_Raw: 1.40314
2025-07-18 12:28:56,586 - logger.py:50 - Epoch: [462][5/6]	Total Loss: 0.72989	Main MSE (x10^-2): 72.9890	LR: 6.96e-06	EMPP_Raw: 1.44167
2025-07-18 12:28:56,628 - logger.py:50 - Epoch 462 Training Summary: Avg Total Loss: 0.72989, Avg Main MSE: 0.72989, Time: 16.90s
2025-07-18 12:29:14,861 - logger.py:50 - Epoch 462 Summary | Train MSE (x10^-2): 72.9890 | Val MSE (x10^-2): 79.2583 | Time: 35.14s
2025-07-18 12:29:17,921 - logger.py:50 - Epoch: [463][0/6]	Total Loss: 0.74246	Main MSE (x10^-2): 74.2459	LR: 6.66e-06	EMPP_Raw: 1.46733
2025-07-18 12:29:31,724 - logger.py:50 - Epoch: [463][5/6]	Total Loss: 0.73357	Main MSE (x10^-2): 73.3570	LR: 6.66e-06	EMPP_Raw: 1.44936
2025-07-18 12:29:31,765 - logger.py:50 - Epoch 463 Training Summary: Avg Total Loss: 0.73357, Avg Main MSE: 0.73357, Time: 16.89s
2025-07-18 12:29:49,650 - logger.py:50 - Epoch 463 Summary | Train MSE (x10^-2): 73.3570 | Val MSE (x10^-2): 79.2756 | Time: 34.78s
2025-07-18 12:29:52,818 - logger.py:50 - Epoch: [464][0/6]	Total Loss: 0.72033	Main MSE (x10^-2): 72.0327	LR: 6.37e-06	EMPP_Raw: 1.42129
2025-07-18 12:30:06,551 - logger.py:50 - Epoch: [464][5/6]	Total Loss: 0.72966	Main MSE (x10^-2): 72.9663	LR: 6.37e-06	EMPP_Raw: 1.44136
2025-07-18 12:30:06,595 - logger.py:50 - Epoch 464 Training Summary: Avg Total Loss: 0.72966, Avg Main MSE: 0.72966, Time: 16.94s
2025-07-18 12:30:24,541 - logger.py:50 - Epoch 464 Summary | Train MSE (x10^-2): 72.9663 | Val MSE (x10^-2): 79.2703 | Time: 34.88s
2025-07-18 12:30:27,569 - logger.py:50 - Epoch: [465][0/6]	Total Loss: 0.73735	Main MSE (x10^-2): 73.7346	LR: 6.08e-06	EMPP_Raw: 1.45655
2025-07-18 12:30:41,531 - logger.py:50 - Epoch: [465][5/6]	Total Loss: 0.73533	Main MSE (x10^-2): 73.5332	LR: 6.08e-06	EMPP_Raw: 1.45282
2025-07-18 12:30:41,576 - logger.py:50 - Epoch 465 Training Summary: Avg Total Loss: 0.73533, Avg Main MSE: 0.73533, Time: 17.03s
2025-07-18 12:30:59,544 - logger.py:50 - Epoch 465 Summary | Train MSE (x10^-2): 73.5332 | Val MSE (x10^-2): 79.3640 | Time: 35.00s
2025-07-18 12:31:02,552 - logger.py:50 - Epoch: [466][0/6]	Total Loss: 0.75172	Main MSE (x10^-2): 75.1723	LR: 5.80e-06	EMPP_Raw: 1.48459
2025-07-18 12:31:16,517 - logger.py:50 - Epoch: [466][5/6]	Total Loss: 0.73251	Main MSE (x10^-2): 73.2505	LR: 5.80e-06	EMPP_Raw: 1.44669
2025-07-18 12:31:16,564 - logger.py:50 - Epoch 466 Training Summary: Avg Total Loss: 0.73251, Avg Main MSE: 0.73251, Time: 17.01s
2025-07-18 12:31:34,491 - logger.py:50 - Epoch 466 Summary | Train MSE (x10^-2): 73.2505 | Val MSE (x10^-2): 79.4879 | Time: 34.94s
2025-07-18 12:31:37,510 - logger.py:50 - Epoch: [467][0/6]	Total Loss: 0.76055	Main MSE (x10^-2): 76.0549	LR: 5.54e-06	EMPP_Raw: 1.50207
2025-07-18 12:31:51,291 - logger.py:50 - Epoch: [467][5/6]	Total Loss: 0.73989	Main MSE (x10^-2): 73.9887	LR: 5.54e-06	EMPP_Raw: 1.46247
2025-07-18 12:31:51,333 - logger.py:50 - Epoch 467 Training Summary: Avg Total Loss: 0.73989, Avg Main MSE: 0.73989, Time: 16.83s
2025-07-18 12:32:09,208 - logger.py:50 - Epoch 467 Summary | Train MSE (x10^-2): 73.9887 | Val MSE (x10^-2): 79.5349 | Time: 34.71s
2025-07-18 12:32:12,365 - logger.py:50 - Epoch: [468][0/6]	Total Loss: 0.72824	Main MSE (x10^-2): 72.8236	LR: 5.27e-06	EMPP_Raw: 1.43710
2025-07-18 12:32:26,110 - logger.py:50 - Epoch: [468][5/6]	Total Loss: 0.73596	Main MSE (x10^-2): 73.5961	LR: 5.27e-06	EMPP_Raw: 1.45374
2025-07-18 12:32:26,151 - logger.py:50 - Epoch 468 Training Summary: Avg Total Loss: 0.73596, Avg Main MSE: 0.73596, Time: 16.93s
2025-07-18 12:32:44,036 - logger.py:50 - Epoch 468 Summary | Train MSE (x10^-2): 73.5961 | Val MSE (x10^-2): 79.4504 | Time: 34.82s
2025-07-18 12:32:47,199 - logger.py:50 - Epoch: [469][0/6]	Total Loss: 0.74060	Main MSE (x10^-2): 74.0600	LR: 5.02e-06	EMPP_Raw: 1.46326
2025-07-18 12:33:00,948 - logger.py:50 - Epoch: [469][5/6]	Total Loss: 0.72996	Main MSE (x10^-2): 72.9965	LR: 5.02e-06	EMPP_Raw: 1.44184
2025-07-18 12:33:00,989 - logger.py:50 - Epoch 469 Training Summary: Avg Total Loss: 0.72996, Avg Main MSE: 0.72996, Time: 16.94s
2025-07-18 12:33:18,920 - logger.py:50 - Epoch 469 Summary | Train MSE (x10^-2): 72.9965 | Val MSE (x10^-2): 79.3833 | Time: 34.88s
2025-07-18 12:33:21,967 - logger.py:50 - Epoch: [470][0/6]	Total Loss: 0.72026	Main MSE (x10^-2): 72.0261	LR: 4.77e-06	EMPP_Raw: 1.42306
2025-07-18 12:33:35,866 - logger.py:50 - Epoch: [470][5/6]	Total Loss: 0.72947	Main MSE (x10^-2): 72.9470	LR: 4.77e-06	EMPP_Raw: 1.44084
2025-07-18 12:33:35,905 - logger.py:50 - Epoch 470 Training Summary: Avg Total Loss: 0.72947, Avg Main MSE: 0.72947, Time: 16.97s
2025-07-18 12:33:53,808 - logger.py:50 - Epoch 470 Summary | Train MSE (x10^-2): 72.9470 | Val MSE (x10^-2): 79.4188 | Time: 34.88s
2025-07-18 12:33:56,814 - logger.py:50 - Epoch: [471][0/6]	Total Loss: 0.75307	Main MSE (x10^-2): 75.3069	LR: 4.53e-06	EMPP_Raw: 1.48827
2025-07-18 12:34:10,687 - logger.py:50 - Epoch: [471][5/6]	Total Loss: 0.73652	Main MSE (x10^-2): 73.6519	LR: 4.53e-06	EMPP_Raw: 1.45499
2025-07-18 12:34:10,729 - logger.py:50 - Epoch 471 Training Summary: Avg Total Loss: 0.73652, Avg Main MSE: 0.73652, Time: 16.91s
2025-07-18 12:34:28,755 - logger.py:50 - Epoch 471 Summary | Train MSE (x10^-2): 73.6519 | Val MSE (x10^-2): 79.4452 | Time: 34.94s
2025-07-18 12:34:31,765 - logger.py:50 - Epoch: [472][0/6]	Total Loss: 0.73545	Main MSE (x10^-2): 73.5453	LR: 4.30e-06	EMPP_Raw: 1.45284
2025-07-18 12:34:45,576 - logger.py:50 - Epoch: [472][5/6]	Total Loss: 0.73690	Main MSE (x10^-2): 73.6903	LR: 4.30e-06	EMPP_Raw: 1.45628
2025-07-18 12:34:45,616 - logger.py:50 - Epoch 472 Training Summary: Avg Total Loss: 0.73690, Avg Main MSE: 0.73690, Time: 16.85s
2025-07-18 12:35:03,490 - logger.py:50 - Epoch 472 Summary | Train MSE (x10^-2): 73.6903 | Val MSE (x10^-2): 79.4332 | Time: 34.73s
2025-07-18 12:35:06,647 - logger.py:50 - Epoch: [473][0/6]	Total Loss: 0.73740	Main MSE (x10^-2): 73.7399	LR: 4.08e-06	EMPP_Raw: 1.45431
2025-07-18 12:35:20,402 - logger.py:50 - Epoch: [473][5/6]	Total Loss: 0.73308	Main MSE (x10^-2): 73.3083	LR: 4.08e-06	EMPP_Raw: 1.44790
2025-07-18 12:35:20,445 - logger.py:50 - Epoch 473 Training Summary: Avg Total Loss: 0.73308, Avg Main MSE: 0.73308, Time: 16.94s
2025-07-18 12:35:38,392 - logger.py:50 - Epoch 473 Summary | Train MSE (x10^-2): 73.3083 | Val MSE (x10^-2): 79.3207 | Time: 34.89s
2025-07-18 12:35:41,406 - logger.py:50 - Epoch: [474][0/6]	Total Loss: 0.73398	Main MSE (x10^-2): 73.3980	LR: 3.86e-06	EMPP_Raw: 1.45125
2025-07-18 12:35:55,364 - logger.py:50 - Epoch: [474][5/6]	Total Loss: 0.73200	Main MSE (x10^-2): 73.2005	LR: 3.86e-06	EMPP_Raw: 1.44661
2025-07-18 12:35:55,409 - logger.py:50 - Epoch 474 Training Summary: Avg Total Loss: 0.73200, Avg Main MSE: 0.73200, Time: 17.01s
2025-07-18 12:36:13,328 - logger.py:50 - Epoch 474 Summary | Train MSE (x10^-2): 73.2005 | Val MSE (x10^-2): 79.2822 | Time: 34.93s
2025-07-18 12:36:16,353 - logger.py:50 - Epoch: [475][0/6]	Total Loss: 0.71327	Main MSE (x10^-2): 71.3266	LR: 3.66e-06	EMPP_Raw: 1.40611
2025-07-18 12:36:30,093 - logger.py:50 - Epoch: [475][5/6]	Total Loss: 0.73022	Main MSE (x10^-2): 73.0221	LR: 3.66e-06	EMPP_Raw: 1.44258
2025-07-18 12:36:30,138 - logger.py:50 - Epoch 475 Training Summary: Avg Total Loss: 0.73022, Avg Main MSE: 0.73022, Time: 16.80s
2025-07-18 12:36:48,217 - logger.py:50 - Epoch 475 Summary | Train MSE (x10^-2): 73.0221 | Val MSE (x10^-2): 79.3517 | Time: 34.88s
2025-07-18 12:36:51,227 - logger.py:50 - Epoch: [476][0/6]	Total Loss: 0.70473	Main MSE (x10^-2): 70.4728	LR: 3.46e-06	EMPP_Raw: 1.39152
2025-07-18 12:37:05,043 - logger.py:50 - Epoch: [476][5/6]	Total Loss: 0.72758	Main MSE (x10^-2): 72.7580	LR: 3.46e-06	EMPP_Raw: 1.43796
2025-07-18 12:37:05,104 - logger.py:50 - Epoch 476 Training Summary: Avg Total Loss: 0.72758, Avg Main MSE: 0.72758, Time: 16.88s
2025-07-18 12:37:23,149 - logger.py:50 - Epoch 476 Summary | Train MSE (x10^-2): 72.7580 | Val MSE (x10^-2): 79.4615 | Time: 34.93s
2025-07-18 12:37:26,141 - logger.py:50 - Epoch: [477][0/6]	Total Loss: 0.75001	Main MSE (x10^-2): 75.0012	LR: 3.26e-06	EMPP_Raw: 1.48152
2025-07-18 12:37:39,923 - logger.py:50 - Epoch: [477][5/6]	Total Loss: 0.73483	Main MSE (x10^-2): 73.4830	LR: 3.26e-06	EMPP_Raw: 1.45196
2025-07-18 12:37:39,971 - logger.py:50 - Epoch 477 Training Summary: Avg Total Loss: 0.73483, Avg Main MSE: 0.73483, Time: 16.82s
2025-07-18 12:37:57,843 - logger.py:50 - Epoch 477 Summary | Train MSE (x10^-2): 73.4830 | Val MSE (x10^-2): 79.4471 | Time: 34.69s
2025-07-18 12:38:01,231 - logger.py:50 - Epoch: [478][0/6]	Total Loss: 0.74110	Main MSE (x10^-2): 74.1098	LR: 3.08e-06	EMPP_Raw: 1.46477
2025-07-18 12:38:14,983 - logger.py:50 - Epoch: [478][5/6]	Total Loss: 0.72694	Main MSE (x10^-2): 72.6940	LR: 3.08e-06	EMPP_Raw: 1.43596
2025-07-18 12:38:15,038 - logger.py:50 - Epoch 478 Training Summary: Avg Total Loss: 0.72694, Avg Main MSE: 0.72694, Time: 17.18s
2025-07-18 12:38:33,041 - logger.py:50 - Epoch 478 Summary | Train MSE (x10^-2): 72.6940 | Val MSE (x10^-2): 79.3065 | Time: 35.19s
2025-07-18 12:38:36,244 - logger.py:50 - Epoch: [479][0/6]	Total Loss: 0.72681	Main MSE (x10^-2): 72.6814	LR: 2.90e-06	EMPP_Raw: 1.43517
2025-07-18 12:38:50,007 - logger.py:50 - Epoch: [479][5/6]	Total Loss: 0.73290	Main MSE (x10^-2): 73.2901	LR: 2.90e-06	EMPP_Raw: 1.44763
2025-07-18 12:38:50,055 - logger.py:50 - Epoch 479 Training Summary: Avg Total Loss: 0.73290, Avg Main MSE: 0.73290, Time: 17.01s
2025-07-18 12:39:07,983 - logger.py:50 - Epoch 479 Summary | Train MSE (x10^-2): 73.2901 | Val MSE (x10^-2): 79.2503 | Time: 34.94s
2025-07-18 12:39:11,013 - logger.py:50 - Epoch: [480][0/6]	Total Loss: 0.74508	Main MSE (x10^-2): 74.5082	LR: 2.73e-06	EMPP_Raw: 1.47247
2025-07-18 12:39:24,957 - logger.py:50 - Epoch: [480][5/6]	Total Loss: 0.72595	Main MSE (x10^-2): 72.5951	LR: 2.73e-06	EMPP_Raw: 1.43399
2025-07-18 12:39:25,000 - logger.py:50 - Epoch 480 Training Summary: Avg Total Loss: 0.72595, Avg Main MSE: 0.72595, Time: 17.01s
2025-07-18 12:39:42,833 - logger.py:50 - Epoch 480 Summary | Train MSE (x10^-2): 72.5951 | Val MSE (x10^-2): 79.3031 | Time: 34.84s
2025-07-18 12:39:45,824 - logger.py:50 - Epoch: [481][0/6]	Total Loss: 0.73488	Main MSE (x10^-2): 73.4877	LR: 2.57e-06	EMPP_Raw: 1.45227
2025-07-18 12:39:59,637 - logger.py:50 - Epoch: [481][5/6]	Total Loss: 0.73453	Main MSE (x10^-2): 73.4532	LR: 2.57e-06	EMPP_Raw: 1.45153
2025-07-18 12:39:59,683 - logger.py:50 - Epoch 481 Training Summary: Avg Total Loss: 0.73453, Avg Main MSE: 0.73453, Time: 16.84s
2025-07-18 12:40:17,718 - logger.py:50 - Epoch 481 Summary | Train MSE (x10^-2): 73.4532 | Val MSE (x10^-2): 79.3977 | Time: 34.88s
2025-07-18 12:40:20,759 - logger.py:50 - Epoch: [482][0/6]	Total Loss: 0.73405	Main MSE (x10^-2): 73.4046	LR: 2.42e-06	EMPP_Raw: 1.44929
2025-07-18 12:40:34,547 - logger.py:50 - Epoch: [482][5/6]	Total Loss: 0.73843	Main MSE (x10^-2): 73.8426	LR: 2.42e-06	EMPP_Raw: 1.45884
2025-07-18 12:40:34,587 - logger.py:50 - Epoch 482 Training Summary: Avg Total Loss: 0.73843, Avg Main MSE: 0.73843, Time: 16.86s
2025-07-18 12:40:52,665 - logger.py:50 - Epoch 482 Summary | Train MSE (x10^-2): 73.8426 | Val MSE (x10^-2): 79.4340 | Time: 34.94s
2025-07-18 12:40:55,675 - logger.py:50 - Epoch: [483][0/6]	Total Loss: 0.72432	Main MSE (x10^-2): 72.4318	LR: 2.27e-06	EMPP_Raw: 1.43183
2025-07-18 12:41:09,479 - logger.py:50 - Epoch: [483][5/6]	Total Loss: 0.73508	Main MSE (x10^-2): 73.5080	LR: 2.27e-06	EMPP_Raw: 1.45230
2025-07-18 12:41:09,515 - logger.py:50 - Epoch 483 Training Summary: Avg Total Loss: 0.73508, Avg Main MSE: 0.73508, Time: 16.84s
2025-07-18 12:41:27,366 - logger.py:50 - Epoch 483 Summary | Train MSE (x10^-2): 73.5080 | Val MSE (x10^-2): 79.3395 | Time: 34.70s
2025-07-18 12:41:30,528 - logger.py:50 - Epoch: [484][0/6]	Total Loss: 0.73718	Main MSE (x10^-2): 73.7182	LR: 2.14e-06	EMPP_Raw: 1.45799
2025-07-18 12:41:44,281 - logger.py:50 - Epoch: [484][5/6]	Total Loss: 0.73242	Main MSE (x10^-2): 73.2421	LR: 2.14e-06	EMPP_Raw: 1.44764
2025-07-18 12:41:44,320 - logger.py:50 - Epoch 484 Training Summary: Avg Total Loss: 0.73242, Avg Main MSE: 0.73242, Time: 16.94s
2025-07-18 12:42:02,246 - logger.py:50 - Epoch 484 Summary | Train MSE (x10^-2): 73.2421 | Val MSE (x10^-2): 79.2590 | Time: 34.87s
2025-07-18 12:42:05,272 - logger.py:50 - Epoch: [485][0/6]	Total Loss: 0.72737	Main MSE (x10^-2): 72.7371	LR: 2.01e-06	EMPP_Raw: 1.43790
2025-07-18 12:42:19,227 - logger.py:50 - Epoch: [485][5/6]	Total Loss: 0.74174	Main MSE (x10^-2): 74.1745	LR: 2.01e-06	EMPP_Raw: 1.46584
2025-07-18 12:42:19,276 - logger.py:50 - Epoch 485 Training Summary: Avg Total Loss: 0.74174, Avg Main MSE: 0.74174, Time: 17.02s
2025-07-18 12:42:37,171 - logger.py:50 - Epoch 485 Summary | Train MSE (x10^-2): 74.1745 | Val MSE (x10^-2): 79.2732 | Time: 34.92s
2025-07-18 12:42:40,172 - logger.py:50 - Epoch: [486][0/6]	Total Loss: 0.73293	Main MSE (x10^-2): 73.2931	LR: 1.89e-06	EMPP_Raw: 1.44694
2025-07-18 12:42:54,087 - logger.py:50 - Epoch: [486][5/6]	Total Loss: 0.73000	Main MSE (x10^-2): 73.0002	LR: 1.89e-06	EMPP_Raw: 1.44186
2025-07-18 12:42:54,126 - logger.py:50 - Epoch 486 Training Summary: Avg Total Loss: 0.73000, Avg Main MSE: 0.73000, Time: 16.95s
2025-07-18 12:43:12,226 - logger.py:50 - Epoch 486 Summary | Train MSE (x10^-2): 73.0002 | Val MSE (x10^-2): 79.3334 | Time: 35.05s
2025-07-18 12:43:15,229 - logger.py:50 - Epoch: [487][0/6]	Total Loss: 0.75598	Main MSE (x10^-2): 75.5976	LR: 1.77e-06	EMPP_Raw: 1.49285
2025-07-18 12:43:29,000 - logger.py:50 - Epoch: [487][5/6]	Total Loss: 0.73799	Main MSE (x10^-2): 73.7989	LR: 1.77e-06	EMPP_Raw: 1.45764
2025-07-18 12:43:29,039 - logger.py:50 - Epoch 487 Training Summary: Avg Total Loss: 0.73799, Avg Main MSE: 0.73799, Time: 16.80s
2025-07-18 12:43:46,907 - logger.py:50 - Epoch 487 Summary | Train MSE (x10^-2): 73.7989 | Val MSE (x10^-2): 79.3765 | Time: 34.67s
2025-07-18 12:43:50,065 - logger.py:50 - Epoch: [488][0/6]	Total Loss: 0.72460	Main MSE (x10^-2): 72.4601	LR: 1.67e-06	EMPP_Raw: 1.43211
2025-07-18 12:44:03,822 - logger.py:50 - Epoch: [488][5/6]	Total Loss: 0.73709	Main MSE (x10^-2): 73.7090	LR: 1.67e-06	EMPP_Raw: 1.45594
2025-07-18 12:44:03,865 - logger.py:50 - Epoch 488 Training Summary: Avg Total Loss: 0.73709, Avg Main MSE: 0.73709, Time: 16.95s
2025-07-18 12:44:21,745 - logger.py:50 - Epoch 488 Summary | Train MSE (x10^-2): 73.7090 | Val MSE (x10^-2): 79.4013 | Time: 34.83s
2025-07-18 12:44:24,918 - logger.py:50 - Epoch: [489][0/6]	Total Loss: 0.73827	Main MSE (x10^-2): 73.8269	LR: 1.57e-06	EMPP_Raw: 1.45780
2025-07-18 12:44:38,667 - logger.py:50 - Epoch: [489][5/6]	Total Loss: 0.72823	Main MSE (x10^-2): 72.8231	LR: 1.57e-06	EMPP_Raw: 1.43889
2025-07-18 12:44:38,711 - logger.py:50 - Epoch 489 Training Summary: Avg Total Loss: 0.72823, Avg Main MSE: 0.72823, Time: 16.95s
2025-07-18 12:44:56,518 - logger.py:50 - Epoch 489 Summary | Train MSE (x10^-2): 72.8231 | Val MSE (x10^-2): 79.3933 | Time: 34.77s
2025-07-18 12:44:59,514 - logger.py:50 - Epoch: [490][0/6]	Total Loss: 0.75956	Main MSE (x10^-2): 75.9557	LR: 1.48e-06	EMPP_Raw: 1.49917
2025-07-18 12:45:13,428 - logger.py:50 - Epoch: [490][5/6]	Total Loss: 0.73996	Main MSE (x10^-2): 73.9964	LR: 1.48e-06	EMPP_Raw: 1.46201
2025-07-18 12:45:13,473 - logger.py:50 - Epoch 490 Training Summary: Avg Total Loss: 0.73996, Avg Main MSE: 0.73996, Time: 16.94s
2025-07-18 12:45:31,527 - logger.py:50 - Epoch 490 Summary | Train MSE (x10^-2): 73.9964 | Val MSE (x10^-2): 79.3805 | Time: 35.00s
2025-07-18 12:45:34,556 - logger.py:50 - Epoch: [491][0/6]	Total Loss: 0.71379	Main MSE (x10^-2): 71.3791	LR: 1.39e-06	EMPP_Raw: 1.40764
2025-07-18 12:45:48,369 - logger.py:50 - Epoch: [491][5/6]	Total Loss: 0.74582	Main MSE (x10^-2): 74.5818	LR: 1.39e-06	EMPP_Raw: 1.47325
2025-07-18 12:45:48,413 - logger.py:50 - Epoch 491 Training Summary: Avg Total Loss: 0.74582, Avg Main MSE: 0.74582, Time: 16.88s
2025-07-18 12:46:06,573 - logger.py:50 - Epoch 491 Summary | Train MSE (x10^-2): 74.5818 | Val MSE (x10^-2): 79.3442 | Time: 35.04s
2025-07-18 12:46:09,633 - logger.py:50 - Epoch: [492][0/6]	Total Loss: 0.72883	Main MSE (x10^-2): 72.8825	LR: 1.32e-06	EMPP_Raw: 1.44014
2025-07-18 12:46:23,392 - logger.py:50 - Epoch: [492][5/6]	Total Loss: 0.73866	Main MSE (x10^-2): 73.8659	LR: 1.32e-06	EMPP_Raw: 1.45970
2025-07-18 12:46:23,433 - logger.py:50 - Epoch 492 Training Summary: Avg Total Loss: 0.73866, Avg Main MSE: 0.73866, Time: 16.85s
2025-07-18 12:46:41,428 - logger.py:50 - Epoch 492 Summary | Train MSE (x10^-2): 73.8659 | Val MSE (x10^-2): 79.3101 | Time: 34.85s
2025-07-18 12:46:44,607 - logger.py:50 - Epoch: [493][0/6]	Total Loss: 0.72458	Main MSE (x10^-2): 72.4582	LR: 1.25e-06	EMPP_Raw: 1.43190
2025-07-18 12:46:58,347 - logger.py:50 - Epoch: [493][5/6]	Total Loss: 0.72346	Main MSE (x10^-2): 72.3461	LR: 1.25e-06	EMPP_Raw: 1.42907
2025-07-18 12:46:58,387 - logger.py:50 - Epoch 493 Training Summary: Avg Total Loss: 0.72346, Avg Main MSE: 0.72346, Time: 16.95s
2025-07-18 12:47:16,201 - logger.py:50 - Epoch 493 Summary | Train MSE (x10^-2): 72.3461 | Val MSE (x10^-2): 79.2749 | Time: 34.77s
2025-07-18 12:47:19,236 - logger.py:50 - Epoch: [494][0/6]	Total Loss: 0.70887	Main MSE (x10^-2): 70.8870	LR: 1.19e-06	EMPP_Raw: 1.40236
2025-07-18 12:47:33,141 - logger.py:50 - Epoch: [494][5/6]	Total Loss: 0.72410	Main MSE (x10^-2): 72.4098	LR: 1.19e-06	EMPP_Raw: 1.43121
2025-07-18 12:47:33,186 - logger.py:50 - Epoch 494 Training Summary: Avg Total Loss: 0.72410, Avg Main MSE: 0.72410, Time: 16.98s
2025-07-18 12:47:51,023 - logger.py:50 - Epoch 494 Summary | Train MSE (x10^-2): 72.4098 | Val MSE (x10^-2): 79.2948 | Time: 34.82s
2025-07-18 12:47:54,015 - logger.py:50 - Epoch: [495][0/6]	Total Loss: 0.75008	Main MSE (x10^-2): 75.0079	LR: 1.14e-06	EMPP_Raw: 1.48366
2025-07-18 12:48:07,757 - logger.py:50 - Epoch: [495][5/6]	Total Loss: 0.73431	Main MSE (x10^-2): 73.4313	LR: 1.14e-06	EMPP_Raw: 1.45095
2025-07-18 12:48:07,807 - logger.py:50 - Epoch 495 Training Summary: Avg Total Loss: 0.73431, Avg Main MSE: 0.73431, Time: 16.77s
2025-07-18 12:48:25,741 - logger.py:50 - Epoch 495 Summary | Train MSE (x10^-2): 73.4313 | Val MSE (x10^-2): 79.3189 | Time: 34.71s
2025-07-18 12:48:28,748 - logger.py:50 - Epoch: [496][0/6]	Total Loss: 0.73327	Main MSE (x10^-2): 73.3272	LR: 1.10e-06	EMPP_Raw: 1.44764
2025-07-18 12:48:42,617 - logger.py:50 - Epoch: [496][5/6]	Total Loss: 0.72999	Main MSE (x10^-2): 72.9993	LR: 1.10e-06	EMPP_Raw: 1.44162
2025-07-18 12:48:42,664 - logger.py:50 - Epoch 496 Training Summary: Avg Total Loss: 0.72999, Avg Main MSE: 0.72999, Time: 16.91s
2025-07-18 12:49:00,642 - logger.py:50 - Epoch 496 Summary | Train MSE (x10^-2): 72.9993 | Val MSE (x10^-2): 79.3356 | Time: 34.89s
2025-07-18 12:49:03,648 - logger.py:50 - Epoch: [497][0/6]	Total Loss: 0.72991	Main MSE (x10^-2): 72.9911	LR: 1.06e-06	EMPP_Raw: 1.44139
2025-07-18 12:49:17,424 - logger.py:50 - Epoch: [497][5/6]	Total Loss: 0.73860	Main MSE (x10^-2): 73.8604	LR: 1.06e-06	EMPP_Raw: 1.45934
2025-07-18 12:49:17,468 - logger.py:50 - Epoch 497 Training Summary: Avg Total Loss: 0.73860, Avg Main MSE: 0.73860, Time: 16.82s
2025-07-18 12:49:35,359 - logger.py:50 - Epoch 497 Summary | Train MSE (x10^-2): 73.8604 | Val MSE (x10^-2): 79.3402 | Time: 34.71s
2025-07-18 12:49:38,698 - logger.py:50 - Epoch: [498][0/6]	Total Loss: 0.72970	Main MSE (x10^-2): 72.9701	LR: 1.04e-06	EMPP_Raw: 1.44203
2025-07-18 12:49:52,490 - logger.py:50 - Epoch: [498][5/6]	Total Loss: 0.74001	Main MSE (x10^-2): 74.0011	LR: 1.04e-06	EMPP_Raw: 1.46225
2025-07-18 12:49:52,545 - logger.py:50 - Epoch 498 Training Summary: Avg Total Loss: 0.74001, Avg Main MSE: 0.74001, Time: 17.18s
2025-07-18 12:50:10,442 - logger.py:50 - Epoch 498 Summary | Train MSE (x10^-2): 74.0011 | Val MSE (x10^-2): 79.3286 | Time: 35.08s
2025-07-18 12:50:13,647 - logger.py:50 - Epoch: [499][0/6]	Total Loss: 0.73639	Main MSE (x10^-2): 73.6386	LR: 1.02e-06	EMPP_Raw: 1.45552
2025-07-18 12:50:27,399 - logger.py:50 - Epoch: [499][5/6]	Total Loss: 0.73108	Main MSE (x10^-2): 73.1076	LR: 1.02e-06	EMPP_Raw: 1.44458
2025-07-18 12:50:27,446 - logger.py:50 - Epoch 499 Training Summary: Avg Total Loss: 0.73108, Avg Main MSE: 0.73108, Time: 16.99s
2025-07-18 12:50:45,481 - logger.py:50 - Epoch 499 Summary | Train MSE (x10^-2): 73.1076 | Val MSE (x10^-2): 79.2887 | Time: 35.03s
2025-07-18 12:50:45,488 - logger.py:50 - --- Finished training for malonaldehyde ---
2025-07-18 12:50:45,488 - logger.py:50 - Final Best Val MSE (at Epoch 26): 0.469997 (x10^-2: 46.9997)
2025-07-18 12:50:45,488 - logger.py:50 - Final Test MSE (at Best Val Epoch): 0.472275 (x10^-2: 47.2275)
2025-07-18 12:50:45,523 - logger.py:50 - --- Starting training for naphthalene ---
2025-07-18 12:50:45,524 - logger.py:50 - Namespace(amp=False, batch_size=80, clip_grad=1.0, contrastive_aug_mask_ratio=0.15, contrastive_loss_weight=0.1, contrastive_mask_token_idx=0, contrastive_prioritize_heteroatoms=False, contrastive_projection_dim=128, contrastive_temp=0.1, cooldown_epochs=10, data_path='data/md17', decay_rate=0.1, delta_frame=3000, device='cuda:0', drop_path=0.0, empp_atom_type_embed_irreps='16x0e', empp_loss_weight=0.5, empp_num_mask=1, empp_pos_pred_num_s2_channels=32, empp_pos_pred_res_s2grid=100, empp_pos_pred_temp_label=0.1, empp_pos_pred_temp_softmax=0.1, empp_prioritize_heteroatoms=True, empp_ssp_feature_dim='16x0e', enable_contrastive=False, epochs=500, exp_name='md17_final_run_20250717_152800', logger=<logger.FileLogger object at 0x7f2569e9d8e0>, loss='l2', lr=0.0004, max_test_samples=2000, max_train_samples=500, max_val_samples=2000, min_lr=1e-06, model_name='graph_attention_transformer_nonlinear_l2', molecule_type='naphthalene', momentum=0.9, num_basis=128, opt='adamw', opt_betas=None, opt_eps=1e-08, output_dir='outputs/md17_final_run_20250717_152800', patience_epochs=10, pin_mem=True, print_freq=50, radius=5.0, sched='cosine', seed=42, ssp=True, warmup_epochs=10, warmup_lr=1e-06, weight_decay=1e-06, workers=8)
2025-07-18 12:50:45,525 - logger.py:50 - Loading datasets...
2025-07-18 12:50:47,878 - logger.py:50 - Creating model...
2025-07-18 12:50:56,242 - logger.py:50 - Number of params: 3,205,881
2025-07-18 12:51:00,957 - logger.py:50 - Epoch: [0][0/6]	Total Loss: 1.23303	Main MSE (x10^-2): 123.3028	LR: 1.00e-06	EMPP_Raw: 2.42879
2025-07-18 12:51:20,424 - logger.py:50 - Epoch: [0][5/6]	Total Loss: 1.22233	Main MSE (x10^-2): 122.2326	LR: 1.00e-06	EMPP_Raw: 2.40718
2025-07-18 12:51:20,469 - logger.py:50 - Epoch 0 Training Summary: Avg Total Loss: 1.22233, Avg Main MSE: 1.22233, Time: 24.22s
2025-07-18 12:51:59,151 - logger.py:50 - *** New Best Val MSE (x10^-2): 1.9050, Corresponding Test MSE (x10^-2): 1.9418 at Epoch 0 ***
2025-07-18 12:51:59,197 - logger.py:50 - Epoch 0 Summary | Train MSE (x10^-2): 122.2326 | Val MSE (x10^-2): 1.9050 | Time: 62.95s
2025-07-18 12:52:03,105 - logger.py:50 - Epoch: [1][0/6]	Total Loss: 1.18133	Main MSE (x10^-2): 118.1327	LR: 1.00e-06	EMPP_Raw: 2.32398
2025-07-18 12:52:20,462 - logger.py:50 - Epoch: [1][5/6]	Total Loss: 1.20642	Main MSE (x10^-2): 120.6417	LR: 1.00e-06	EMPP_Raw: 2.37543
2025-07-18 12:52:20,508 - logger.py:50 - Epoch 1 Training Summary: Avg Total Loss: 1.20642, Avg Main MSE: 1.20642, Time: 21.31s
2025-07-18 12:52:58,863 - logger.py:50 - *** New Best Val MSE (x10^-2): 1.9040, Corresponding Test MSE (x10^-2): 1.9408 at Epoch 1 ***
2025-07-18 12:52:58,911 - logger.py:50 - Epoch 1 Summary | Train MSE (x10^-2): 120.6417 | Val MSE (x10^-2): 1.9040 | Time: 59.71s
2025-07-18 12:53:02,805 - logger.py:50 - Epoch: [2][0/6]	Total Loss: 1.16694	Main MSE (x10^-2): 116.6937	LR: 4.09e-05	EMPP_Raw: 2.29505
2025-07-18 12:53:20,214 - logger.py:50 - Epoch: [2][5/6]	Total Loss: 1.03156	Main MSE (x10^-2): 103.1556	LR: 4.09e-05	EMPP_Raw: 2.02583
2025-07-18 12:53:20,255 - logger.py:50 - Epoch 2 Training Summary: Avg Total Loss: 1.03156, Avg Main MSE: 1.03156, Time: 21.34s
2025-07-18 12:53:58,632 - logger.py:50 - *** New Best Val MSE (x10^-2): 1.8962, Corresponding Test MSE (x10^-2): 1.9321 at Epoch 2 ***
2025-07-18 12:53:58,679 - logger.py:50 - Epoch 2 Summary | Train MSE (x10^-2): 103.1556 | Val MSE (x10^-2): 1.8962 | Time: 59.77s
2025-07-18 12:54:02,582 - logger.py:50 - Epoch: [3][0/6]	Total Loss: 0.92973	Main MSE (x10^-2): 92.9731	LR: 8.08e-05	EMPP_Raw: 1.81857
2025-07-18 12:54:19,973 - logger.py:50 - Epoch: [3][5/6]	Total Loss: 0.86889	Main MSE (x10^-2): 86.8891	LR: 8.08e-05	EMPP_Raw: 1.70050
2025-07-18 12:54:20,017 - logger.py:50 - Epoch 3 Training Summary: Avg Total Loss: 0.86889, Avg Main MSE: 0.86889, Time: 21.33s
2025-07-18 12:54:58,245 - logger.py:50 - *** New Best Val MSE (x10^-2): 1.8840, Corresponding Test MSE (x10^-2): 1.9200 at Epoch 3 ***
2025-07-18 12:54:58,294 - logger.py:50 - Epoch 3 Summary | Train MSE (x10^-2): 86.8891 | Val MSE (x10^-2): 1.8840 | Time: 59.61s
2025-07-18 12:55:02,207 - logger.py:50 - Epoch: [4][0/6]	Total Loss: 0.80949	Main MSE (x10^-2): 80.9495	LR: 1.21e-04	EMPP_Raw: 1.58451
2025-07-18 12:55:19,614 - logger.py:50 - Epoch: [4][5/6]	Total Loss: 0.80085	Main MSE (x10^-2): 80.0852	LR: 1.21e-04	EMPP_Raw: 1.56482
2025-07-18 12:55:19,661 - logger.py:50 - Epoch 4 Training Summary: Avg Total Loss: 0.80085, Avg Main MSE: 0.80085, Time: 21.36s
2025-07-18 12:55:57,807 - logger.py:50 - *** New Best Val MSE (x10^-2): 1.8729, Corresponding Test MSE (x10^-2): 1.9085 at Epoch 4 ***
2025-07-18 12:55:57,854 - logger.py:50 - Epoch 4 Summary | Train MSE (x10^-2): 80.0852 | Val MSE (x10^-2): 1.8729 | Time: 59.56s
2025-07-18 12:56:01,745 - logger.py:50 - Epoch: [5][0/6]	Total Loss: 0.77686	Main MSE (x10^-2): 77.6857	LR: 1.61e-04	EMPP_Raw: 1.51662
2025-07-18 12:56:19,044 - logger.py:50 - Epoch: [5][5/6]	Total Loss: 0.74819	Main MSE (x10^-2): 74.8186	LR: 1.61e-04	EMPP_Raw: 1.45953
2025-07-18 12:56:19,086 - logger.py:50 - Epoch 5 Training Summary: Avg Total Loss: 0.74819, Avg Main MSE: 0.74819, Time: 21.23s
2025-07-18 12:56:57,423 - logger.py:50 - *** New Best Val MSE (x10^-2): 1.8650, Corresponding Test MSE (x10^-2): 1.9001 at Epoch 5 ***
2025-07-18 12:56:57,473 - logger.py:50 - Epoch 5 Summary | Train MSE (x10^-2): 74.8186 | Val MSE (x10^-2): 1.8650 | Time: 59.62s
2025-07-18 12:57:01,345 - logger.py:50 - Epoch: [6][0/6]	Total Loss: 0.67736	Main MSE (x10^-2): 67.7359	LR: 2.00e-04	EMPP_Raw: 1.31885
2025-07-18 12:57:18,627 - logger.py:50 - Epoch: [6][5/6]	Total Loss: 0.70466	Main MSE (x10^-2): 70.4665	LR: 2.00e-04	EMPP_Raw: 1.37274
2025-07-18 12:57:18,676 - logger.py:50 - Epoch 6 Training Summary: Avg Total Loss: 0.70466, Avg Main MSE: 0.70466, Time: 21.20s
2025-07-18 12:57:57,025 - logger.py:50 - *** New Best Val MSE (x10^-2): 1.8525, Corresponding Test MSE (x10^-2): 1.8872 at Epoch 6 ***
2025-07-18 12:57:57,211 - logger.py:50 - Epoch 6 Summary | Train MSE (x10^-2): 70.4665 | Val MSE (x10^-2): 1.8525 | Time: 59.74s
2025-07-18 12:58:00,926 - logger.py:50 - Epoch: [7][0/6]	Total Loss: 0.76809	Main MSE (x10^-2): 76.8088	LR: 2.40e-04	EMPP_Raw: 1.50319
2025-07-18 12:58:18,235 - logger.py:50 - Epoch: [7][5/6]	Total Loss: 0.71985	Main MSE (x10^-2): 71.9848	LR: 2.40e-04	EMPP_Raw: 1.40355
2025-07-18 12:58:18,277 - logger.py:50 - Epoch 7 Training Summary: Avg Total Loss: 0.71985, Avg Main MSE: 0.71985, Time: 21.06s
2025-07-18 12:58:56,537 - logger.py:50 - *** New Best Val MSE (x10^-2): 1.8337, Corresponding Test MSE (x10^-2): 1.8681 at Epoch 7 ***
2025-07-18 12:58:56,585 - logger.py:50 - Epoch 7 Summary | Train MSE (x10^-2): 71.9848 | Val MSE (x10^-2): 1.8337 | Time: 59.37s
2025-07-18 12:59:00,291 - logger.py:50 - Epoch: [8][0/6]	Total Loss: 0.74911	Main MSE (x10^-2): 74.9110	LR: 2.80e-04	EMPP_Raw: 1.46287
2025-07-18 12:59:17,695 - logger.py:50 - Epoch: [8][5/6]	Total Loss: 0.71371	Main MSE (x10^-2): 71.3710	LR: 2.80e-04	EMPP_Raw: 1.39141
2025-07-18 12:59:17,735 - logger.py:50 - Epoch 8 Training Summary: Avg Total Loss: 0.71371, Avg Main MSE: 0.71371, Time: 21.15s
2025-07-18 12:59:56,344 - logger.py:50 - *** New Best Val MSE (x10^-2): 1.8032, Corresponding Test MSE (x10^-2): 1.8368 at Epoch 8 ***
2025-07-18 12:59:56,392 - logger.py:50 - Epoch 8 Summary | Train MSE (x10^-2): 71.3710 | Val MSE (x10^-2): 1.8032 | Time: 59.81s
2025-07-18 13:00:00,151 - logger.py:50 - Epoch: [9][0/6]	Total Loss: 0.64839	Main MSE (x10^-2): 64.8390	LR: 3.20e-04	EMPP_Raw: 1.26230
2025-07-18 13:00:17,488 - logger.py:50 - Epoch: [9][5/6]	Total Loss: 0.68441	Main MSE (x10^-2): 68.4408	LR: 3.20e-04	EMPP_Raw: 1.33333
2025-07-18 13:00:17,530 - logger.py:50 - Epoch 9 Training Summary: Avg Total Loss: 0.68441, Avg Main MSE: 0.68441, Time: 21.13s
2025-07-18 13:00:55,909 - logger.py:50 - *** New Best Val MSE (x10^-2): 1.7825, Corresponding Test MSE (x10^-2): 1.8164 at Epoch 9 ***
2025-07-18 13:00:55,957 - logger.py:50 - Epoch 9 Summary | Train MSE (x10^-2): 68.4408 | Val MSE (x10^-2): 1.7825 | Time: 59.56s
2025-07-18 13:00:59,698 - logger.py:50 - Epoch: [10][0/6]	Total Loss: 0.74103	Main MSE (x10^-2): 74.1026	LR: 3.60e-04	EMPP_Raw: 1.44590
2025-07-18 13:01:17,081 - logger.py:50 - Epoch: [10][5/6]	Total Loss: 0.71310	Main MSE (x10^-2): 71.3101	LR: 3.60e-04	EMPP_Raw: 1.39147
2025-07-18 13:01:17,124 - logger.py:50 - Epoch 10 Training Summary: Avg Total Loss: 0.71310, Avg Main MSE: 0.71310, Time: 21.16s
2025-07-18 13:01:55,573 - logger.py:50 - *** New Best Val MSE (x10^-2): 1.7181, Corresponding Test MSE (x10^-2): 1.7512 at Epoch 10 ***
2025-07-18 13:01:55,623 - logger.py:50 - Epoch 10 Summary | Train MSE (x10^-2): 71.3101 | Val MSE (x10^-2): 1.7181 | Time: 59.67s
2025-07-18 13:01:59,360 - logger.py:50 - Epoch: [11][0/6]	Total Loss: 0.71354	Main MSE (x10^-2): 71.3538	LR: 4.00e-04	EMPP_Raw: 1.39345
2025-07-18 13:02:16,686 - logger.py:50 - Epoch: [11][5/6]	Total Loss: 0.70534	Main MSE (x10^-2): 70.5342	LR: 4.00e-04	EMPP_Raw: 1.37709
2025-07-18 13:02:16,731 - logger.py:50 - Epoch 11 Training Summary: Avg Total Loss: 0.70534, Avg Main MSE: 0.70534, Time: 21.10s
2025-07-18 13:02:55,105 - logger.py:50 - *** New Best Val MSE (x10^-2): 1.6424, Corresponding Test MSE (x10^-2): 1.6748 at Epoch 11 ***
2025-07-18 13:02:55,152 - logger.py:50 - Epoch 11 Summary | Train MSE (x10^-2): 70.5342 | Val MSE (x10^-2): 1.6424 | Time: 59.53s
2025-07-18 13:02:58,864 - logger.py:50 - Epoch: [12][0/6]	Total Loss: 0.65377	Main MSE (x10^-2): 65.3766	LR: 4.00e-04	EMPP_Raw: 1.27333
2025-07-18 13:03:16,138 - logger.py:50 - Epoch: [12][5/6]	Total Loss: 0.67426	Main MSE (x10^-2): 67.4261	LR: 4.00e-04	EMPP_Raw: 1.31646
2025-07-18 13:03:16,187 - logger.py:50 - Epoch 12 Training Summary: Avg Total Loss: 0.67426, Avg Main MSE: 0.67426, Time: 21.03s
2025-07-18 13:03:54,712 - logger.py:50 - *** New Best Val MSE (x10^-2): 1.5514, Corresponding Test MSE (x10^-2): 1.5826 at Epoch 12 ***
2025-07-18 13:03:54,759 - logger.py:50 - Epoch 12 Summary | Train MSE (x10^-2): 67.4261 | Val MSE (x10^-2): 1.5514 | Time: 59.61s
2025-07-18 13:03:58,483 - logger.py:50 - Epoch: [13][0/6]	Total Loss: 0.73053	Main MSE (x10^-2): 73.0532	LR: 3.99e-04	EMPP_Raw: 1.42839
2025-07-18 13:04:15,697 - logger.py:50 - Epoch: [13][5/6]	Total Loss: 0.67923	Main MSE (x10^-2): 67.9234	LR: 3.99e-04	EMPP_Raw: 1.32806
2025-07-18 13:04:15,743 - logger.py:50 - Epoch 13 Training Summary: Avg Total Loss: 0.67923, Avg Main MSE: 0.67923, Time: 20.98s
2025-07-18 13:04:54,106 - logger.py:50 - *** New Best Val MSE (x10^-2): 1.4308, Corresponding Test MSE (x10^-2): 1.4597 at Epoch 13 ***
2025-07-18 13:04:54,157 - logger.py:50 - Epoch 13 Summary | Train MSE (x10^-2): 67.9234 | Val MSE (x10^-2): 1.4308 | Time: 59.40s
2025-07-18 13:04:57,875 - logger.py:50 - Epoch: [14][0/6]	Total Loss: 0.69610	Main MSE (x10^-2): 69.6097	LR: 3.99e-04	EMPP_Raw: 1.36345
2025-07-18 13:05:15,184 - logger.py:50 - Epoch: [14][5/6]	Total Loss: 0.66904	Main MSE (x10^-2): 66.9041	LR: 3.99e-04	EMPP_Raw: 1.30411
2025-07-18 13:05:15,225 - logger.py:50 - Epoch 14 Training Summary: Avg Total Loss: 0.66904, Avg Main MSE: 0.66904, Time: 21.06s
2025-07-18 13:05:34,324 - logger.py:50 - Epoch 14 Summary | Train MSE (x10^-2): 66.9041 | Val MSE (x10^-2): 1.5907 | Time: 40.17s
2025-07-18 13:05:38,224 - logger.py:50 - Epoch: [15][0/6]	Total Loss: 0.67316	Main MSE (x10^-2): 67.3157	LR: 3.99e-04	EMPP_Raw: 1.31328
2025-07-18 13:05:55,482 - logger.py:50 - Epoch: [15][5/6]	Total Loss: 0.66680	Main MSE (x10^-2): 66.6805	LR: 3.99e-04	EMPP_Raw: 1.30285
2025-07-18 13:05:55,525 - logger.py:50 - Epoch 15 Training Summary: Avg Total Loss: 0.66680, Avg Main MSE: 0.66680, Time: 21.19s
2025-07-18 13:06:33,564 - logger.py:50 - *** New Best Val MSE (x10^-2): 1.2872, Corresponding Test MSE (x10^-2): 1.3140 at Epoch 15 ***
2025-07-18 13:06:33,614 - logger.py:50 - Epoch 15 Summary | Train MSE (x10^-2): 66.6805 | Val MSE (x10^-2): 1.2872 | Time: 59.28s
2025-07-18 13:06:37,509 - logger.py:50 - Epoch: [16][0/6]	Total Loss: 0.66387	Main MSE (x10^-2): 66.3866	LR: 3.99e-04	EMPP_Raw: 1.30239
2025-07-18 13:06:54,820 - logger.py:50 - Epoch: [16][5/6]	Total Loss: 0.65360	Main MSE (x10^-2): 65.3598	LR: 3.99e-04	EMPP_Raw: 1.27424
2025-07-18 13:06:54,865 - logger.py:50 - Epoch 16 Training Summary: Avg Total Loss: 0.65360, Avg Main MSE: 0.65360, Time: 21.25s
2025-07-18 13:07:14,046 - logger.py:50 - Epoch 16 Summary | Train MSE (x10^-2): 65.3598 | Val MSE (x10^-2): 1.6435 | Time: 40.43s
2025-07-18 13:07:17,930 - logger.py:50 - Epoch: [17][0/6]	Total Loss: 0.68134	Main MSE (x10^-2): 68.1341	LR: 3.99e-04	EMPP_Raw: 1.33044
2025-07-18 13:07:35,220 - logger.py:50 - Epoch: [17][5/6]	Total Loss: 0.66047	Main MSE (x10^-2): 66.0469	LR: 3.99e-04	EMPP_Raw: 1.29215
2025-07-18 13:07:35,265 - logger.py:50 - Epoch 17 Training Summary: Avg Total Loss: 0.66047, Avg Main MSE: 0.66047, Time: 21.21s
2025-07-18 13:08:13,581 - logger.py:50 - *** New Best Val MSE (x10^-2): 1.2818, Corresponding Test MSE (x10^-2): 1.3102 at Epoch 17 ***
2025-07-18 13:08:13,629 - logger.py:50 - Epoch 17 Summary | Train MSE (x10^-2): 66.0469 | Val MSE (x10^-2): 1.2818 | Time: 59.58s
2025-07-18 13:08:17,492 - logger.py:50 - Epoch: [18][0/6]	Total Loss: 0.69210	Main MSE (x10^-2): 69.2096	LR: 3.99e-04	EMPP_Raw: 1.35781
2025-07-18 13:08:34,755 - logger.py:50 - Epoch: [18][5/6]	Total Loss: 0.66841	Main MSE (x10^-2): 66.8410	LR: 3.99e-04	EMPP_Raw: 1.30904
2025-07-18 13:08:34,796 - logger.py:50 - Epoch 18 Training Summary: Avg Total Loss: 0.66841, Avg Main MSE: 0.66841, Time: 21.16s
2025-07-18 13:08:54,023 - logger.py:50 - Epoch 18 Summary | Train MSE (x10^-2): 66.8410 | Val MSE (x10^-2): 1.3188 | Time: 40.39s
2025-07-18 13:08:57,735 - logger.py:50 - Epoch: [19][0/6]	Total Loss: 0.65833	Main MSE (x10^-2): 65.8333	LR: 3.99e-04	EMPP_Raw: 1.28887
2025-07-18 13:09:15,150 - logger.py:50 - Epoch: [19][5/6]	Total Loss: 0.66306	Main MSE (x10^-2): 66.3058	LR: 3.99e-04	EMPP_Raw: 1.29928
2025-07-18 13:09:15,196 - logger.py:50 - Epoch 19 Training Summary: Avg Total Loss: 0.66306, Avg Main MSE: 0.66306, Time: 21.16s
2025-07-18 13:09:53,582 - logger.py:50 - *** New Best Val MSE (x10^-2): 1.2503, Corresponding Test MSE (x10^-2): 1.2780 at Epoch 19 ***
2025-07-18 13:09:53,629 - logger.py:50 - Epoch 19 Summary | Train MSE (x10^-2): 66.3058 | Val MSE (x10^-2): 1.2503 | Time: 59.60s
2025-07-18 13:09:57,356 - logger.py:50 - Epoch: [20][0/6]	Total Loss: 0.65566	Main MSE (x10^-2): 65.5656	LR: 3.99e-04	EMPP_Raw: 1.28546
2025-07-18 13:10:14,775 - logger.py:50 - Epoch: [20][5/6]	Total Loss: 0.65970	Main MSE (x10^-2): 65.9698	LR: 3.99e-04	EMPP_Raw: 1.29234
2025-07-18 13:10:14,819 - logger.py:50 - Epoch 20 Training Summary: Avg Total Loss: 0.65970, Avg Main MSE: 0.65970, Time: 21.19s
2025-07-18 13:10:53,113 - logger.py:50 - *** New Best Val MSE (x10^-2): 1.2371, Corresponding Test MSE (x10^-2): 1.2636 at Epoch 20 ***
2025-07-18 13:10:53,161 - logger.py:50 - Epoch 20 Summary | Train MSE (x10^-2): 65.9698 | Val MSE (x10^-2): 1.2371 | Time: 59.53s
2025-07-18 13:10:56,864 - logger.py:50 - Epoch: [21][0/6]	Total Loss: 0.65942	Main MSE (x10^-2): 65.9423	LR: 3.98e-04	EMPP_Raw: 1.29362
2025-07-18 13:11:14,321 - logger.py:50 - Epoch: [21][5/6]	Total Loss: 0.65005	Main MSE (x10^-2): 65.0053	LR: 3.98e-04	EMPP_Raw: 1.27395
2025-07-18 13:11:14,367 - logger.py:50 - Epoch 21 Training Summary: Avg Total Loss: 0.65005, Avg Main MSE: 0.65005, Time: 21.20s
2025-07-18 13:11:33,584 - logger.py:50 - Epoch 21 Summary | Train MSE (x10^-2): 65.0053 | Val MSE (x10^-2): 1.2520 | Time: 40.42s
2025-07-18 13:11:37,329 - logger.py:50 - Epoch: [22][0/6]	Total Loss: 0.63844	Main MSE (x10^-2): 63.8440	LR: 3.98e-04	EMPP_Raw: 1.25362
2025-07-18 13:11:54,542 - logger.py:50 - Epoch: [22][5/6]	Total Loss: 0.64576	Main MSE (x10^-2): 64.5758	LR: 3.98e-04	EMPP_Raw: 1.26575
2025-07-18 13:11:54,587 - logger.py:50 - Epoch 22 Training Summary: Avg Total Loss: 0.64576, Avg Main MSE: 0.64576, Time: 20.99s
2025-07-18 13:12:32,906 - logger.py:50 - *** New Best Val MSE (x10^-2): 1.2307, Corresponding Test MSE (x10^-2): 1.2546 at Epoch 22 ***
2025-07-18 13:12:32,953 - logger.py:50 - Epoch 22 Summary | Train MSE (x10^-2): 64.5758 | Val MSE (x10^-2): 1.2307 | Time: 59.36s
2025-07-18 13:12:36,672 - logger.py:50 - Epoch: [23][0/6]	Total Loss: 0.64929	Main MSE (x10^-2): 64.9294	LR: 3.98e-04	EMPP_Raw: 1.27391
2025-07-18 13:12:53,935 - logger.py:50 - Epoch: [23][5/6]	Total Loss: 0.64494	Main MSE (x10^-2): 64.4938	LR: 3.98e-04	EMPP_Raw: 1.26398
2025-07-18 13:12:53,980 - logger.py:50 - Epoch 23 Training Summary: Avg Total Loss: 0.64494, Avg Main MSE: 0.64494, Time: 21.02s
2025-07-18 13:13:13,205 - logger.py:50 - Epoch 23 Summary | Train MSE (x10^-2): 64.4938 | Val MSE (x10^-2): 1.4929 | Time: 40.25s
2025-07-18 13:13:16,962 - logger.py:50 - Epoch: [24][0/6]	Total Loss: 0.69200	Main MSE (x10^-2): 69.1999	LR: 3.98e-04	EMPP_Raw: 1.35254
2025-07-18 13:13:34,294 - logger.py:50 - Epoch: [24][5/6]	Total Loss: 0.66755	Main MSE (x10^-2): 66.7548	LR: 3.98e-04	EMPP_Raw: 1.30662
2025-07-18 13:13:34,341 - logger.py:50 - Epoch 24 Training Summary: Avg Total Loss: 0.66755, Avg Main MSE: 0.66755, Time: 21.13s
2025-07-18 13:13:53,492 - logger.py:50 - Epoch 24 Summary | Train MSE (x10^-2): 66.7548 | Val MSE (x10^-2): 1.4574 | Time: 40.28s
2025-07-18 13:13:57,409 - logger.py:50 - Epoch: [25][0/6]	Total Loss: 0.63923	Main MSE (x10^-2): 63.9229	LR: 3.98e-04	EMPP_Raw: 1.24952
2025-07-18 13:14:14,643 - logger.py:50 - Epoch: [25][5/6]	Total Loss: 0.65958	Main MSE (x10^-2): 65.9583	LR: 3.98e-04	EMPP_Raw: 1.29097
2025-07-18 13:14:14,687 - logger.py:50 - Epoch 25 Training Summary: Avg Total Loss: 0.65958, Avg Main MSE: 0.65958, Time: 21.19s
2025-07-18 13:14:33,832 - logger.py:50 - Epoch 25 Summary | Train MSE (x10^-2): 65.9583 | Val MSE (x10^-2): 1.3046 | Time: 40.33s
2025-07-18 13:14:37,555 - logger.py:50 - Epoch: [26][0/6]	Total Loss: 0.70613	Main MSE (x10^-2): 70.6134	LR: 3.98e-04	EMPP_Raw: 1.38473
2025-07-18 13:14:55,188 - logger.py:50 - Epoch: [26][5/6]	Total Loss: 0.66214	Main MSE (x10^-2): 66.2143	LR: 3.98e-04	EMPP_Raw: 1.29748
2025-07-18 13:14:55,241 - logger.py:50 - Epoch 26 Training Summary: Avg Total Loss: 0.66214, Avg Main MSE: 0.66214, Time: 21.40s
2025-07-18 13:15:14,379 - logger.py:50 - Epoch 26 Summary | Train MSE (x10^-2): 66.2143 | Val MSE (x10^-2): 1.5323 | Time: 40.54s
2025-07-18 13:15:18,076 - logger.py:50 - Epoch: [27][0/6]	Total Loss: 0.66549	Main MSE (x10^-2): 66.5493	LR: 3.97e-04	EMPP_Raw: 1.29892
2025-07-18 13:15:35,376 - logger.py:50 - Epoch: [27][5/6]	Total Loss: 0.65580	Main MSE (x10^-2): 65.5796	LR: 3.97e-04	EMPP_Raw: 1.27906
2025-07-18 13:15:35,426 - logger.py:50 - Epoch 27 Training Summary: Avg Total Loss: 0.65580, Avg Main MSE: 0.65580, Time: 21.04s
2025-07-18 13:15:54,612 - logger.py:50 - Epoch 27 Summary | Train MSE (x10^-2): 65.5796 | Val MSE (x10^-2): 1.6471 | Time: 40.22s
2025-07-18 13:15:58,543 - logger.py:50 - Epoch: [28][0/6]	Total Loss: 0.63048	Main MSE (x10^-2): 63.0476	LR: 3.97e-04	EMPP_Raw: 1.22917
2025-07-18 13:16:15,859 - logger.py:50 - Epoch: [28][5/6]	Total Loss: 0.64106	Main MSE (x10^-2): 64.1063	LR: 3.97e-04	EMPP_Raw: 1.24881
2025-07-18 13:16:15,909 - logger.py:50 - Epoch 28 Training Summary: Avg Total Loss: 0.64106, Avg Main MSE: 0.64106, Time: 21.29s
2025-07-18 13:16:35,154 - logger.py:50 - Epoch 28 Summary | Train MSE (x10^-2): 64.1063 | Val MSE (x10^-2): 1.2605 | Time: 40.54s
2025-07-18 13:16:39,034 - logger.py:50 - Epoch: [29][0/6]	Total Loss: 0.66289	Main MSE (x10^-2): 66.2894	LR: 3.97e-04	EMPP_Raw: 1.30146
2025-07-18 13:16:56,357 - logger.py:50 - Epoch: [29][5/6]	Total Loss: 0.65294	Main MSE (x10^-2): 65.2937	LR: 3.97e-04	EMPP_Raw: 1.27919
2025-07-18 13:16:56,403 - logger.py:50 - Epoch 29 Training Summary: Avg Total Loss: 0.65294, Avg Main MSE: 0.65294, Time: 21.24s
2025-07-18 13:17:34,578 - logger.py:50 - *** New Best Val MSE (x10^-2): 1.2075, Corresponding Test MSE (x10^-2): 1.2336 at Epoch 29 ***
2025-07-18 13:17:34,625 - logger.py:50 - Epoch 29 Summary | Train MSE (x10^-2): 65.2937 | Val MSE (x10^-2): 1.2075 | Time: 59.47s
2025-07-18 13:17:38,485 - logger.py:50 - Epoch: [30][0/6]	Total Loss: 0.63163	Main MSE (x10^-2): 63.1631	LR: 3.97e-04	EMPP_Raw: 1.23910
2025-07-18 13:17:55,672 - logger.py:50 - Epoch: [30][5/6]	Total Loss: 0.63351	Main MSE (x10^-2): 63.3515	LR: 3.97e-04	EMPP_Raw: 1.24272
2025-07-18 13:17:55,715 - logger.py:50 - Epoch 30 Training Summary: Avg Total Loss: 0.63351, Avg Main MSE: 0.63351, Time: 21.09s
2025-07-18 13:18:14,897 - logger.py:50 - Epoch 30 Summary | Train MSE (x10^-2): 63.3515 | Val MSE (x10^-2): 1.2143 | Time: 40.27s
2025-07-18 13:18:18,601 - logger.py:50 - Epoch: [31][0/6]	Total Loss: 0.62198	Main MSE (x10^-2): 62.1980	LR: 3.96e-04	EMPP_Raw: 1.22058
2025-07-18 13:18:36,004 - logger.py:50 - Epoch: [31][5/6]	Total Loss: 0.64472	Main MSE (x10^-2): 64.4719	LR: 3.96e-04	EMPP_Raw: 1.26530
2025-07-18 13:18:36,060 - logger.py:50 - Epoch 31 Training Summary: Avg Total Loss: 0.64472, Avg Main MSE: 0.64472, Time: 21.15s
2025-07-18 13:19:14,297 - logger.py:50 - *** New Best Val MSE (x10^-2): 1.1870, Corresponding Test MSE (x10^-2): 1.2115 at Epoch 31 ***
2025-07-18 13:19:14,340 - logger.py:50 - Epoch 31 Summary | Train MSE (x10^-2): 64.4719 | Val MSE (x10^-2): 1.1870 | Time: 59.44s
2025-07-18 13:19:18,068 - logger.py:50 - Epoch: [32][0/6]	Total Loss: 0.63900	Main MSE (x10^-2): 63.8998	LR: 3.96e-04	EMPP_Raw: 1.25469
2025-07-18 13:19:35,523 - logger.py:50 - Epoch: [32][5/6]	Total Loss: 0.64645	Main MSE (x10^-2): 64.6447	LR: 3.96e-04	EMPP_Raw: 1.26891
2025-07-18 13:19:35,568 - logger.py:50 - Epoch 32 Training Summary: Avg Total Loss: 0.64645, Avg Main MSE: 0.64645, Time: 21.22s
2025-07-18 13:20:14,137 - logger.py:50 - *** New Best Val MSE (x10^-2): 1.1811, Corresponding Test MSE (x10^-2): 1.2068 at Epoch 32 ***
2025-07-18 13:20:14,184 - logger.py:50 - Epoch 32 Summary | Train MSE (x10^-2): 64.6447 | Val MSE (x10^-2): 1.1811 | Time: 59.84s
2025-07-18 13:20:17,960 - logger.py:50 - Epoch: [33][0/6]	Total Loss: 0.62475	Main MSE (x10^-2): 62.4746	LR: 3.96e-04	EMPP_Raw: 1.22506
2025-07-18 13:20:35,479 - logger.py:50 - Epoch: [33][5/6]	Total Loss: 0.64410	Main MSE (x10^-2): 64.4101	LR: 3.96e-04	EMPP_Raw: 1.26412
2025-07-18 13:20:35,523 - logger.py:50 - Epoch 33 Training Summary: Avg Total Loss: 0.64410, Avg Main MSE: 0.64410, Time: 21.34s
2025-07-18 13:20:54,647 - logger.py:50 - Epoch 33 Summary | Train MSE (x10^-2): 64.4101 | Val MSE (x10^-2): 1.1901 | Time: 40.46s
2025-07-18 13:20:58,355 - logger.py:50 - Epoch: [34][0/6]	Total Loss: 0.62986	Main MSE (x10^-2): 62.9858	LR: 3.96e-04	EMPP_Raw: 1.23524
2025-07-18 13:21:15,671 - logger.py:50 - Epoch: [34][5/6]	Total Loss: 0.64190	Main MSE (x10^-2): 64.1900	LR: 3.96e-04	EMPP_Raw: 1.25950
2025-07-18 13:21:15,719 - logger.py:50 - Epoch 34 Training Summary: Avg Total Loss: 0.64190, Avg Main MSE: 0.64190, Time: 21.06s
2025-07-18 13:21:54,201 - logger.py:50 - *** New Best Val MSE (x10^-2): 1.1724, Corresponding Test MSE (x10^-2): 1.1973 at Epoch 34 ***
2025-07-18 13:21:54,249 - logger.py:50 - Epoch 34 Summary | Train MSE (x10^-2): 64.1900 | Val MSE (x10^-2): 1.1724 | Time: 59.60s
2025-07-18 13:21:57,944 - logger.py:50 - Epoch: [35][0/6]	Total Loss: 0.64550	Main MSE (x10^-2): 64.5496	LR: 3.95e-04	EMPP_Raw: 1.26699
2025-07-18 13:22:15,172 - logger.py:50 - Epoch: [35][5/6]	Total Loss: 0.64807	Main MSE (x10^-2): 64.8067	LR: 3.95e-04	EMPP_Raw: 1.27170
2025-07-18 13:22:15,217 - logger.py:50 - Epoch 35 Training Summary: Avg Total Loss: 0.64807, Avg Main MSE: 0.64807, Time: 20.96s
2025-07-18 13:22:34,425 - logger.py:50 - Epoch 35 Summary | Train MSE (x10^-2): 64.8067 | Val MSE (x10^-2): 1.2370 | Time: 40.18s
2025-07-18 13:22:38,151 - logger.py:50 - Epoch: [36][0/6]	Total Loss: 0.63340	Main MSE (x10^-2): 63.3396	LR: 3.95e-04	EMPP_Raw: 1.24251
2025-07-18 13:22:55,459 - logger.py:50 - Epoch: [36][5/6]	Total Loss: 0.64386	Main MSE (x10^-2): 64.3861	LR: 3.95e-04	EMPP_Raw: 1.26347
2025-07-18 13:22:55,502 - logger.py:50 - Epoch 36 Training Summary: Avg Total Loss: 0.64386, Avg Main MSE: 0.64386, Time: 21.07s
2025-07-18 13:23:14,703 - logger.py:50 - Epoch 36 Summary | Train MSE (x10^-2): 64.3861 | Val MSE (x10^-2): 1.1846 | Time: 40.27s
2025-07-18 13:23:18,418 - logger.py:50 - Epoch: [37][0/6]	Total Loss: 0.62663	Main MSE (x10^-2): 62.6630	LR: 3.95e-04	EMPP_Raw: 1.23003
2025-07-18 13:23:35,708 - logger.py:50 - Epoch: [37][5/6]	Total Loss: 0.63497	Main MSE (x10^-2): 63.4967	LR: 3.95e-04	EMPP_Raw: 1.24533
2025-07-18 13:23:35,754 - logger.py:50 - Epoch 37 Training Summary: Avg Total Loss: 0.63497, Avg Main MSE: 0.63497, Time: 21.04s
2025-07-18 13:23:55,110 - logger.py:50 - Epoch 37 Summary | Train MSE (x10^-2): 63.4967 | Val MSE (x10^-2): 1.2143 | Time: 40.40s
2025-07-18 13:23:59,025 - logger.py:50 - Epoch: [38][0/6]	Total Loss: 0.63310	Main MSE (x10^-2): 63.3099	LR: 3.95e-04	EMPP_Raw: 1.23995
2025-07-18 13:24:16,382 - logger.py:50 - Epoch: [38][5/6]	Total Loss: 0.65009	Main MSE (x10^-2): 65.0092	LR: 3.95e-04	EMPP_Raw: 1.27588
2025-07-18 13:24:16,427 - logger.py:50 - Epoch 38 Training Summary: Avg Total Loss: 0.65009, Avg Main MSE: 0.65009, Time: 21.31s
2025-07-18 13:24:35,604 - logger.py:50 - Epoch 38 Summary | Train MSE (x10^-2): 65.0092 | Val MSE (x10^-2): 1.2853 | Time: 40.49s
2025-07-18 13:24:39,342 - logger.py:50 - Epoch: [39][0/6]	Total Loss: 0.67924	Main MSE (x10^-2): 67.9241	LR: 3.94e-04	EMPP_Raw: 1.33344
2025-07-18 13:24:56,749 - logger.py:50 - Epoch: [39][5/6]	Total Loss: 0.64105	Main MSE (x10^-2): 64.1045	LR: 3.94e-04	EMPP_Raw: 1.25667
2025-07-18 13:24:56,820 - logger.py:50 - Epoch 39 Training Summary: Avg Total Loss: 0.64105, Avg Main MSE: 0.64105, Time: 21.21s
2025-07-18 13:25:16,031 - logger.py:50 - Epoch 39 Summary | Train MSE (x10^-2): 64.1045 | Val MSE (x10^-2): 1.3935 | Time: 40.42s
2025-07-18 13:25:19,727 - logger.py:50 - Epoch: [40][0/6]	Total Loss: 0.64674	Main MSE (x10^-2): 64.6740	LR: 3.94e-04	EMPP_Raw: 1.26511
2025-07-18 13:25:37,094 - logger.py:50 - Epoch: [40][5/6]	Total Loss: 0.63489	Main MSE (x10^-2): 63.4891	LR: 3.94e-04	EMPP_Raw: 1.24178
2025-07-18 13:25:37,138 - logger.py:50 - Epoch 40 Training Summary: Avg Total Loss: 0.63489, Avg Main MSE: 0.63489, Time: 21.10s
2025-07-18 13:25:56,369 - logger.py:50 - Epoch 40 Summary | Train MSE (x10^-2): 63.4891 | Val MSE (x10^-2): 1.2489 | Time: 40.33s
2025-07-18 13:26:00,235 - logger.py:50 - Epoch: [41][0/6]	Total Loss: 0.65008	Main MSE (x10^-2): 65.0085	LR: 3.94e-04	EMPP_Raw: 1.27349
2025-07-18 13:26:17,470 - logger.py:50 - Epoch: [41][5/6]	Total Loss: 0.64180	Main MSE (x10^-2): 64.1796	LR: 3.94e-04	EMPP_Raw: 1.25916
2025-07-18 13:26:17,512 - logger.py:50 - Epoch 41 Training Summary: Avg Total Loss: 0.64180, Avg Main MSE: 0.64180, Time: 21.13s
2025-07-18 13:26:36,767 - logger.py:50 - Epoch 41 Summary | Train MSE (x10^-2): 64.1796 | Val MSE (x10^-2): 1.2015 | Time: 40.39s
2025-07-18 13:26:40,461 - logger.py:50 - Epoch: [42][0/6]	Total Loss: 0.63884	Main MSE (x10^-2): 63.8845	LR: 3.93e-04	EMPP_Raw: 1.25215
2025-07-18 13:26:57,909 - logger.py:50 - Epoch: [42][5/6]	Total Loss: 0.63995	Main MSE (x10^-2): 63.9947	LR: 3.93e-04	EMPP_Raw: 1.25553
2025-07-18 13:26:57,954 - logger.py:50 - Epoch 42 Training Summary: Avg Total Loss: 0.63995, Avg Main MSE: 0.63995, Time: 21.18s
2025-07-18 13:27:17,122 - logger.py:50 - Epoch 42 Summary | Train MSE (x10^-2): 63.9947 | Val MSE (x10^-2): 1.1800 | Time: 40.35s
2025-07-18 13:27:20,873 - logger.py:50 - Epoch: [43][0/6]	Total Loss: 0.65666	Main MSE (x10^-2): 65.6661	LR: 3.93e-04	EMPP_Raw: 1.28963
2025-07-18 13:27:38,143 - logger.py:50 - Epoch: [43][5/6]	Total Loss: 0.64062	Main MSE (x10^-2): 64.0619	LR: 3.93e-04	EMPP_Raw: 1.25675
2025-07-18 13:27:38,190 - logger.py:50 - Epoch 43 Training Summary: Avg Total Loss: 0.64062, Avg Main MSE: 0.64062, Time: 21.06s
2025-07-18 13:27:57,481 - logger.py:50 - Epoch 43 Summary | Train MSE (x10^-2): 64.0619 | Val MSE (x10^-2): 1.2121 | Time: 40.36s
2025-07-18 13:28:01,221 - logger.py:50 - Epoch: [44][0/6]	Total Loss: 0.64843	Main MSE (x10^-2): 64.8432	LR: 3.93e-04	EMPP_Raw: 1.27354
2025-07-18 13:28:18,602 - logger.py:50 - Epoch: [44][5/6]	Total Loss: 0.62954	Main MSE (x10^-2): 62.9535	LR: 3.93e-04	EMPP_Raw: 1.23479
2025-07-18 13:28:18,648 - logger.py:50 - Epoch 44 Training Summary: Avg Total Loss: 0.62954, Avg Main MSE: 0.62954, Time: 21.16s
2025-07-18 13:28:37,835 - logger.py:50 - Epoch 44 Summary | Train MSE (x10^-2): 62.9535 | Val MSE (x10^-2): 1.2013 | Time: 40.35s
2025-07-18 13:28:41,592 - logger.py:50 - Epoch: [45][0/6]	Total Loss: 0.63304	Main MSE (x10^-2): 63.3043	LR: 3.92e-04	EMPP_Raw: 1.24049
2025-07-18 13:28:58,959 - logger.py:50 - Epoch: [45][5/6]	Total Loss: 0.64565	Main MSE (x10^-2): 64.5650	LR: 3.92e-04	EMPP_Raw: 1.26712
2025-07-18 13:28:59,003 - logger.py:50 - Epoch 45 Training Summary: Avg Total Loss: 0.64565, Avg Main MSE: 0.64565, Time: 21.16s
2025-07-18 13:29:37,467 - logger.py:50 - *** New Best Val MSE (x10^-2): 1.1704, Corresponding Test MSE (x10^-2): 1.1943 at Epoch 45 ***
2025-07-18 13:29:37,515 - logger.py:50 - Epoch 45 Summary | Train MSE (x10^-2): 64.5650 | Val MSE (x10^-2): 1.1704 | Time: 59.67s
2025-07-18 13:29:41,228 - logger.py:50 - Epoch: [46][0/6]	Total Loss: 0.63232	Main MSE (x10^-2): 63.2323	LR: 3.92e-04	EMPP_Raw: 1.24083
2025-07-18 13:29:58,482 - logger.py:50 - Epoch: [46][5/6]	Total Loss: 0.64297	Main MSE (x10^-2): 64.2967	LR: 3.92e-04	EMPP_Raw: 1.26264
2025-07-18 13:29:58,524 - logger.py:50 - Epoch 46 Training Summary: Avg Total Loss: 0.64297, Avg Main MSE: 0.64297, Time: 21.00s
2025-07-18 13:30:36,932 - logger.py:50 - *** New Best Val MSE (x10^-2): 1.1649, Corresponding Test MSE (x10^-2): 1.1897 at Epoch 46 ***
2025-07-18 13:30:36,979 - logger.py:50 - Epoch 46 Summary | Train MSE (x10^-2): 64.2967 | Val MSE (x10^-2): 1.1649 | Time: 59.46s
2025-07-18 13:30:40,667 - logger.py:50 - Epoch: [47][0/6]	Total Loss: 0.64416	Main MSE (x10^-2): 64.4163	LR: 3.92e-04	EMPP_Raw: 1.26490
2025-07-18 13:30:57,942 - logger.py:50 - Epoch: [47][5/6]	Total Loss: 0.65514	Main MSE (x10^-2): 65.5145	LR: 3.92e-04	EMPP_Raw: 1.28663
2025-07-18 13:30:57,985 - logger.py:50 - Epoch 47 Training Summary: Avg Total Loss: 0.65514, Avg Main MSE: 0.65514, Time: 21.00s
2025-07-18 13:31:16,994 - logger.py:50 - Epoch 47 Summary | Train MSE (x10^-2): 65.5145 | Val MSE (x10^-2): 1.1837 | Time: 40.01s
2025-07-18 13:31:20,866 - logger.py:50 - Epoch: [48][0/6]	Total Loss: 0.65851	Main MSE (x10^-2): 65.8511	LR: 3.91e-04	EMPP_Raw: 1.29242
2025-07-18 13:31:38,243 - logger.py:50 - Epoch: [48][5/6]	Total Loss: 0.64153	Main MSE (x10^-2): 64.1529	LR: 3.91e-04	EMPP_Raw: 1.25970
2025-07-18 13:31:38,295 - logger.py:50 - Epoch 48 Training Summary: Avg Total Loss: 0.64153, Avg Main MSE: 0.64153, Time: 21.29s
2025-07-18 13:31:57,467 - logger.py:50 - Epoch 48 Summary | Train MSE (x10^-2): 64.1529 | Val MSE (x10^-2): 1.1851 | Time: 40.47s
2025-07-18 13:32:01,338 - logger.py:50 - Epoch: [49][0/6]	Total Loss: 0.64202	Main MSE (x10^-2): 64.2018	LR: 3.91e-04	EMPP_Raw: 1.26108
2025-07-18 13:32:18,612 - logger.py:50 - Epoch: [49][5/6]	Total Loss: 0.63386	Main MSE (x10^-2): 63.3864	LR: 3.91e-04	EMPP_Raw: 1.24398
2025-07-18 13:32:18,656 - logger.py:50 - Epoch 49 Training Summary: Avg Total Loss: 0.63386, Avg Main MSE: 0.63386, Time: 21.18s
2025-07-18 13:32:57,030 - logger.py:50 - *** New Best Val MSE (x10^-2): 1.1543, Corresponding Test MSE (x10^-2): 1.1777 at Epoch 49 ***
2025-07-18 13:32:57,078 - logger.py:50 - Epoch 49 Summary | Train MSE (x10^-2): 63.3864 | Val MSE (x10^-2): 1.1543 | Time: 59.60s
2025-07-18 13:33:00,943 - logger.py:50 - Epoch: [50][0/6]	Total Loss: 0.64826	Main MSE (x10^-2): 64.8256	LR: 3.91e-04	EMPP_Raw: 1.27278
2025-07-18 13:33:18,146 - logger.py:50 - Epoch: [50][5/6]	Total Loss: 0.64713	Main MSE (x10^-2): 64.7130	LR: 3.91e-04	EMPP_Raw: 1.27105
2025-07-18 13:33:18,189 - logger.py:50 - Epoch 50 Training Summary: Avg Total Loss: 0.64713, Avg Main MSE: 0.64713, Time: 21.11s
2025-07-18 13:33:56,488 - logger.py:50 - *** New Best Val MSE (x10^-2): 1.1437, Corresponding Test MSE (x10^-2): 1.1674 at Epoch 50 ***
2025-07-18 13:33:56,535 - logger.py:50 - Epoch 50 Summary | Train MSE (x10^-2): 64.7130 | Val MSE (x10^-2): 1.1437 | Time: 59.46s
2025-07-18 13:34:00,418 - logger.py:50 - Epoch: [51][0/6]	Total Loss: 0.61672	Main MSE (x10^-2): 61.6717	LR: 3.90e-04	EMPP_Raw: 1.20973
2025-07-18 13:34:17,616 - logger.py:50 - Epoch: [51][5/6]	Total Loss: 0.62870	Main MSE (x10^-2): 62.8697	LR: 3.90e-04	EMPP_Raw: 1.23433
2025-07-18 13:34:17,659 - logger.py:50 - Epoch 51 Training Summary: Avg Total Loss: 0.62870, Avg Main MSE: 0.62870, Time: 21.12s
2025-07-18 13:34:55,990 - logger.py:50 - *** New Best Val MSE (x10^-2): 1.1413, Corresponding Test MSE (x10^-2): 1.1663 at Epoch 51 ***
2025-07-18 13:34:56,041 - logger.py:50 - Epoch 51 Summary | Train MSE (x10^-2): 62.8697 | Val MSE (x10^-2): 1.1413 | Time: 59.51s
2025-07-18 13:34:59,898 - logger.py:50 - Epoch: [52][0/6]	Total Loss: 0.65447	Main MSE (x10^-2): 65.4466	LR: 3.90e-04	EMPP_Raw: 1.28583
2025-07-18 13:35:17,182 - logger.py:50 - Epoch: [52][5/6]	Total Loss: 0.63943	Main MSE (x10^-2): 63.9427	LR: 3.90e-04	EMPP_Raw: 1.25592
2025-07-18 13:35:17,229 - logger.py:50 - Epoch 52 Training Summary: Avg Total Loss: 0.63943, Avg Main MSE: 0.63943, Time: 21.18s
2025-07-18 13:35:36,400 - logger.py:50 - Epoch 52 Summary | Train MSE (x10^-2): 63.9427 | Val MSE (x10^-2): 1.1456 | Time: 40.36s
2025-07-18 13:35:40,102 - logger.py:50 - Epoch: [53][0/6]	Total Loss: 0.64226	Main MSE (x10^-2): 64.2264	LR: 3.89e-04	EMPP_Raw: 1.26285
2025-07-18 13:35:57,488 - logger.py:50 - Epoch: [53][5/6]	Total Loss: 0.63281	Main MSE (x10^-2): 63.2810	LR: 3.89e-04	EMPP_Raw: 1.24275
2025-07-18 13:35:57,540 - logger.py:50 - Epoch 53 Training Summary: Avg Total Loss: 0.63281, Avg Main MSE: 0.63281, Time: 21.13s
2025-07-18 13:36:16,706 - logger.py:50 - Epoch 53 Summary | Train MSE (x10^-2): 63.2810 | Val MSE (x10^-2): 1.1518 | Time: 40.30s
2025-07-18 13:36:20,436 - logger.py:50 - Epoch: [54][0/6]	Total Loss: 0.64712	Main MSE (x10^-2): 64.7118	LR: 3.89e-04	EMPP_Raw: 1.26876
2025-07-18 13:36:37,742 - logger.py:50 - Epoch: [54][5/6]	Total Loss: 0.64292	Main MSE (x10^-2): 64.2917	LR: 3.89e-04	EMPP_Raw: 1.26261
2025-07-18 13:36:37,789 - logger.py:50 - Epoch 54 Training Summary: Avg Total Loss: 0.64292, Avg Main MSE: 0.64292, Time: 21.07s
2025-07-18 13:36:56,941 - logger.py:50 - Epoch 54 Summary | Train MSE (x10^-2): 64.2917 | Val MSE (x10^-2): 1.1467 | Time: 40.23s
2025-07-18 13:37:00,650 - logger.py:50 - Epoch: [55][0/6]	Total Loss: 0.63960	Main MSE (x10^-2): 63.9605	LR: 3.89e-04	EMPP_Raw: 1.25699
2025-07-18 13:37:17,943 - logger.py:50 - Epoch: [55][5/6]	Total Loss: 0.63821	Main MSE (x10^-2): 63.8215	LR: 3.89e-04	EMPP_Raw: 1.25329
2025-07-18 13:37:17,987 - logger.py:50 - Epoch 55 Training Summary: Avg Total Loss: 0.63821, Avg Main MSE: 0.63821, Time: 21.04s
2025-07-18 13:37:37,320 - logger.py:50 - Epoch 55 Summary | Train MSE (x10^-2): 63.8215 | Val MSE (x10^-2): 1.1452 | Time: 40.37s
2025-07-18 13:37:41,050 - logger.py:50 - Epoch: [56][0/6]	Total Loss: 0.67962	Main MSE (x10^-2): 67.9622	LR: 3.88e-04	EMPP_Raw: 1.33697
2025-07-18 13:37:58,302 - logger.py:50 - Epoch: [56][5/6]	Total Loss: 0.63906	Main MSE (x10^-2): 63.9060	LR: 3.88e-04	EMPP_Raw: 1.25511
2025-07-18 13:37:58,347 - logger.py:50 - Epoch 56 Training Summary: Avg Total Loss: 0.63906, Avg Main MSE: 0.63906, Time: 21.02s
2025-07-18 13:38:17,397 - logger.py:50 - Epoch 56 Summary | Train MSE (x10^-2): 63.9060 | Val MSE (x10^-2): 1.1445 | Time: 40.07s
2025-07-18 13:38:21,281 - logger.py:50 - Epoch: [57][0/6]	Total Loss: 0.62409	Main MSE (x10^-2): 62.4095	LR: 3.88e-04	EMPP_Raw: 1.22665
2025-07-18 13:38:38,563 - logger.py:50 - Epoch: [57][5/6]	Total Loss: 0.64079	Main MSE (x10^-2): 64.0791	LR: 3.88e-04	EMPP_Raw: 1.25863
2025-07-18 13:38:38,604 - logger.py:50 - Epoch 57 Training Summary: Avg Total Loss: 0.64079, Avg Main MSE: 0.64079, Time: 21.20s
2025-07-18 13:39:16,741 - logger.py:50 - *** New Best Val MSE (x10^-2): 1.1389, Corresponding Test MSE (x10^-2): 1.1613 at Epoch 57 ***
2025-07-18 13:39:16,789 - logger.py:50 - Epoch 57 Summary | Train MSE (x10^-2): 64.0791 | Val MSE (x10^-2): 1.1389 | Time: 59.39s
2025-07-18 13:39:20,672 - logger.py:50 - Epoch: [58][0/6]	Total Loss: 0.64768	Main MSE (x10^-2): 64.7683	LR: 3.87e-04	EMPP_Raw: 1.27353
2025-07-18 13:39:37,875 - logger.py:50 - Epoch: [58][5/6]	Total Loss: 0.63145	Main MSE (x10^-2): 63.1454	LR: 3.87e-04	EMPP_Raw: 1.24018
2025-07-18 13:39:37,925 - logger.py:50 - Epoch 58 Training Summary: Avg Total Loss: 0.63145, Avg Main MSE: 0.63145, Time: 21.13s
2025-07-18 13:39:57,020 - logger.py:50 - Epoch 58 Summary | Train MSE (x10^-2): 63.1454 | Val MSE (x10^-2): 1.1415 | Time: 40.23s
2025-07-18 13:40:00,722 - logger.py:50 - Epoch: [59][0/6]	Total Loss: 0.62019	Main MSE (x10^-2): 62.0186	LR: 3.87e-04	EMPP_Raw: 1.21853
2025-07-18 13:40:18,228 - logger.py:50 - Epoch: [59][5/6]	Total Loss: 0.63475	Main MSE (x10^-2): 63.4754	LR: 3.87e-04	EMPP_Raw: 1.24660
2025-07-18 13:40:18,272 - logger.py:50 - Epoch 59 Training Summary: Avg Total Loss: 0.63475, Avg Main MSE: 0.63475, Time: 21.24s
2025-07-18 13:40:37,404 - logger.py:50 - Epoch 59 Summary | Train MSE (x10^-2): 63.4754 | Val MSE (x10^-2): 1.1420 | Time: 40.38s
2025-07-18 13:40:41,138 - logger.py:50 - Epoch: [60][0/6]	Total Loss: 0.65560	Main MSE (x10^-2): 65.5596	LR: 3.86e-04	EMPP_Raw: 1.28899
2025-07-18 13:40:58,370 - logger.py:50 - Epoch: [60][5/6]	Total Loss: 0.63437	Main MSE (x10^-2): 63.4375	LR: 3.86e-04	EMPP_Raw: 1.24580
2025-07-18 13:40:58,411 - logger.py:50 - Epoch 60 Training Summary: Avg Total Loss: 0.63437, Avg Main MSE: 0.63437, Time: 21.00s
2025-07-18 13:41:36,934 - logger.py:50 - *** New Best Val MSE (x10^-2): 1.1346, Corresponding Test MSE (x10^-2): 1.1581 at Epoch 60 ***
2025-07-18 13:41:36,982 - logger.py:50 - Epoch 60 Summary | Train MSE (x10^-2): 63.4375 | Val MSE (x10^-2): 1.1346 | Time: 59.57s
2025-07-18 13:41:40,698 - logger.py:50 - Epoch: [61][0/6]	Total Loss: 0.61456	Main MSE (x10^-2): 61.4556	LR: 3.86e-04	EMPP_Raw: 1.20498
2025-07-18 13:41:58,006 - logger.py:50 - Epoch: [61][5/6]	Total Loss: 0.62468	Main MSE (x10^-2): 62.4684	LR: 3.86e-04	EMPP_Raw: 1.22652
2025-07-18 13:41:58,052 - logger.py:50 - Epoch 61 Training Summary: Avg Total Loss: 0.62468, Avg Main MSE: 0.62468, Time: 21.07s
2025-07-18 13:42:36,297 - logger.py:50 - *** New Best Val MSE (x10^-2): 1.1303, Corresponding Test MSE (x10^-2): 1.1542 at Epoch 61 ***
2025-07-18 13:42:36,345 - logger.py:50 - Epoch 61 Summary | Train MSE (x10^-2): 62.4684 | Val MSE (x10^-2): 1.1303 | Time: 59.36s
2025-07-18 13:42:40,033 - logger.py:50 - Epoch: [62][0/6]	Total Loss: 0.65926	Main MSE (x10^-2): 65.9265	LR: 3.86e-04	EMPP_Raw: 1.29735
2025-07-18 13:42:57,308 - logger.py:50 - Epoch: [62][5/6]	Total Loss: 0.63121	Main MSE (x10^-2): 63.1208	LR: 3.86e-04	EMPP_Raw: 1.23988
2025-07-18 13:42:57,352 - logger.py:50 - Epoch 62 Training Summary: Avg Total Loss: 0.63121, Avg Main MSE: 0.63121, Time: 21.00s
2025-07-18 13:43:16,606 - logger.py:50 - Epoch 62 Summary | Train MSE (x10^-2): 63.1208 | Val MSE (x10^-2): 1.1308 | Time: 40.26s
2025-07-18 13:43:20,340 - logger.py:50 - Epoch: [63][0/6]	Total Loss: 0.61363	Main MSE (x10^-2): 61.3633	LR: 3.85e-04	EMPP_Raw: 1.20332
2025-07-18 13:43:37,615 - logger.py:50 - Epoch: [63][5/6]	Total Loss: 0.63212	Main MSE (x10^-2): 63.2116	LR: 3.85e-04	EMPP_Raw: 1.24155
2025-07-18 13:43:37,657 - logger.py:50 - Epoch 63 Training Summary: Avg Total Loss: 0.63212, Avg Main MSE: 0.63212, Time: 21.04s
2025-07-18 13:43:56,835 - logger.py:50 - Epoch 63 Summary | Train MSE (x10^-2): 63.2116 | Val MSE (x10^-2): 1.1310 | Time: 40.22s
2025-07-18 13:44:00,709 - logger.py:50 - Epoch: [64][0/6]	Total Loss: 0.65281	Main MSE (x10^-2): 65.2810	LR: 3.85e-04	EMPP_Raw: 1.28276
2025-07-18 13:44:18,045 - logger.py:50 - Epoch: [64][5/6]	Total Loss: 0.63152	Main MSE (x10^-2): 63.1520	LR: 3.85e-04	EMPP_Raw: 1.24026
2025-07-18 13:44:18,088 - logger.py:50 - Epoch 64 Training Summary: Avg Total Loss: 0.63152, Avg Main MSE: 0.63152, Time: 21.24s
2025-07-18 13:44:37,232 - logger.py:50 - Epoch 64 Summary | Train MSE (x10^-2): 63.1520 | Val MSE (x10^-2): 1.1375 | Time: 40.39s
2025-07-18 13:44:40,952 - logger.py:50 - Epoch: [65][0/6]	Total Loss: 0.62105	Main MSE (x10^-2): 62.1050	LR: 3.84e-04	EMPP_Raw: 1.21981
2025-07-18 13:44:58,446 - logger.py:50 - Epoch: [65][5/6]	Total Loss: 0.63463	Main MSE (x10^-2): 63.4626	LR: 3.84e-04	EMPP_Raw: 1.24668
2025-07-18 13:44:58,492 - logger.py:50 - Epoch 65 Training Summary: Avg Total Loss: 0.63463, Avg Main MSE: 0.63463, Time: 21.25s
2025-07-18 13:45:36,788 - logger.py:50 - *** New Best Val MSE (x10^-2): 1.1295, Corresponding Test MSE (x10^-2): 1.1508 at Epoch 65 ***
2025-07-18 13:45:36,835 - logger.py:50 - Epoch 65 Summary | Train MSE (x10^-2): 63.4626 | Val MSE (x10^-2): 1.1295 | Time: 59.60s
2025-07-18 13:45:40,556 - logger.py:50 - Epoch: [66][0/6]	Total Loss: 0.62052	Main MSE (x10^-2): 62.0520	LR: 3.84e-04	EMPP_Raw: 1.21890
2025-07-18 13:45:57,980 - logger.py:50 - Epoch: [66][5/6]	Total Loss: 0.62229	Main MSE (x10^-2): 62.2291	LR: 3.84e-04	EMPP_Raw: 1.22203
2025-07-18 13:45:58,021 - logger.py:50 - Epoch 66 Training Summary: Avg Total Loss: 0.62229, Avg Main MSE: 0.62229, Time: 21.18s
2025-07-18 13:46:17,238 - logger.py:50 - Epoch 66 Summary | Train MSE (x10^-2): 62.2291 | Val MSE (x10^-2): 1.1306 | Time: 40.40s
2025-07-18 13:46:20,958 - logger.py:50 - Epoch: [67][0/6]	Total Loss: 0.64560	Main MSE (x10^-2): 64.5595	LR: 3.83e-04	EMPP_Raw: 1.26735
2025-07-18 13:46:38,257 - logger.py:50 - Epoch: [67][5/6]	Total Loss: 0.62918	Main MSE (x10^-2): 62.9183	LR: 3.83e-04	EMPP_Raw: 1.23558
2025-07-18 13:46:38,302 - logger.py:50 - Epoch 67 Training Summary: Avg Total Loss: 0.62918, Avg Main MSE: 0.62918, Time: 21.05s
2025-07-18 13:46:57,622 - logger.py:50 - Epoch 67 Summary | Train MSE (x10^-2): 62.9183 | Val MSE (x10^-2): 1.1367 | Time: 40.38s
2025-07-18 13:47:01,373 - logger.py:50 - Epoch: [68][0/6]	Total Loss: 0.61176	Main MSE (x10^-2): 61.1761	LR: 3.83e-04	EMPP_Raw: 1.20055
2025-07-18 13:47:18,691 - logger.py:50 - Epoch: [68][5/6]	Total Loss: 0.62822	Main MSE (x10^-2): 62.8219	LR: 3.83e-04	EMPP_Raw: 1.23368
2025-07-18 13:47:18,738 - logger.py:50 - Epoch 68 Training Summary: Avg Total Loss: 0.62822, Avg Main MSE: 0.62822, Time: 21.11s
