2025-07-19 13:36:36,541 - logger.py:50 - --- Starting training for aspirin ---
2025-07-19 13:36:36,541 - logger.py:50 - Namespace(amp=True, batch_size=80, clip_grad=1.0, contrastive_aug_mask_ratio=0.15, contrastive_loss_weight=0.1, contrastive_mask_token_idx=0, contrastive_prioritize_heteroatoms=False, contrastive_projection_dim=128, contrastive_temp=0.1, cooldown_epochs=10, data_path='data/md17', decay_rate=0.1, delta_frame=3000, device='cuda:0', drop_path=0.0, empp_atom_type_embed_irreps='16x0e', empp_loss_weight=0.1, empp_num_mask=1, empp_pos_pred_num_s2_channels=32, empp_pos_pred_res_s2grid=100, empp_pos_pred_temp_label=0.1, empp_pos_pred_temp_softmax=0.1, empp_prioritize_heteroatoms=True, empp_ssp_feature_dim='16x0e', enable_contrastive=False, epochs=500, exp_name='md17_final_run_20250719_133633', logger=<logger.FileLogger object at 0x7fa62304cbb0>, loss='l2', lr=0.0004, max_test_samples=50000, max_train_samples=10000, max_val_samples=2000, min_lr=1e-06, model_name='graph_attention_transformer_nonlinear_l2', molecule_type='aspirin', momentum=0.9, num_basis=128, opt='adamw', opt_betas=None, opt_eps=1e-08, output_dir='outputs/md17_final_run_20250719_133633', patience_epochs=10, pin_mem=True, print_freq=50, radius=5.0, sched='cosine', seed=42, ssp=False, warmup_epochs=10, warmup_lr=1e-06, weight_decay=0.0001, workers=8)
2025-07-19 13:36:36,542 - logger.py:50 - Loading datasets...
2025-07-19 13:36:39,554 - logger.py:50 - Creating model...
2025-07-19 13:36:47,538 - logger.py:50 - Number of params: 3,136,834
2025-07-19 13:36:50,367 - logger.py:50 - Epoch: [0][0/123]	Total Loss: 0.22392	Main MSE (x10^-2): 22.3919	LR: 1.00e-06
2025-07-19 13:38:31,588 - logger.py:50 - Epoch: [0][50/123]	Total Loss: 0.24637	Main MSE (x10^-2): 24.6369	LR: 1.00e-06
2025-07-19 13:41:14,957 - logger.py:50 - Epoch: [0][100/123]	Total Loss: 0.24331	Main MSE (x10^-2): 24.3312	LR: 1.00e-06
2025-07-19 13:42:03,910 - logger.py:50 - Epoch: [0][122/123]	Total Loss: 0.24213	Main MSE (x10^-2): 24.2132	LR: 1.00e-06
2025-07-19 13:42:03,935 - logger.py:50 - Epoch 0 Training Summary: Avg Total Loss: 0.24213, Avg Main MSE: 0.24213, Time: 316.39s
2025-07-19 13:50:23,541 - logger.py:50 - *** New Best Val MSE (x10^-2): 23.9571, Corresponding Test MSE (x10^-2): 23.9026 at Epoch 0 ***
2025-07-19 13:50:23,583 - logger.py:50 - Epoch 0 Summary | Train MSE (x10^-2): 24.2132 | Val MSE (x10^-2): 23.9571 | Time: 816.04s
2025-07-19 13:50:25,365 - logger.py:50 - Epoch: [1][0/123]	Total Loss: 0.22221	Main MSE (x10^-2): 22.2210	LR: 1.00e-06
2025-07-19 13:51:41,500 - logger.py:50 - Epoch: [1][50/123]	Total Loss: 0.23702	Main MSE (x10^-2): 23.7023	LR: 1.00e-06
2025-07-19 13:52:58,263 - logger.py:50 - Epoch: [1][100/123]	Total Loss: 0.23824	Main MSE (x10^-2): 23.8236	LR: 1.00e-06
2025-07-19 13:53:31,977 - logger.py:50 - Epoch: [1][122/123]	Total Loss: 0.23765	Main MSE (x10^-2): 23.7651	LR: 1.00e-06
2025-07-19 13:53:32,042 - logger.py:50 - Epoch 1 Training Summary: Avg Total Loss: 0.23765, Avg Main MSE: 0.23765, Time: 188.46s
2025-07-19 14:01:49,655 - logger.py:50 - *** New Best Val MSE (x10^-2): 23.3429, Corresponding Test MSE (x10^-2): 23.2889 at Epoch 1 ***
2025-07-19 14:01:49,698 - logger.py:50 - Epoch 1 Summary | Train MSE (x10^-2): 23.7651 | Val MSE (x10^-2): 23.3429 | Time: 686.11s
2025-07-19 14:01:51,503 - logger.py:50 - Epoch: [2][0/123]	Total Loss: 0.21489	Main MSE (x10^-2): 21.4886	LR: 4.09e-05
2025-07-19 14:03:07,692 - logger.py:50 - Epoch: [2][50/123]	Total Loss: 0.19249	Main MSE (x10^-2): 19.2492	LR: 4.09e-05
