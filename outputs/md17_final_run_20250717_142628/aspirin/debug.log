2025-07-17 14:26:31,052 - logger.py:50 - --- Starting training for aspirin ---
2025-07-17 14:26:31,052 - logger.py:50 - Namespace(amp=False, batch_size=64, clip_grad=1.0, contrastive_aug_mask_ratio=0.15, contrastive_loss_weight=0.1, contrastive_mask_token_idx=0, contrastive_prioritize_heteroatoms=False, contrastive_projection_dim=128, contrastive_temp=0.1, cooldown_epochs=10, data_path='data/md17', decay_rate=0.1, delta_frame=3000, device='cuda:0', drop_path=0.0, empp_atom_type_embed_irreps='16x0e', empp_loss_weight=0.5, empp_num_mask=1, empp_pos_pred_num_s2_channels=32, empp_pos_pred_res_s2grid=100, empp_pos_pred_temp_label=0.1, empp_pos_pred_temp_softmax=0.1, empp_prioritize_heteroatoms=True, empp_ssp_feature_dim='16x0e', enable_contrastive=False, epochs=500, exp_name='md17_final_run_20250717_142628', logger=<logger.FileLogger object at 0x7fc7758b8b20>, loss='l2', lr=0.0004, max_test_samples=2000, max_train_samples=500, max_val_samples=2000, min_lr=1e-06, model_name='graph_attention_transformer_nonlinear_l2', molecule_type='aspirin', momentum=0.9, num_basis=128, opt='adamw', opt_betas=None, opt_eps=1e-08, output_dir='outputs/md17_final_run_20250717_142628', patience_epochs=10, pin_mem=True, print_freq=50, radius=5.0, sched='cosine', seed=42, ssp=True, warmup_epochs=10, warmup_lr=1e-06, weight_decay=1e-06, workers=8)
2025-07-17 14:26:31,053 - logger.py:50 - Loading datasets...
2025-07-17 14:26:31,060 - logger.py:50 - Creating model...
2025-07-17 14:26:39,695 - logger.py:50 - Number of params: 3,205,881
2025-07-17 14:26:45,100 - logger.py:50 - Epoch: [0][0/7]	Total Loss: 1.64429	Main MSE (x10^-2): 164.4285	LR: 1.00e-06	EMPP_Raw: 2.78607
2025-07-17 14:27:09,518 - logger.py:50 - Epoch: [0][6/7]	Total Loss: 1.55424	Main MSE (x10^-2): 155.4239	LR: 1.00e-06	EMPP_Raw: 2.61332
2025-07-17 14:27:09,546 - logger.py:50 - Epoch 0 Training Summary: Avg Total Loss: 1.55424, Avg Main MSE: 1.55424, Time: 29.85s
2025-07-17 14:27:57,104 - logger.py:50 - *** New Best Val MSE (x10^-2): 24.3084, Corresponding Test MSE (x10^-2): 24.4797 at Epoch 0 ***
2025-07-17 14:27:57,150 - logger.py:50 - Epoch 0 Summary | Train MSE (x10^-2): 155.4239 | Val MSE (x10^-2): 24.3084 | Time: 77.45s
2025-07-17 14:28:00,772 - logger.py:50 - Epoch: [1][0/7]	Total Loss: 1.65436	Main MSE (x10^-2): 165.4362	LR: 1.00e-06	EMPP_Raw: 2.82134
2025-07-17 14:28:21,345 - logger.py:50 - Epoch: [1][6/7]	Total Loss: 1.51466	Main MSE (x10^-2): 151.4664	LR: 1.00e-06	EMPP_Raw: 2.54281
2025-07-17 14:28:21,383 - logger.py:50 - Epoch 1 Training Summary: Avg Total Loss: 1.51466, Avg Main MSE: 1.51466, Time: 24.23s
2025-07-17 14:29:08,876 - logger.py:50 - *** New Best Val MSE (x10^-2): 24.2944, Corresponding Test MSE (x10^-2): 24.4657 at Epoch 1 ***
2025-07-17 14:29:08,947 - logger.py:50 - Epoch 1 Summary | Train MSE (x10^-2): 151.4664 | Val MSE (x10^-2): 24.2944 | Time: 71.80s
2025-07-17 14:29:12,565 - logger.py:50 - Epoch: [2][0/7]	Total Loss: 1.67922	Main MSE (x10^-2): 167.9219	LR: 4.09e-05	EMPP_Raw: 2.84962
2025-07-17 14:29:33,179 - logger.py:50 - Epoch: [2][6/7]	Total Loss: 1.35855	Main MSE (x10^-2): 135.8546	LR: 4.09e-05	EMPP_Raw: 2.23165
2025-07-17 14:29:33,218 - logger.py:50 - Epoch 2 Training Summary: Avg Total Loss: 1.35855, Avg Main MSE: 1.35855, Time: 24.27s
2025-07-17 14:30:20,813 - logger.py:50 - *** New Best Val MSE (x10^-2): 23.7451, Corresponding Test MSE (x10^-2): 23.9147 at Epoch 2 ***
2025-07-17 14:30:20,863 - logger.py:50 - Epoch 2 Summary | Train MSE (x10^-2): 135.8546 | Val MSE (x10^-2): 23.7451 | Time: 71.92s
2025-07-17 14:30:24,485 - logger.py:50 - Epoch: [3][0/7]	Total Loss: 1.23514	Main MSE (x10^-2): 123.5135	LR: 8.08e-05	EMPP_Raw: 2.04948
2025-07-17 14:30:45,125 - logger.py:50 - Epoch: [3][6/7]	Total Loss: 1.18478	Main MSE (x10^-2): 118.4777	LR: 8.08e-05	EMPP_Raw: 1.90618
2025-07-17 14:30:45,163 - logger.py:50 - Epoch 3 Training Summary: Avg Total Loss: 1.18478, Avg Main MSE: 1.18478, Time: 24.30s
