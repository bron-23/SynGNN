2025-07-26 21:14:23,983 - logger.py:50 - --- Starting training for ethanol ---
2025-07-26 21:14:23,983 - logger.py:50 - Namespace(amp=True, batch_size=100, clip_grad=1.0, contrastive_aug_mask_ratio=0.15, contrastive_loss_weight=0.1, contrastive_mask_token_idx=0, contrastive_prioritize_heteroatoms=False, contrastive_projection_dim=128, contrastive_temp=0.1, cooldown_epochs=10, data_path='data/md17', decay_rate=0.1, delta_frame=3000, device='cuda:0', drop_path=0.0, empp_atom_type_embed_irreps='16x0e', empp_loss_weight=1.0, empp_num_mask=1, empp_pos_pred_num_s2_channels=32, empp_pos_pred_res_s2grid=100, empp_pos_pred_temp_label=0.1, empp_pos_pred_temp_softmax=0.1, empp_prioritize_heteroatoms=True, empp_ssp_feature_dim='16x0e', enable_contrastive=False, epochs=500, exp_name='md17_final_run_20250726_211421', logger=<logger.FileLogger object at 0x7f5881591b50>, loss='l2', lr=0.0005, max_test_samples=2000, max_train_samples=100000, max_val_samples=2000, min_lr=1e-06, model_name='graph_attention_transformer_nonlinear_l2', molecule_type='ethanol', momentum=0.9, num_basis=128, opt='adamw', opt_betas=None, opt_eps=1e-08, output_dir='outputs/md17_final_run_20250726_211421', patience_epochs=10, pin_mem=True, print_freq=50, radius=7.0, sched='cosine', seed=42, ssp=False, warmup_epochs=10, warmup_lr=1e-06, weight_decay=0.0001, workers=8)
2025-07-26 21:14:23,983 - logger.py:50 - Loading datasets...
2025-07-26 21:14:27,868 - logger.py:50 - Creating model...
2025-07-26 21:14:35,985 - logger.py:50 - Number of params: 3,136,066
2025-07-26 21:14:38,765 - logger.py:50 - Epoch: [0][0/994]	Total Loss: 0.37706	Main MSE (x10^-2): 37.7056	LR: 1.00e-06
2025-07-26 21:16:07,234 - logger.py:50 - Epoch: [0][50/994]	Total Loss: 0.37150	Main MSE (x10^-2): 37.1499	LR: 1.00e-06
2025-07-26 21:17:19,578 - logger.py:50 - Epoch: [0][100/994]	Total Loss: 0.37005	Main MSE (x10^-2): 37.0047	LR: 1.00e-06
2025-07-26 21:18:31,781 - logger.py:50 - Epoch: [0][150/994]	Total Loss: 0.36664	Main MSE (x10^-2): 36.6641	LR: 1.00e-06
